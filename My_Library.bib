
@misc{26AlignedTextGrids,
  title = {(26) {{Aligned}}\_{{TextGrids}} | {{Powered}} by {{Box}}},
  file = {/Users/megcychosz/Zotero/storage/6RY48U7M/login.html},
  howpublished = {https://umd.app.box.com/folder/123367081032?sortColumn=date\&sortDirection=ASC}
}

@misc{26AlignedTextGridsa,
  title = {(26) {{Aligned}}\_{{TextGrids}} | {{Powered}} by {{Box}}},
  file = {/Users/megcychosz/Zotero/storage/3IAD9QV8/login.html},
  howpublished = {https://umd.app.box.com/folder/123367081032?sortColumn=date\&sortDirection=ASC}
}

@book{acevedo-valleProprioceptiveFeedbackIntrinsic2015,
  title = {Proprioceptive {{Feedback}} and {{Intrinsic Motivations}} in {{Early}}-{{Vocal Development}}},
  author = {{Acevedo-Valle}, Juan and Angulo, Cecilio and {Moulin-Frier}, Cl{\'e}ment and Agell, Nuria},
  year = {2015},
  month = oct,
  doi = {10.13140/RG.2.1.1981.9603},
  abstract = {This work introduces new results on early-vocal development in infants and machines using artificial intelligent agents. It is addressed using the perspective of intrinsically-motivated learning algorithms for autonomous exploration. The agent autonomously selects goals to explore its own sensorimotor system in regions where a certain competence measure is maximized. Unlike previous experiments, we propose to include a somatosensory model to provide a proprioceptive feedback to reinforce learning. We argue that proprioceptive feedback will drive the learning process more efficiently than algorithms taking into account only auditory feedback. Considering the proprioceptive feedback to generate a constraint model, which is unknown beforehand to the learner, guarantees that the agent is less prone to selecting goals that violated the system constraints in previous experiments.}
}

@article{adamsPhonologicalWorkingMemory1995,
  title = {Phonological {{Working Memory}} and {{Speech Production}} in {{Preschool Children}}},
  author = {Adams, Anne-Marie and Gathercole, Susan E.},
  year = {1995},
  month = apr,
  volume = {38},
  pages = {403--414},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/jshr.3802.403},
  abstract = {This study investigates whether phonological working memory is associated with spoken language development in preschool children. Assessments were made of speech corpora taken from 3-year old children grouped in terms of their phonological memory abilities. Both quantitative and qualitative indices of the children's spontaneous speech output were taken in a structured play session. Significant differences were found, with children of good phonological memory abilities producing language that was more grammatically complex, contained a richer array of words, and included longer utterances than children of poor phonological memory abilities. The possible mechanisms by which phonological working memory skills are linked to the production of speech are considered.},
  file = {/Users/megcychosz/Zotero/storage/PRJ9HTWV/Adams and Gathercole - 1995 - Phonological Working Memory and Speech Production .pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {2}
}

@article{adamsPhonologicalWorkingMemory1996a,
  title = {Phonological {{Working Memory}} and {{Spoken Language Development}} in {{Young Children}}},
  author = {Adams, Anne-Marie and Gathercole, Susan E.},
  year = {1996},
  month = feb,
  volume = {49},
  pages = {216--233},
  publisher = {{Taylor \& Francis Ltd}},
  issn = {02724987},
  doi = {10.1080/027249896392874},
  abstract = {This study investigated the relationship between phonological working memory and spoken language development in a large unselected sample of 4- and 5-year old children. Assessments were made of the language produced by the children on the Bus Story (Renfrew, 1969), a standard test of continuous speech. In this test, children listen to a story, which they then recount with the aid of visual clues. The amount of information recalled and the average length of the five longest utterances are taken as indices of children's expressive language abilities. Phonological working memory skills were indexed by memory span and the ability to repeat non-words. The ability to repeat non-words made a significant contribution to the variance in the children's speech independently of age, vocabulary knowledge, and nonverbal cognitive skills. The possible mechanisms by which skills assessed by phonological memory tasks may be linked to the development of speech production abilities are considered.},
  file = {/Users/megcychosz/Zotero/storage/5NS87CCN/Adams and Gathercole - 1996 - Phonological Working Memory and Spoken Language De.pdf},
  journal = {Quarterly Journal of Experimental Psychology: Section A},
  keywords = {Children's language,Memory in children,Short-term memory},
  number = {1}
}

@article{adankComparisonVowelNormalization2004,
  title = {A Comparison of Vowel Normalization Procedures for Language Variation Research},
  author = {Adank, Patti and Smits, Roel and {van Hout}, Roeland},
  year = {2004},
  month = nov,
  volume = {116},
  pages = {3099--3107},
  issn = {0001-4966},
  doi = {10.1121/1.1795335},
  file = {/Users/megcychosz/Zotero/storage/4K4P2XE3/Adank et al. - 2004 - A comparison of vowel normalization procedures for.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@incollection{adolphMotorSkills2009,
  title = {Motor Skills},
  booktitle = {Handbook of Cultural Developmental Science},
  author = {Adolph, K. E. and Karasik, L. B. and {Tamis-LeMonda}, C. S.},
  editor = {Bornstein, M.H.},
  year = {2009},
  pages = {61--88},
  publisher = {{Taylor \& Francis}},
  address = {{New York, NY}}
}

@inproceedings{adriaansDistributionalLearningVowel2012,
  title = {Distributional {{Learning}} of {{Vowel Categories}} Is {{Supported}} by {{Prosody}} in {{Infant}}-{{Directed Speech}}},
  booktitle = {Proceedings of the {{Annual Meeting}} of the {{Cognitive Science Society}}},
  author = {Adriaans, Frans and Swingley, D.},
  year = {2012},
  abstract = {Infants' acquisition of phonetic categories involves a distributional learning mechanism that operates on acoustic dimensions of the input. However, natural infant-directed speech shows large degrees of phonetic variability, and the resulting overlap between categories suggests that category learning based on distributional clustering may not be feasible without constraints on the learning process, or exploitation of other sources of information. The present study examines whether mothers' prosodic modifications within infantdirected speech help the distributional learning of vowel categories. Specifically, we hypothesize that `motherese' provides the infant with a subset of high-quality learning tokens that improve category learning. In an analysis of vowel tokens taken from natural mother-infant interactions, we found that prosody can be used to distinguish high-quality tokens (with expanded formant frequencies) from low-quality tokens in the input. Moreover, in simulations of distributional learning we found that models trained on this small set of high-quality tokens provide better classification than models trained on the complete set of tokens. Taken together, these findings show that distributional learning of vowel categories can be improved by attributing importance to tokens that are prosodically prominent in the input. The prosodic properties of motherese might thus be a helpful cue for infants in supporting phonetic category learning.},
  file = {/Users/megcychosz/Zotero/storage/5W7MENN5/Adriaans - Distributional Learning of Vowel Categories is Sup.pdf},
  language = {en}
}

@article{adriaansProsodicExaggerationInfantdirected2017,
  title = {Prosodic Exaggeration within Infant-Directed Speech: {{Consequences}} for Vowel Learnability},
  shorttitle = {Prosodic Exaggeration within Infant-Directed Speech},
  author = {Adriaans, Frans and Swingley, Daniel},
  year = {2017},
  month = may,
  volume = {141},
  pages = {3070--3078},
  issn = {0001-4966},
  doi = {10.1121/1.4982246},
  file = {/Users/megcychosz/Zotero/storage/LSN87I3Y/Adriaans and Swingley - 2017 - Prosodic exaggeration within infant-directed speec.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{agwueleEffectSpeakingRate2008,
  title = {The {{Effect}} of {{Speaking Rate onConsonant Vowel Coarticulation}}},
  author = {Agwuele, Augustine and Sussman, Harvey M. and Lindblom, Bj{\"o}rn},
  year = {2008},
  volume = {65},
  pages = {194--209},
  issn = {0031-8388, 1423-0321},
  doi = {10.1159/000192792},
  abstract = {In 2007 Lindblom et al. introduced a methodological tool to disentangle consonant-vowel (CV) coarticulation attributable to emphatic stress apart from the vowel expansion effects known to accompany the prosodic overlay. After empirically accounting for the altered vowel positions, they reported small but consistent increases in F2 transition onsets in emphatically produced CVs that could not be attributed to vowel context influences, and that differed across stop place. At issue is whether the findings of these authors can be replicated, but in the opposite direction, for CVs produced at fast speaking rates. A modified locus equation regression metric was similarly used to account for rate-induced vowel reduction effects in predicting frequencies of F2 transition onsets in rapid speech. Six American-English speakers produced [V1.CV2] sequences embedded in a carrier sentence, at three speaking tempos: normal, fast, and fastest. Significant differences were found between `predicted' and `observed' F2 onsets across stops, with alveolars and velars showing greater decreases in F2 onsets during more rapid speech than labials. The complementary findings are discussed relative to a unified view of anticipatory coarticulation in CV production across a continuum of hyperarticulated spectral expansion to hypoarticulated spectral reduction.},
  file = {/Users/megcychosz/Zotero/storage/FK5DELCX/Agwuele et al. - 2008 - The Effect of Speaking Rate onConsonant Vowel Coar.pdf},
  journal = {Phonetica},
  language = {en},
  number = {4}
}

@article{akhtarDeficitDifferenceInterpreting2013,
  title = {Deficit or Difference? {{Interpreting}} Diverse Developmental Paths: {{An}} Introduction to the Special Section.},
  shorttitle = {Deficit or Difference?},
  author = {Akhtar, Nameera and Jaswal, Vikram K.},
  year = {2013},
  volume = {49},
  pages = {1--3},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/a0029851},
  abstract = {How should differences between ``typically developing'' children and other populations be interpreted? To what extent should the emphasis be on advocating remediation for children who are on a developmental trajectory that differs from the norm versus embracing different developmental trajectories as equally valid contributions to the diversity of human experience? The 6 target articles and 2 commentaries in this special section offer a diverse set of perspectives on the tensions and responsibilities inherent in interpreting and acting on differences between children of different cultural, ethnic, linguistic, socioeconomic, and neurological backgrounds.},
  file = {/Users/megcychosz/Zotero/storage/BAWLYLJC/Akhtar and Jaswal - 2013 - Deficit or difference Interpreting diverse develo.pdf},
  journal = {Developmental Psychology},
  language = {en},
  number = {1}
}

@article{albertSocialFunctionsBabbling2018,
  title = {The Social Functions of Babbling: Acoustic and Contextual Characteristics That Facilitate Maternal Responsiveness},
  shorttitle = {The Social Functions of Babbling},
  author = {Albert, Rachel R. and Schwade, Jennifer A. and Goldstein, Michael H.},
  year = {2018},
  month = sep,
  volume = {21},
  pages = {e12641},
  issn = {1363755X},
  doi = {10.1111/desc.12641},
  abstract = {What is the social function of babbling? An important function of prelinguistic vocalizing may be to elicit parental behavior in ways that facilitate the infant's own learning about speech and language. Infants use parental feedback to their babbling to learn new vocal forms, but the microstructure of parental responses to babbling has not been studied. To enable precise manipulation of the proximal infant cues that may influence maternal behavior, we used a playback paradigm to assess mothers' responsiveness to prerecorded audiovisual clips of unfamiliar infants' noncry prelinguistic vocalizations and actions. Acoustic characteristics and directedness of vocalizations were manipulated to test their efficacy in structuring social interactions. We also compared maternal responsiveness in the playback paradigm and in free play with their own infants. Maternal patterns of reactions to babbling were stable across both tasks. In the playback task, we found specific vocal cues, such as the degree of resonance and the transition timing of consonant-\-vowel syllables, predicted contingent maternal responding. Vocalizations directed at objects also facilitated increased responsiveness. The responses mothers exhibited, such as sensitive speech and vocal imitation, are known to facilitate vocal learning and development. Infants, by influencing the behavior of their caregivers with their babbling, create social interactions that facilitate their own communicative development.},
  file = {/Users/megcychosz/Zotero/storage/5TT2233P/Albert et al. - 2018 - The social functions of babbling acoustic and con.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {5}
}

@article{alegreFrequencyEffectsRepresentational1999,
  title = {Frequency {{Effects}} and the {{Representational Status}} of {{Regular Inflections}}},
  author = {Alegre, Maria and Gordon, Peter},
  year = {1999},
  month = jan,
  volume = {40},
  pages = {41--61},
  issn = {0749596X},
  doi = {10.1006/jmla.1998.2607},
  file = {/Users/megcychosz/Zotero/storage/2XAHCSWN/Alegre and Gordon - 1999 - Frequency Effects and the Representational Status .pdf},
  journal = {Journal of Memory and Language},
  language = {en},
  number = {1}
}

@article{alegreFrequencyEffectsRepresentational1999a,
  title = {Frequency {{Effects}} and the {{Representational Status}} of {{Regular Inflections}}},
  author = {Alegre, Maria and Gordon, Peter},
  year = {1999},
  month = jan,
  volume = {40},
  pages = {41--61},
  issn = {0749596X},
  doi = {10.1006/jmla.1998.2607},
  file = {/Users/megcychosz/Zotero/storage/33ZHSI3Q/Alegre and Gordon - 1999 - Frequency Effects and the Representational Status .pdf},
  journal = {Journal of Memory and Language},
  language = {en},
  number = {1}
}

@article{allenSpeechIntelligibilityChildren1998,
  title = {Speech Intelligibility in Children after Cochlear Implantation},
  author = {Allen, M. and Nikolopoulos, T.P. and O'Donoghue, G.M.},
  year = {1998},
  volume = {19},
  pages = {742--746},
  journal = {Otology \& Neurotology},
  number = {6}
}

@article{ambridgeStoredAbstractionsRadical2019,
  title = {Against Stored Abstractions: {{A}} Radical Exemplar Model of Language Acquisition},
  author = {Ambridge, B.},
  year = {2019},
  file = {/Users/megcychosz/Zotero/storage/2HM5E6WG/Ambridge - Against stored abstractions A radical exemplar mo.pdf},
  journal = {pre-print}
}

@article{ambridgeUbiquityFrequencyEffects2015,
  title = {The Ubiquity of Frequency Effects in First Language Acquisition},
  author = {Ambridge, Ben and Kidd, Evan and Rowland, Caroline F. and Theakston, Anna L.},
  year = {2015},
  month = mar,
  volume = {42},
  pages = {239--273},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S030500091400049X},
  abstract = {This review article presents evidence for the claim that frequency effects are pervasive in children's first language acquisition, and hence constitute a phenomenon that any successful account must explain.},
  file = {/Users/megcychosz/Zotero/storage/GJKVKLDH/Ambridge et al. - 2015 - The ubiquity of frequency effects in first languag.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {02}
}

@article{ambroseLinguisticInputElectronic2014,
  title = {Linguistic {{Input}}, {{Electronic Media}}, and {{Communication Outcomes}} of {{Toddlers}} with {{Hearing Loss}}},
  author = {Ambrose, Sophie E. and VanDam, Mark and Moeller, Mary Pat},
  year = {2014},
  volume = {35},
  pages = {139--147},
  issn = {0196-0202},
  doi = {10.1097/AUD.0b013e3182a76768},
  abstract = {Objectives The objectives of this study were to examine the quantity of adult words, adult-child conversational turns, and electronic media in the auditory environments of toddlers who are hard of hearing (HH) and to examine whether these variables contributed to variability in children's communication outcomes. Design Participants were 28 children with mild to severe hearing loss. Full-day recordings of children's auditory environments were collected within 6 months of their 2nd birthdays by utilizing LENA (Language ENvironment Analysis) technology. The system analyzes full-day acoustic recordings, yielding estimates of the quantity of adult words, conversational turns, and electronic media exposure in the recordings. Children's communication outcomes were assessed via the receptive and expressive scales of the Mullen Scales of Early Learning at 2 years of age and the Comprehensive Assessment of Spoken Language at 3 years of age. Results On average, the HH toddlers were exposed to approximately 1400 adult words per hour and participated in approximately 60 conversational turns per hour. An average of 8\% of each recording was classified as electronic media. However, there was considerable within-group variability on all three measures. Frequency of conversational turns, but not adult words, was positively associated with children's communication outcomes at 2 and 3 years of age. Amount of electronic media exposure was negatively associated with 2-year-old receptive language abilities; however, regression results indicate that the relationship was fully mediated by the quantity of conversational turns. Conclusions HH toddlers who were engaged in more conversational turns demonstrated stronger linguistic outcomes than HH toddlers who were engaged in fewer conversational turns. The frequency of these interactions was found to be decreased in households with high rates of electronic media exposure. Optimal language-learning environments for HH toddlers include frequent linguistic interactions between parents and children. To support this goal, parents should be encouraged to reduce their children's exposure to electronic media.},
  file = {/Users/megcychosz/Zotero/storage/M3YZBV86/Ambrose et al. - 2014 - Linguistic Input, Electronic Media, and Communicat.pdf},
  journal = {Ear and Hearing},
  number = {2},
  pmcid = {PMC3944057},
  pmid = {24441740}
}

@article{ambrosePhonologicalAwarenessPrint2012,
  title = {Phonological {{Awareness}} and {{Print Knowledge}} of {{Preschool Children With Cochlear Implants}}},
  author = {Ambrose, Sophie E. and Fey, Marc E. and Eisenberg, Laurie S.},
  year = {2012},
  month = jun,
  volume = {55},
  pages = {811--823},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2011/11-0086)},
  abstract = {Purpose\textemdash To determine whether preschool-age children with cochlear implants have ageappropriate phonological awareness and print knowledge and to examine the relationships of these skills with related speech and language abilities. Method\textemdash 24 children with cochlear implants (CIs) and 23 peers with normal hearing (NH), ages 36 to 60 months, participated. Children's print knowledge, phonological awareness, language, speech production, and speech perception abilities were assessed. Results\textemdash For phonological awareness, the CI group's mean score fell within 1 standard deviation of the TOPEL's normative sample mean but was more than 1 standard deviation below our NH group mean. The CI group's performance did not differ significantly from that of the NH group for print knowledge. For the CI group, phonological awareness and print knowledge were significantly correlated with language, speech production, and speech perception. Together, these predictor variables accounted for 34\% of variance in the CI group's phonological awareness but no significant variance in their print knowledge. Conclusions\textemdash Children with CIs have the potential to develop age-appropriate early literacy skills by preschool-age but are likely to lag behind their NH peers in phonological awareness. Intervention programs serving these children should target these skills with instruction and by facilitating speech and language development.},
  file = {/Users/megcychosz/Zotero/storage/2PUIAWCU/Ambrose et al. - 2012 - Phonological Awareness and Print Knowledge of Pres.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {3}
}

@article{ambroseQuantityQualityCaregivers2015,
  title = {Quantity and {{Quality}} of {{Caregivers}}' {{Linguistic Input}} to 18-{{Month}} and 3-{{Year}}-{{Old Children Who Are Hard}} of {{Hearing}}:},
  shorttitle = {Quantity and {{Quality}} of {{Caregivers}}' {{Linguistic Input}} to 18-{{Month}} and 3-{{Year}}-{{Old Children Who Are Hard}} of {{Hearing}}},
  author = {Ambrose, Sophie E. and Walker, Elizabeth A. and {Unflat-Berry}, Lauren M. and Oleson, Jacob J. and Moeller, Mary Pat},
  year = {2015},
  volume = {36},
  pages = {48S-59S},
  issn = {0196-0202},
  doi = {10.1097/AUD.0000000000000209},
  abstract = {Objectives\textemdash The primary objective of this study was to examine the quantity and quality of caregiver talk directed to children who are hard of hearing (CHH) as compared to children with normal hearing (CNH). For the CHH only, the study explored how caregiver input changed as a function of child age (18 months versus 3 years), which child and family factors contributed to variance in caregiver linguistic input at 18 months and 3 years, and how caregiver talk at 18 months related to child language outcomes at 3 years.},
  file = {/Users/megcychosz/Zotero/storage/3X6HCDMN/Ambrose et al. - 2015 - Quantity and Quality of Caregivers’ Linguistic Inp.pdf},
  journal = {Ear and Hearing},
  language = {en},
  number = {1}
}

@article{andersonClassroomTapingLegal2017,
  title = {Classroom {{Taping Under Legal Scrutiny}}-{{A Road Map}} for a {{Law School Policy}}},
  author = {Anderson, Alexis},
  year = {2017, Winter},
  volume = {66},
  pages = {372--408},
  file = {/Users/megcychosz/Zotero/storage/SRH4SPRB/Anderson - Classroom Taping Under Legal Scrutiny-A Road Map f.pdf},
  journal = {Journal of Legal Education},
  language = {en},
  number = {2}
}

@misc{andersonModelingNonuniformitiesInfants2019,
  title = {Modeling Non-Uniformities in Infants' Everyday Speech Environments},
  author = {Anderson, H. and Fausey, C.},
  year = {2019},
  address = {{Baltimore, MD}}
}

@article{andersonPhonologicalNeighborhoodWord2007,
  title = {Phonological Neighborhood and Word Frequency Effects in the Stuttered Disfluencies of Children Who Stutter},
  author = {Anderson, Julie D.},
  year = {2007},
  volume = {50},
  pages = {229--247},
  issn = {1092-4388},
  doi = {10.1044/1092-4388(2007/018)},
  abstract = {Purpose The purpose of this study was to examine (a) the role of neighborhood density (number of words that are phonologically similar to a target word) and frequency variables on the stuttering-like disfluencies of preschool children who stutter, and (b) whether these variables have an effect on the type of stuttering-like disfluency produced. Method A 500+ word speech sample was obtained from each participant (N = 15). Each stuttered word was randomly paired with the firstly produced word that closely matched it in grammatical class, familiarity, and number of syllables/phonemes. Frequency, neighborhood density, and neighborhood frequency values were obtained for the stuttered and fluent words from an online database. Results Findings revealed that stuttered words were lower in frequency and neighborhood frequency than fluent words. Words containing part-word repetitions and sound prolongations were also lower in frequency and/or neighborhood frequency than fluent words, but these frequency variables did not have an effect on single-syllable word repetitions. Neighborhood density failed to influence the susceptibility of words to stuttering, as well as the type of stuttering-like disfluency produced. Conclusions In general, findings suggest that neighborhood and frequency variables not only influence the fluency with which words are produced in speech, but also have an impact on the type of stuttering-like disfluency produced.},
  file = {/Users/megcychosz/Zotero/storage/C9865AJN/Anderson - 2007 - Phonological Neighborhood and Word Frequency Effec.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  number = {1},
  pmcid = {PMC2478697},
  pmid = {17344561}
}

@article{apostolModelAcousticInterspeaker2004,
  title = {A Model of Acoustic Interspeaker Variability Based on the Concept of Formant\textendash Cavity Affiliation},
  author = {Apostol, Lian and Perrier, Pascal and Bailly, G{\'e}rard},
  year = {2004},
  month = jan,
  volume = {115},
  pages = {337--351},
  issn = {0001-4966},
  doi = {10.1121/1.1631946},
  file = {/Users/megcychosz/Zotero/storage/J522JNFE/Apostol et al. - 2004 - A model of acoustic interspeaker variability based.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{aragonUsingLanguageENvironment2012,
  title = {Using {{Language ENvironment Analysis}} to Improve Outcomes for Children Who Are Deaf or Hard of Hearing},
  author = {Aragon, Miranda and {Yoshinaga-Itano}, Christine},
  year = {2012},
  volume = {33},
  pages = {340--353},
  journal = {Seminars in Speech and Language},
  number = {4}
}

@article{arjmandiEstimatingReducedBenefit2021,
  title = {Estimating the Reduced Benefit of Infant-Directed Speech in Cochlear Implant-Related Speech Processing},
  author = {Arjmandi, Meisam and Houston, Derek and Wang, Yuanyuan and Dilley, Laura},
  year = {2021},
  month = jan,
  pages = {S0168010221000213},
  issn = {01680102},
  doi = {10.1016/j.neures.2021.01.007},
  file = {/Users/megcychosz/Zotero/storage/V7T3I5ZW/Arjmandi et al. - 2021 - Estimating the reduced benefit of infant-directed .pdf},
  journal = {Neuroscience Research},
  language = {en}
}

@inproceedings{arjmandiIndividualDifferencesCaregivers2019,
  title = {Individual Differences across Caregivers in Acoustic Implementation of Infant-Directed and Adult-Directed Speech: {{Modeling}} Impacts on Intelligibility in Children with Cochlear Implants},
  booktitle = {Acoustical {{Society}} of {{America}}},
  author = {Arjmandi, M. K. and Houston, Derek M. and Svirsky, Mario A. and Wang, Yuanyuan and Lehet, Matthew and Dilley, L.},
  year = {2019},
  abstract = {Caregivers modify their speaking style from adult-directed speech (ADS) to infant-directed speech (IDS) when talking to infants. However, it is unclear how individual caregivers acoustically implement differences between ADS and IDS, and how these differences may affect experienced speech intelligibility by infants, particularly those with cochlear implants (CIs). Seven female talkers spoke fifteen utterances both in IDS and ADS. We analyzed these utterances and their cochlear implant-simulated versions (using 22-channel noise vocoders) to investigate how acoustic distances between ADS and IDS varied across talkers (based on Mel-frequency cepstral coefficients, MFCCs) and how the effect of these shifts in speaking style on utterance intelligibility were different between talkers (using the acoustic index of speech-to-reverberation modulation energy ratio tailored to CI devices, SRMR-CI). Results showed substantial variability across talkers comparing ADS and IDS for caregivers' acoustic profiles from MFCCs and for speech intelligibility from SRMR-CI. These findings suggest that acoustic choices by individual mothers may differentially affect recoverability of intelligible words from speech signals by children with CIs, which may contribute to differences in these children's language outcomes. [Work supported by NIH grant R01DC008581.]}
}

@article{arnoldPhonologicalNeighborhoodDensity2005,
  title = {Phonological Neighborhood Density in the Picture Naming of Young Children Who Stutter: {{Preliminary}} Study},
  shorttitle = {Phonological Neighborhood Density in the Picture Naming of Young Children Who Stutter},
  author = {Arnold, Hayley and Conture, Edward and Ohde, Ralph},
  year = {2005},
  month = dec,
  volume = {30},
  pages = {125--48},
  doi = {10.1016/j.jfludis.2005.01.001},
  abstract = {Unlabelled:  The purpose of this study was to assess the effect of phonological neighborhood density on the speech reaction time (SRT) and errors of children who do and do not stutter during a picture-naming task. Participants were nine 3-5-year-old children who stutter (CWS) matched in age and gender to nine children who do not stutter (CWNS). Initial analyses indicated that both CWNS and CWS were significantly faster (i.e., exhibited shorter SRTs) and more accurate on phonologically sparse than phonologically dense words, findings consistent with those found with older children (Newman \& German, 2002). Further analyses indicated that talker group differences in receptive language scores weakened these findings. These preliminary findings were taken to suggest that phonological neighborhood density appears to influence the picture-naming speed and accuracy of preschool-aged children. Educational objectives: The reader will learn about and be able to: (1) recognize the relevance of examining phonological variables in relation to childhood stuttering; and (2) describe the method of measuring speech reaction times and errors during a picture-naming task as a means of assessing linguistic skills.},
  journal = {Journal of fluency disorders}
}

@article{arnonMoreWordsEffect2013,
  title = {More than Words: {{The}} Effect of Multi-Word Frequency and Constituency on Phonetic Duration},
  shorttitle = {More than {{Words}}},
  author = {Arnon, Inbal and Cohen Priva, Uriel},
  year = {2013},
  volume = {56},
  pages = {349--371},
  issn = {0023-8309, 1756-6053},
  doi = {10.1177/0023830913484891},
  abstract = {There is mounting evidence that language users are sensitive to the distributional properties of multi-word sequences. Such findings expand the range of information speakers are sensitive to and call for processing models that can represent larger chains of relations. In the current paper we investigate the effect of multi-word statistics on phonetic duration using a combination of experimental and corpus-based research. We ask (a) if phonetic duration is affected by multi-word frequency in both elicited and spontaneous speech, and (b) if syntactic constituency modulates the effect. We show that phonetic durations are reduced in higher frequency sequences, regardless of constituency: duration is shorter for more frequent sequences within and across syntactic boundaries. The effects are not reducible to the frequency of the individual words or substrings. These findings open up a novel set of questions about the interaction between surface distributions and higher order properties, and the resulting need (or lack thereof) to incorporate higher order properties into processing models.},
  file = {/Users/megcychosz/Zotero/storage/SESHVWMY/Arnon and Cohen Priva - 2013 - More than Words The Effect of Multi-word Frequenc.pdf},
  journal = {Language and Speech},
  language = {en},
  number = {3}
}

@article{arnonMoreWordsFrequency2010,
  title = {More than Words: {{Frequency}} Effects for Multi-Word Phrases},
  shorttitle = {More than Words},
  author = {Arnon, Inbal and Snider, Neal},
  year = {2010},
  month = jan,
  volume = {62},
  pages = {67--82},
  issn = {0749596X},
  doi = {10.1016/j.jml.2009.09.005},
  abstract = {There is mounting evidence that language users are sensitive to distributional information at many grain-sizes. Much of this research has focused on the distributional properties of words, the units they consist of (morphemes, phonemes), and the syntactic structures they appear in (verb-categorization frames, syntactic constructions). In a series of studies we show that comprehenders are also sensitive to the frequencies of compositional four-word phrases (e.g. don't have to worry): more frequent phrases are processed faster. The effect is not reducible to the frequency of the individual words or substrings and is observed across the entire frequency range (for low, mid- and high frequency phrases). Comprehenders seem to learn and store frequency information about multi-word phrases. These findings call for processing models that can capture and predict phrase-frequency effects and support accounts where linguistic knowledge consists of patterns of varying sizes and levels of abstraction.},
  file = {/Users/megcychosz/Zotero/storage/DBGDU85X/Arnon and Snider - 2010 - More than words Frequency effects for multi-word .pdf},
  journal = {Journal of Memory and Language},
  language = {en},
  number = {1}
}

@article{arnonRoleMultiwordBuilding2017,
  title = {The Role of Multiword Building Blocks in Explaining {{L1}}-{{L2}} Differences},
  author = {Arnon, Inbal and Christiansen, Morten H.},
  year = {2017},
  volume = {9},
  pages = {621--636},
  issn = {17568757},
  doi = {10.1111/tops.12271},
  abstract = {Why are children better language learners than adults despite being worse at a range of other cognitive tasks? Here, we explore the role of multiword sequences in explaining L1\textendash L2 differences in learning. In particular, we propose that children and adults differ in their reliance on such multiword units (MWUs) in learning, and that this difference affects learning strategies and outcomes, and leads to difficulty in learning certain grammatical relations. In the first part, we review recent findings that suggest that MWUs play a facilitative role in learning. We then discuss the implications of these findings for L1\textendash L2 differences: We hypothesize that adults are both less likely to extract MWUs and less capable of benefiting from them in the process of learning. In the next section, we draw on psycholinguistic, developmental, and computational findings to support these predictions. We end with a discussion of the relation between this proposal and other accounts of L1\textendash L2 difficulty.},
  file = {/Users/megcychosz/Zotero/storage/5M8IFAF5/Abstract(1).pdf;/Users/megcychosz/Zotero/storage/PTG68IQW/Arnon and Christiansen - 2017 - The Role of Multiword Building Blocks in Explainin.pdf},
  journal = {Topics in Cognitive Science},
  language = {en},
  number = {3}
}

@phdthesis{arnonStartingBigRole2010,
  title = {Starting Big: {{The}} Role of Multiword Phrases},
  author = {Arnon, Inbal},
  year = {2010},
  abstract = {Why are children better language learners than adults? Intuitively, there is a difference between the unstructured (yet successful) way a child learns language and the effortful and often frustrating experience of trying to master a new language as an adult. On an empirical level, non-native speakers rarely reach native proficiency in pronunciation, morphological and syntactic processing, or in the use of formulaic language and idioms. How we understand these differences is related to our conception of first language learning, and of the object of learning \textendash{} what does it mean to know language? What is it that children or second learners have to learn? In this dissertation, I suggest that the answer lies, at least in part, in the linguistic units that children and adults learn from. I propose the Starting Big Hypothesis: children learn from units that are larger and less analyzed than the ones adults learn from. Because they do not know where word-boundaries are (or even that they exist), infants start out with a mix of words, multi-word fragments (e.g. give-it), and short multi-word utterances (e.g. Idon't-know or It's-my-turn), and from this early inventory extract linguistic knowledge. This process of using larger units to learn about smaller ones can v argue that L2 learners make insufficient use of larger units in learning, we have to first show that such units are an integral part of the native speaker's inventory. I first highlight the prominence of multi-word chunks (unanalyzed units) in children's early language use. I then show that multi-word phrases play a facilitative role in children's production even after segmentation has taken place: for example, 4;6 yearolds produce irregular plurals better after sentence-frames they often occur with (e.g. Brush your \textendash{} teeth) that they do in response to questions (What are those?). These findings show that children attend to larger units, and that such units play a role in the process of lexical and morphological development. Multi-word phrases, I argue, are also part of the adult inventory. In a series of studies, I demonstrate that adult speakers are faster to process higher frequency compositional four-word phrases like don't have to worry compared to lower frequency ones like don't have to wait. Since the phrases were matched for part frequency (the frequency of all the unigrams, bigrams and trigrams) and plausibility, this effect must reflect speakers' knowledge of the frequencies of the whole-phrases. That is, on some level adult speakers have memory traces of phrases that could otherwise have been generated. This in turn undermines the claim that `atomic' and `derive' forms are represented in a qualitatively different way. Children's enhanced word production after familiar frames and adults' sensitivity to phrase frequency both illustrate the importance of multi-word phrases in native language learning and use. If adult difficulty in learning a second language is related to the more segmented units they learn from, then their learning outcome should improve if they start with larger chunks of language. I test this prediction by looking at adult learning of grammatical gender in an artificial language. Their learning was facilitated when they learned segmentation, semantics (the labels for objects), and grammar (which article a noun appears with) at the same time. These findings demonstrate that (1) early units can influence subsequent learning, and (2) there is an advantage to learning grammar from segmenting larger units vi In examining the size and nature of early linguistic units, I've offered a novel perspective on the difficulty that adults experience in learning a second language while at the same time endorsing a usage-based and exemplar-driven approach to first language learning where early experience plays such an important role. My focus on compositional phrases also allowed me to contrast single-system and dual-system approaches to language and to present evidence in support of an emergentist view of language where all linguistic experience (be it atomic or complex) is processed by the same cognitive mechanism. Finally, the Starting Big Hypothesis has theoretical implications for theories of L1 and L2 learning, and practical implications for the teaching of second languages.},
  file = {/Users/megcychosz/Zotero/storage/3SRJQREB/Starting big The role of multiword phrases.pdf;/Users/megcychosz/Zotero/storage/C2XKRB5E/cdev.12648.pdf},
  school = {Stanford University},
  type = {Dissertation}
}

@article{arnonWhyBrushYour2011,
  title = {Why {{{\emph{Brush Your Teeth}}}} {{Is Better Than}} {{{\emph{Teeth}}}} \textendash{} {{Children}}'s {{Word Production Is Facilitated}} in {{Familiar Sentence}}-{{Frames}}},
  author = {Arnon, Inbal and Clark, Eve V.},
  year = {2011},
  month = mar,
  volume = {7},
  pages = {107--129},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2010.505489},
  file = {/Users/megcychosz/Zotero/storage/3AV8NCQ4/Arnon and Clark - 2011 - Why iBrush Your Teethi Is Better Than iTeet.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {2}
}

@incollection{aslinWhatStatisticalLearning2009,
  title = {What Statistical Learning Can and Can't Tell Us about Language Acquisition},
  booktitle = {Infant Pathways to Language: {{Methods}}, Models, and Research Disorders},
  author = {Aslin, Richard N. and Newport, Elissa L.},
  year = {2009},
  pages = {15--29},
  publisher = {{Psychology Press}},
  address = {{New York, NY, US}},
  abstract = {The term statistical learning (SL)--from Charniak's (1993) description of algorithms in computational linguistics-- is used to describe the psychological process by which the transitional probabilities from one syllable to another in the continuous speech streams could enable word segmentation and its complement, what Hayes and Clark referred to as clustering. Our goals in this chapter are to address four key questions: 1. What is SL, at least as we define it, and over what ages, domains, and species does it operate? 2. How is SL constrained to enable rapid learning to be tractable given the limits of human information processing and the explosive combinatorics of even the simplest language? 3. What are the limits of SL for explaining language acquisition beyond the word-segmentation problem? 4. How might SL go awry in special populations of children who suffer from language deficits? (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/megcychosz/Zotero/storage/5HSZQEMQ/2007-15597-002.html},
  isbn = {978-0-8058-6063-4},
  keywords = {Language,Language Development,Oral Communication,Probability,Syllables}
}

@article{assmannTimevaryingSpectralChange2000,
  title = {Time-Varying Spectral Change in the Vowels of Children and Adults},
  author = {Assmann, Peter F. and Katz, William F.},
  year = {2000},
  month = oct,
  volume = {108},
  pages = {1856--1866},
  issn = {0001-4966},
  doi = {10.1121/1.1289363},
  file = {/Users/megcychosz/Zotero/storage/APGXN4YH/Assmann and Katz - 2000 - Time-varying spectral change in the vowels of chil.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@inproceedings{atalRecentAdvancesPredictive1974,
  title = {Recent Advances in Predictive Coding\textemdash Applications to Speech Synthesis},
  booktitle = {Proceedings of {{Speech Communication Symposium}} 1974},
  author = {Atal, B.S. and Schroeder, M.R.},
  year = {1974},
  pages = {27--31}
}

@misc{audacityteamAudacityFreeAudio2017,
  title = {Audacity: {{Free Audio Editor}} and {{Recorder}}},
  author = {Audacity Team},
  year = {2017}
}

@book{austPapajaCreateAPA2018,
  title = {Papaja:{{Create APA}} Manuscripts with {{R Markdown}}},
  author = {Aust, F. and Barth, M.},
  year = {2018}
}

@misc{AvailableBetaTesting,
  title = {Available for Beta Testing: {{Zotero Connector}} for {{Safari}} 13},
  shorttitle = {Available for Beta Testing},
  abstract = {Zotero is a powerful, easy-to-use research tool that helps you gather, organize, and analyze sources and then share the results of your research., A test version of the Zotero Connector for Safari that works with Safari 13 is now available in the latest Zotero beta. [Update:},
  file = {/Users/megcychosz/Zotero/storage/C5MBH7NN/p1.html},
  howpublished = {https://forums.zotero.org/discussion/80255/available-for-beta-testing-zotero-connector-for-safari-13},
  journal = {Zotero Forums},
  language = {en}
}

@article{aylettSmoothSignalRedundancy2004,
  title = {The Smooth Signal Redundancy Hypothesis: {{A}} Functional Explanation for Relationships between Redundancy, Prosodic Prominence, and Duration in Spontaneous Speech},
  shorttitle = {The {{Smooth Signal Redundancy Hypothesis}}},
  author = {Aylett, Matthew and Turk, Alice},
  year = {2004},
  volume = {47},
  pages = {31--56},
  issn = {0023-8309, 1756-6053},
  doi = {10.1177/00238309040470010201},
  file = {/Users/megcychosz/Zotero/storage/HWZSKXE9/Aylett and Turk - 2004 - The Smooth Signal Redundancy Hypothesis A Functio.pdf},
  journal = {Language and Speech},
  language = {en},
  number = {1}
}

@incollection{baayenFrequencyEffectsRegular2003,
  title = {Frequency Effects in Regular Inflectional Morphology: {{Revisiting Dutch}} Plurals},
  shorttitle = {Frequency Effects in Regular Inflectional Morphology},
  booktitle = {Morphological {{Structure}} in {{Language Processing}}},
  author = {Baayen, R. Harald and McQueen, James M. and Dijkstra, Ton and Schreuder, Robert},
  editor = {Baayen, R. Harald and Schreuder, Robert},
  year = {2003},
  pages = {355--390},
  publisher = {{De Gruyter Mouton}},
  address = {{Berlin, New York}},
  doi = {10.1515/9783110910186.355},
  isbn = {978-3-11-091018-6}
}

@incollection{baayenQuantitativeAspectsMorphological1992,
  title = {Quantitative Aspects of Morphological Productivity},
  booktitle = {Yearbook of {{Morphology}} 1991},
  author = {Baayen, Harald},
  editor = {Booij, G. and {van Marle}, J.},
  year = {1992},
  pages = {109--149},
  publisher = {{Kluwer Academic Publishers}},
  file = {/Users/megcychosz/Zotero/storage/T3Y93QJE/Quantitative aspects of morphological productivity.pdf}
}

@article{baddeleyPhonologicalLoopLanguage1998,
  title = {The {{Phonological Loop}} as a {{Language Learning Device}}},
  author = {Baddeley, Alan and Gathercole, Susan and Papagno, Costanza},
  year = {1998},
  month = feb,
  volume = {105},
  pages = {158--73},
  doi = {10.1037/0033-295X.105.1.158},
  abstract = {A relatively simple model of the phonological loop (A. D. Baddeley, 1986), a component of working memory, has proved capable of accommodating a great deal of experimental evidence from normal adult participants, children, and neuropsychological patients. Until recently, however, the role of this subsystem in everyday cognitive activities was unclear. In this article the authors review studies of word learning by normal adults and children, neuropsychological patients, and special developmental populations, which provide evidence that the phonological loop plays a crucial role in learning the novel phonological forms of new words. The authors propose that the primary purpose for which the phonological loop evolved is to store unfamiliar sound patterns while more permanent memory records are being constructed. Its use in retaining sequences of familiar words is, it is argued, secondary.},
  file = {/Users/megcychosz/Zotero/storage/UG7NV5CN/Baddeley et al. - 1998 - The Phonological Loop as a Language Learning Devic.pdf},
  journal = {Psychological review}
}

@article{baese-berkLongtermTemporalTracking2014,
  title = {Long-Term Temporal Tracking of Speech Rate Affects Spoken-Word Recognition},
  author = {{Baese-Berk}, Melissa M. and Heffner, Christopher C. and Dilley, Laura C. and Pitt, Mark A. and Morrill, Tuuli H. and McAuley, J. Devin},
  year = {2014},
  month = aug,
  volume = {25},
  pages = {1546--1553},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797614533705},
  abstract = {Humans unconsciously track a wide array of distributional characteristics in their sensory environment. Recent research in spoken-language processing has demonstrated that the speech rate surrounding a target region within an utterance influences which words, and how many words, listeners hear later in that utterance. On the basis of hypotheses that listeners track timing information in speech over long timescales, we investigated the possibility that the perception of words is sensitive to speech rate over such a timescale (e.g., an extended conversation). Results demonstrated that listeners tracked variation in the overall pace of speech over an extended duration (analogous to that of a conversation that listeners might have outside the lab) and that this global speech rate influenced which words listeners reported hearing. The effects of speech rate became stronger over time. Our findings are consistent with the hypothesis that neural entrainment by speech occurs on multiple timescales, some lasting more than an hour.},
  file = {/Users/megcychosz/Zotero/storage/BH6NCXQ9/Baese-Berk et al. - 2014 - Long-term temporal tracking of speech rate affects.pdf},
  journal = {Psychological Science},
  number = {8}
}

@article{baese-berkMechanismsInteractionSpeech2009,
  title = {Mechanisms of Interaction in Speech Production},
  author = {{Baese-Berk}, Melissa and Goldrick, Matthew},
  year = {2009},
  month = may,
  volume = {24},
  pages = {527--554},
  issn = {0169-0965, 1464-0732},
  doi = {10.1080/01690960802299378},
  file = {/Users/megcychosz/Zotero/storage/CTEGECFB/Baese-Berk and Goldrick - 2009 - Mechanisms of interaction in speech production.pdf},
  journal = {Language and Cognitive Processes},
  language = {en},
  number = {4}
}

@inproceedings{baese-berkNonnativeSpeakersUse2016,
  title = {Do Non-Native Speakers Use Context Speaking Rate in Spoken Word Recognition?},
  booktitle = {Proceedings of {{Speech Prosody}}},
  author = {{Baese-Berk}, Melissa and Morrill, Tuuli and Dilley, Laura},
  year = {2016},
  month = may,
  volume = {8},
  pages = {979--983},
  doi = {10.21437/SpeechProsody.2016-201},
  abstract = {Context speaking rate is an important cue in spoken-word recognition in a speaker's native language [1], [2]. Native speakers entrain to the context rate; when they encounter ambiguous regions of speech, native speakers perceive fewer words and/or syllables when the surrounding speaking material is presented a relatively slow rate than when presented with a relatively fast context speaking rate. In the present study, we ask whether non-native speakers are able to use context speaking rate in the same way. We present results from an experiment examining whether non-native speakers show similar patterns to native speakers when determining the number of words being spoken. Results suggest that while non-native speakers are sensitive speaking rate when they hear ambiguous regions of speech, they only show such sensitivity when the speech is relatively slow. When the speech is fast, they do not demonstrate context speaking rate effects. This suggests that some aspects of the context speaking rate effect may be closely tied to proficiency, while other aspects may demonstrate more language-general patterns.},
  file = {/Users/megcychosz/Zotero/storage/WS4EWXLH/Baese-Berk et al. - 2016 - Do non-native speakers use context speaking rate i.pdf},
  language = {en}
}

@inproceedings{bakerPhoneticDifferencesMis2007,
  title = {Phonetic Differences between Mis- and Dis- in {{English}} Prefixed and Pseudo-Prefixed Words},
  booktitle = {Proceedings of the 16th {{ICPhS}}},
  author = {Baker, Rachel and Smith, Rachel and Hawkins, Sarah},
  year = {2007},
  address = {{Saarbr\"ucken}},
  abstract = {It has been claimed that speakers distinguish between phonemically-identical initial syllables that differ in morphological structure, but the phonetic details are poorly understood. Five SSBE speakers read scripted dialogues containing words with such syllables, half with true prefixes (Pr) e.g. mistimes, displease, and half with pseudo-prefixes (PsPr) e.g. mistakes, displays. Each word occurred both with nuclear (N) stress and in postnuclear (PN) position. Pr words were longer up to voicing onset in the second syllable and had longer [ ] and VOT, and shorter [s] than PsPr words. For mis-, the average amplitude of the burst + aspiration was higher in Pr than PsPr. Implications for models of morphological decomposition are discussed.},
  file = {/Users/megcychosz/Zotero/storage/GLUKZPAR/Baker et al. - 2007 - PHONETIC DIFFERENCES BETWEEN MIS- AND DIS- IN ENGL.pdf},
  language = {en}
}

@article{bakstArticulationAlteredAuditory,
  title = {Articulation and {{Altered Auditory Feedback}}},
  author = {Bakst, Sarah G},
  pages = {101},
  file = {/Users/megcychosz/Zotero/storage/DIYMN325/Bakst - Articulation and Altered Auditory Feedback.pdf},
  language = {en}
}

@article{bakstModelingEffectPalate2018,
  title = {Modeling the Effect of Palate Shape on the Articulatory-Acoustics Mapping},
  author = {Bakst, Sarah and Johnson, Keith},
  year = {2018},
  month = jul,
  volume = {144},
  pages = {EL71-EL75},
  issn = {0001-4966},
  doi = {10.1121/1.5048043},
  abstract = {Articulatory variability is reduced for people with flatter palates [Bakst and Lin (2015). Proceedings of the 18th International Congress of Phonetic Sciences; Brunner, Fuchs, and Perrier (2009). J. Acoust. Soc. Am. 125(6), 3936\textendash 3949]. Brunner, Fuchs, and Perrier [(2009). J. Acoust. Soc. Am. 125(6), 3936\textendash 3949] hypothesized that this is because the mapping between articulation and acoustics depends on palate depth. Articulatory synthesis was used with three different palate shapes to generate productions of /r/. The parameter spaces of the articulatory synthesizers were searched for vocal tract configurations that result in low F3 (the hallmark acoustic cue for /r/). Palate shape influences not only the sensitivity of the articulatory-acoustic mapping, but also the effect of each individual articulatory parameter on F3.},
  file = {/Users/megcychosz/Zotero/storage/L7SYZDL9/Bakst and Johnson - 2018 - Modeling the effect of palate shape on the articul.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{bannardStoredWordSequences2008,
  title = {Stored Word Sequences in Language Learning: {{The}} Effect of Familiarity on Children's Repetition of Four-Word Combinations},
  shorttitle = {Stored {{Word Sequences}} in {{Language Learning}}},
  author = {Bannard, Colin and Matthews, Danielle},
  year = {2008},
  volume = {19},
  pages = {241--248},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/j.1467-9280.2008.02075.x},
  file = {/Users/megcychosz/Zotero/storage/EW2SNQWW/Bannard and Matthews - 2008 - Stored Word Sequences in Language Learning The Ef.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {3}
}

@article{baraltHablameBebePhone2020,
  title = {H\'ablame {{Beb\'e}}: {{A}} Phone Application Intervention to Support {{Hispanic}} Children's Early Language Environments and Bilingualism},
  shorttitle = {H\'ablame {{Beb\'e}}},
  author = {Baralt, Melissa and Darcy Mahoney, Ashley and Brito, Natalie},
  year = {2020},
  month = feb,
  pages = {026565902090377},
  issn = {0265-6590, 1477-0865},
  doi = {10.1177/0265659020903779},
  abstract = {The early language environments of low-income Hispanic children can be negatively affected when their Spanish-speaking caregivers face racism, assimilation pressure, and/or misinformed advice based on English-only ideologies. This article reports on the design and efficacy of H\'ablame Beb\'e, a language-promoting phone application that encourages low-income Hispanic mothers to talk more to their children in their native Spanish with the goals of (1) improving their children's early language environment, (2) promoting bilingualism, and (3) monitoring developmental milestones. The app was designed and tested across three phases as mandated by the US HRSA Bridging the Word Gap Challenge. In Phase I, we developed a curriculum that promotes high-quality language interactions in Spanish and designed the app components. In Phase II, we tested the app with 20 Hispanic mothers (half high school-educated, half college-educated) in a pretest\textendash posttest design in which we examined their language interactions before and after two months of using the app. Preliminary results indicated that mother\textendash child verbal interactions increased, but not always in their native Spanish, and the difference was not statistically significant. Focus group data revealed that many of the mothers had experienced linguistic racism and that tropes surrounding Spanish-speaking identity in the USA needed to be explicitly addressed within the intervention. In Phase III, a sociolinguistic pride component was added and the app was again tested with 12 additional Hispanic mothers (all high school-educated only). This time, a statistically significant increase in mother\textendash child verbal interactions was found. Mothers also reported feeling prouder to use Spanish with their children. These results suggest that H\'ablame Beb\'e may be a viable means to reach low-income Hispanic caregivers who face obstacles in accessing health information and/or home-visiting programs for their children.},
  file = {/Users/megcychosz/Zotero/storage/JA2A2MED/Baralt et al. - 2020 - Háblame Bebé A phone application intervention to .pdf},
  journal = {Child Language Teaching and Therapy},
  language = {en}
}

@article{barbaroAutomatedSensingDaily2019,
  title = {Automated Sensing of Daily Activity: {{A}} New Lens into Development},
  shorttitle = {Automated Sensing of Daily Activity},
  author = {Barbaro, Kaya},
  year = {2019},
  month = apr,
  volume = {61},
  pages = {444--464},
  issn = {0012-1630, 1098-2302},
  doi = {10.1002/dev.21831},
  abstract = {Rapidly maturing technologies for sensing and activity recognition can provide unprecedented access to the complex structure daily activity and interaction, promising new insight into the mechanisms by which experience shapes developmental outcomes. Motion data, autonomic activity, and ``snippets'' of audio and video recordings can be conveniently logged by wearable sensors (Lazer et al., 2009). Machine learning algorithms can process these signals into meaningful markers, from child and parent behavior to outcomes such as depression or teenage drinking. Theoretically motivated aspects of daily activity can be combined and synchronized to examine reciprocal effects between children's behaviors and their environments or internal processes. Captured over longitudinal time, such data provide a new opportunity to study the processes by which individual differences emerge and stabilize. This paper introduces the reader to developments in sensing and activity recognition with implications for developmental phenomena across the lifespan, sketching a framework for leveraging mobile sensors for transactional analyses that bridge micro- and longitudinal- timescales of development. It finishes by detailing resources and best practices to facilitate the next generation of developmentalists to contribute to this emerging area.},
  file = {/Users/megcychosz/Zotero/storage/V6MM5KBC/Barbaro - 2019 - Automated sensing of daily activity A new lens in.pdf},
  journal = {Developmental Psychobiology},
  language = {en},
  number = {3}
}

@inproceedings{barbierSpeechPlanning4yearold2015,
  title = {Speech Planning in 4-Year-Old Children versus Adults: {{Acoustic}} and Articulatory Analyses},
  booktitle = {Proceedings of {{Interspeech}} 2015},
  author = {Barbier, Guillaume and Perrier, Pascal and M{\'e}nard, Lucie and Payan, Yohan and Tiede, Mark K and Perkell, Joseph S},
  year = {2015},
  address = {{Dresden, Germany}},
  abstract = {This study investigates speech motor control in 4-year-old Canadian French children in comparison with adults. It focuses on measures of token-to-token variability in the production of isolated vowels and on anticipatory extrasyllabic coarticulation within V1-C-V2 sequences. Acoustic and ultrasound articulatory data were recorded. Acoustic data from 20 children and 10 adults have been analyzed. Thus far, ultrasound data have been analyzed from a subset of these participants: 6 children and 2 adults. In agreement with former studies, token-to-token variability was greater in children than in adults. Strong anticipation of V2 in V1 was found in all adults, but not in children. Most of the children showed no anticipation at all and some of them showed a small amount of anticipation along the antero-posterior dimension only, manifested in the acoustic F2 dimension. These results are interpreted as evidence for the immaturity of children's speech motor control from two perspectives: insufficiently stable motor control patterns for vowel production, and a lack of effectiveness in anticipating forthcoming gestures. In line with theories of optimal motor control, anticipatory coarticulation is assumed to be based on the use of internal models of the speech apparatus and the increasing maturation of these representations as speech develops.},
  file = {/Users/megcychosz/Zotero/storage/AUZQ9WGL/Speech planning in 4-year-old children versus adul.pdf},
  language = {en}
}

@inproceedings{barbierSpeechPlanningIndex2013,
  title = {Speech Planning as an Index of Speech Motor Control Maturity},
  booktitle = {Proceedings of {{Interspeech}} 2013},
  author = {Barbier, Guillaume and Perrier, Pascal and M{\'e}nard, Lucie and Payan, Yohan and Tiede, Mark K and Perkell, Joseph S},
  year = {2013},
  address = {{Lyon, France}},
  abstract = {This paper investigates speech motor control maturity in 4year-old Canadian French children. Acoustic and ultrasound data recorded from four children, and for comparison, from four adults, are presented and analyzed. Maturity of speech motor control is assessed by measuring two characteristics: token-to-token variability of isolated vowels, as a measure of motor control accuracy, and extra-syllabic anticipatory coarticulation within V1-C-V2 sequences. In line with theories of optimal motor control, anticipatory coarticulation is assumed to be based on the use of internal models of the speech apparatus and its efficiency is considered to reflect the maturity of these representations. In agreement with former studies, token-to-token variability is larger in children than in adults. An anticipation of V2 in V1 was found in all adults but in none of the children studied so far. These results indicate that children's speech motor control is immature from two perspectives: insufficiently accurate motor control patterns for vowel production, and inability to anticipate forthcoming gestures. Both aspects are discussed and interpreted in the context of the immaturity of the internal representations of the speech motor apparatus in 4-year-old children.},
  file = {/Users/megcychosz/Zotero/storage/5R3ZAA4G/desc.12111.pdf;/Users/megcychosz/Zotero/storage/77W7HDDN/Barbier et al. - Speech planning as an index of speech motor contro.pdf},
  language = {en}
}

@article{barbierWhatAnticipatoryCoarticulation2020,
  title = {What Anticipatory Coarticulation in Children Tells Us about Speech Motor Control Maturity},
  author = {Barbier, Guillaume and Perrier, Pascal and Payan, Yohan and Tiede, Mark K. and Gerber, Silvain and Perkell, Joseph S. and M{\'e}nard, Lucie},
  editor = {Johnson, Blake},
  year = {2020},
  volume = {15},
  pages = {e0231484},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0231484},
  abstract = {Purpose This study aimed to evaluate the role of motor control immaturity in the speech production characteristics of 4-year-old children, compared to adults. Specifically, two indices were examined: trial-to-trial variability, which is assumed to be linked to motor control accuracy, and anticipatory extra-syllabic vowel-to-vowel coarticulation, which is assumed to be linked to the comprehensiveness, maturity and efficiency of sensorimotor representations in the central nervous system. Method Acoustic and articulatory (ultrasound) data were recorded for 20 children and 10 adults, all native speakers of Canadian French, during the production of isolated vowels and vowelconsonant-vowel (V1-C-V2) sequences. Trial-to-trial variability was measured in isolated vowels. Extra-syllabic anticipatory coarticulation was assessed in V1-C-V2 sequences by measuring the patterns of variability of V1 associated with variations in V2. Acoustic data were reported for all subjects and articulatory data, for a subset of 6 children and 2 adults. Results Trial-to-trial variability was significantly larger in children. Systematic and significant anticipation of V2 in V1 was always found in adults, but was rare in children. Significant anticipation was observed in children only when V1 was /a/, and only along the antero-posterior dimension, with a much smaller magnitude than in adults. A closer analysis of individual speakers revealed that some children showed adult-like anticipation along this dimension, whereas the majority did not. Conclusion The larger trial-to-trial variability and the lack of anticipatory behavior in most children\textemdash two phenomena that have been observed in several non-speech motor tasks\textemdash support the},
  file = {/Users/megcychosz/Zotero/storage/I7G8KX3C/Barbier et al. - 2020 - What anticipatory coarticulation in children tells.pdf},
  journal = {PLoS ONE},
  language = {en},
  number = {4}
}

@book{barredaPhonToolsFunctionsPhonetics2015,
  title = {{{phonTools}}: {{Functions}} for Phonetics in {{R}}},
  author = {Barreda, S.},
  year = {2015},
  series = {R Package Version 0.2-2.1}
}

@article{batesFittingLinearMixedeffects2015,
  title = {Fitting Linear Mixed-Effects Models Using Lme4},
  author = {Bates, D. and Maechler, M. and Bolker, B. and Walker, S.},
  year = {2015},
  volume = {67},
  pages = {1--48},
  journal = {Journal of Statistical Software},
  number = {1}
}

@article{baudonckComparisonVowelProductions2011,
  title = {A {{Comparison}} of {{Vowel Productions}} in {{Prelingually Deaf Children Using Cochlear Implants}}, {{Severe Hearing}}-{{Impaired Children Using Conventional Hearing Aids}} and {{Normal}}-{{Hearing Children}}},
  author = {Baudonck, N. and Van Lierde, K. and Dhooge, I. and Corthals, P.},
  year = {2011},
  volume = {63},
  pages = {154--160},
  issn = {1421-9972, 1021-7762},
  doi = {10.1159/000318879},
  abstract = {Objective: The purpose of this study was to compare vowel productions by deaf cochlear implant (CI) children, hearingimpaired hearing aid (HA) children and normal-hearing (NH) children. Patients and Methods: 73 children [mean age: 9;14 years (years;months)] participated: 40 deaf CI children, 34 moderately to profoundly hearing-impaired HA children and 42 NH children. For the 3 corner vowels [a], [i] and [u], F1, F2 and the intrasubject SD were measured using the Praat software. Spectral separation between these vowel formants and vowel space were calculated. Results: The significant effects in the CI group all pertain to a higher intrasubject variability in formant values, whereas the significant effects in the HA group all pertain to lower formant values. Both hearing-impaired subgroups showed a tendency toward greater intervowel distances and vowel space. Conclusion: Several subtle deviations in the vowel production of deaf CI children and hearing-impaired HA children could be established, using a well-defined acoustic analysis. CI children as well as HA children in this study tended to overarticulate, which hypothetically can be explained by a lack of auditory feedback and an attempt to compensate it by proprioceptive feedback during articulatory maneuvers.},
  file = {/Users/megcychosz/Zotero/storage/CG6ZWBLP/Baudonck et al. - 2011 - A Comparison of Vowel Productions in Prelingually .pdf},
  journal = {Folia Phoniatrica et Logopaedica},
  language = {en},
  number = {3}
}

@article{beaverWhenSemanticsMeets2007,
  title = {When {{Semantics Meets Phonetics}}: {{Acoustical Studies}} of {{Second}}-{{Occurrence Focus}}},
  shorttitle = {When {{Semantics Meets Phonetics}}},
  author = {Beaver, David I. and Clark, Brady Zack. and Flemming, Edward Stanton and Jaeger, T. Florian. and Wolters, Maria.},
  year = {2007},
  volume = {83},
  pages = {245--276},
  issn = {1535-0665},
  doi = {10.1353/lan.2007.0053},
  file = {/Users/megcychosz/Zotero/storage/PK3T9WMR/Beaver et al. - 2007 - When Semantics Meets Phonetics Acoustical Studies.pdf},
  journal = {Language},
  language = {en},
  number = {2}
}

@article{beckmanGeneralizingLexiconsPredict2010,
  title = {Generalizing over Lexicons to Predict Consonant Mastery},
  author = {Beckman, Mary E. and Edwards, Jan},
  year = {2010},
  month = jan,
  volume = {1},
  issn = {1868-6346, 1868-6354},
  doi = {10.1515/labphon.2010.017},
  abstract = {When they first begin to talk, children show characteristic consonant errors, which are often described in terms that recall Neogrammarian sound change. For example, a Japanese child's production of the word kimono might be transcribed with an initial postalveolar affricate, as in typical velar-softening sound changes. Broad-stroke reviews of errors list striking commonalities across children acquiring different languages, whereas quantitative studies reveal enormous variability across children, some of which seems related to differences in consonant frequencies across different lexicons. This paper asks whether the appearance of commonalities across children acquiring different languages might be reconciled with the observed variability by referring to the ways in which sound change might affect frequencies in the lexicon. Correlational analyses were used to assess relationships between consonant accuracy in a database of recordings of toddlers acquiring Cantonese, English, Greek, or Japanese and two measures of consonant frequency: one specific to the lexicon being acquired, the other an average frequency calculated for the other three languages. Results showed generally positive trends, although the strength of the trends differed across measures and across languages. Many outliers in plots depicting the relationships suggested historical contingencies that have conspired to make for unexpected paths, much as in biological evolution.},
  file = {/Users/megcychosz/Zotero/storage/5PLKD49D/Beckman and Edwards - 2010 - Generalizing over lexicons to predict consonant ma.pdf},
  journal = {Laboratory Phonology},
  language = {en},
  number = {2}
}

@article{beckmanNotesSoundChange,
  title = {Notes on Sound Change / Acquisition, Age (Grading), and Gender for {{Plummer}} et al. Normalization Paper, Etc.},
  author = {Beckman, Mary E and Plummer, Andrew R},
  pages = {12},
  file = {/Users/megcychosz/Zotero/storage/978UYBKT/Beckman and Plummer - Notes on sound change  acquisition, age (grading).pdf},
  language = {en}
}

@article{beckmanSubmittedPublicationCole,
  title = {Submitted for Publication in {{J}}. {{Cole}} and {{J}}. {{Hualde}} (Eds.) {{Laboratory Phonology}} 9. {{Mouton}} de {{Gruyter}}. ({{Please}} Do Not Cite without Permission of the Authors until It Is in Print.)},
  author = {Beckman, Mary E and Munson, Benjamin and Edwards, Jan},
  pages = {27},
  abstract = {A growing body of evidence on adult phonological processing supports the idea that phonological knowledge emerges through generalization over the experience of acquiring and using words. Some of this evidence suggests that knowledge is hierarchical, with generalization occurring at several different levels of abstraction away from the raw sensory input. Each familiar word-form has a distributed representation in the parametric phonetic space, which captures relevant generalizations over an individual's experience of hearing and saying specific tokens of the same word, but a parallel coarser-grained representation can be composed on the fly to process novel forms in terms of generalizations over the neighborhood of different word-forms in the individual's mental lexicon. Results of several studies of two clinical populations suggest that these different types of phonological knowledge can develop separately. Children with phonological disorder resemble younger children with typical phonological development in terms of measures of the robustness of parametric phonetic representations, whereas children with specific language impairment look like children with smaller vocabularies in terms of their processing of nonwords.},
  file = {/Users/megcychosz/Zotero/storage/94BLNSAS/Beckman et al. - Submitted for publication in J. Cole and J. Hualde.pdf},
  language = {en}
}

@article{beddorTimeCourseIndividuals2018,
  title = {The Time Course of Individuals' Perception of Coarticulatory Information Is Linked to Their Production: {{Implications}} for Sound Change.},
  author = {Beddor, Patrice Speeter and Coetzee, Andries W and Styler, Will},
  year = {2018},
  volume = {94},
  pages = {931--968},
  file = {/Users/megcychosz/Zotero/storage/DSEX2JK7/Beddor et al. - 2018 - THE TIME COURSE OF INDIVIDUALS’ PERCEPTION OF COAR.pdf},
  journal = {Language},
  language = {en},
  number = {4}
}

@article{belardiRetrospectiveVideoAnalysis2017,
  title = {A {{Retrospective Video Analysis}} of {{Canonical Babbling}} and {{Volubility}} in {{Infants}} with {{Fragile X Syndrome}} at 9\textendash 12 {{Months}} of {{Age}}},
  author = {Belardi, Katie and Watson, Linda R. and Faldowski, Richard A. and Hazlett, Heather and Crais, Elizabeth and Baranek, Grace T. and McComish, Cara and Patten, Elena and Oller, D. Kimbrough},
  year = {2017},
  month = apr,
  volume = {47},
  pages = {1193--1206},
  issn = {0162-3257, 1573-3432},
  doi = {10.1007/s10803-017-3033-4},
  file = {/Users/megcychosz/Zotero/storage/8485Y5Y7/Belardi et al. - 2017 - A Retrospective Video Analysis of Canonical Babbli.pdf},
  journal = {Journal of Autism and Developmental Disorders},
  language = {en},
  number = {4}
}

@article{bellPredictabilityEffectsDurations2009,
  title = {Predictability Effects on Durations of Content and Function Words in Conversational {{English}}},
  author = {Bell, Alan and Brenier, Jason M. and Gregory, Michelle and Girand, Cynthia and Jurafsky, Dan},
  year = {2009},
  month = jan,
  volume = {60},
  pages = {92--111},
  issn = {0749596X},
  doi = {10.1016/j.jml.2008.06.003},
  abstract = {In a regression study of conversational speech, we show that frequency, contextual predictability, and repetition have separate contributions to word duration, despite their substantial correlations. We also found that content- and function-word durations are affected differently by their frequency and predictability. Content words are shorter when more frequent, and shorter when repeated, while function words are not so affected. Function words have shorter pronunciations, after controlling for frequency and predictability. While both content and function words are strongly affected by predictability from the word following them, sensitivity to predictability from the preceding word is largely limited to very frequent function words. The results support the view that content and function words are accessed differently in production. We suggest a lexical-access-based model of our results, in which frequency or repetition leads to shorter or longer word durations by causing faster or slower lexical access, mediated by a general mechanism that coordinates the pace of higher-level planning and the execution of the articulatory plan.},
  file = {/Users/megcychosz/Zotero/storage/BG9ITTM8/Bell et al. - 2009 - Predictability effects on durations of content and.pdf},
  journal = {Journal of Memory and Language},
  language = {en},
  number = {1}
}

@article{belmoreDevelopmentAuditoryFeedback1973,
  title = {The {{Development}} of {{Auditory Feedback Monitoring}}: {{Delayed Auditory Feedback Studies}} on the {{Vocalizations}} of {{Children Aged Six Months}} to 19 {{Months}}},
  shorttitle = {The {{Development}} of {{Auditory Feedback Monitoring}}},
  author = {Belmore, N. Fargo and {Kewley-Port}, Diane and Mobley, Richard L. and Goodman, Violet E.},
  year = {1973},
  month = dec,
  volume = {16},
  pages = {709--720},
  issn = {0022-4685},
  doi = {10.1044/jshr.1604.709},
  file = {/Users/megcychosz/Zotero/storage/UGJ7LVHK/Belmore et al. - 1973 - The Development of Auditory Feedback Monitoring D.pdf},
  journal = {Journal of Speech and Hearing Research},
  language = {en},
  number = {4}
}

@article{benderGeneralizedAdditiveModel2018,
  title = {A Generalized Additive Model Approach to Time-to-Event Analysis},
  author = {Bender, Andreas and Groll, Andreas and Scheipl, Fabian},
  year = {2018},
  month = jun,
  volume = {18},
  pages = {299--321},
  issn = {1471-082X, 1477-0342},
  doi = {10.1177/1471082X17748083},
  abstract = {This tutorial article demonstrates how time-to-event data can be modelled in a very flexible way by taking advantage of advanced inference methods that have recently been developed for generalized additive mixed models. In particular, we describe the necessary pre-processing steps for transforming such data into a suitable format and show how a variety of effects, including a smooth nonlinear baseline hazard, and potentially nonlinear and nonlinearly time-varying effects, can be estimated and interpreted. We also present useful graphical tools for model evaluation and interpretation of the estimated effects. Throughout, we demonstrate this approach using various application examples. The article is accompanied by a new R-package called pammtools implementing all of the tools described here.},
  file = {/Users/megcychosz/Zotero/storage/3GMIZN2C/Bender et al. - 2018 - A generalized additive model approach to time-to-e.pdf},
  journal = {Statistical Modelling},
  language = {en},
  number = {3-4}
}

@article{bensonBilingualSchoolingMozambique2004,
  title = {Bilingual Schooling in {{Mozambique}} and {{Bolivia}}: {{From}} Experimentation to Implementation},
  shorttitle = {Bilingual {{Schooling}} in {{Mozambique}} and {{Bolivia}}},
  author = {Benson, Carol},
  year = {2004},
  volume = {3},
  pages = {47--66},
  issn = {1568-4555},
  doi = {10.1023/B:LPOL.0000017725.62093.66},
  file = {/Users/megcychosz/Zotero/storage/Q9BDKRFJ/Benson - 2004 - Bilingual Schooling in Mozambique and Bolivia Fro.pdf},
  journal = {Language Policy},
  language = {en},
  number = {1}
}

@article{bentzEntropyWordsLearnability2017,
  title = {The {{Entropy}} of {{Words}}\textemdash{{Learnability}} and {{Expressivity}} across {{More}} than 1000 {{Languages}}},
  author = {Bentz, Christian and Alikaniotis, Dimitrios and Cysouw, Michael and {Ferrer-i-Cancho}, Ramon},
  year = {2017},
  month = jun,
  volume = {19},
  pages = {275},
  issn = {1099-4300},
  doi = {10.3390/e19060275},
  abstract = {The choice associated with words is a fundamental property of natural languages. It lies at the heart of quantitative linguistics, computational linguistics and language sciences more generally. Information theory gives us tools at hand to measure precisely the average amount of choice associated with words: the word entropy. Here, we use three parallel corpora, encompassing ca. 450 million words in 1916 texts and 1259 languages, to tackle some of the major conceptual and practical problems of word entropy estimation: dependence on text size, register, style and estimation method, as well as non-independence of words in co-text. We present two main findings: Firstly, word entropies display relatively narrow, unimodal distributions. There is no language in our sample with a unigram entropy of less than six bits/word. We argue that this is in line with information-theoretic models of communication. Languages are held in a narrow range by two fundamental pressures: word learnability and word expressivity, with a potential bias towards expressivity. Secondly, there is a strong linear relationship between unigram entropies and entropy rates. The entropy difference between words with and without co-textual information is narrowly distributed around ca. three bits/word. In other words, knowing the preceding text reduces the uncertainty of words by roughly the same amount across languages of the world.},
  file = {/Users/megcychosz/Zotero/storage/9ZYA7J8Y/Bentz et al. - 2017 - The Entropy of Words—Learnability and Expressivity.pdf},
  journal = {Entropy},
  language = {en},
  number = {6}
}

@article{berentNoIntegrationStructured2019,
  title = {No Integration without Structured Representations: {{Response}} to {{Pater}}},
  shorttitle = {No Integration without Structured Representations},
  author = {Berent, Iris and Marcus, Gary},
  year = {2019},
  issn = {1535-0665},
  doi = {10.1353/lan.2019.0006},
  file = {/Users/megcychosz/Zotero/storage/E2LM979E/Berent and Marcus - 2019 - No integration without structured representations.pdf},
  journal = {Language},
  language = {en}
}

@article{berentPhonologicalMind2013,
  title = {The Phonological Mind},
  author = {Berent, Iris},
  year = {2013},
  month = jul,
  volume = {17},
  pages = {319--327},
  issn = {13646613},
  doi = {10.1016/j.tics.2013.05.004},
  file = {/Users/megcychosz/Zotero/storage/PZ7TGWYW/Berent - 2013 - The phonological mind.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {7}
}

@article{berentRoleVariablesPhonology2012,
  title = {On the {{Role}} of {{Variables}} in {{Phonology}}: {{Remarks}} on {{Hayes}} and {{Wilson}} 2008},
  shorttitle = {On the {{Role}} of {{Variables}} in {{Phonology}}},
  author = {Berent, Iris and Wilson, Colin and Marcus, Gary F. and Bemis, Douglas K.},
  year = {2012},
  month = jan,
  volume = {43},
  pages = {97--119},
  issn = {0024-3892, 1530-9150},
  doi = {10.1162/LING_a_00075},
  abstract = {A computational model by Hayes and Wilson (2008) seemingly captures a diverse range of phonotactic phenomena without variables, contrasting with the presumptions of many formal theories. Here, we examine the plausibility of this approach by comparing generalizations of identity restrictions by this architecture and human learners. Whereas humans generalize identity restrictions broadly, to both native and nonnative phonemes, the original model and several related variants failed to generalize to nonnative phonemes. In contrast, a revised model equipped with variables more closely matches human behavior. These findings suggest that, like syntax, phonological grammars are endowed with algebraic relations among variables that support acrossthe-board generalizations.},
  file = {/Users/megcychosz/Zotero/storage/4FL9U8H5/Berent et al. - 2012 - On the Role of Variables in Phonology Remarks on .pdf},
  journal = {Linguistic Inquiry},
  language = {en},
  number = {1}
}

@article{berentUniversalConstraintsSound2010,
  title = {Universal Constraints on the Sound Structure of Language: {{Phonological}} or Acoustic?},
  shorttitle = {Universal Constraints on the Sound Structure of Language},
  author = {Berent, Iris and Lennertz, Tracy},
  year = {2010},
  volume = {36},
  pages = {212--223},
  issn = {1939-1277, 0096-1523},
  doi = {10.1037/a0017638},
  file = {/Users/megcychosz/Zotero/storage/LMBXXWL5/Berent and Lennertz - 2010 - Universal constraints on the sound structure of la.pdf},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  language = {en},
  number = {1}
}

@article{bergelson69MonthsHuman2012,
  title = {At 6-9 Months, Human Infants Know the Meanings of Many Common Nouns},
  author = {Bergelson, E. and Swingley, D.},
  year = {2012},
  month = feb,
  volume = {109},
  pages = {3253--3258},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1113380109},
  file = {/Users/megcychosz/Zotero/storage/NZM3D29B/Bergelson and Swingley - 2012 - At 6-9 months, human infants know the meanings of .pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {9}
}

@book{bergelsonBergelsonSeedlingsHomeBank2017,
  title = {Bergelson {{Seedlings HomeBank Corpus}}},
  author = {Bergelson, Elika},
  year = {2017}
}

@article{bergelsonDayDayHour2019,
  title = {Day by Day, Hour by Hour: {{Naturalistic}} Language Input to Infants},
  shorttitle = {Day by Day, Hour by Hour},
  author = {Bergelson, Elika and Amatuni, Andrei and Dailey, Shannon and Koorathota, Sharath and Tor, Shaelise},
  year = {2019},
  volume = {22},
  pages = {e12715},
  issn = {1363-755X, 1467-7687},
  doi = {10.1111/desc.12715},
  file = {/Users/megcychosz/Zotero/storage/UFWM8Q2C/Bergelson et al. - 2019 - Day by day, hour by hour Naturalistic language in.pdf;/Users/megcychosz/Zotero/storage/Z6WIJAIS/nihms214573.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {1}
}

@article{bergelsonNatureOriginsLexicon2017,
  title = {Nature and Origins of the Lexicon in 6-Mo-Olds},
  author = {Bergelson, Elika and Aslin, Richard N.},
  year = {2017},
  month = dec,
  volume = {114},
  pages = {12916--12921},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1712966114},
  abstract = {Recent research reported the surprising finding that even 6-mo-olds understand common nouns [Bergelson E, Swingley D (2012)               Proc Natl Acad Sci USA               109:3253\textendash 3258]. However, is their early lexicon structured and acquired like older learners? We test 6-mo-olds for a hallmark of the mature lexicon: cross-word relations. We also examine whether properties of the home environment that have been linked with lexical knowledge in older children are detectable in the initial stage of comprehension. We use a new dataset, which includes in-lab comprehension and home measures from the same infants. We find evidence for cross-word structure: On seeing two images of common nouns, infants looked significantly more at named target images when the competitor images were semantically unrelated (e.g., milk and foot) than when they were related (e.g., milk and juice), just as older learners do. We further find initial evidence for home-lab links: common noun ``copresence'' (i.e., whether words' referents were present and attended to in home recordings) correlated with in-lab comprehension. These findings suggest that, even in neophyte word learners, cross-word relations are formed early and the home learning environment measurably helps shape the lexicon from the outset.},
  file = {/Users/megcychosz/Zotero/storage/FGB54WFV/Bergelson and Aslin - 2017 - Nature and origins of the lexicon in 6-mo-olds.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {49}
}

@article{bergelsonWhatNorthAmerican2019,
  title = {What {{Do North American Babies Hear}}? {{A}} Large-scale Cross-corpus Analysis},
  shorttitle = {What {{Do North American Babies Hear}}?},
  author = {Bergelson, Elika and Casillas, Marisa and Soderstrom, Melanie and Seidl, Amanda and Warlaumont, Anne S. and Amatuni, Andrei},
  year = {2019},
  volume = {22},
  pages = {e12724},
  issn = {1363-755X, 1467-7687},
  doi = {10.1111/desc.12724},
  abstract = {A range of demographic variables influences how much speech young children hear. However, because studies have used vastly different sampling methods, quantitative comparison of interlocking demographic effects has been nearly impossible, across or within studies. We harnessed a unique collection of existing naturalistic, day-l\-ong recordings from 61 homes across four North American cities to examine language input as a function of age, gender, and maternal education. We analyzed adult speech heard by 3-\- to 20-\-month-o\- lds who wore audio recorders for an entire day. We annotated speaker gender and speech register (child-\-directed or adult-\-directed) for 10,861 utterances from female and male adults in these recordings. Examining age, gender, and maternal education collectively in this ecologically valid dataset, we find several key results. First, the speaker gender imbalance in the input is striking: children heard 2\textendash 3\texttimes{} more speech from females than males. Second, children in higher-\- maternal education homes heard more child-d\-irected speech than those in lower-\-maternal education homes. Finally, our analyses revealed a previously unreported effect: the proportion of child-d\- irected speech in the input increases with age, due to a decrease in adult-\-directed speech with age. This large-s\- cale analysis is an important step forward in collectively examining demographic variables that influence early development, made possible by pooled, comparable, day-\-long recordings of children's language environments. The audio recordings, annotations, and annotation software are readily available for reuse and reanalysis by other researchers.},
  file = {/Users/megcychosz/Zotero/storage/R6C56YC2/Bergelson et al. notes.rtf;/Users/megcychosz/Zotero/storage/WUC9YYC2/Bergelson et al. - 2019 - What Do North American Babies Hear A large‐scale .pdf},
  journal = {Developmental Science},
  language = {en},
  number = {1}
}

@article{bergesonEffectsCongenitalHearing2010,
  title = {Effects of Congenital Hearing Loss and Cochlear Implantation on Audiovisual Speech Perception in Infants and Children},
  author = {Bergeson, Tonya R. and Houston, Derek M. and Miyamoto, Richard T.},
  year = {2010},
  volume = {28},
  pages = {157--165},
  issn = {0922-6028},
  doi = {10.3233/RNN-2010-0522},
  abstract = {Purpose Cochlear implantation has recently become available as an intervention strategy for young children with profound hearing impairment. In fact, infants as young as 6 months are now receiving cochlear implants (CIs), and even younger infants are being fitted with hearing aids (HAs). Because early audiovisual experience may be important for normal development of speech perception, it is important to investigate the effects of a period of auditory deprivation and amplification type on multimodal perceptual processes of infants and children. The purpose of this study was to investigate audiovisual perception skills in normal-hearing (NH) infants and children and deaf infants and children with CIs and HAs of similar chronological ages. Methods We used an Intermodal Preferential Looking Paradigm to present the same woman's face articulating two words (``judge'' and ``back'') in temporal synchrony on two sides of a TV monitor, along with an auditory presentation of one of the words. Results The results showed that NH infants and children spontaneously matched auditory and visual information in spoken words; deaf infants and children with HAs did not integrate the audiovisual information; and deaf infants and children with CIs initially did not initially integrate the audiovisual information but gradually matched the auditory and visual information in spoken words. Conclusions These results suggest that a period of auditory deprivation affects multimodal perceptual processes that may begin to develop normally after several months of auditory experience.},
  file = {/Users/megcychosz/Zotero/storage/R82QAQHW/Bergeson et al. - 2010 - Effects of congenital hearing loss and cochlear im.pdf},
  journal = {Restorative neurology and neuroscience},
  number = {2},
  pmcid = {PMC5675532},
  pmid = {20404405}
}

@article{bergesonLongitudinalStudyAudiovisual2003,
  title = {A {{Longitudinal Study}} of {{Audiovisual Speech Perception}} by {{Children}} with {{Hearing Loss Who}} Have {{Cochlear Implants}}},
  author = {Bergeson, Tonya R. and Pisoni, David B. and Davis, Rebecca A. O.},
  year = {2003},
  volume = {103},
  pages = {347--370},
  issn = {0042-8639},
  abstract = {The present study investigated the development of audiovisual speech perception skills in children who are prelingually deaf and received cochlear implants. We analyzed results from the Pediatric Speech Intelligibility () test of audiovisual spoken word and sentence recognition skills obtained from a large group of young children with cochlear implants enrolled in a longitudinal study, from pre-implantation to 3 years post-implantation. The results revealed better performance under the audiovisual presentation condition compared with auditory-alone and visual-alone conditions. Performance in all three conditions improved over time following implantation. The results also revealed differential effects of early sensory and linguistic experience. Children from oral communication (OC) education backgrounds performed better overall than children from total communication (TC backgrounds. Finally, children in the early-implanted group performed better than children in the late-implanted group in the auditory-alone presentation condition after 2 years of cochlear implant use, whereas children in the late-implanted group performed better than children in the early-implanted group in the visual-alone condition. The results of the present study suggest that measures of audiovisual speech perception may provide new methods to assess hearing, speech, and language development in young children with cochlear implants.},
  file = {/Users/megcychosz/Zotero/storage/7VFPN33M/Bergeson et al. - 2003 - A Longitudinal Study of Audiovisual Speech Percept.pdf},
  journal = {The Volta review},
  number = {4},
  pmcid = {PMC3130603},
  pmid = {21743753}
}

@article{bergesonMothersSpeechHearingImpaired2006,
  title = {Mothers' {{Speech}} to {{Hearing}}-{{Impaired Infants}} and {{Children With Cochlear Implants}}},
  author = {Bergeson, Tonya R. and Miller, Rachel J. and McCune, Kasi},
  year = {2006},
  volume = {10},
  pages = {221--240},
  issn = {1532-7078},
  doi = {10.1207/s15327078in1003_2},
  abstract = {This study investigated the effects of age, hearing loss, and cochlear implantation on mothers' speech to infants and children. We recorded normal-hearing (NH) mothers speaking to their children as they typically would do at home and speaking to an adult experimenter. Nine infants (10\textendash 37 months) were hearing-impaired and had used a cochlear implant (CI) for 3 to 18 months. Eighteen NH infants and children were matched either by chronological age (10\textendash 37 months) or hearing experience (3\textendash 18 months) to the CI children. Prosodic characteristics such as fundamental frequency, utterance duration, and pause duration were measured across utterances in the speech samples. The results revealed that mothers use a typical infant-directed speech style when speaking to hearing-impaired children with CIs. The results also suggested that NH mothers speak with more similar vocal styles to NH children and hearing-impaired children with CIs when matched by hearing experience rather than chronological age. Thus, mothers are sensitive to hearing experience and linguistic abilities of their NH children as well as hearing-impaired children with CIs.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15327078in1003\_2},
  file = {/Users/megcychosz/Zotero/storage/XGBP95LP/Bergeson et al. - 2006 - Mothers' Speech to Hearing-Impaired Infants and Ch.pdf;/Users/megcychosz/Zotero/storage/7NS3PRTU/s15327078in1003_2.html},
  journal = {Infancy},
  language = {en},
  number = {3}
}

@article{bergmannSociodemographicInfluencesLanguage2016,
  title = {Socio-Demographic Influences on Language Structure and Change: {{Not}} All Learners Are the Same (Commentary on {{Christiansen}} \& {{Chater}})},
  author = {Bergmann, Till and Dale, Rick and Lupyan, Gary},
  year = {2016},
  volume = {39},
  pages = {22--23},
  journal = {Behavioral and Brain Sciences}
}

@inproceedings{bergmannTopDownBottomupTheories2017,
  title = {Top-{{Down}} versus Bottom-up Theories of Phonological Acquisition: {{A}} Big Data Approach},
  shorttitle = {Top-{{Down}} versus {{Bottom}}-{{Up Theories}} of {{Phonological Acquisition}}},
  booktitle = {Interspeech 2017},
  author = {Bergmann, Christina and Tsuji, Sho and Cristia, Alejandrina},
  year = {2017},
  pages = {2103--2107},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2017-1443},
  file = {/Users/megcychosz/Zotero/storage/2R3D3CL6/Bergmann et al. - 2017 - Top-Down versus Bottom-Up Theories of Phonological.PDF;/Users/megcychosz/Zotero/storage/75832DVM/model_comparison.pdf;/Users/megcychosz/Zotero/storage/J8EHTH7C/mathematical_terminology.pdf;/Users/megcychosz/Zotero/storage/NN3VQYIW/parameter_estimation.pdf;/Users/megcychosz/Zotero/storage/SW9ZPPPZ/greek_symbols.pdf;/Users/megcychosz/Zotero/storage/Y4NZPK29/introduction_to_modeling.pdf},
  language = {en}
}

@article{berkoChildLearningEnglish1958,
  title = {The Child's Learning of {{English}} Morphology},
  author = {Berko, Jean},
  year = {1958},
  volume = {14},
  pages = {150--177},
  issn = {0043-7956, 2373-5112},
  doi = {10.1080/00437956.1958.11659661},
  file = {/Users/megcychosz/Zotero/storage/ZGZZFVR9/Berko - 1958 - The Child's Learning of English Morphology.pdf},
  journal = {Word},
  language = {en},
  number = {2-3}
}

@book{bernhardtHandbookPhonologicalDevelopment1998,
  title = {Handbook of Phonological Development: {{From}} the Perspective of Constraint-Based Nonlinear Phonology.},
  editor = {Bernhardt, B. H. and Stemberger, J. P.},
  year = {1998},
  publisher = {{Academic Press}},
  address = {{New York, NY}}
}

@article{bernsteinAcousticHearingCan2020,
  title = {Acoustic Hearing Can Interfere with Single-Sided Deafness Cochlear-Implant Speech Perception},
  author = {Bernstein, J. G. and Stakhovskaya, O.A. and Jensen, K K. and Goupell, Matthew J.},
  year = {2020},
  volume = {41},
  pages = {747--761},
  journal = {Ear and Hearing},
  number = {4}
}

@article{bernsteinratnerEffectsWordFrequency2009,
  title = {Effects of Word Frequency and Phonological Neighborhood Characteristics on Confrontation Naming in Children Who Stutter and Normally Fluent Peers},
  author = {Bernstein Ratner, Nan and Newman, Rochelle and Strekas, Amy},
  year = {2009},
  month = dec,
  volume = {34},
  pages = {225--241},
  issn = {0094730X},
  doi = {10.1016/j.jfludis.2009.09.005},
  abstract = {In a prior study (Newman \& Bernstein Ratner, 2007), we examined the effects of word frequency and phonological neighborhood characteristics on confrontation naming latency, accuracy and fluency in adults who stutter and typically fluent speakers. A small difference in accuracy favoring fluent adults was noted, but no other patterns differentiated fluent speaker responses from those obtained from the adults who stutter. Because lexical organization or retrieval differences might be more easily observed in less mature language users, we replicated the experiment using 15 children who stutter (ages 4;10 16;2) and age- and gender-matched peers. Results replicated the earlier study: the two groups of participants showed strikingly similar patterns of responses based on word frequency and neighborhood characteristics. There were also no differences in naming accuracy overall between the two groups. Given our results and those of other researchers who have explored the impact of neighborhood variables on lexical retrieval in people who stutter, we suggest that differences between language production in PWS and fluent speakers are not likely to involve atypical phonological organization of lexical neighborhoods.},
  file = {/Users/megcychosz/Zotero/storage/M9YVHGJ3/Bernstein Ratner et al. - 2009 - Effects of word frequency and phonological neighbo.pdf},
  journal = {Journal of Fluency Disorders},
  language = {en},
  number = {4}
}

@article{bernsteinratnerWhyTalkChildren2013,
  title = {Why {{Talk}} with {{Children Matters}}: {{Clinical Implications}} of {{Infant}}- and {{Child}}-{{Directed Speech Research}}},
  author = {Bernstein Ratner, Nan},
  year = {2013},
  volume = {34},
  pages = {203--214},
  file = {/Users/megcychosz/Zotero/storage/QKEP2CP2/Bernstein Ratner - 2013 - Why Talk with Children Matters Clinical Implicati.pdf},
  journal = {Seminars in Speech and Language},
  number = {04}
}

@article{bertiTongueDisplacementDurational2016,
  title = {Tongue Displacement and Durational Characteristics of Normal and Disordered {{Brazilian Portuguese}} Liquids},
  author = {Berti, Larissa and Boer, Gillian De and Bressmann, Tim},
  year = {2016},
  month = feb,
  volume = {30},
  pages = {131--149},
  issn = {0269-9206, 1464-5076},
  doi = {10.3109/02699206.2015.1116607},
  abstract = {The goal of the present study was to characterize normal and disordered Brazilian Portuguese liquids. The research hypotheses were that disordered liquid sounds would be characterized by (1) longer syllable and segment durations, (2) larger and more undifferentiated displacement of the tongue and (3) that the speech errors would show sub-phonemic differences depending on the target sound. The participants of this study were 11 children with phonological disorders and 9 control participants matched for age and educational background. The children's tongue movement in the sagittal plane was recorded with ultrasound. The speech stimuli consisted of 3 repetitions of 5 words representing the four Brazilian Portuguese liquids /l/, /{$\Elztrny$}/, /{$\Elzfhr$}/ and /ʀ/ in the context of the vowel /a/. A panel of four listeners transcribed each of the productions and classified them as correct or incorrect. The outcome measures were based on duration (syllable duration, ratio L/V) and tongue displacement (percentage average displacement, anterior displacement, posterior displacement). Based on mixed model analyses of variance, the first research hypothesis was confirmed for the /l/ and /{$\Elzfhr$}/ targets, but not for the /ʀ/ and /{$\Elztrny$}/ targets. The second hypothesis was partially confirmed. The third hypothesis was confirmed. The research serves to illustrate the effects of phonological disorder on the phonetic realisation of Brazilian Portuguese liquid sounds.},
  file = {/Users/megcychosz/Zotero/storage/TNHDV5A7/Berti et al. - 2016 - Tongue displacement and durational characteristics.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {2}
}

@incollection{bestNonnativeSecondlanguageSpeech2007,
  title = {Nonnative and Second-Language Speech Perception: {{Commonalities}} and Complementarities},
  shorttitle = {Nonnative and Second-Language Speech Perception},
  booktitle = {Language {{Learning}} \& {{Language Teaching}}},
  author = {Best, Catherine T. and Tyler, Michael D.},
  editor = {Bohn, Ocke-Schwen and Munro, Murray J.},
  year = {2007},
  volume = {17},
  pages = {13--34},
  publisher = {{John Benjamins Publishing Company}},
  address = {{Amsterdam}},
  doi = {10.1075/lllt.17.07bes},
  abstract = {Language experience systematically constrains perception of speech contrasts that deviate phonologically and/or phonetically from those of the listener's native language. These effects are most dramatic in adults, but begin to emerge in infancy and undergo further development through at least early childhood. The central question addressed here is: How do nonnative speech perception findings bear on phonological and phonetic aspects of second language (L2) perceptual learning? A frequent assumption has been that nonnative speech perception can also account for the relative difficulties that late learners have with specific L2 segments and contrasts. However, evaluation of this assumption must take into account the fact that models of nonnative speech perception such as the Perceptual Assimilation Model (PAM) have focused primarily on na\"ive listeners, whereas models of L2 speech acquisition such as the Speech Learning Model (SLM) have focused on experienced listeners. This chapter probes the assumption that L2 perceptual learning is determined by nonnative speech perception principles, by considering the commonalities and complementarities between inexperienced listeners and those learning an L2, as viewed from PAM and SLM. Among the issues examined are how language learning may affect perception of phonetic vs. phonological information, how monolingual vs. multiple language experience may impact perception, and what these may imply for attunement of speech perception to changes in the listener's language environment.},
  file = {/Users/megcychosz/Zotero/storage/WCEG6QWK/Best and Tyler - 2007 - Nonnative and second-language speech perception C.pdf},
  isbn = {978-90-272-1973-2 978-90-272-9287-2},
  language = {en}
}

@article{bialystokGlobalLocalTrailmaking2010,
  title = {Global\textendash Local and Trail-Making Tasks by Monolingual and Bilingual Children: {{Beyond}} Inhibition.},
  shorttitle = {Global\textendash Local and Trail-Making Tasks by Monolingual and Bilingual Children},
  author = {Bialystok, Ellen},
  year = {2010},
  month = jan,
  volume = {46},
  pages = {93--105},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/a0015466},
  abstract = {In three experiments, a total of 151 monolingual and bilingual 6-year-olds performed similarly on measures of language and cognitive ability but bilinguals solved the global-local and trail-making tasks more rapidly than monolinguals. This bilingual advantage was found not only for the traditionally demanding conditions, incongruent global-local trials and Trails B, but also for the conditions not usually considered to be cognitively demanding, congruent global-local trials and Trails A. All the children performed similarly when congruent trials were presented in a single block or perceptually simple stimuli were used, ruling out speed differences between the groups. The results demonstrate a bilingual advantage in processing complex stimuli in tasks that require executive processing components for conflict resolution, including switching and updating, even when no inhibition appears to be involved. They also suggest that simple conditions of the trail-making and global-local tasks involve some level of effortful processing for young children. Finally, the bilingual advantage in the trail-making task suggests that the interpretation of standardized measures of executive control needs to be reconsidered for children with specific experiences such as bilingualism.},
  file = {/Users/megcychosz/Zotero/storage/UEBMAFN9/Bialystok - 2010 - Global–local and trail-making tasks by monolingual.pdf},
  journal = {Developmental Psychology},
  language = {en},
  number = {1}
}

@article{bidelmanAcousticNoiseVision2019,
  title = {Acoustic Noise and Vision Differentially Warp the Auditory Categorization of Speech},
  author = {Bidelman, Gavin M. and Sigley, Lauren and Lewis, Gwyneth A.},
  year = {2019},
  month = jul,
  volume = {146},
  pages = {60--70},
  issn = {0001-4966},
  doi = {10.1121/1.5114822},
  file = {/Users/megcychosz/Zotero/storage/WV7LRG63/Bidelman et al. - 2019 - Acoustic noise and vision differentially warp the .pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{bijeljac-babicEffectBilingualismLexical2012,
  title = {Effect of Bilingualism on Lexical Stress Pattern Discrimination in {{French}}-Learning Infants},
  author = {{Bijeljac-Babic}, Ranka and Serres, Josette and H{\"o}hle, Barbara and Nazzi, Thierry},
  editor = {{Rodriguez-Fornells}, Antoni},
  year = {2012},
  month = feb,
  volume = {7},
  pages = {e30843},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0030843},
  file = {/Users/megcychosz/Zotero/storage/YSLFBSGF/Bijeljac-Babic et al. - 2012 - Effect of Bilingualism on Lexical Stress Pattern D.pdf},
  journal = {PLoS ONE},
  language = {en},
  number = {2}
}

@book{birdsonBilingualLanguageProfile2012,
  title = {Bilingual {{Language Profile}}: {{An Easy}}-to-{{Use Instrument}} to {{Assess Bilingualism}}},
  author = {Birdson, D. and Gertken, L. M. and Amengual, M.},
  year = {2012},
  address = {{COERLL, University of Texas at Austin}}
}

@article{blomquistSemanticPredictionChildrenunderreview,
  title = {Semantic Prediction by Children with Cochlear Implants},
  author = {Blomquist, Christina and Newman, Rochelle S. and Huang, Yi Ting and Edwards, Jan R.},
  year = {under review},
  file = {/Users/megcychosz/Zotero/storage/8UF2QGEX/SubmittedManuscript.pdf;/Users/megcychosz/Zotero/storage/F2CXCEY7/SupplementaryMaterials.pdf}
}

@article{bloomCapacitiesUnderylingWord1998,
  title = {Capacities Underyling Word Learning},
  author = {Bloom, P. and Markson, L.},
  year = {1998},
  volume = {2},
  pages = {67--73},
  file = {/Users/megcychosz/Zotero/storage/JWUC5KQ7/2 bloom markson capacities word learning.pdf},
  journal = {Trends in Cognitive Sciences},
  number = {2}
}

@misc{boersmaPraatDoingPhonetics2020,
  title = {Praat: Doing Phonetics by Computer},
  author = {Boersma, P. and Weenink, D.},
  year = {2020}
}

@article{boeWhichWayDawn2019,
  title = {Which Way to the Dawn of Speech?: {{Reanalyzing}} Half a Century of Debates and Data in Light of Speech Science},
  shorttitle = {Which Way to the Dawn of Speech?},
  author = {Bo{\"e}, Louis-Jean and Sawallis, Thomas R. and Fagot, Jo{\"e}l and Badin, Pierre and Barbier, Guillaume and Captier, Guillaume and M{\'e}nard, Lucie and Heim, Jean-Louis and Schwartz, Jean-Luc},
  year = {2019},
  month = dec,
  volume = {5},
  pages = {eaaw3916},
  issn = {2375-2548},
  doi = {10.1126/sciadv.aaw3916},
  abstract = {Recent articles on primate articulatory abilities are revolutionary regarding speech emergence, a crucial aspect of language evolution, by revealing a human-like system of proto-vowels in nonhuman primates and implicitly throughout our hominid ancestry. This article presents both a schematic history and the state of the art in primate vocalization research and its importance for speech emergence. Recent speech research advances allow more incisive comparison of phylogeny and ontogeny and also an illuminating reinterpretation of vintage primate vocalization data. This review produces three major findings. First, even among primates, laryngeal descent is not uniquely human. Second, laryngeal descent is not required to produce contrasting formant patterns in vocalizations. Third, living nonhuman primates produce vocalizations with contrasting formant patterns. Thus, evidence now overwhelmingly refutes the long-standing laryngeal descent theory, which pushes back ``the dawn of speech'' beyond \textasciitilde 200 ka ago to over \textasciitilde 20 Ma ago, a difference of two orders of magnitude.},
  file = {/Users/megcychosz/Zotero/storage/BVQ2E4P6/Boë et al. - 2019 - Which way to the dawn of speech Reanalyzing half.pdf},
  journal = {Science Advances},
  language = {en},
  number = {12}
}

@misc{bolkerBroomMixedTidying2020,
  title = {Broom.Mixed: {{Tidying}} Methods for Mixed Models},
  author = {Bolker, B. and Robinson, D},
  year = {2020}
}

@incollection{bollenEightMythsCausality2013,
  title = {Eight {{Myths About Causality}} and {{Structural Equation Models}}},
  booktitle = {Handbook of {{Causal Analysis}} for {{Social Research}}},
  author = {Bollen, Kenneth A. and Pearl, Judea},
  editor = {Morgan, Stephen L.},
  year = {2013},
  pages = {301--328},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  doi = {10.1007/978-94-007-6094-3_15},
  abstract = {Causality was at the center of the early history of Structural Equation Models (SEMs) which continue to serve as the most popular approach to causal analysis in the social sciences. Through decades of development critics and defenses of the capability of SEMs to support causal inference have accumulated. A variety of misunderstandings and myths about the nature of SEMs and their role in causal analysis have emerged and their repetition has led some to believe they are true. Our paper is organized by presenting eight myths about causality and SEMs in the hope that this will lead to a more accurate understanding. More specifically, the eight myths are: (1) SEMs aim to establish causal relations from associations alone, (2) SEMs and regression are essentially equivalent, (3) No causation without manipulation, (4) SEMs are not equipped to handle nonlinear causal relationships, (5) A potential outcome framework is more principled than SEMs, (6) SEMs are not applicable to experiments with randomized treatments, (7) Mediation analysis in SEMs is inherently noncausal, and (8) SEMs do not test any major part of the theory against the data. We present the facts that dispell these myths, describe what SEMs can and cannot do, and briefly present our critique of current practice using SEMs. We conclude that the current capabilities of SEMs to formalize and implement causal inference tasks are indispensible; its potential to do more is even greater.},
  file = {/Users/megcychosz/Zotero/storage/9LURBE9C/Bollen and Pearl - 2013 - Eight Myths About Causality and Structural Equatio.pdf},
  isbn = {978-94-007-6093-6 978-94-007-6094-3},
  language = {en}
}

@article{bornsteinMaternalResponsivenessInfants1992,
  title = {Maternal Responsiveness to Infants in Three Societies: {{The United States}}, {{France}}, and {{Japan}}},
  author = {Bornstein, M.H. and {Tamis-LeMonda}, Catherine S and Ludematn, Pamela and Tal, Joseph and Toda, Sueko and Rahn, Charles W. and P{\^e}cheux, Marie-Germaine and Azuma, Hiroshi and Vardi, Danya},
  year = {1992},
  volume = {63},
  pages = {808--821},
  abstract = {The present study examines and compares characteristics of maternal responsiveness during home-based naturalistic interactions of mother-infant dyads in New York City, Paris, and Tokyo. Results indicate some culture-general as well as some culture-specific patterns of responsiveness. In all three places, mothers and infants manifested a high degree of specificity and mutual appropriateness: Mothers responded to infants' exploration of the environment with encouragement to the environment, to infants' vocaliz;ng nondistress with imitation, and to infants' vocalizing distress with nurturance. Differences in maternal responsiveness among the three cultures tended to occur to infant looking rather than to infant vocalizing, and the most salient West--East difference involved Japanese and Americans with respect to dyadic versus extradyadic loci of interaction. Potential sources of cultural variation and implications of differences in responsiveness for child development in different cultural contexts are discussed.},
  file = {/Users/megcychosz/Zotero/storage/WDZYPVZC/Tamis-LeMonda et al. - National Institute of Child Health and Human Devel.pdf},
  journal = {Child Development},
  language = {en},
  number = {4}
}

@article{boskerAccountingRatedependentCategory2017,
  title = {Accounting for Rate-Dependent Category Boundary Shifts in Speech Perception},
  author = {Bosker, Hans Rutger},
  year = {2017},
  month = jan,
  volume = {79},
  pages = {333--343},
  issn = {1943-3921, 1943-393X},
  doi = {10.3758/s13414-016-1206-4},
  abstract = {The perception of temporal contrasts in speech is known to be influenced by the speech rate in the surrounding context. This rate-dependent perception is suggested to involve general auditory processes because it is also elicited by nonspeech contexts, such as pure tone sequences. Two general auditory mechanisms have been proposed to underlie ratedependent perception: durational contrast and neural entrainment. This study compares the predictions of these two accounts of rate-dependent speech perception by means of four experiments, in which participants heard tone sequences followed by Dutch target words ambiguous between /ɑs/ Bash\^ and /a:s/ Bbait\^. Tone sequences varied in the duration of tones (short vs. long) and in the presentation rate of the tones (fast vs. slow). Results show that the duration of preceding tones did not influence target perception in any of the experiments, thus challenging durational contrast as explanatory mechanism behind rate-dependent perception. Instead, the presentation rate consistently elicited a category boundary shift, with faster presentation rates inducing more /a:s/ responses, but only if the tone sequence was isochronous. Therefore, this study proposes an alternative, neurobiologically plausible account of ratedependent perception involving neural entrainment of endogenous oscillations to the rate of a rhythmic stimulus.},
  file = {/Users/megcychosz/Zotero/storage/BI2T8J5X/Bosker - 2017 - Accounting for rate-dependent category boundary sh.pdf},
  journal = {Attention, Perception, \& Psychophysics},
  language = {en},
  number = {1}
}

@article{boutonAtypicalPhonologicalProcessing2015,
  title = {Atypical Phonological Processing Impairs Written Word Recognition in Children with Cochlear Implants},
  author = {Bouton, Sophie and Col{\'e}, Pascale and Serniclaes, Willy and Duncan, Lynne G. and Giraud, Anne-Lise},
  year = {2015},
  month = jul,
  volume = {30},
  pages = {684--699},
  issn = {2327-3798, 2327-3801},
  doi = {10.1080/23273798.2014.1002796},
  file = {/Users/megcychosz/Zotero/storage/TPKNZYP4/Bouton et al. - 2015 - Atypical phonological processing impairs written w.pdf},
  journal = {Language, Cognition and Neuroscience},
  language = {en},
  number = {6}
}

@article{boutonInfluenceLexicalKnowledge2012,
  title = {The Influence of Lexical Knowledge on Phoneme Discrimination in Deaf Children with Cochlear Implants},
  author = {Bouton, Sophie and Col{\'e}, Pascale and Serniclaes, Willy},
  year = {2012},
  month = feb,
  volume = {54},
  pages = {189--198},
  issn = {01676393},
  doi = {10.1016/j.specom.2011.08.002},
  abstract = {This paper addresses the questions of whether lexical information influences phoneme discrimination in children with cochlear implants (CI) and whether this influence is similar to what occurs in normal-hearing (NH) children. Previous research with CI children evidenced poor accuracy in phonemic perception, which might have an incidence on the use of lexical information in phoneme discrimination. A discrimination task with French vowels and consonants in minimal pairs of words (e.g., mouche/bouche) or pseudowords (e.g., moute/boute) was used to search for possible differences in the use of lexical knowledge between CI children and NH children matched for listening age. Minimal pairs differed in a single consonant or vowel feature (e.g., nasality, vocalic aperture, voicing) to unveil possible interactions between phonological/acoustic and lexical processing. The results showed that both the word and pseudoword discrimination of CI children are inferior to those of NH children, with the magnitude of the deficit depending on the feature. However, word discrimination was better than pseudoword discrimination, and this lexicality effect was equivalent for both CI and NH children. Further, this lexicality effect did not depend on the feature in either group. Our results support the idea that hearing deprivation period may not have consequence on lexical processes implied on speech perception.},
  file = {/Users/megcychosz/Zotero/storage/BZDX9BN5/Bouton et al. - 2012 - The influence of lexical knowledge on phoneme disc.pdf},
  journal = {Speech Communication},
  language = {en},
  number = {2}
}

@article{boutonPerceptionSpeechFeatures2012,
  title = {Perception of {{Speech Features}} by {{French}}-{{Speaking Children With Cochlear Implants}}},
  author = {Bouton, Sophie and Serniclaes, Willy and Bertoncini, Josiane and Col{\'e}, Pascale},
  year = {2012},
  month = feb,
  volume = {55},
  pages = {139--153},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2011/10-0330)},
  abstract = {Purpose: The present study investigates the perception of phonological features in French-speaking children with cochlear implants (CIs) compared with normal-hearing ( NH) children matched for listening age. Method: Scores for discrimination and identification of minimal pairs for all features defining consonants (e.g., place, voicing, manner, nasality) and vowels (e.g., frontness, nasality, aperture) were measured in each listener. Results: The results indicated no differences in ``categorical perception,'' specified as a similar difference between discrimination and identification between CI children and controls. However, CI children demonstrated a lower level of ``categorical precision,'' that is, lesser accuracy in both feature identification and discrimination, than NH children, with the magnitude of the deficit depending on the feature. Conclusions: If sensitive periods of language development extend well beyond the moment of implantation, the consequences of hearing deprivation for the acquisition of categorical perception should be fairly important in comparison to categorical precision because categorical precision develops more slowly than categorical perception in NH children. These results do not support the idea that the sensitive period for development of categorical perception is restricted to the first 1\textendash 2 years of life. The sensitive period may be significantly longer. Differences in precision may reflect the acoustic limitations of the cochlear implant, such as coding for temporal fine structure and frequency resolution.},
  file = {/Users/megcychosz/Zotero/storage/6EA5ZTAF/Bouton et al. - 2012 - Perception of Speech Features by French-Speaking C.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {1}
}

@book{bowernLinguisticFieldworkPractical2015,
  title = {Linguistic Fieldwork: {{A}} Practical Guide},
  author = {Bowern, Claire},
  year = {2015},
  edition = {Second},
  publisher = {{Palgrave Macmillan}},
  address = {{New York, NY}}
}

@article{bradlowComparativeAcousticStudy1995,
  title = {A Comparative Acoustic Study of {{English}} and {{Spanish}} Vowels},
  author = {Bradlow, Ann R.},
  year = {1995},
  month = mar,
  volume = {97},
  pages = {1916--1924},
  issn = {0001-4966},
  doi = {10.1121/1.412064},
  file = {/Users/megcychosz/Zotero/storage/P8X64XCM/Bradlow - 1995 - A comparative acoustic study of English and Spanis.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {3}
}

@incollection{bradlowConfluentTalkerListeneroriented2002,
  title = {Confluent Talker- and Listener-Oriented Forces in Clear Speech Production},
  booktitle = {Laboratory {{Phonology}}},
  author = {Bradlow, Ann R.},
  editor = {Gussenhoven, C. and Warner, N.},
  year = {2002},
  volume = {7},
  pages = {241--273},
  publisher = {{Mouton de Gruyter}},
  address = {{Berlin and New York}},
  file = {/Users/megcychosz/Zotero/storage/JSHSAC9D/bradlow-labphon7.pdf}
}

@article{bradlowIntelligibilityNormalSpeech1996,
  title = {Intelligibility of Normal Speech {{I}}: {{Global}} and Fine-Grained Acoustic-Phonetic Talker Characteristics,},
  shorttitle = {Intelligibility of Normal Speech {{I}}},
  author = {Bradlow, Ann R. and Torretta, Gina M. and Pisoni, David B.},
  year = {1996},
  month = dec,
  volume = {20},
  pages = {255--272},
  issn = {0167-6393},
  doi = {10.1016/S0167-6393(96)00063-5},
  abstract = {This study used a multi-talker database containing intelligibility scores for 2000 sentences (20 talkers, 100 sentences), to identify talker-related correlates of speech intelligibility. We first investigated ``global'' talker characteristics (e.g., gender, F0 and speaking rate). Findings showed female talkers to be more intelligible as a group than male talkers. Additionally, we found a tendency for F0 range to correlate positively with higher speech intelligibility scores. However, F0 mean and speaking rate did not correlate with intelligibility. We then examined several fine-grained acoustic-phonetic talker-characteristics as correlates of overall intelligibility. We found that talkers with larger vowel spaces were generally more intelligible than talkers with reduced spaces. In investigating two cases of consistent listener errors (segment deletion and syllable affiliation), we found that these perceptual errors could be traced directly to detailed timing characteristics in the speech signal. Results suggest that a substantial portion of variability in normal speech intelligibility is traceable to specific acoustic-phonetic characteristics of the talker. Knowledge about these factors may be valuable for improving speech synthesis and recognition strategies, and for special populations (e.g., the hearing-impaired and second-language learners) who are particularly sensitive to intelligibility differences among talkers.},
  file = {/Users/megcychosz/Zotero/storage/GBQAMVCJ/Bradlow et al. - 1996 - Intelligibility of normal speech I Global and fin.pdf},
  journal = {Speech communication},
  number = {3},
  pmcid = {PMC3066472},
  pmid = {21461127}
}

@article{braginskyConsistencyVariabilityChildren,
  title = {Consistency and {{Variability}} in {{Children}}'s {{Word Learning Across Languages}}},
  author = {Braginsky, Mika and Yurovsky, Daniel and Marchman, Virginia A and Frank, Michael C},
  pages = {16},
  abstract = {Why do children learn some words earlier than others? The order in which words are acquired can provide clues about the mechanisms of word learning. In a large-scale corpus analysis, we use parent-report data from over 32,000 children to estimate the acquisition trajectories of around 400 words in each of 10 languages, predicting them on the basis of independently derived properties of the words' linguistic environment (from corpora) and meaning (from adult judgments). We examine the consistency and variability of these predictors across languages, by lexical category, and over development. The patterning of predictors across languages is quite similar, suggesting similar processes in operation. In contrast, the patterning of predictors across different lexical categories is distinct, in line with theories that posit different factors at play in the acquisition of content words and function words. By leveraging data at a significantly larger scale than previous work, our analyses identify candidate generalizations about the processes underlying word learning across languages.},
  file = {/Users/megcychosz/Zotero/storage/X9BEWHMH/Braginsky et al. - Consistency and Variability in Children’s Word Lea.pdf},
  journal = {OPEN MIND},
  language = {en}
}

@article{brandekerLanguageExposureBilingual2015,
  title = {Language {{Exposure}} in {{Bilingual Toddlers}}: {{Performance}} on {{Nonword Repetition}} and {{Lexical Tasks}}},
  shorttitle = {Language {{Exposure}} in {{Bilingual Toddlers}}},
  author = {Brandeker, Myrto and Thordardottir, Elin},
  year = {2015},
  month = may,
  volume = {24},
  pages = {126--138},
  issn = {1058-0360, 1558-9110},
  doi = {10.1044/2015_AJSLP-13-0106},
  abstract = {Purpose               The amount of language exposure is correlated with bilingual lexical development, but findings are mixed on how exposure relates to nonword repetition (NWR), a complex skill involving both short-term processing and long-term vocabulary knowledge. We extend previous work to a younger age group by investigating the role of exposure on NWR versus vocabulary, along with the effect of item construction and scoring.                                         Method               Sixty typically developing children (ages 2;5\textendash 3;6[years;months]) were assessed for NWR and receptive and expressive vocabulary. Participants ranged in amount of previous exposure to English and French from 0\% to 100\% and were tested in both languages if able to participate, even with very limited exposure (28 completed testing in both languages, 11 completed testing in English only, 21 completed testing in French only).                                         Results               Correlational analyses showed moderate to strong associations between the amount of exposure and vocabulary in that language, whereas the relationship of exposure with NWR was weak or nonsignificant, depending on scoring method. NWR correlated with vocabulary in English only. Performance on NWR was affected by nonword length but unaffected by wordlikeness.                                         Conclusions               NWR and vocabulary were differently related to language exposure. The underlying mechanisms of NWR at this age appeared mainly reliant on short-term processes, in contrast to long-term vocabulary knowledge.},
  file = {/Users/megcychosz/Zotero/storage/RRH72ME2/Brandeker and Thordardottir - 2015 - Language Exposure in Bilingual Toddlers Performan.pdf},
  journal = {American Journal of Speech-Language Pathology},
  language = {en},
  number = {2}
}

@article{brandEvidenceMotioneseModifications2002,
  title = {Evidence for `Motionese': Modifications in Mothers' Infant-Directed Action},
  shorttitle = {Evidence for `Motionese'},
  author = {Brand, Rebecca J. and Baldwin, Dare A. and Ashburn, Leslie A.},
  year = {2002},
  volume = {5},
  pages = {72--83},
  issn = {1467-7687},
  doi = {10.1111/1467-7687.00211},
  abstract = {We investigated the possibility that mothers modify their infant-directed actions in ways that might assist infants' processing of human action. In a between-subjects design, 51 mothers demonstrated the properties of five novel objects either to their infant (age 6\textendash 8 months or 11\textendash 13 months) or to an adult partner. As predicted, demonstrations to infants were higher in interactiveness, enthusiasm, proximity to partner, range of motion, repetitiveness and simplicity, indicating that mothers indeed modify their infant-directed actions in ways that likely maintain infants' attention and highlight the structure and meaning of action. The findings demonstrate that `motherese' is broader in scope than previously recognized, including modifications to action as well as language.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-7687.00211},
  file = {/Users/megcychosz/Zotero/storage/FXD4SDG7/Brand et al. - 2002 - Evidence for ‘motionese’ modifications in mothers.pdf;/Users/megcychosz/Zotero/storage/TCC8QTMA/1467-7687.html},
  journal = {Developmental Science},
  language = {en},
  number = {1}
}

@article{brandInfantsPreferMotionese2008,
  title = {Infants Prefer Motionese to Adult-Directed Action},
  author = {Brand, Rebecca J. and Shallcross, Wendy L.},
  year = {2008},
  volume = {11},
  pages = {853--861},
  issn = {1467-7687},
  doi = {10.1111/j.1467-7687.2008.00734.x},
  abstract = {In two studies, we investigated infants' preference for infant-directed (ID) action or `motionese' (Brand, Baldwin \& Ashburn, 2002) relative to adult-directed (AD) action. In Study 1, full-featured videos were shown to 32 6- to 8-month-olds, who demonstrated a strong preference for ID action. In Study 2, infants at 6\textendash 8 months (n= 28) and 11\textendash 13 months (n= 24) were shown either standard ID and AD clips, or clips in which demonstrators' faces were blurred to obscure emotional and eye-gaze information. Across both ages, infants showed evidence of preferring ID to AD action, even when faces were blurred. Infants did not have a preference for still-frame images of the demonstrators, indicating that the ID preference arose from action characteristics, not demonstrators' general appearance. These results suggest that motionese enhances infants' attention to action, possibly supporting infants' learning.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-7687.2008.00734.x},
  file = {/Users/megcychosz/Zotero/storage/54G6SDPA/Brand and Shallcross - 2008 - Infants prefer motionese to adult-directed action.pdf;/Users/megcychosz/Zotero/storage/P23UUXKR/j.1467-7687.2008.00734.html},
  journal = {Developmental Science},
  language = {en},
  number = {6}
}

@article{brauerLinearMixedeffectsModels2018,
  title = {Linear Mixed-Effects Models and the Analysis of Nonindependent Data: {{A}} Unified Framework to Analyze Categorical and Continuous Independent Variables That Vary within-Subjects and/or within-Items.},
  shorttitle = {Linear Mixed-Effects Models and the Analysis of Nonindependent Data},
  author = {Brauer, Markus and Curtin, John J.},
  year = {2018},
  month = sep,
  volume = {23},
  pages = {389--411},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000159},
  abstract = {In this article we address a number of important issues that arise in the analysis of nonindependent data. Such data are common in studies in which predictors vary within ``units'' (e.g., within-subjects, within-classrooms). Most researchers analyze categorical within-unit predictors with repeated-measures ANOVAs, but continuous within-unit predictors with linear mixed-effects models (LMEMs). We show that both types of predictor variables can be analyzed within the LMEM framework. We discuss designs with multiple sources of nonindependence, for example, studies in which the same subjects rate the same set of items or in which students nested in classrooms provide multiple answers. We provide clear guidelines about the types of random effects that should be included in the analysis of such designs. We also present a number of corrective steps that researchers can take when convergence fails in LMEM models with too many parameters. We end with a brief discussion on the trade-off between power and generalizability in designs with ``within-unit'' predictors.},
  file = {/Users/megcychosz/Zotero/storage/VAFSHESA/Brauer and Curtin - 2018 - Linear mixed-effects models and the analysis of no.pdf},
  journal = {Psychological Methods},
  language = {en},
  number = {3}
}

@article{brauerLinearMixedeffectsModels2018a,
  title = {Linear Mixed-Effects Models and the Analysis of Nonindependent Data: {{A}} Unified Framework to Analyze Categorical and Continuous Independent Variables That Vary within-Subjects and/or within-Items.},
  shorttitle = {Linear Mixed-Effects Models and the Analysis of Nonindependent Data},
  author = {Brauer, Markus and Curtin, John J.},
  year = {2018},
  month = sep,
  volume = {23},
  pages = {389--411},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000159},
  abstract = {In this article we address a number of important issues that arise in the analysis of nonindependent data. Such data are common in studies in which predictors vary within ``units'' (e.g., within-subjects, within-classrooms). Most researchers analyze categorical within-unit predictors with repeated-measures ANOVAs, but continuous within-unit predictors with linear mixed-effects models (LMEMs). We show that both types of predictor variables can be analyzed within the LMEM framework. We discuss designs with multiple sources of nonindependence, for example, studies in which the same subjects rate the same set of items or in which students nested in classrooms provide multiple answers. We provide clear guidelines about the types of random effects that should be included in the analysis of such designs. We also present a number of corrective steps that researchers can take when convergence fails in LMEM models with too many parameters. We end with a brief discussion on the trade-off between power and generalizability in designs with ``within-unit'' predictors.},
  file = {/Users/megcychosz/Zotero/storage/MNQDJ67E/Brauer and Curtin - 2018 - Linear mixed-effects models and the analysis of no.pdf},
  journal = {Psychological Methods},
  language = {en},
  number = {3}
}

@article{brooksGlmmTMBBalancesSpeed2017,
  title = {{{glmmTMB}} Balances Speed and Flexibility among Packages for Zero-Inflated Generalized Linear Mixed Modeling},
  author = {Brooks, M. E. and Kristensen, K. and {van Benthem}, K. J. and Magnusson, A. and Berg, C. W. and Nielsen, A. and Skaug, H. J. and Maechler, M. and Bolker, B. M.},
  year = {2017},
  volume = {9},
  pages = {378--400},
  journal = {The R Journal},
  number = {2}
}

@article{brouwerVerbbasedPredictionLanguage2019,
  title = {Verb-Based Prediction during Language Processing: The Case of {{Dutch}} and {{Turkish}}},
  shorttitle = {Verb-Based Prediction during Language Processing},
  author = {Brouwer, Susanne and {\"O}zkan, Deniz and K{\"u}ntay, Aylin C.},
  year = {2019},
  month = jan,
  volume = {46},
  pages = {80--97},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000918000375},
  abstract = {This study investigated whether cross-linguistic differences affect semantic prediction. We assessed this by looking at two languages, Dutch and Turkish, that differ in word order and thus vary in how words come together to create sentence meaning. In an eyetracking task, Dutch and Turkish four-year-olds (N = 40), five-year-olds (N = 58), and adults (N = 40) were presented with a visual display containing two familiar objects (e.g., a cake and a tree). Participants heard semantically constraining (e.g., ``The boy eats the big cake'') or neutral sentences (e.g., ``The boy sees the big cake'') in their native language. The Dutch data revealed a prediction effect for children and adults; however, it was larger for the adults. The Turkish data revealed no prediction effect for the children but only for the adults. These findings reveal that experience with word order structures and/or automatization of language processing routines may lead to timecourse differences in semantic prediction.},
  file = {/Users/megcychosz/Zotero/storage/TWKVIF27/Brouwer et al. - 2019 - Verb-based prediction during language processing .pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {01}
}

@article{browmanArticulatoryGesturesPhonological1989,
  title = {Articulatory Gestures as Phonological Units},
  author = {Browman, Catherine P. and Goldstein, Louis},
  year = {1989},
  volume = {6},
  pages = {201--251},
  issn = {0952-6757, 1469-8188},
  doi = {10.1017/S0952675700001019},
  file = {/Users/megcychosz/Zotero/storage/FTDMYV2Q/Browman and Goldstein - 1989 - Articulatory gestures as phonological units.pdf},
  journal = {Phonology},
  language = {en},
  number = {02}
}

@article{browmanArticulatoryPhonologyOverview1992,
  title = {Articulatory {{Phonology}}: {{An Overview}}},
  shorttitle = {Articulatory {{Phonology}}},
  author = {Browman, Catherine P. and Goldstein, Louis},
  year = {1992},
  volume = {49},
  pages = {155--180},
  issn = {1423-0321, 0031-8388},
  doi = {10.1159/000261913},
  file = {/Users/megcychosz/Zotero/storage/SCGNKBA2/Browman and Goldstein - 1992 - Articulatory Phonology An Overview.pdf},
  journal = {Phonetica},
  language = {en},
  number = {3-4}
}

@book{brownellExpressiveOneWordPicture,
  title = {Expressive {{One}}-{{Word Picture Vocabulary Test}}},
  author = {Brownell, R.},
  edition = {3rd},
  publisher = {{Academic Therapy Publications}},
  address = {{Novato, CA}}
}

@article{brudererSensorimotorInfluencesSpeech2015,
  title = {Sensorimotor Influences on Speech Perception in Infancy},
  author = {Bruderer, Alison G. and Danielson, D. Kyle and Kandhadai, Padmapriya and Werker, Janet F.},
  year = {2015},
  month = nov,
  volume = {112},
  pages = {13531--13536},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1508631112},
  file = {/Users/megcychosz/Zotero/storage/7ERPXL2J/Bruderer et al. - 2015 - Sensorimotor influences on speech perception in in.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {44}
}

@article{brysbaertMovingKuceraFrancis2009,
  title = {Moving beyond {{Ku\v{c}era}} and {{Francis}}: {{A}} Critical Evaluation of Current Word Frequency Norms and the Introduction of a New and Improved Word Frequency Measure for {{American English}}},
  shorttitle = {Moving beyond {{Ku\v{c}era}} and {{Francis}}},
  author = {Brysbaert, Marc and New, Boris},
  year = {2009},
  month = nov,
  volume = {41},
  pages = {977--990},
  issn = {1554-351X, 1554-3528},
  doi = {10.3758/BRM.41.4.977},
  file = {/Users/megcychosz/Zotero/storage/533EIKMV/Brysbaert and New - 2009 - Moving beyond Kučera and Francis A critical evalu.pdf},
  journal = {Behavior Research Methods},
  language = {en},
  number = {4}
}

@article{bucherTapeRecordedInterviews1956,
  title = {Tape {{Recorded Interviews}} in {{Social Research}}},
  author = {Bucher, Rue and Fritz, Charles E. and Quarantelli, E. L.},
  year = {1956},
  month = jun,
  volume = {21},
  pages = {359},
  issn = {00031224},
  doi = {10.2307/2089294},
  file = {/Users/megcychosz/Zotero/storage/F5VEX8TD/Bucher et al. - 1956 - Tape Recorded Interviews in Social Research.pdf},
  journal = {American Sociological Review},
  language = {en},
  number = {3}
}

@article{buntaPhonologicalWholeWord2009,
  title = {Phonological Whole-word Measures in 3-year-old Bilingual Children and Their Age-matched Monolingual Peers},
  author = {Bunta, Ferenc and Fabiano-Smith, Leah and Goldstein, Brian and Ingram, David},
  year = {2009},
  month = jan,
  volume = {23},
  pages = {156--175},
  issn = {0269-9206, 1464-5076},
  doi = {10.1080/02699200802603058},
  abstract = {The present study investigated phonological whole-word measures and consonant accuracy in bilingual and monolingual children to investigate how target approximations drive phonological acquisition. The study included eight bilingual Spanish- and English-speaking 3-year-olds and their monolingual peers (eight Spanish and eight American English). Phonological whole-word measures (pMLU and Proximity) and consonant accuracy (PCC) were calculated on elicited single words. Differences were found on each measure between bilinguals and monolinguals in English, but in Spanish, only the PCC displayed differences between bilinguals and monolinguals. Bilinguals displayed language separation on the pMLU and the PCC but not the Proximity, indicating structural phonological differences between the Spanish and English of bilinguals but commensurate target approximations. This suggests that maintaining a consistent level of phonological proximity to the target is an important factor in phonological acquisition. The measures and their relationships are also discussed.},
  file = {/Users/megcychosz/Zotero/storage/RUIUKFZV/Bunta et al. - 2009 - Phonological whole‐word measures in 3‐year‐old bil.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {2}
}

@article{burnhamPhoneticModificationVowel2015,
  title = {Phonetic {{Modification}} of {{Vowel Space}} in {{Storybook Speech}} to {{Infants}} up to 2 {{Years}} of {{Age}}},
  author = {Burnham, Evamarie B. and Wieland, Elizabeth A. and Kondaurova, Maria V. and McAuley, J. Devin and Bergeson, Tonya R. and Dilley, Laura C.},
  year = {2015},
  month = apr,
  volume = {58},
  pages = {241--253},
  issn = {1092-4388},
  doi = {10.1044/2015_JSLHR-S-13-0205},
  abstract = {Purpose A large body of literature has indicated vowel space area expansion in infant-directed (ID) speech compared with adult-directed (AD) speech, which may promote language acquisition. The current study tested whether this expansion occurs in storybook speech read to infants at various points during their first 2 years of life. Method In 2 studies, mothers read a storybook containing target vowels in ID and AD speech conditions. Study 1 was longitudinal, with 11 mothers recorded when their infants were 3, 6, and 9 months old. Study 2 was cross-sectional, with 48 mothers recorded when their infants were 3, 9, 13, or 20 months old (n = 12 per group). The 1st and 2nd formants of vowels /i/, /ɑ/, and /u/ were measured, and vowel space area and dispersion were calculated. Results Across both studies, 1st and/or 2nd formant frequencies shifted systematically for /i/ and /u/ vowels in ID compared with AD speech. No difference in vowel space area or dispersion was found. Conclusions The results suggest that a variety of communication and situational factors may affect phonetic modifications in ID speech, but that vowel space characteristics in speech to infants stay consistent across the first 2 years of life.},
  file = {/Users/megcychosz/Zotero/storage/N9WUA3VR/Burnham et al. - 2015 - Phonetic Modification of Vowel Space in Storybook .pdf},
  journal = {Journal of Speech, Language, and Hearing Research : JSLHR},
  number = {2},
  pmcid = {PMC4675117},
  pmid = {25659121}
}

@article{burrisQuantitativeDescriptiveComparison2014,
  title = {Quantitative and Descriptive Comparison of Four Acoustic Analysis Systems: Vowel Measurements},
  shorttitle = {Quantitative and Descriptive Comparison of Four Acoustic Analysis Systems},
  author = {Burris, Carlyn and Vorperian, Houri K. and Fourakis, Marios and Kent, Ray D. and Bolt, Daniel M.},
  year = {2014},
  month = feb,
  volume = {57},
  pages = {26--45},
  issn = {1092-4388},
  doi = {10.1044/1092-4388(2013/12-0103)},
  abstract = {Purpose This study examines accuracy and comparability of four trademarked acoustic analysis software packages (AASP): Praat, Wavesurfer, TF32 and CSL using synthesized and natural vowels. Features of AASP are also described. Methods Synthesized and natural vowels were analyzed using each of AASP's default settings to secure nine acoustic measures: fundamental frequency (F0), formant frequencies (F1-F4), and formant bandwidths (B1-B4). The discrepancy between the software measured values and the input values (synthesized, previously reported, and manual measurements) was used to assess comparability and accuracy. Basic AASP features are described. Results Results indicate that Praat, Wavesurfer, and TF32 generate accurate and comparable F0 and F1-F4 data for synthesized vowels and adult male natural vowels. Results varied by vowel for adult females and children, with some serious errors. Bandwidth measurements by AASPs were highly inaccurate as compared to manual measurements and published data on formant bandwidths. Conclusions Values of F0 and F1-F4 are generally consistent and fairly accurate for adult vowels and for some child vowels using the default settings in Praat, Wavesurfer, and TF32. Manipulation of default settings yields improved output values in TF32 and CSL. Caution is recommended especially before accepting F1-F4 results for children and B1-B4 results for all speakers.},
  file = {/Users/megcychosz/Zotero/storage/WZ8DTIVB/Burris et al. - 2014 - Quantitative and descriptive comparison of four ac.pdf},
  journal = {Journal of speech, language, and hearing research : JSLHR},
  number = {1},
  pmcid = {PMC3972630},
  pmid = {24687465}
}

@article{bushManagementHearingLoss2019,
  title = {Management of {{Hearing Loss Through Telemedicine}}},
  author = {Bush, Matthew L. and Sprang, Rob},
  year = {2019},
  month = mar,
  volume = {145},
  pages = {204},
  issn = {2168-6181},
  doi = {10.1001/jamaoto.2018.3885},
  file = {/Users/megcychosz/Zotero/storage/NSQUGAPI/Bush and Sprang - 2019 - Management of Hearing Loss Through Telemedicine.pdf},
  journal = {JAMA Otolaryngology\textendash Head \& Neck Surgery},
  language = {en},
  number = {3}
}

@inproceedings{bybeeWhySmallChildren1982,
  title = {Why Small Children Cannot Change Language on Their Own: Suggestions from the {{English}} Past Tense},
  booktitle = {Papers from the {{Fifth International Conference}} on {{Historical Linguistics}}},
  author = {Bybee, Joan L and Slobin, D.},
  editor = {Alqvist, Anders},
  year = {1982},
  pages = {29--37},
  publisher = {{John Benjamins}},
  address = {{Amsterdam}},
  file = {/Users/megcychosz/Zotero/storage/4JEZB2HF/Bybee - WHY SMALL CHILDREN CANNOT CHANGE LANGUAGE ON THEIR.pdf},
  language = {en}
}

@article{byers-heinleinCaseMeasuringReporting2019,
  title = {The Case for Measuring and Reporting Bilingualism in Developmental Research},
  author = {{Byers-Heinlein}, Krista and Esposito, Alena G and Winsler, Adam and Marian, Viorica and Castro, Dina C and Luk, Gigi},
  year = {2019},
  volume = {5},
  pages = {37},
  file = {/Users/megcychosz/Zotero/storage/NQ6KGNAF/Byers-Heinlein et al. - The case for measuring and reporting bilingualism .pdf},
  journal = {Collabra: Psychology},
  language = {en},
  number = {1}
}

@article{byers-heinleinMAPLEMultilingualApproach2019,
  title = {{{MAPLE}}: {{A Multilingual Approach}} to {{Parent Language Estimates}}},
  shorttitle = {{{MAPLE}}},
  author = {{Byers-Heinlein}, Krista and Schott, Esther and {Gonzalez-Barrero}, Ana Maria and Brouillard, Melanie and Dub{\'e}, Daphn{\'e}e and Jardak, Amel and {Laoun-Rubenstein}, Alexandra and Mastroberardino, Meghan and {Morin-Lessard}, Elizabeth and Pour Iliaei, Sadaf and {Salama-Siroishka}, Nicholas and Tamayo, Maria Paula},
  year = {2019},
  month = jun,
  pages = {1--7},
  issn = {1366-7289, 1469-1841},
  doi = {10.1017/S1366728919000282},
  abstract = {Bilingual infants vary in when, how, and how often they hear each of their languages. Variables such as the particular languages of exposure, the community context, the onset of exposure, the amount of exposure, and socioeconomic status are crucial for describing any bilingual infant sample. Parent report is an effective approach for gathering data about infants' language experience. However, its quality is highly dependent on how information is elicited. This paper introduces a Multilingual Approach to Parent Language Estimates (MAPLE). MAPLE promotes best practices for using structured interviews to reliably elicit information from parents on bilingual infants' language background, with an emphasis on the challenging task of quantifying infants' relative exposure to each language. We discuss sensitive issues that must be navigated in this process, including diversity in family characteristics and cultural values. Finally, we identify six systematic effects that can impact parent report, and strategies for minimizing their influence.},
  file = {/Users/megcychosz/Zotero/storage/58E3SPWR/Byers-Heinlein et al. - 2019 - MAPLE A Multilingual Approach to Parent Language .pdf},
  journal = {Bilingualism: Language and Cognition},
  language = {en}
}

@article{byers-heinleinParentalLanguageMixing2013,
  title = {Parental Language Mixing: {{Its}} Measurement and the Relation of Mixed Input to Young Bilingual Children's Vocabulary Size},
  shorttitle = {Parental Language Mixing},
  author = {{Byers-Heinlein}, Krista},
  year = {2013},
  month = jan,
  volume = {16},
  pages = {32--48},
  issn = {1366-7289, 1469-1841},
  doi = {10.1017/S1366728912000120},
  abstract = {Is parental language mixing related to vocabulary acquisition in bilingual infants and children? Bilingual parents (who spoke English and another language; n = 181) completed the Language Mixing Scale questionnaire, a new self-report measure that assesses how frequently parents use words from two different languages in the same sentence, such as borrowing words from another language or code switching between two languages in the same sentence. Concurrently, English vocabulary size was measured in the bilingual children of these parents. Most parents reported regular language mixing in interactions with their child. Increased rates of parental language mixing were associated with significantly smaller comprehension vocabularies in 1.5-year-old bilingual infants, and marginally smaller production vocabularies in 2-year-old bilingual children. Exposure to language mixing might obscure cues that facilitate young bilingual children's separation of their languages and could hinder the functioning of learning mechanisms that support the early growth of their vocabularies.},
  file = {/Users/megcychosz/Zotero/storage/GBZVLCXB/Byers-Heinlein - 2013 - Parental language mixing Its measurement and the .pdf},
  journal = {Bilingualism: Language and Cognition},
  language = {en},
  number = {1}
}

@article{byers-heinleinRootsBilingualismNewborns2010,
  title = {The {{Roots}} of {{Bilingualism}} in {{Newborns}}},
  author = {{Byers-Heinlein}, Krista and Burns, Tracey C. and Werker, Janet F.},
  year = {2010},
  month = mar,
  volume = {21},
  pages = {343--348},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797609360758},
  abstract = {The first steps toward bilingual language acquisition have already begun at birth. When tested on their preference for English versus Tagalog, newborns whose mothers spoke only English during pregnancy showed a robust preference for English. In contrast, newborns whose mothers spoke both English and Tagalog regularly during pregnancy showed equal preference for both languages. A group of newborns whose mothers had spoken both Chinese and English showed an intermediate pattern of preference for Tagalog over English. Preference for two languages does not suggest confusion between them, however. Study 2 showed that both English monolingual newborns and Tagalog-English bilingual newborns could discriminate English from Tagalog. The same perceptual and learning mechanisms that support acquisition in a monolingual environment thus also naturally support bilingual acquisition.},
  file = {/Users/megcychosz/Zotero/storage/YMRNKEFG/Byers-Heinlein et al. - 2010 - The Roots of Bilingualism in Newborns.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {3}
}

@article{byrdNonwordRepetitionPhoneme2012,
  title = {Nonword Repetition and Phoneme Elision in Adults Who Do and Do Not Stutter},
  author = {Byrd, Courtney T. and Vallely, Megann and Anderson, Julie D. and Sussman, Harvey},
  year = {2012},
  month = sep,
  volume = {37},
  pages = {188--201},
  issn = {0094730X},
  doi = {10.1016/j.jfludis.2012.03.003},
  abstract = {The purpose of the present study was to explore the phonological working memory of adults who stutter through the use of a non-word repetition and a phoneme elision task. Participants were 14 adults who stutter (M = 28 years) and 14 age/gender matched adults who do not stutter (M = 28 years). For the non-word repetition task, the participants had to repeat a set of 12 non-words across four syllable lengths (2-, 3-, 4-, and 7-syllables) (N = 48 total non-words). For the phoneme elision task, the participants repeated the same set of non-words at each syllable length, but with a designated target phoneme eliminated. Adults who stutter were significantly less accurate than adults who do not stutter in their initial attempts to produce the longest non-words (i.e., 7-syllable). Adults who stutter also required a significantly higher mean number of attempts to accurately produce 7-syllable non-words than adults who do not stutter. For the phoneme elision task, both groups demonstrated a significant reduction in accuracy as the non-words increased in length; however, there was no significant interaction between group and syllable length. Thus, although there appear to be advancements in the phonological working memory for adults who stutter relative to children who stutter, preliminary data from the present study suggest that the advancements may not be comparable to those demonstrated by adults who do not stutter.},
  file = {/Users/megcychosz/Zotero/storage/QI73H26W/Byrd et al. - 2012 - Nonword repetition and phoneme elision in adults w.pdf},
  journal = {Journal of Fluency Disorders},
  language = {en},
  number = {3}
}

@article{callanAuditoryfeedbackbasedNeuralNetwork2000,
  title = {An Auditory-Feedback-Based Neural Network Model of Speech Production That Is Robust to Developmental Changes in the Size and Shape of the Articulatory System},
  author = {Callan, Daniel E. and Kent, R.D. and Guenther, Frank H. and Vorperian, Houri K},
  year = {2000},
  volume = {43},
  pages = {721--736},
  journal = {Journal of Speech Language and Hearing Research}
}

@phdthesis{camachoriosVerbMorphologySouth2019,
  title = {Verb Morphology in {{South Bolivian Quechua}}: {{A}} Case Study of the {{Uma Piwra}} Rural Variety},
  author = {Camacho Rios, Gladys},
  year = {2019},
  address = {{Austin, TX}},
  file = {/Users/megcychosz/Zotero/storage/37IEJ3D4/CAMACHORIOS-MASTERSREPORT-2019.pdf},
  school = {University of Texas, Austin},
  type = {Unpublished {{Master}}'s {{Thesis}}}
}

@article{carbajalDualLanguageInput2019,
  title = {Dual Language Input and the Impact of Language Separation on Early Lexical Development},
  author = {Carbajal, Maria Julia and Peperkamp, Sharon},
  year = {2019},
  volume = {25},
  pages = {22--45},
  issn = {1525-0008, 1532-7078},
  doi = {10.1111/infa.12315},
  abstract = {We examined properties of the input and the environment that characterize bilingual exposure in 11-month-old infants with a regular exposure to French and an additional language, and their possible effects on receptive vocabulary size. Using a diary method, we found that a majority of the families roughly followed a one-parent\textendash one-language approach. Yet, the two languages co-occurred to various extents within the same half-hour both within and across speakers. We used exploratory correlation analyses to examine potential effects of the dual input on the size of infants' vocabularies. The results revealed some evidence for an impact of language separation by speakers.},
  file = {/Users/megcychosz/Zotero/storage/7DQWCUA7/Carbajal and Peperkamp - 2020 - Dual language input and the impact of language sep.pdf},
  journal = {Infancy},
  language = {en},
  number = {1}
}

@article{carlsonHowChildrenExplore2014,
  title = {How Children Explore the Phonological Network in Child-Directed Speech: {{A}} Survival Analysis of Children's First Word Productions},
  shorttitle = {How Children Explore the Phonological Network in Child-Directed Speech},
  author = {Carlson, Matthew T. and Sonderegger, Morgan and Bane, Max},
  year = {2014},
  month = aug,
  volume = {75},
  pages = {159--180},
  issn = {0749596X},
  doi = {10.1016/j.jml.2014.05.005},
  file = {/Users/megcychosz/Zotero/storage/Q99NEKDB/Carlson et al. - 2014 - How children explore the phonological network in c.pdf},
  journal = {Journal of Memory and Language},
  language = {en}
}

@article{carraDifferencesPracticesBody2014,
  title = {Differences in Practices of Body Stimulation during the First 3 Months: {{Ethnotheories}} and Behaviors of {{Italian}} Mothers and {{West African}} Immigrant Mothers},
  shorttitle = {Differences in Practices of Body Stimulation during the First 3 Months},
  author = {Carra, Cecilia and Lavelli, Manuela and Keller, Heidi},
  year = {2014},
  month = feb,
  volume = {37},
  pages = {5--15},
  issn = {01636383},
  doi = {10.1016/j.infbeh.2013.10.004},
  abstract = {This study investigated cultural differences, continuity and change of practices concerning body stimulation in a context of immigration. Parenting behaviors during the interaction with infants at 4, 8 and 12 weeks, and parenting ethnotheories at 12 weeks of firstgeneration West African immigrant mothers in Italy and autochthonous Italian mothers were compared. A qualitative inspection of ethnotheories using a thematic approach was included. As expected, results showed that immigrant mothers placed more emphasis on motor stimulation and showed longer durations of rhythmic motor and rhythmic tactile behaviors than Italian mothers; the latter placed more emphasis on tactile stimulation than immigrant mothers. The practice of motor stimulation in immigrant mothers was also adapted to values of the new context of life, becoming a positive interaction game with a mutual exchange of positive emotions. Findings express the complexity of a multidimensional process of acculturation.},
  file = {/Users/megcychosz/Zotero/storage/TCCWSIP4/Carra et al. - 2014 - Differences in practices of body stimulation durin.pdf},
  journal = {Infant Behavior and Development},
  language = {en},
  number = {1}
}

@article{carrollExposureInputBilingual2017,
  title = {Exposure and Input in Bilingual Development},
  author = {Carroll, Susanne E.},
  year = {2017},
  month = jan,
  volume = {20},
  pages = {3--16},
  issn = {1366-7289, 1469-1841},
  doi = {10.1017/S1366728915000863},
  abstract = {A growing literature on bilingual development explores relationships between language exposure and learning outcomes. Vocabulary size and pace of grammar learning have been claimed to be causally related to amounts or types of exposure to each language. Strong claims are made about the role of exposure on bilingual outcomes. Some researchers posit a unique learning result: a `weak language'. In a critical review, I voice reasons for scepticism that quantity or quality of exposure alone will explain findings. Central constructs are not well defined; inappropriate research methods have been used; the right kind of data is not discussed. Crucially, authors prevaricate on the notion of language itself, switching between cognitive and environmental perspectives. Both are needed to interpret bilingual behaviours but play different roles in the construction of learner grammars.},
  file = {/Users/megcychosz/Zotero/storage/ZQ8IMPPU/Carroll - 2017 - Exposure and input in bilingual development.pdf},
  journal = {Bilingualism: Language and Cognition},
  language = {en},
  number = {1}
}

@article{cartmillQualityEarlyParent,
  title = {Quality of Early Parent Input Predicts Child Vocabulary 3 Years Later},
  author = {Cartmill, Erica A and Iii, Benjamin F Armstrong and Gleitman, Lila R and {Goldin-Meadow}, Susan and Medina, Tamara N and Trueswell, John C},
  pages = {6},
  file = {/Users/megcychosz/Zotero/storage/7JUFMIXD/Cartmill et al. - Quality of early parent input predicts child vocab.pdf},
  journal = {COGNITIVE SCIENCES},
  language = {en}
}

@book{casillasCasillasHomeBankCorpus2017,
  title = {Casillas {{HomeBank Corpus}}},
  author = {Casillas, M and Brown, P. and Levinson, S.},
  year = {2017}
}

@article{casillasEarlyLanguageExperience2019,
  title = {Early Language Experience in a {{Tseltal Mayan}} Village},
  author = {Casillas, Marisa and Brown, P. and Levinson, S.},
  year = {2019},
  volume = {0},
  pages = {1--17},
  file = {/Users/megcychosz/Zotero/storage/3SFNJBWZ/Early language experience in a Tseltal Mayan villa.pdf},
  journal = {Child Development},
  language = {en},
  number = {0}
}

@article{casillasEarlyLanguageExperience2020,
  title = {Early Language Experience in a {{Papuan}} Community},
  author = {Casillas, Marisa and Brown, Penelope and Levinson, Stephen C.},
  year = {2020},
  month = sep,
  pages = {1--23},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000920000549},
  abstract = {The rate at which young children are directly spoken to varies due to many factors, including (a) caregiver ideas about children as conversational partners and (b) the organization of everyday life. Prior work suggests cross-cultural variation in rates of child-directed speech is due to the former factor, but has been fraught with confounds in comparing postindustrial and subsistence farming communities. We investigate the daylong language environments of children (0;0\textendash 3;0) on Rossel Island, Papua New Guinea, a small-scale traditional community where prior ethnographic study demonstrated contingency-seeking child interaction styles. In fact, children were infrequently directly addressed and linguistic input rate was primarily affected by situational factors, though children's vocalization maturity showed no developmental delay. We compare the input characteristics between this community and a Tseltal Mayan one in which near-parallel methods produced comparable results, then briefly discuss the models and mechanisms for learning best supported by our findings.},
  file = {/Users/megcychosz/Zotero/storage/62ECSGVP/Casillas et al. - 2020 - Early language experience in a Papuan community.pdf},
  journal = {Journal of Child Language},
  language = {en}
}

@inproceedings{casillasNewWorkflowSemiAutomatized2017,
  title = {A {{New Workflow}} for {{Semi}}-{{Automatized Annotations}}: {{Tests}} with {{Long}}-{{Form Naturalistic Recordings}} of {{Childrens Language Environments}}},
  shorttitle = {A {{New Workflow}} for {{Semi}}-{{Automatized Annotations}}},
  booktitle = {Interspeech 2017},
  author = {Casillas, Marisa and Bergelson, Elika and Warlaumont, Anne S. and Cristia, Alejandrina and Soderstrom, Melanie and VanDam, Mark and Sloetjes, Han},
  year = {2017},
  month = aug,
  pages = {2098--2102},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2017-1418},
  abstract = {Interoperable annotation formats are fundamental to the utility, expansion, and sustainability of collective data repositories. In language development research, shared annotation schemes have been critical to facilitating the transition from raw acoustic data to searchable, structured corpora. Current schemes typically require comprehensive and manual annotation of utterance boundaries and orthographic speech content, with an additional, optional range of tags of interest. These schemes have been enormously successful for datasets on the scale of dozens of recording hours but are untenable for long-format recording corpora, which routinely contain hundreds to thousands of audio hours. Long-format corpora would benefit greatly from (semi-)automated analyses, both on the earliest steps of annotation\textemdash voice activity detection, utterance segmentation, and speaker diarization\textemdash as well as later steps\textemdash e.g., classification-based codes such as child-vsadult-directed speech, and speech recognition to produce phonetic/orthographic representations. We present an annotation workflow specifically designed for long-format corpora which can be tailored by individual researchers and which interfaces with the current dominant scheme for short-format recordings. The workflow allows semi-automated annotation and analyses at higher linguistic levels. We give one example of how the workflow has been successfully implemented in a large crossdatabase project.},
  file = {/Users/megcychosz/Zotero/storage/BQC5RYMS/Casillas et al. - 2017 - A New Workflow for Semi-Automatized Annotations T.pdf},
  language = {en}
}

@article{casillasShapeLanguageExperience,
  title = {The Shape of Language Experience in Two Traditional Communities},
  author = {Casillas, Marisa},
  pages = {7},
  abstract = {This study sketches the language environments of children ages 0;0\textendash 3;0 growing up in two traditional, indigenous communities: one Tseltal (Mayan) and the other Ye\textasciiacute l\textasciicircum\i{} (Papuan). Past ethnographic work has suggested that caregivers' ideas about talking to young children differ greatly between these two communities. However, the present daylong recording analyses suggest that, in fact, children are rarely directly addressed in both places, with no age-related increase and with most child-directed speech coming from adults. Children's manual activities also suggest that child-carrying practices and cultural context moderate the extent to which children might use co-occurrence between held objects and ambient language to learn words.},
  file = {/Users/megcychosz/Zotero/storage/TX64PTVY/Casillas - The shape of language experience in two traditiona.pdf},
  language = {en}
}

@article{casillasStepbystepGuideCollecting2019,
  title = {A Step-by-Step Guide to Collecting and Analyzing Long-Format Speech Environment ({{LFSE}}) Recordings},
  author = {Casillas, Marisa and Cristia, Alejandrina},
  year = {2019},
  month = may,
  volume = {5},
  pages = {24},
  issn = {2474-7394},
  doi = {10.1525/collabra.209},
  file = {/Users/megcychosz/Zotero/storage/KJNDFG2B/Casillas and Cristia - 2019 - A step-by-step guide to collecting and analyzing l.pdf},
  journal = {Collabra: Psychology},
  language = {en},
  number = {1}
}

@article{caskeyImportanceParentTalk2011,
  title = {Importance of {{Parent Talk}} on the {{Development}} of {{Preterm Infant Vocalizations}}},
  author = {Caskey, M. and Stephens, B. and Tucker, R. and Vohr, B.},
  year = {2011},
  month = nov,
  volume = {128},
  pages = {910--916},
  issn = {0031-4005, 1098-4275},
  doi = {10.1542/peds.2011-0609},
  abstract = {OBJECTIVE: To determine the sound environment of preterm infants cared for in the NICU and to test the hypothesis that infants exposed to more adult language will make more vocalizations. METHODS: This was a prospective cohort study of 36 infants who had a birth weight of Յ1250 g. Sixteen-hour recordings of the infant sound environment were made in the NICU from a digital language processor at 32 and 36 weeks' postmenstrual age. Adult word counts, infant vocalizations, and conversational turns were analyzed. RESULTS: Infant vocalizations are present as early as 32 weeks. Both adult word counts per hour and infant vocalizations per hour increase significantly between 32 and 36 weeks. Infant exposure to language as a percentage of time was small but increased significantly. When a parent was present, infants had significantly more conversational turns per hour than when a parent was not present at both 32 and 36 weeks (P Ͻ .0001). CONCLUSIONS: Preterm infants begin to make vocalizations at least 8 weeks before their projected due date and significantly increase their number of vocalizations over time. Although infant exposure to language increased over time, adult language accounted for only a small percentage of the sounds to which an infant is exposed in the NICU. Exposure to parental talk was a significantly stronger predictor of infant vocalizations at 32 weeks and conversational turns at 32 and 36 weeks than language from other adults. These findings highlight the powerful impact that parent talk has on the appearance and increment of vocalizations in preterm infants in the NICU. Pediatrics 2011;128: 910\textendash 916},
  file = {/Users/megcychosz/Zotero/storage/GM427GY9/Caskey et al. - 2011 - Importance of Parent Talk on the Development of Pr.pdf},
  journal = {Pediatrics},
  language = {en},
  number = {5}
}

@article{catanoRetrospectiveStudyPhonetic2009,
  title = {A Retrospective Study of Phonetic Inventory Complexity in Acquisition of {{Spanish}}: {{Implications}} for Phonological Universals},
  shorttitle = {A Retrospective Study of Phonetic Inventory Complexity in Acquisition of {{Spanish}}},
  author = {Cata{\~n}o, Lorena and Barlow, Jessica A. and Moyna, Mar{\'i}a Irene},
  year = {2009},
  month = jan,
  volume = {23},
  pages = {446--472},
  issn = {0269-9206, 1464-5076},
  doi = {10.1080/02699200902839818},
  abstract = {This study evaluates 39 different phonetic inventories of 16 Spanish-speaking children (ages 0;11 to 5;1) in terms of hierarchical complexity. Phonetic featural differences are considered in order to evaluate the proposed implicational hierarchy of Dinnsen et al.'s phonetic inventory typology for English. The children's phonetic inventories are examined independently and in relation to one another. Five hierarchical complexity levels are proposed, similar to those of English and other languages, although with some language-specific differences. These findings have implications for theoretical assumptions about the universality of phonetic inventory development, and for remediation of Spanish-speaking children with phonological impairments.},
  file = {/Users/megcychosz/Zotero/storage/SRXBJEJ4/Cataño et al. - 2009 - A retrospective study of phonetic inventory comple.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {6}
}

@article{caudrelierTransferSensorimotorLearning2019,
  title = {Transfer of Sensorimotor Learning Reveals Phoneme Representations in Preliterate Children},
  author = {Caudrelier, Tiphaine and M{\'e}nard, Lucie and Perrier, Pascal and Schwartz, Jean-Luc and Gerber, Silvain and Vidou, Camille and {Rochet-Capellan}, Am{\'e}lie},
  year = {2019},
  month = nov,
  volume = {192},
  pages = {103973},
  issn = {00100277},
  doi = {10.1016/j.cognition.2019.05.010},
  abstract = {Reading acquisition is strongly intertwined with phoneme awareness that relies on implicit phoneme representations. We asked whether phoneme representations emerge before literacy. We recruited two groups of children, 4 to 5-year-old preschoolers (N = 29) and 7 to 8-year-old schoolchildren (N = 24), whose phonological awareness was evaluated, and one adult control group (N = 17). We altered speakers' auditory feedback in real time to elicit persisting pronunciation changes, referred to as auditory-motor adaptation or learning. Assessing the transfer of learning at phoneme level enabled us to investigate the developmental time-course of phoneme representations. Significant transfer at phoneme level occurred in preschoolers, as well as schoolchildren and adults. In addition, we found a relationship between auditory-motor adaptation and phonological awareness in both groups of children. Overall, these results suggest that phoneme representations emerge before literacy acquisition, and that these sensorimotor representations may set the ground for phonological awareness.},
  file = {/Users/megcychosz/Zotero/storage/Q2S6KNPD/Caudrelier et al. - 2019 - Transfer of sensorimotor learning reveals phoneme .pdf},
  journal = {Cognition},
  language = {en}
}

@article{cejasDevelopmentJointEngagement2014,
  title = {Development of {{Joint Engagement}} in {{Young Deaf}} and {{Hearing Children}}: {{Effects}} of {{Chronological Age}} and {{Language Skills}}},
  shorttitle = {Development of {{Joint Engagement}} in {{Young Deaf}} and {{Hearing Children}}},
  author = {Cejas, Ivette and Barker, David H. and Quittner, Alexandra L. and Niparko, John K.},
  year = {2014},
  month = oct,
  volume = {57},
  pages = {1831--1841},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2014_JSLHR-L-13-0262},
  abstract = {Purpose\textemdash To evaluate joint engagement (JE) in age-matched children with and without hearing and its relationship to oral language skills. Method\textemdash Participants were 180 children with severe-to-profound hearing loss prior to cochlear implant surgery, and 96 age-matched children with normal hearing; all parents were hearing. JE was evaluated in a 10-minute videotaped free play task with parents. Engagement states ranged from the lowest (unengaged) to the highest level (symbol-infused coordinated). Standardized language measures were administered. Results\textemdash Multivariate analyses were conducted between the groups, stratified by chronological and language age. Children who were deaf (Deaf) spent less time in total symbol-infused JE than children with normal hearing (NH) across all ages. The majority of the Deaf group (83\%) fell in the lowest language age group, in comparison to 35\% of the NH group, and spent significantly less time in symbol-infused JE than hearing children. These delays were also observed in the Deaf group, who fell into the 18-36 month language age. No children in the Deaf group had achieved a language age of {$>$}36 months. Conclusions\textemdash Young children with and without hearing had different developmental trajectories of JE, which were related to oral language skills.},
  file = {/Users/megcychosz/Zotero/storage/H5LLMMPI/Cejas et al. - 2014 - Development of Joint Engagement in Young Deaf and .pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {5}
}

@article{changRapidMultifacetedEffects2012,
  title = {Rapid and Multifaceted Effects of Second-Language Learning on First-Language Speech Production},
  author = {Chang, Charles B.},
  year = {2012},
  month = mar,
  volume = {40},
  pages = {249--268},
  issn = {00954470},
  doi = {10.1016/j.wocn.2011.10.007},
  abstract = {Despite abundant evidence of malleability in speech production, previous studies of the effects of late second-language learning on first-language speech production have been limited to advanced learners. This study examined these effects in novice learners, adult native English speakers enrolled in elementary Korean classes. In two acoustic studies, learners' production of English was found to be influenced by even brief experience with Korean. The effect was consistently one of assimilation to phonetic properties of Korean; moreover, it occurred at segmental, subsegmental, and global levels, often simultaneously. Taken together, the results suggest that cross-language linkages are established from the onset of second-language learning at multiple levels of phonological structure, allowing for pervasive influence of second-language experience on first-language representations. The findings are discussed with respect to current notions of cross-linguistic similarity, language development, and historical sound change.},
  file = {/Users/megcychosz/Zotero/storage/BQBRWX87/Chang - 2012 - Rapid and multifaceted effects of second-language .pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {2}
}

@article{chapmanRelationshipEarlySpeech2003a,
  title = {The Relationship between Early Speech and Later Speech and Language Performance for Children with Cleft Lip and Palate},
  author = {Chapman, Kathy L. and {Hardin-Jones}, Mary and Halter, Kelli Ann},
  year = {2003},
  month = jan,
  volume = {17},
  pages = {173--197},
  issn = {0269-9206, 1464-5076},
  doi = {10.1080/0269920021000047864},
  abstract = {This study examined the relationship between speech measures at presurgery/9 months and postsurgery/13 months and speech and language performance at 21 months for children with cleft lip and palate and their noncleft peers. Comparisons were also made between the speech and lexical development of children with cleft lip and palate and noncleft children at 21 months of age. The participants included 30 children; 15 with cleft lip and palate and 15 noncleft children. Results revealed differences between the groups for several measures of speech and lexical development at 21 months. For the children with cleft palate, correlational analyses suggested that true stop production, both immediately before and after palatal surgery, was positively correlated with a majority of the speech production measures at 21 months. At postsurgery/13 months, true stop production was related to later vocabulary development, and size of true consonant inventory was related to all measure of speech production and one measure of lexical development at 21 months. For the noncleft group, true canonical babbling ratio at 13 months was the only measure that was significantly correlated with any of the speech and/or language measures at 21 months. The impact of clefting on prelinguistic and later speech and language skills is discussed.},
  file = {/Users/megcychosz/Zotero/storage/KEBD8RHR/Chapman et al. - 2003 - The relationship between early speech and later sp.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {3}
}

@article{charles-luceSimilarityNeighbourhoodsWords1990,
  title = {Similarity Neighbourhoods of Words in Young Children's Lexicons},
  author = {{Charles-Luce}, Jan and Luce, Paul A.},
  year = {1990},
  month = feb,
  volume = {17},
  pages = {205--215},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000900013180},
  abstract = {Similarity neighbourhoods for words in young children's lexicons were investigated using three computerized databases. These databases were representative of three groups of native English speakers: 5-year-olds, 7-year-olds, and adults. Computations relating to the similarity neighbourhoods of words in the children's and adult's lexicon revealed that words in the 5- and 7-year-olds' lexicons have many fewer similar neighbours than the same words analyzed in the adult lexicon. Thus, young children may employ more global recognition strategies because words are more discriminable in memory. The neighbourhood analyses provide a number of insights into the processes of auditory word recognition in children and the possible structural organization of words in the young child's mental lexicon.},
  file = {/Users/megcychosz/Zotero/storage/3JC6DEUF/Charles-Luce_Luce 1990.pdf;/Users/megcychosz/Zotero/storage/AJ5SEBFL/Charles-Luce_Luce 1990.pdf;/Users/megcychosz/Zotero/storage/QYT6XIUD/Charles-Luce and Luce - 1990 - Similarity neighbourhoods of words in young childr.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {1}
}

@article{chenEffectsChildrenHearing2019,
  title = {Effects of Children's Hearing Loss on the Synchrony between Parents' Object Naming and Children's Attention},
  author = {Chen, Chi-hsin and Castellanos, Irina and Yu, Chen and Houston, Derek M.},
  year = {2019},
  month = nov,
  volume = {57},
  pages = {101322},
  issn = {01636383},
  doi = {10.1016/j.infbeh.2019.04.004},
  abstract = {Children's attentional state during parent-child interactions is important for word learning. The current study examines the real-time attentional patterns of toddlers with and without hearing loss (N = 15, age range: 12\textendash 37 months) in parent-child interactions. High-density gaze data recorded from head-mounted eye-trackers were used to investigate the synchrony between parents' naming of novel objects and children's sustained attention on the named objects in joint play. Results show that the sheer quantities of parents' naming and children's sustained attention episodes were comparable in children with hearing loss and their peers with normal hearing. However, parents' naming and children's sustained attention episodes were less synchronized in the hearing loss group compared to children with normal hearing. Possible implications are discussed.},
  file = {/Users/megcychosz/Zotero/storage/8ZFMFFMH/Chen et al. - 2019 - Effects of children’s hearing loss on the synchron.pdf},
  journal = {Infant Behavior and Development},
  language = {en}
}

@article{chenF0inducedFormantMeasurement2019,
  title = {F0-Induced Formant Measurement Errors Result in Biased Variabilities},
  author = {Chen, Wei-Rong and Whalen, D. H. and Shadle, Christine H.},
  year = {2019},
  month = may,
  volume = {145},
  pages = {EL360-EL366},
  issn = {0001-4966},
  doi = {10.1121/1.5103195},
  abstract = {Many developmental studies attribute reduction of acoustic variability to increasing motor control. However, linear prediction-based formant measurements are known to be biased toward the nearest harmonic of F0, especially at high F0s. Thus, the amount of reported formant variability generated by changes in F0 is unknown. Here, 470 000 vowels were synthesized, mimicking statistics reported in four developmental studies, to estimate the proportion of formant variability that can be attributed to F0 bias, as well as other formant measurement errors. Results showed that the F0-induced formant measurements errors are large and systematic, and cannot be eliminated by a large sample size.},
  file = {/Users/megcychosz/Zotero/storage/WMELDVKZ/Chen et al. - 2019 - F 0-induced formant measurement errors resu.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{chenMovementPlanningReflects2010,
  title = {Movement {{Planning Reflects Skill Level}} and {{Age Changes}} in {{Toddlers}}},
  author = {Chen, Yu-ping and Keen, Rachel and Rosander, Kerstin and Hofsten, Claes Von},
  year = {2010},
  volume = {81},
  pages = {1846--1858},
  issn = {1467-8624},
  doi = {10.1111/j.1467-8624.2010.01514.x},
  abstract = {Kinematic measures of children's reaching were found to reflect stable differences in skill level for planning for future actions. Thirty-five toddlers (18\textendash 21 months) were engaged in building block towers (precise task) and in placing blocks into an open container (imprecise task). Sixteen children were retested on the same tasks a year later. Longer deceleration as the hand approached the block for pickup was found in the tower task compared with the imprecise task, indicating planning for the second movement. More skillful toddlers who could build high towers had a longer deceleration phase when placing blocks on the tower than toddlers who built low towers. Kinematic differences between the groups remained a year later when all children could build high towers.},
  file = {/Users/megcychosz/Zotero/storage/HHICDFHX/Chen et al. - 2010 - Movement Planning Reflects Skill Level and Age Cha.pdf;/Users/megcychosz/Zotero/storage/ANM9V8P2/j.1467-8624.2010.01514.html},
  journal = {Child Development},
  language = {en},
  number = {6}
}

@article{chenParentalLinguisticInput2019a,
  title = {Parental {{Linguistic Input}} and {{Its Relation}} to {{Toddlers}}' {{Visual Attention}} in {{Joint Object Play}}: {{A Comparison Between Children}} with {{Normal Hearing}} and {{Children With Hearing Loss}}},
  shorttitle = {Parental {{Linguistic Input}} and {{Its Relation}} to {{Toddlers}}' {{Visual Attention}} in {{Joint Object Play}}},
  author = {Chen, Chi-hsin and Castellanos, Irina and Yu, Chen and Houston, Derek M.},
  year = {2019},
  month = jul,
  volume = {24},
  pages = {589--612},
  issn = {1525-0008, 1532-7078},
  doi = {10.1111/infa.12291},
  file = {/Users/megcychosz/Zotero/storage/B2KENCNC/Chen et al. - 2019 - Parental Linguistic Input and Its Relation to Todd.pdf},
  journal = {Infancy},
  language = {en},
  number = {4}
}

@article{chenWhatLeadsCoordinated2020,
  title = {What Leads to Coordinated Attention in Parent\textendash Toddler Interactions? {{Children}}'s Hearing Status Matters},
  shorttitle = {What Leads to Coordinated Attention in Parent\textendash Toddler Interactions?},
  author = {Chen, Chi-hsin and Castellanos, Irina and Yu, Chen and Houston, Derek M.},
  year = {2020},
  month = may,
  volume = {23},
  issn = {1363-755X, 1467-7687},
  doi = {10.1111/desc.12919},
  abstract = {Coordinated attention between children and their parents plays an important role in their social, language, and cognitive development. The current study used headmounted eye-trackers to investigate the effects of children's prelingual hearing loss on how they achieve coordinated attention with their hearing parents during freeflowing object play. We found that toddlers with hearing loss (age: 24\textendash 37 months) had similar overall gaze patterns (e.g., gaze length and proportion of face looking) as their normal-hearing peers. In addition, children's hearing status did not affect how likely parents and children attended to the same object at the same time during play. However, when following parents' attention, children with hearing loss used both parents' gaze directions and hand actions as cues, whereas children with normal hearing mainly relied on parents' hand actions. The diversity of pathways leading to coordinated attention suggests the flexibility and robustness of developing systems in using multiple pathways to achieve the same functional end.},
  file = {/Users/megcychosz/Zotero/storage/6BXR47K8/Chen et al. - 2020 - What leads to coordinated attention in parent–todd.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {3}
}

@article{cheungSpeechPerceptionMetalinguistic2010,
  title = {Speech Perception, Metalinguistic Awareness, Reading, and Vocabulary in {{Chinese}}\textendash{{English}} Bilingual Children.},
  author = {Cheung, Him and Chung, Kevin Kien Hoa and Wong, Simpson Wai Lap and {McBride-Chang}, Catherine and Penney, Trevor Bruce and Ho, Connie Suk-Han},
  year = {2010},
  volume = {102},
  pages = {367--380},
  issn = {1939-2176, 0022-0663},
  doi = {10.1037/a0017850},
  abstract = {This study examines the intercorrelations among speech perception, metalinguistic (i.e., phonological and morphological) awareness, word reading, and vocabulary in a first (L1) and a second language (L2). Results from three age groups of Chinese-English bilingual children showed that speech perception was more predictive of reading and vocabulary in the L1 than L2. While morphological awareness uniquely predicted reading and vocabulary in both languages, phonological awareness played such a role after controlling for morphological awareness only in the L2, which was alphabetic. L1 speech perception and metalinguistic awareness predicted L2 word reading but not vocabulary, after controlling for the corresponding L2 variables. Hence, there are both similarities and differences between the two languages in how the constructs are related. The differences are attributable to variations in language properties and learning contexts. Implications of the present results for an effective L2 learning program are discussed.},
  file = {/Users/megcychosz/Zotero/storage/C7JUWBFR/Cheung et al. - 2010 - Speech perception, metalinguistic awareness, readi.pdf},
  journal = {Journal of Educational Psychology},
  language = {en},
  number = {2}
}

@article{chiatPreschoolRepetitionTest2007,
  title = {The {{Preschool Repetition Test}}: {{An Evaluation}} of {{Performance}} in {{Typically Developing}} and {{Clinically Referred Children}}},
  shorttitle = {The {{Preschool Repetition Test}}},
  author = {Chiat, Shula and Roy, Penny},
  year = {2007},
  month = apr,
  volume = {50},
  pages = {429--443},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2007/030)},
  abstract = {Purpose: To determine the psychometric properties of the Preschool Repetition Test (Roy \& Chiat, 2004); to establish the range of performance in typically developing children and variables affecting this; and to compare the performance of clinically referred children. Method: The PSRep Test comprises 18 words and 18 phonologically matched nonwords systematically varied for length and prosodic structure. This test was administered to a `typical' sample of children aged 2;0\textendash 4;0 (n=315) and a `clinic' sample of children aged 2;6-4;0 (n=168), together with language assessments. Results: Performance in the typical sample was independent of gender and SES, but was affected by age, item length, and prosodic structure, and was moderately correlated with receptive vocabulary. Performance in the clinic sample was significantly poorer, but revealed similar effects of length and prosody, and similar relations to language measures overall, with some notable exceptions. Test-retest and interrater reliability were high. Conclusions: The PSRep Test is a viable and informative test. It differentiates within and between `typical' and `clinic' samples of children, and reveals some unusual profiles within the clinic sample. These findings lay the foundations for a follow-up study of the clinic sample to investigate the predictive value of the test.},
  file = {/Users/megcychosz/Zotero/storage/XVZYYPIR/Chiat and Roy - 2007 - The Preschool Repetition Test An Evaluation of Pe.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {2}
}

@article{chiatRelationProsodicStructure1989,
  title = {The Relation between Prosodic Structure, Syllabification and Segmental Realization: {{Evidence}} from a Child with Fricative Stopping},
  shorttitle = {The Relation between Prosodic Structure, Syllabification and Segmental Realization},
  author = {Chiat, Shula},
  year = {1989},
  month = jan,
  volume = {3},
  pages = {223--242},
  issn = {0269-9206, 1464-5076},
  doi = {10.3109/02699208908985287},
  abstract = {This study is concerned with the interaction between prosodic structure, phonotactic structurc and syllabification in the realization of segmental targets. It is based on a detailed investigation into the realization of intervocalic fricative targets by a child who stopped fricatives word-initially, but produced them correctly wordfinally. Intervocalic fricatives in different prosodic and phonotactic domains were elicited using controlled repetition tasks, backed up by speech samples. It was found that intervocalic fricatives were realized correctly provided they occurred between strong and weak syllables within a word, in a phonotactic sequence which is permissible word-finally, c.g. if/ in buflalo, selfislz. Intervocalic fricatives were generally stopped in other prosodic domains, e.g. if/ in beautiful, and in other phonotactic domains, e.g. if/ in comfvt. These findings have implications for the processes involved in the output of lexical phonology.},
  file = {/Users/megcychosz/Zotero/storage/SLVGQCV5/Chiat - 1989 - The relation between prosodic structure, syllabifi.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {3}
}

@article{chinSpeechIntelligibilityProsody2012,
  title = {Speech Intelligibility and Prosody Production in Children with Cochlear Implants},
  author = {Chin, Steven B. and Bergeson, Tonya R. and Phan, Jennifer},
  year = {2012},
  month = sep,
  volume = {45},
  pages = {355--366},
  issn = {00219924},
  doi = {10.1016/j.jcomdis.2012.05.003},
  abstract = {Objectives\textemdash The purpose of the current study was to examine the relation between speech intelligibility and prosody production in children who use cochlear implants.},
  file = {/Users/megcychosz/Zotero/storage/F3W3JGJD/Chin et al. - 2012 - Speech intelligibility and prosody production in c.pdf},
  journal = {Journal of Communication Disorders},
  language = {en},
  number = {5}
}

@article{choAutoregressiveGeneralizedLinear2018,
  title = {Autoregressive {{Generalized Linear Mixed Effect Models}} with {{Crossed Random Effects}}: {{An Application}} to {{Intensive Binary Time Series Eye}}-{{Tracking Data}}},
  shorttitle = {Autoregressive {{Generalized Linear Mixed Effect Models}} with {{Crossed Random Effects}}},
  author = {Cho, Sun-Joo and {Brown-Schmidt}, Sarah and Lee, Woo-yeol},
  year = {2018},
  month = sep,
  volume = {83},
  pages = {751--771},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/s11336-018-9604-2},
  file = {/Users/megcychosz/Zotero/storage/53NIRJ9B/Cho et al. - 2018 - Autoregressive Generalized Linear Mixed Effect Mod.pdf},
  journal = {Psychometrika},
  language = {en},
  number = {3}
}

@article{choEffectsMorphemeBoundaries2001,
  title = {Effects of {{Morpheme Boundaries}} on {{Intergestural Timing}}: {{Evidence}} from {{Korean}}},
  shorttitle = {Effects of {{Morpheme Boundaries}} on {{Intergestural Timing}}},
  author = {Cho, Taehong},
  year = {2001},
  volume = {58},
  pages = {129--162},
  issn = {0031-8388, 1423-0321},
  doi = {10.1159/000056196},
  abstract = {This paper examines the effects of morpheme boundaries on intergestural timing, and demonstrates that low-level phonetic realization is influenced by morphological structure, i.e. compounding and affixation. It reports two experiments, one using electromagnetic midsagittal articulography (EMA) and one electropalatography (EPG), examining Korean data. The results of the EMA study show that intergestural timing is less variable for adjacent gestures across the word boundary inside a lexicalized compound than inside a nonlexicalized compound, and inside a monomorphemic word than across a morpheme boundary. The EPG study (which examined the timing in palatalization of a coronal) shows that both [ti] and [ni] have more variability in gestural timing when heteromorphemic than when tautomorphemic. Furthermore, the phonetic details of gestural overlap shed light on the asymmetry on palatalization between tautomorphemic and heteromorphemic gestural sequences (e.g. ni vs. n-i ), presumably driven by paradigmatic contrast and preference of overlap. In short, what emerges from two experiments is that gestures are coordinated more stably within a single lexical item (a morpheme or a lexicalized compound) than across a boundary between lexical items. In accounting for the stability of intergestural timing within a lexical entry, several hypotheses were discussed including the Phase Window, Bonding Strength, Phonological Timing and Extended Phase Window model newly proposed here. The implication is that the morphological structure may be encoded in the phonetic realization, as is the case with other linguistic structure (e.g. prosodic structure).},
  file = {/Users/megcychosz/Zotero/storage/K4LXCSMI/Cho - 2001 - Effects of Morpheme Boundaries on Intergestural Ti.pdf},
  journal = {Phonetica},
  language = {en},
  number = {3}
}

@article{choiSensorimotorInfluencesSpeech2019,
  title = {Sensorimotor Influences on Speech Perception in Pre-Babbling Infants: {{Replication}} and Extension of {{Bruderer}} et al. (2015)},
  shorttitle = {Sensorimotor Influences on Speech Perception in Pre-Babbling Infants},
  author = {Choi, Dawoon and Bruderer, Alison G. and Werker, Janet F.},
  year = {2019},
  month = aug,
  volume = {26},
  pages = {1388--1399},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-019-01601-0},
  abstract = {The relationship between speech perception and production is central to understanding language processing, yet remains under debate, particularly in early development. Recent research suggests that in infants aged 6-months, when the native phonological system is still being established, sensorimotor information from the articulators influences speech perception (Bruderer et al. 2015): the placement of a teething toy restricting tongue-tip movements interfered with infants' discrimination of a non-native contrast, /Da/-/da/, that involves tongue-tip movement. This effect was selective: a different teething toy that prevented lip closure but not tongue-tip movement did not disrupt discrimination. We conducted two sets of studies to replicate and extend these findings. Experiments 1 and 2 replicated Bruderer et al. (2015), but with synthesized auditory stimuli. Infants discriminated the non-native contrast (dental /da/ - retroflex /Da/) (Experiment 1), but showed no evidence of discrimination when the tongue-tip movement was prevented with a teething toy (Experiment 2). Experiments 3 and 4 extended this work to a native phonetic contrast (bilabial /ba/-dental /da/). Infants discriminated the distinction with no teething toy present (Experiment 3), but when they were given a teething toy that interfered only with lip closure, a movement involved in the production of /ba/, discrimination was disrupted (Experiment 4). Importantly, this was the same teething toy that did not interfere with discrimination of /da/-/Da/ in Bruderer et al. (2015). These findings reveal specificity in the relation between sensorimotor and perceptual processes in pre-babbling infants, and show generalizability to a second phonetic contrast.},
  file = {/Users/megcychosz/Zotero/storage/2Z9BYRQU/Choi et al. - 2019 - Sensorimotor influences on speech perception in pr.pdf},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {4}
}

@article{cholinEffectsSyllableFrequency2006,
  title = {Effects of Syllable Frequency in Speech Production},
  author = {Cholin, J and Levelt, W and Schiller, N},
  year = {2006},
  month = mar,
  volume = {99},
  pages = {205--235},
  issn = {00100277},
  doi = {10.1016/j.cognition.2005.01.009},
  abstract = {In the speech production model proposed by [Levelt, W. J. M., Roelofs, A., Meyer, A. S. (1999). A theory of lexical access in speech production. Behavioral and Brain Sciences, 22, pp. 1\textendash 75.], syllables play a crucial role at the interface of phonological and phonetic encoding. At this interface, abstract phonological syllables are translated into phonetic syllables. It is assumed that this translation process is mediated by a so-called Mental Syllabary. Rather than constructing the motor programs for each syllable on-line, the mental syllabary is hypothesized to provide pre-compiled gestural scores for the articulators. In order to find evidence for such a repository, we investigated syllable-frequency effects: If the mental syllabary consists of retrievable representations corresponding to syllables, then the retrieval process should be sensitive to frequency differences. In a series of experiments using a symbol-position association learning task, we tested whether highfrequency syllables are retrieved and produced faster compared to low-frequency syllables. We found significant syllable frequency effects with monosyllabic pseudo-words and disyllabic pseudo-words in which the first syllable bore the frequency manipulation; no effect was found when the frequency manipulation was on the second syllable. The implications of these results for the theory of word form encoding at the interface of phonological and phonetic encoding; especially with respect to the access mechanisms to the mental syllabary in the speech production model by (Levelt et al.) are discussed.},
  file = {/Users/megcychosz/Zotero/storage/HEZFAKRR/Cholin et al. - 2006 - Effects of syllable frequency in speech production.pdf},
  journal = {Cognition},
  language = {en},
  number = {2}
}

@article{chomskyReviewBFSkinner1959,
  title = {A Review of {{BF Skinner}}'s {{Verbal Behavior}}},
  author = {Chomsky, Noam},
  year = {1959},
  volume = {35},
  pages = {26--58},
  journal = {Language},
  number = {1}
}

@article{cicchettiGuidelinesCriteriaRules1994,
  title = {Guidelines, Criteria, and Rules of Thumb for Evaluating Normed and Standardized Assessment Instruments in Psychology},
  author = {Cicchetti, D.V.},
  year = {1994},
  volume = {6},
  pages = {284--290},
  journal = {Psychological Assessment}
}

@article{clancySoylentPeopleWEIRD2019,
  title = {Soylent {{Is People}}, and {{WEIRD Is White}}: {{Biological Anthropology}}, {{Whiteness}}, and the {{Limits}} of the {{WEIRD}}},
  shorttitle = {Soylent {{Is People}}, and {{WEIRD Is White}}},
  author = {Clancy, Kathryn B.H. and Davis, Jenny L.},
  year = {2019},
  month = oct,
  volume = {48},
  pages = {169--186},
  issn = {0084-6570, 1545-4290},
  doi = {10.1146/annurev-anthro-102218-011133},
  abstract = {WEIRD populations, or those categorized as Western, educated, industrialized, rich, and democratic, are sampled in the majority of quantitative human subjects research. Although this oversampling is criticized in some corners of social science research, it is not always clear what we are critiquing. In this article, we make three interventions into the WEIRD concept and its common usage. First, we seek to better operationalize the terms within WEIRD to avoid erasing people with varying identities who also live within WEIRD contexts. Second, we name whiteness as the factor that most strongly unites WEIRD research and researchers yet typically goes unacknowledged. We show how reflexivity is a tool that can help social scientists better understand the effects of whiteness within the scientific enterprise. Third, we look at the positionality of biological anthropology, as not cultural anthropology and not psychology, and how that offers both promise and pitfalls to the study of human variation. We offer other perspectives on what constitutes worthy and rigorous biological anthropology research that does not always prioritize replicability and statistical power, but rather emphasizes the full spectrum of the human experience. From here, we offer several ways forward to produce more inclusive human subjects research, particularly around existing methodologies such as grounded theory, Indigenous methodologies, and participatory action research, and call on biological anthropology to contribute to our understanding of whiteness.},
  file = {/Users/megcychosz/Zotero/storage/ZJKJQQE7/Clancy and Davis - 2019 - Soylent Is People, and WEIRD Is White Biological .pdf},
  journal = {Annual Review of Anthropology},
  language = {en},
  number = {1}
}

@article{coadyChildrenSpecificLanguage2007,
  title = {Children {{With Specific Language Impairments Perceive Speech Most Categorically When Tokens Are Natural}} and {{Meaningful}}},
  author = {Coady, Jeffry A. and Evans, Julia L. and {Mainela-Arnold}, Elina and Kluender, Keith R.},
  year = {2007},
  month = feb,
  volume = {50},
  pages = {41--57},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2007/004)},
  abstract = {Purpose\textemdash To examine perceptual deficits as a potential underlying cause of specific language impairments (SLI). Method\textemdash Twenty-one children with SLI (8;7\textendash 11;11 [years;months]) and 21 age-matched controls participated in categorical perception tasks using four series of syllables for which perceived syllable-initial voicing varied. Series were either words or abstract nonword syllables and either synthesized or high-quality edited natural utterances. Children identified and discriminated (a) digitally edited tokens of naturally spoken ``bowl''\textendash ''pole'', (b) synthesized renditions of ``bowl''\textendash ''pole'', (c) natural ``ba''\textendash ''pa'', and (d) synthetic ``ba''\textendash ''pa''. Results\textemdash Identification crossover locations were the same for both groups of children, but there was modestly less accuracy on unambiguous endpoints for children with SLI. Planned comparisons revealed these effects to be limited to synthesized speech. Children with SLI showed overall reduced discrimination, but these effects were limited to abstract nonword syllables. Conclusion\textemdash Overall, children with SLI perceived naturally spoken real words comparably to age-matched peers but showed impaired identification and discrimination of synthetic speech and of abstract syllables. Poor performance on speech perception tasks may result from task demands and stimulus properties, not perceptual deficits.},
  file = {/Users/megcychosz/Zotero/storage/8SYVCGAL/Coady et al. - 2007 - Children With Specific Language Impairments Percei.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {1}
}

@article{coadyPhonologicalNeighbourhoodsDeveloping2003,
  title = {Phonological Neighbourhoods in the Developing Lexicon},
  author = {Coady, Jeffry A. and Aslin, Richard N.},
  year = {2003},
  month = may,
  volume = {30},
  pages = {441--469},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000903005579},
  abstract = {Structural analyses of developing lexicons have provided evidence for both children's holistic lexical representations and sensitivity to phonetic segments. In the present investigation, neighbourhood analyses of two children's (age 3;6) expressive lexicons, maternal input, and an adult lexicon were conducted. In addition to raw counts and frequency-weighted counts, neighbourhood size was calculated as the proportion of the lexicon to which each target word is similar, to normalize for vocabulary size differences. These analyses revealed that children's lexicons contain more similar sounding words than previous analyses indicated. Further, neighbourhoods appear denser earlier in development relative to vocabulary size, presumably because children first learn words with more frequent sounds and sound combinations. Neighbourhood density as a proportion of the size of the lexicon then decreases over development as children acquire words with less frequent sounds and sound combinations. These findings suggest that positing fundamentally different lexical representations for children may be premature.},
  file = {/Users/megcychosz/Zotero/storage/UYRD7TM5/Coady and Aslin - 2003 - Phonological neighbourhoods in the developing lexi.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {2}
}

@article{coadyYoungChildrenSensitivity2004,
  title = {Young Children's Sensitivity to Probabilistic Phonotactics in the Developing Lexicon},
  author = {Coady, Jeffry A. and Aslin, Richard N.},
  year = {2004},
  month = nov,
  volume = {89},
  pages = {183--213},
  issn = {00220965},
  doi = {10.1016/j.jecp.2004.07.004},
  abstract = {A series of three experiments examined children's sensitivity to probabilistic phonotactic structure as reflected in the relative frequencies with which speech sounds occur and co-occur in American English. Children, ages and years, participated in a nonword repetition task that examined their sensitivity to the frequency of individual phonetic segments and to the frequency of combinations of segments. After partialling out ease of articulation and lexical variables, both groups of children repeated higher phonotactic frequency nonwords more accurately than they did low phonotactic frequency nonwords, suggesting sensitivity to phoneme frequency. In addition, sensitivity to individual phonetic segments increased with age. Finally, older children, but not younger children, were sensitive to the frequency of larger (diphone) units. These results suggest not only that young children are sensitive to fine-grained acoustic\textendash phonetic information in the developing lexicon but also that sensitivity to all aspects of the sound structure increases over development. Implications for the acoustic nature of both developing and mature lexical representations are discussed.},
  file = {/Users/megcychosz/Zotero/storage/4HRDZ79B/Coady and Aslin - 2004 - Young children’s sensitivity to probabilistic phon.pdf},
  journal = {Journal of Experimental Child Psychology},
  language = {en},
  number = {3}
}

@article{cohenprivaInterdependenceFrequencyPredictability2018,
  title = {The Interdependence of Frequency, Predictability, and Informativity in the Segmental Domain},
  author = {Cohen Priva, Uriel and Jaeger, T. Florian},
  year = {2018},
  month = sep,
  volume = {4},
  issn = {2199-174X},
  doi = {10.1515/lingvan-2017-0028},
  file = {/Users/megcychosz/Zotero/storage/6G6ZDUQD/Cohen Priva and Jaeger - 2018 - The interdependence of frequency, predictability, .pdf},
  journal = {Linguistics Vanguard},
  language = {en},
  number = {s2}
}

@phdthesis{cohenprivaSignSignalDeriving2012,
  title = {Sign and Signal: {{Deriving}} Linguistic Generalizations for Information Utility},
  author = {Cohen Priva, Uriel},
  year = {2012},
  school = {Stanford University},
  type = {Dissertation}
}

@article{cohenProbabilisticReductionProbabilistic2014,
  title = {Probabilistic Reduction and Probabilistic Enhancement: {{Contextual}} and Paradigmatic Effects on Morpheme Pronunciation},
  shorttitle = {Probabilistic Reduction and Probabilistic Enhancement},
  author = {Cohen, Clara},
  year = {2014},
  month = nov,
  volume = {24},
  pages = {291--323},
  issn = {1871-5621, 1871-5656},
  doi = {10.1007/s11525-014-9243-y},
  abstract = {Research on probabilistic pronunciation variation has generally focused on contextual probability, or the probability of using a linguistic unit (segment, syllable, word, etc.) in the context of a particular utterance. Overwhelmingly, this research has found that higher contextual probability leads to phonetic reduction. Less attention, however, has been given to paradigmatic probability, or the probability of using a particular linguistic form from a paradigm of related forms. The research that has addressed this type of probability has found inconsistent results: Sometimes higher paradigmatic probability leads to phonetic enhancement, and sometimes to phonetic reduction. In this paper I present the results of an experiment exploring the effects of both types of probability simultaneously on the pronunciation of agreement suffixes on English verbs. I find that (i) singular verb suffixes and stems are phonetically reduced when singular agreement is contextually probable; (ii) the nature of the reduction is modulated by verb frequency, consistent with dual-route models of lexical retrieval; and (iii) suffixes are phonetically enhanced when they are paradigmatically probable. I conclude by discussing how the patterns observed in this study shed light on the previous contradictory findings regarding the effects of paradigmatic probability on pronunciation.},
  file = {/Users/megcychosz/Zotero/storage/I7H6QR7X/Cohen - 2014 - Probabilistic reduction and probabilistic enhancem.pdf},
  journal = {Morphology},
  language = {en},
  number = {4}
}

@article{coleWordsMorphemesUnits1997,
  title = {Words and {{Morphemes}} as {{Units}} for {{Lexical Access}}},
  author = {Col{\'e}, Pascale and Segui, Juan and Taft, Marcus},
  year = {1997},
  month = oct,
  volume = {37},
  pages = {312--330},
  issn = {0749596X},
  doi = {10.1006/jmla.1997.2523},
  file = {/Users/megcychosz/Zotero/storage/G9WNKVL9/Colé et al. - 1997 - Words and Morphemes as Units for Lexical Access.pdf},
  journal = {Journal of Memory and Language},
  language = {en},
  number = {3}
}

@article{collettiInfantsOlderChildren2011,
  title = {Infants versus Older Children Fitted with Cochlear Implants: {{Performance}} over 10 Years},
  author = {Colletti, Liliana and Mandal{\`a}, Marco and Zoccante, Leonardo and Shannon, Robert V. and Colletti, Vittorio},
  year = {2011},
  volume = {75},
  pages = {504--509},
  journal = {International Journal of Pediatric Otorhinolaryngology},
  number = {4}
}

@article{constantinescuSatisfactionTelemedicineTeaching2012,
  title = {Satisfaction with Telemedicine for Teaching Listening and Spoken Language to Children with Hearing Loss},
  author = {Constantinescu, Gabriella},
  year = {2012},
  month = jul,
  volume = {18},
  pages = {267--272},
  issn = {1357-633X, 1758-1109},
  doi = {10.1258/jtt.2012.111208},
  abstract = {Auditory-Verbal Therapy (AVT) is an effective early intervention for children with hearing loss. The Hear and Say Centre in Brisbane offers AVT sessions to families soon after diagnosis, and about 20\% of the families in Queensland participate via PC-based videoconferencing (Skype). Parent and therapist satisfaction with the telemedicine sessions was examined by questionnaire. All families had been enrolled in the telemedicine AVT programme for at least six months. Their average distance from the Hear and Say Centre was 600 km. Questionnaires were completed by 13 of the 17 parents and all five therapists. Parents and therapists generally expressed high satisfaction in the majority of the sections of the questionnaire, e.g. most rated the audio and video quality as good or excellent. All parents felt comfortable or as comfortable as face-toface when discussing matters with the therapist online, and were satisfied or as satisfied as face-to-face with their level and their child's level of interaction/rapport with the therapist. All therapists were satisfied or very satisfied with the telemedicine AVT programme. The results demonstrate the potential of telemedicine service delivery for teaching listening and spoken language to children with hearing loss in rural and remote areas of Australia.},
  file = {/Users/megcychosz/Zotero/storage/WDDAASID/Constantinescu - 2012 - Satisfaction with telemedicine for teaching listen.pdf},
  journal = {Journal of Telemedicine and Telecare},
  language = {en},
  number = {5}
}

@article{cooperIdentifyingChildrenVoices2020,
  title = {Identifying Children's Voices},
  author = {Cooper, Angela and Fecher, Natalie and Johnson, Elizabeth K.},
  year = {2020},
  month = jul,
  volume = {148},
  pages = {324--333},
  issn = {0001-4966},
  doi = {10.1121/10.0001576},
  file = {/Users/megcychosz/Zotero/storage/AYY2MJKC/Cooper et al. - 2020 - Identifying children's voices.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{cooperPreferenceInfantdirectedSpeech1990,
  title = {Preference for Infant-Directed Speech in the First Month after Birth},
  author = {Cooper, R.P. and Aslin, R.N.},
  year = {1990},
  volume = {61},
  pages = {1584--1595},
  journal = {Child Development},
  number = {5}
}

@article{cooperToddlersComprehensionAdult2018,
  title = {Toddlers' Comprehension of Adult and Child Talkers: {{Adult}} Targets versus Vocal Tract Similarity},
  shorttitle = {Toddlers' Comprehension of Adult and Child Talkers},
  author = {Cooper, Angela and Fecher, Natalie and Johnson, Elizabeth K.},
  year = {2018},
  month = apr,
  volume = {173},
  pages = {16--20},
  issn = {00100277},
  doi = {10.1016/j.cognition.2017.12.013},
  file = {/Users/megcychosz/Zotero/storage/RBTHA38G/Cooper et al. - 2018 - Toddlers’ comprehension of adult and child talkers.pdf},
  journal = {Cognition},
  language = {en}
}

@inproceedings{coreRoleLanguageExperience2017,
  title = {The {{Role}} of {{Language Experience}} in {{Nonword Repetition Tasks}} in {{Young Bilingual Spanish}}-{{English Speaking Children}}},
  booktitle = {Proceedings of the 41st {{Annual Boston University Conference}} on {{Language Development}}},
  author = {Core, Cynthia and Chaturvedi, Shreya and {Martinez-Nadramia}, Diego},
  year = {2017},
  pages = {179--185},
  publisher = {{Cascadilla Press}},
  address = {{Somerville, MA}},
  file = {/Users/megcychosz/Zotero/storage/G4PRE36E/Core - The Role of Language Experience in Nonword Repetit.pdf},
  language = {en}
}

@incollection{cournaneDefenceChildInnovator2017,
  title = {In Defence of the Child Innovator},
  booktitle = {Micro-Change and {{Macro}}-Change in {{Diachronic Syntax}}},
  author = {Cournane, Ail{\'i}s},
  editor = {Mathieu, Eric and Truswell, Robert},
  year = {2017},
  edition = {First},
  publisher = {{Oxford University Press}},
  doi = {10.1093/oso/9780198747840.003.0002},
  abstract = {This chapter confronts the two principal arguments levelled against the child-as-innovator approach to language change: (1) child innovations cannot underlie historical innovations because child innovations resolve before adulthood, when they could diffuse (e.g. Traugott and Dasher 2005; Diessel 2011), and (2) parallels must hold between child innovations and historical innovations, but parallels do not hold in the domain of morphosyntax (e.g. Diessel 2012). I argue that both parallel and oppositional alignments are predicted by the two possible innovation-types children make when solving the Mapping Problem (Clark 1977, 1993, i.a.); in short, different L1A processes underlie different types of change. I further argue that input-divergent analyses at most need to persist into the teenage years, when they can be diffused via the sociolinguistic change powerhouse of teenage peer groups (e.g. Labov 2012), and may also be reinforced and prolonged in childhood via peer-to-peer acquisition and bilingualism contexts.},
  file = {/Users/megcychosz/Zotero/storage/UQVH8UBM/Cournane - 2017 - In defence of the child innovator.pdf},
  language = {en}
}

@article{cournaneDevelopmentalViewIncrementation2019,
  title = {A Developmental View on Incrementation in Language Change},
  author = {Cournane, Ail{\'i}s},
  year = {2019},
  volume = {45},
  pages = {127--150},
  issn = {0301-4428, 1613-4060},
  doi = {10.1515/tl-2019-0010},
  abstract = {Acquisition is an intuitive place to look for explanation in language change. Each child must learn their individual grammar(s) via the indirect process of analyzing the output of others' grammars, and the process necessarily involves social transmission over several years. On the basis of child language learning behaviors, I ask whether it is reasonable to expect the incrementation (advancement) of new variants to be kicked off by and sustained by the acquisition process. I discuss literature on how children respond to input variation, and a series of new studies experimentally testing incrementation, and argue that at least for some phenomena, young children overgeneralize innovative variants beyond their input. I sketch a model of incrementation based on initial overgeneralization, and offer further thoughts on next steps. Much collaborative work remains to precisely link analogous dynamic phenomena in learning and change.},
  file = {/Users/megcychosz/Zotero/storage/ZY3KLEPN/Cournane - 2019 - A developmental view on incrementation in language.pdf},
  journal = {Theoretical Linguistics},
  language = {en},
  number = {3-4}
}

@incollection{courtneyChildAcquisitionQuechua2015,
  title = {4 {{Child Acquisition}} of {{Quechua Evidentiality}} and {{Deictic Meaning}}},
  booktitle = {Quechua {{Expressions}} of {{Stance}} and {{Deixis}}},
  author = {Courtney, Ellen H.},
  editor = {Manley, Marilyn and Muntendam, Antje},
  year = {2015},
  month = mar,
  pages = {101--144},
  publisher = {{Brill}},
  doi = {10.1163/9789004290105_005},
  file = {/Users/megcychosz/Zotero/storage/EWCBEMJR/Courtney - 2015 - 4 Child Acquisition of Quechua Evidentiality and D.pdf},
  isbn = {978-90-04-29010-5},
  language = {en}
}

@article{courtneyLearningConstructVerbs2002,
  title = {Learning to Construct Verbs in {{Navajo}} and {{Quechua}}},
  author = {Courtney, Ellen H. and {Saville-Troike}, Muriel},
  year = {2002},
  volume = {29},
  pages = {623--654},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000902005160},
  file = {/Users/megcychosz/Zotero/storage/EUJ7X72V/Courtney and Saville-Troike - 2002 - Learning to construct verbs in Navajo and Quechua.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {03}
}

@book{crelinHumanVocalTract1987,
  title = {The Human Vocal Tract: {{Anatomy}}, Function, Development, and Evolution},
  author = {Crelin, Edmund S.},
  year = {1987},
  publisher = {{Vantage Press}}
}

@article{cristiaChildDirectedSpeechInfrequent2019,
  title = {Child-{{Directed Speech Is Infrequent}} in a {{Forager}}-{{Farmer Population}}: {{A Time Allocation Study}}},
  shorttitle = {Child-{{Directed Speech Is Infrequent}} in a {{Forager}}-{{Farmer Population}}},
  author = {Cristi{\`a}, Alejandrina and Dupoux, Emmanuel and Gurven, Michael and Stieglitz, Jonathan},
  year = {2019},
  volume = {90},
  pages = {759--773},
  issn = {00093920},
  doi = {10.1111/cdev.12974},
  abstract = {This paper provides an estimation of how frequently, and from whom, children aged 0-11 years (Ns between 9 and 24) receive one-on-one verbal input among Tsimane forager-horticulturalists of lowland Bolivia. Analyses of systematic day-time behavioral observations reveal less than 1 minute per daylight hour is spent talking to children younger than 4 years of age, which is 4 times less than estimates for others present at the same time and place. Adults provide a majority of the input at 0-3 years of age, but not afterwards.},
  file = {/Users/megcychosz/Zotero/storage/4JS73LRT/Cristia et al. - 2017 - Child-Directed Speech Is Infrequent in a Forager-F.pdf},
  journal = {Child Development},
  language = {en},
  number = {3}
}

@article{cristiaEffectsDistributionAcoustic2011,
  title = {Effects of the Distribution of Acoustic Cues on Infants' Perception of Sibilants},
  author = {Cristia, Alejandrina and McGuire, Grant L. and Seidl, Amanda and Francis, Alexander L.},
  year = {2011},
  month = jul,
  volume = {39},
  pages = {388--402},
  issn = {00954470},
  doi = {10.1016/j.wocn.2011.02.004},
  abstract = {A current theoretical view proposes that infants converge on the speech categories of their native language by attending to frequency distributions that occur in the acoustic input. To date, the only empirical support for this statistical learning hypothesis comes from studies where a single, salient dimension was manipulated. Additional evidence is sought here, by introducing a less salient pair of categories supported by multiple cues. We exposed English-learning infants to a multi-cue bidimensional grid between retroflex and alveolopalatal sibilants in prevocalic position. This contrast is substantially more difficult according to previous cross-linguistic and perceptual research, and its perception is driven by cues in both the consonantal and the following vowel portions. Infants heard one of two distributions (flat, or with two peaks), and were tested with sounds varying along only one dimension. Infants' responses differed depending on the familiarization distribution, and their performance was equally good for the vocalic and the frication dimension, lending some support to the statistical hypothesis even in this harder learning situation. However, learning was restricted to the retroflex category, and a control experiment showed that lack of learning for the alveolopalatal category was not due to the presence of a competing category. Thus, these results contribute fundamental evidence on the extent and limitations of the statistical hypothesis as an explanation for infants' perceptual tuning.},
  file = {/Users/megcychosz/Zotero/storage/MA74LBRW/Cristià et al. - 2011 - Effects of the distribution of acoustic cues on in.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {3}
}

@article{cristiaFinegrainedVariationCaregivers2011,
  title = {Fine-Grained Variation in Caregivers' /s/ Predicts Their Infants' /s/ Category},
  author = {Cristia, Alejandrina},
  year = {2011},
  month = may,
  volume = {129},
  pages = {3271--3280},
  issn = {0001-4966},
  doi = {10.1121/1.3562562},
  file = {/Users/megcychosz/Zotero/storage/2YCI9YB8/Cristià - 2011 - Fine-grained variation in caregivers’ s predicts.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{cristiaHyperarticulationHypothesisInfantdirected2014,
  title = {The Hyperarticulation Hypothesis of Infant-Directed Speech},
  author = {Cristia, Alejandrina and Seidl, Amanda},
  year = {2014},
  volume = {41},
  pages = {913--934},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000914000105},
  file = {/Users/megcychosz/Zotero/storage/Y4N4SVQG/2014 - The hyperarticulation hypothesis of infant-directe.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {4}
}

@phdthesis{cristiaIndividualVariationInfant2009,
  title = {Individual Variation in Infant Speech Processing: Implications for Language Acquisition Theories},
  author = {Cristia, Alejandrina},
  year = {2009},
  abstract = {To what extent does language acquisition recruit domain-general processing mech- anisms? In this dissertation, evidence concerning this question is garnered from the study of individual differences in infant speech perception and their predictive value with respect to language development in early childhood. In the first experiment, variation in the processing of a linguistic unit at six months was found to predict vocabulary development at around 2 years of age, whereas processing of a non-unit did not. In the second experiment, one possible source for that variation in linguis- tic performance was assessed, namely information processing abilities. Infants were tested on the same linguistic task as in Experiment 1, and on a well-researched task that yields a measure of information processing in infancy. No covariance was found between measures gathered in the linguistic and the information processing tasks. In a third experiment, the impact of variation in the infants' input on their speech processing was investigated. Correlations between infants' performance in a speech sound discrimination task and acoustic characteristics of their primary caregivers' speech were investigated. Two types of acoustic characteristics were measured; some were not relevant to the speech sound being tested, but are known to influence in- fants' attention and learning (pitch and pitch modulations); others were specific to the contrast tested. Results suggested that only those characteristics relevant to the contrast being tested affected infants' speech processing. In sum, these three experiments and extensive literature reviews suggest specific ways in which domain- general factors (such as attentional mechanisms) are involved in infants' development of linguistic knowledge. While these factors appear to play a role in the learning of phonological units, their influence may not be evident once linguistic categories are already established.},
  language = {en},
  school = {Purdue University}
}

@article{cristiaInfantdirectedInputLiteracy2020a,
  title = {Infant-Directed Input and Literacy Effects on Phonological Processing: {{Non}}-Word Repetition Scores among the {{Tsimane}}'},
  shorttitle = {Infant-Directed Input and Literacy Effects on Phonological Processing},
  author = {Cristia, Alejandrina and Farabolini, Gianmatteo and Scaff, Camila and Havron, Naomi and Stieglitz, Jonathan},
  editor = {Mulak, Karen E.},
  year = {2020},
  month = sep,
  volume = {15},
  pages = {e0237702},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0237702},
  file = {/Users/megcychosz/Zotero/storage/98R24VCK/Cristia et al. - 2020 - Infant-directed input and literacy effects on phon.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {9}
}

@article{cristiaInputLanguagePhonetics2013,
  title = {Input to {{Language}}: {{The Phonetics}} and {{Perception}} of {{Infant}}-{{Directed Speech}}},
  shorttitle = {Input to {{Language}}},
  author = {Cristia, Alejandrina},
  year = {2013},
  volume = {7},
  pages = {157--170},
  issn = {1749-818X},
  doi = {10.1111/lnc3.12015},
  abstract = {Over the first year of life, infant perception changes radically as the child learns the phonology of the ambient language from the speech she is exposed to. Since infant-directed speech attracts the child's attention more than other registers, it is necessary to describe that input in order to understand language development, and to address questions of learnability. In this review, evidence from corpora analyses, experimental studies, and observational paradigms is brought together to outline the first comprehensive empirical picture of infant-directed speech and its effects on language acquisition. The ensuing landscape suggests that infant-directed speech provides an emotionally and linguistically rich input to language acquisition.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/lnc3.12015},
  file = {/Users/megcychosz/Zotero/storage/I9HKQQ7N/lnc3.12015.pdf},
  journal = {Language and Linguistics Compass},
  language = {en},
  number = {3}
}

@article{cristiaLanguageInputOutcome2020,
  title = {Language Input and Outcome Variation as a Test of Theory Plausibility: {{The}} Case of Early Phonological Acquisition},
  author = {Cristia, Alejandrina},
  year = {2020},
  file = {/Users/megcychosz/Zotero/storage/7XR72E6Z/Cristia - 2019 - Language input and outcome variation as a test of .pdf;/Users/megcychosz/Zotero/storage/DX9WXQ6Y/Cristia_2019.pdf},
  journal = {Developmental Review}
}

@article{cristiaNonwordRepetitionChildren,
  title = {Non-Word Repetition in Children Learning {{Y\'el\^i Dnye}}},
  author = {Cristia, Alejandrina and Casillas, Marisa},
  pages = {45},
  file = {/Users/megcychosz/Zotero/storage/E33EPYJE/Non-word repetition in children learning Yélî Dnye.pdf},
  language = {en}
}

@article{cristiaPredictingIndividualVariation2014,
  title = {Predicting {{Individual Variation}} in {{Language From Infant Speech Perception Measures}}},
  author = {Cristia, Alejandrina and Seidl, Amanda and Junge, Caroline and Soderstrom, Melanie and Hagoort, Peter},
  year = {2014},
  month = jul,
  volume = {85},
  pages = {1330--1345},
  issn = {00093920},
  doi = {10.1111/cdev.12193},
  file = {/Users/megcychosz/Zotero/storage/MGACT6G7/Cristia et al. - 2014 - Predicting Individual Variation in Language From I.pdf},
  journal = {Child Development},
  language = {en},
  number = {4}
}

@article{cristiaThoroughEvaluationLanguage2020,
  title = {A Thorough Evaluation of the {{Language Environment Analysis}} ({{LENA}}) System},
  author = {Cristia, Alejandrina and Lavechin, Marvin and Scaff, Camila and Soderstrom, Melanie and Rowland, Caroline and R{\"a}s{\"a}nen, Okko and Bunce, John and Bergelson, Elika},
  year = {2020},
  abstract = {In the previous decade, dozens of studies involving thousands of children across several research disciplines have made use of a combined daylong audio-recorder and automated algorithmic analysis called the LENAR system, which aims to assess children's language environment. While the system's prevalence in the language acquisition domain is steadily growing, there are only scattered validation efforts, on only some of its key characteristics. Here, we assess the LENAR system's accuracy across all of its key measures: speaker classification, adult word counts (AWC), child vocalization counts (CVC), and conversational turn counts (CTC). Our assessment is based on manual annotation of clips that have been randomly or periodically sampled out of daylong recordings, collected from (a) populations similar to LENAR`s original training data (North American English-learning children aged 3-36 months), (b) children learning another dialect of English (UK), and (c) slightly older children growing up in a different linguistic and socio-cultural setting (Tsimane' learners in rural Bolivia). We find reasonably high accuracy in some measures (AWC, CTC), with more problematic levels of performance in others (CTC, precision and recall of male adults and other children). We find little difference in accuracy as a function of child age, dialect, or socio-cultural setting. Whether LENAR results are accurate enough for a given research, educational, or clinical application depends largely on the specifics at hand. We therefore conclude with a set of recommendations to help researchers make this determination for their goals.},
  file = {/Users/megcychosz/Zotero/storage/MSVTU5E8/Cristia et al. - A thorough evaluation of the Language Environment .pdf},
  journal = {Behavior Research Methods},
  language = {en}
}

@article{cristiaThoroughEvaluationLanguage2020a,
  title = {A Thorough Evaluation of the {{Language Environment Analysis}} ({{LENA}}) System},
  author = {Cristia, Alejandrina and Lavechin, Marvin and Scaff, Camila and Soderstrom, Melanie and Rowland, Caroline and R{\"a}s{\"a}nen, Okko and Bunce, John and Bergelson, Elika},
  year = {2020},
  month = jul,
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01393-5},
  abstract = {In the previous decade, dozens of studies involving thousands of children across several research disciplines have made use of a combined daylong audio-recorder and automated algorithmic analysis called the LENA system, which aims to assess children's language environment. While the system's prevalence in the language acquisition domain is steadily growing, there are only scattered validation efforts on only some of its key characteristics. Here, we assess the LENA system's accuracy across all of its key measures: speaker classification, Child Vocalization Counts (CVC), Conversational Turn Counts (CTC), and Adult Word Counts (AWC). Our assessment is based on manual annotation of clips that have been randomly or periodically sampled out of daylong recordings, collected from (a) populations similar to the system's original training data (North American English-learning children aged 3-36 months), (b) children learning another dialect of English (UK), and (c) slightly older children growing up in a different linguistic and socio-cultural setting (Tsimane' learners in rural Bolivia). We find reasonably high accuracy in some measures (AWC, CVC), with more problematic levels of performance in others (CTC, precision of male adults and other children). Statistical analyses do not support the view that performance is worse for children who are dissimilar from the LENA original training set. Whether LENA results are accurate enough for a given research, educational, or clinical application depends largely on the specifics at hand. We therefore conclude with a set of recommendations to help researchers make this determination for their goals.},
  file = {/Users/megcychosz/Zotero/storage/L3IIBKZL/Cristia et al. - 2020 - A thorough evaluation of the Language Environment .pdf},
  journal = {Behavior Research Methods},
  language = {en}
}

@misc{CrosslinguisticComparisonUtterance,
  title = {Cross-Linguistic Comparison of Utterance Shapes in {{Korean}}- and {{English}}-Learning Children: {{An}} Ambient Language Effect | {{Elsevier Enhanced Reader}}},
  shorttitle = {Cross-Linguistic Comparison of Utterance Shapes in {{Korean}}- and {{English}}-Learning Children},
  doi = {10.1016/j.infbeh.2021.101528},
  file = {/Users/megcychosz/Zotero/storage/RF8BD6SR/S0163638321000035.html},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S0163638321000035?token=05E7B958C3004AAF393C13549A007397C822EF6A5BC3A4C55C8AC9D157BEE6ACD11BD23C8BAB46E2949364D744D3D959},
  language = {en}
}

@article{cruzIdentificationEffectiveStrategies2013,
  title = {Identification of {{Effective Strategies}} to {{Promote Language}} in {{Deaf Children With Cochlear Implants}}},
  author = {Cruz, Ivette and Quittner, Alexandra L. and Marker, Craig and DesJardin, Jean L. and {CDaCI Investigative Team}},
  year = {2013},
  month = mar,
  volume = {84},
  pages = {543--559},
  issn = {00093920},
  doi = {10.1111/j.1467-8624.2012.01863.x},
  file = {/Users/megcychosz/Zotero/storage/8JQZY3IL/Cruz et al. - 2013 - Identification of Effective Strategies to Promote .pdf},
  journal = {Child Development},
  language = {en},
  number = {2}
}

@article{crystalSegmentalDurationsConnected1982,
  title = {Segmental Durations in Connected Speech Signals: {{Preliminary}} Results},
  shorttitle = {Segmental Durations in Connected Speech Signals},
  author = {Crystal, Thomas H. and House, Arthur S.},
  year = {1982},
  month = sep,
  volume = {72},
  pages = {705--716},
  issn = {0001-4966},
  doi = {10.1121/1.388251},
  file = {/Users/megcychosz/Zotero/storage/C2BU6TMY/Crystal and House - 1982 - Segmental durations in connected speech signals P.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {3}
}

@article{crystalSegmentalDurationsConnected1988,
  title = {Segmental Durations in Connected-speech Signals: {{Current}} Results},
  shorttitle = {Segmental Durations in Connected-speech Signals},
  author = {Crystal, Thomas H. and House, Arthur S.},
  year = {1988},
  month = apr,
  volume = {83},
  pages = {1553--1573},
  issn = {0001-4966},
  doi = {10.1121/1.395911},
  file = {/Users/megcychosz/Zotero/storage/GXHW88XX/Crystal and House - 1988 - Segmental durations in connected‐speech signals C.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@article{culbertsonArtificialLanguageLearning2019,
  title = {Artificial {{Language Learning}} in {{Children}}},
  author = {Culbertson, Jennifer and Schuler, Kathryn},
  year = {2019},
  month = jan,
  volume = {5},
  pages = {353--373},
  issn = {2333-9683, 2333-9691},
  doi = {10.1146/annurev-linguistics-011718-012329},
  abstract = {Artificial language learning methods\textemdash in which learners are taught miniature constructed languages in a controlled laboratory setting\textemdash have become a valuable experimental tool for research on language development. These methods offer a complement to natural language acquisition data, allowing researchers to control both the input to learning and the learning environment. A large proportion of artificial language learning studies has aimed to understand the mechanisms of learning in infants. This review focuses instead on investigations into the nature of early linguistic representations and how they are influenced by both the structure of the input and the cognitive features of the learner. Looking not only at young infants but also at children beyond infancy, we discuss evidence for early abstraction, conditions on generalization, the acquisition of grammatical categories and dependencies, and recent work connecting the cognitive biases of learners to language typology. We end by outlining important areas for future research.},
  file = {/Users/megcychosz/Zotero/storage/RTAFUD8M/Culbertson and Schuler - 2019 - Artificial Language Learning in Children.pdf},
  journal = {Annual Review of Linguistics},
  language = {en},
  number = {1}
}

@article{culbertsonHarmonicBiasesChild2015,
  title = {Harmonic Biases in Child Learners: {{In}} Support of Language Universals},
  shorttitle = {Harmonic Biases in Child Learners},
  author = {Culbertson, Jennifer and Newport, Elissa L.},
  year = {2015},
  month = jun,
  volume = {139},
  pages = {71--82},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2015.02.007},
  abstract = {A fundamental question for cognitive science concerns the ways in which languages are shaped by the biases of language learners. Recent research using laboratory language learning paradigms, primarily with adults, has shown that structures or rules that are common in the languages of the world are learned or processed more easily than patterns that are rare or unattested. Here we target child learners, investigating a set of biases for word order learning in the noun phrase studied by  in college-age adults. We provide the first evidence that child learners exhibit a preference for typologically common harmonic word order patterns\textemdash those which preserve the order of the head with respect to its complements\textemdash validating the psychological reality of a principle formalized in many different linguistic theories. We also discuss important differences between child and adult learners in terms of both the strength and content of the biases at play during language learning. In particular, the bias favoring harmonic patterns is markedly stronger in children than adults, and children (unlike adults) acquire adjective ordering more readily than numeral ordering. The results point to the importance of investigating learning biases across development in order to understand how these biases may shape the history and structure of natural languages.},
  file = {/Users/megcychosz/Zotero/storage/F2TGDLSB/Culbertson and Newport - 2015 - Harmonic biases in child learners In support of l.pdf},
  journal = {Cognition},
  pmcid = {PMC4397919},
  pmid = {25800352}
}

@article{curtinWhenPhonologyGuides2018,
  title = {When Phonology Guides Learning},
  author = {Curtin, Suzanne and Graham, Susan A.},
  year = {2018},
  month = jul,
  volume = {39},
  pages = {729--734},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716418000164},
  file = {/Users/megcychosz/Zotero/storage/2TVELFBQ/Curtin and Graham - 2018 - When phonology guides learning.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {04}
}

@inproceedings{cychoszChildrenNotUniformly2020,
  title = {Children Do Not Uniformly Compensate for Their Changing Vocal Tract Anatomies},
  booktitle = {Acoustical {{Society}} of {{America}}},
  author = {Cychosz, Margaret and Johnson, K.},
  year = {2020},
  address = {{Chicago, IL}}
}

@article{cychoszCoarticulationdurationRelationshipEarly[underreview],
  title = {The Coarticulation-Duration Relationship in Early {{Quechua}} Speech},
  author = {Cychosz, Margaret},
  year = {[under review]},
  doi = {10.31234/osf.io/26uyb}
}

@techreport{cychoszCoarticulatoryPracticesIndicators2018,
  title = {Coarticulatory Practices as Indicators of Morphological Decomposition},
  author = {Cychosz, Margaret},
  year = {2018},
  type = {Open {{Science Framework}} Project}
}

@inproceedings{cychoszContributionFunctionalLoad2018,
  title = {The {{Contribution}} of {{Functional Load}} on {{Children}}'s {{Vocalic Development}}},
  booktitle = {Supplemental {{Proceedings}} of the 2017 {{Annual Meeting}} on {{Phonology}}},
  author = {Cychosz, Margaret and Kalt, Susan},
  editor = {Gallagher, Gillian and Gouskova, M. and Yin, S.},
  year = {2018},
  publisher = {{Linguistic Society of America}},
  address = {{Washington, D.C.}}
}

@book{cychoszCychoszHomeBankCorpus2018,
  title = {Cychosz {{HomeBank Corpus}}},
  author = {Cychosz, Margaret},
  year = {2018}
}

@unpublished{cychoszEfficientEstimationBilingual2020,
  title = {Efficient Estimation of Bilingual Children's Language  Exposure from Daylong Audio Recordings},
  author = {Cychosz, Margaret and Villanueva, Anele and Weisleder, Adriana},
  year = {2020},
  type = {Under Review}
}

@techreport{cychoszExposurePracticeChild2020,
  title = {Exposure, Practice, and Child Speech Variability: {{Evidence}} from Daylong Recordings of Children's Language Environments},
  author = {Cychosz, Margaret and Munson, Benjamin and Edwards, Jan},
  year = {2020},
  type = {Open {{Science Framework}} Project}
}

@misc{cychoszFamiliarityPracticePredict2019,
  title = {Familiarity and Practice Predict Autonomy in Children's Speech Gestures},
  author = {Cychosz, Margaret and Munson, Benjamin and Edwards, Jan},
  year = {2019},
  address = {{Sydney, Australia}}
}

@inproceedings{cychoszFunctionalLoadFrequency2018,
  title = {Functional Load and Frequency as Predictors of Consonant Emergence across Five Languages},
  booktitle = {Proceedings of the 40th {{Annual Meeting}} of the {{Cognitive Science Society}}},
  author = {Cychosz, Margaret},
  year = {2018},
  address = {{Madison, WI}}
}

@inproceedings{cychoszHolisticLexicalStorage2019,
  title = {Holistic Lexical Storage: {{Coarticulatory}} Evidence from Child Speech},
  booktitle = {Proceedings of the 19th {{International Congress}} of the {{Phonetic Sciences}}},
  author = {Cychosz, Margaret},
  year = {2019},
  address = {{Melbourne, Australia}}
}

@article{cychoszHolisticLexicalStorageinprep,
  title = {Holistic Lexical Storage: {{Coarticulatory}} Evidence from Child Speech},
  author = {Cychosz, Margaret and Johnson, Keith},
  year = {in prep}
}

@inproceedings{cychoszLanguageSpecificSourcesAcoustic2018,
  title = {Language-{{Specific Sources}} of {{Acoustic Stability}} in {{Phonological Development}}},
  booktitle = {Proceedings from the 42nd {{Boston University Conference}} on {{Language Development}}},
  author = {Cychosz, Margaret and Kalt, Susan},
  year = {2018},
  address = {{Boston, MA}}
}

@article{cychoszLexicalAdvantageFouryearold2020,
  title = {A Lexical Advantage in Four-Year-Old Children's Word Repetition},
  author = {Cychosz, Margaret and Erskine, Michelle and Munson, Benjamin and Edwards, Jan R.},
  year = {2020},
  file = {/Users/megcychosz/Zotero/storage/KFAAL9V5/Cychosz et al. - 2020 - A lexical advantage in four-year-old children's wo.pdf;/Users/megcychosz/Zotero/storage/VMQ8N8DT/a-lexical-advantage-in-four-year-old-childrens-word-repetition.pdf},
  journal = {Journal of Child Language}
}

@article{cychoszLongformRecordingsEveryday2020,
  title = {Longform Recordings of Everyday Life: {{Ethics}} for Best Practices},
  shorttitle = {Longform Recordings of Everyday Life},
  author = {Cychosz, Margaret and Romeo, Rachel and Soderstrom, Melanie and Scaff, Camila and Ganek, Hillary and Cristia, Alejandrina and Casillas, Marisa and {de Barbaro}, Kaya and Bang, Janet Y. and Weisleder, Adriana},
  year = {2020},
  volume = {52},
  pages = {1951--1969},
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01365-9},
  abstract = {Recent advances in large-scale data storage and processing offer unprecedented opportunities for behavioral scientists to collect and analyze naturalistic data, including from underrepresented groups. Audio data, particularly real-world audio recordings, are of particular interest to behavioral scientists because they provide high-fidelity access to subtle aspects of daily life and social interactions. However, these methodological advances pose novel risks to research participants and communities. In this article, we outline the benefits and challenges associated with collecting, analyzing, and sharing multi-hour audio recording data. Guided by the principles of autonomy, privacy, beneficence, and justice, we propose a set of ethical guidelines for the use of longform audio recordings in behavioral research. This article is also accompanied by an Open Science Framework Ethics Repository that includes informed consent resources such as frequent participant concerns and sample consent forms.},
  file = {/Users/megcychosz/Zotero/storage/PKW4S3V7/Cychosz et al. - 2020 - Longform recordings of everyday life Ethics for b.pdf},
  journal = {Behavior Research Methods},
  language = {en}
}

@phdthesis{cychoszPhoneticDevelopmentAgglutinating2020a,
  title = {Phonetic Development in an Agglutinating Language},
  author = {Cychosz, Margaret},
  year = {2020},
  address = {{Berkeley, CA}},
  school = {University of California, Berkeley},
  type = {Unpublished Doctoral Dissertation}
}

@article{cychoszPracticeExperiencePredict2021,
  title = {Practice and Experience Predict Coarticulation in Child Speech},
  author = {Cychosz, Margaret and Munson, Benjamin and Edwards, Jan R.},
  year = {2021},
  doi = {10.1080/15475441.2021.1890080},
  file = {/Users/megcychosz/Zotero/storage/XP5R8Y6G/Cychosz et al. - 2021 - Practice and experience predict coarticulation in .pdf},
  journal = {Language Learning and Development}
}

@article{cychoszSpectralTemporalMeasures2019,
  title = {Spectral and Temporal Measures of Coarticulation in Child Speech},
  author = {Cychosz, Margaret and Edwards, Jan R. and Munson, Benjamin and Johnson, Keith},
  year = {2019},
  month = dec,
  volume = {146},
  pages = {EL516-EL522},
  issn = {0001-4966},
  doi = {10.1121/1.5139201},
  abstract = {Speech produced by children is characterized by a high fundamental frequency which complicates measurement of vocal tract resonances, and hence coarticulation. Here two whole-spectrum measures of coarticulation are validated, one temporal and one spectral, that are less sensitive to these challenges. Using these measures, consonantvowel coarticulation is calculated in the speech of a large sample of 4-year-old children. The measurements replicate known lingual coarticulatory findings from the literature, demonstrating the utility of these acoustic measures of coarticulation in speakers of all ages.},
  file = {/Users/megcychosz/Zotero/storage/575NYDBN/Cychosz et al. - 2019 - Spectral and temporal measures of coarticulation i.pdf},
  journal = {The Journal of the Acoustical Society of America-Express Letters},
  language = {en},
  number = {6}
}

@article{cychoszVocalDevelopmentLargescaletoappear,
  title = {Vocal Development in a Large-Scale, Cross-Linguistic Corpus},
  author = {Cychosz, Margaret and Cristia, Alejandrina and Bergelson, Elika and Casillas, M and Baudet, Gladys and Warlaumont, Anne S and Scaff, C. and Yankowitz, L. and Seidl, Amanda},
  year = {to appear},
  journal = {Developmental Science}
}

@techreport{cychoszWordStructureEarly2020,
  title = {Word Structure in Early {{Quechua}} Speech: {{Morphology}} and Acoustic Phonetics},
  author = {Cychosz, Margaret},
  year = {2020},
  type = {Open {{Science Framework}} Project}
}

@article{daffernBabblePlayAppInfants2020,
  title = {{{BabblePlay}}: {{An}} App for Infants, Controlled by Infants, to Improve Early Language Outcomes},
  shorttitle = {{{BabblePlay}}},
  author = {Daffern, Helena and {Keren-Portnoy}, Tamar and DePaolis, Rory A. and Brown, Kenneth I.},
  year = {2020},
  month = may,
  volume = {162},
  pages = {107183},
  issn = {0003682X},
  doi = {10.1016/j.apacoust.2019.107183},
  abstract = {This project set out to develop an app for infants under one year of age that responds in real time to language-like infant utterances with attractive images on an iPad screen. Language-like vocalisations were defined as voiced utterances which were not high pitched squeals, nor shouts. The app, BabblePlay, was intended for use in psycholinguistic research to investigate the possible causal relationship between early canonical babble and early onset of word production. It is also designed for a clinical setting, (1) to illustrate the importance of feedback as a way to encourage infant vocalisations, and (2) to provide consonant production practice for infant populations that do not vocalise enough or who vocalise in an atypical way, specifically, autistic infants (once they have begun to produce consonants). This paper describes the development and testing of BabblePlay, which responds to an infant's vocalisations with colourful moving shapes on the screen that are analogous to some features of the infant's vocalization including loudness and duration. Validation testing showed high correlation between the app and two human judges in identifying vocalisations in 200 min of BabblePlay recordings, and a feasibility study conducted with 60 infants indicates that they can learn the contingency between their vocalisations and the appearance of shapes on the screen in one five minute BabblePlay session. BabblePlay meets the specification of being a simple and easy-to-use app. It has been shown to be a promising tool for research on infant language development that could lead to its use in home and professional environments to demonstrate the importance of immediate reward for vocal utterances to increase vocalisations in infants.},
  file = {/Users/megcychosz/Zotero/storage/ZC3SIFIS/Daffern et al. - 2020 - BabblePlay An app for infants, controlled by infa.pdf},
  journal = {Applied Acoustics},
  language = {en}
}

@article{dapiceNaturalisticHomeObservational2019,
  title = {A Naturalistic Home Observational Approach to Children's Language, Cognition, and Behavior.},
  author = {{d'Apice}, Katrina and Latham, Rachel M. and {von Stumm}, Sophie},
  year = {2019},
  month = jul,
  volume = {55},
  pages = {1414--1427},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/dev0000733},
  abstract = {Although early life experiences of language and parenting are critical for children's development, large home observation studies of both domains are scarce in the psychological literature, presumably because of their considerable costs to the participants and researchers. Here, we used digital audio-recorders to unobtrusively observe 107 children, aged 2.03 to 3.99 years (M ϭ 2.77, SD ϭ 0.55), and their families over 3 days (M ϭ 15.06 hr per day, SD ϭ 1.87). The recording software estimated the total number of words that a child heard over the course of a day. In addition, we transcribed six 5-min excerpts per family (i.e., 30 min overall) to extract estimates of children's and their parents' lexical diversity, positive and critical parenting, and children's internalizing and externalizing behaviors. We found that home language input (i.e., number of words and lexical diversity) was positively associated with children's cognitive ability and lexical diversity but not with their behaviors. In addition, we observed that home language input varied as much within as between families across days (intraclass correlation ϭ .47). By comparison, parenting predicted children's behavioral outcomes but was not related to their cognitive or lexical ability. Overall, our findings suggest that home language input affects child development in cognition and language, while positive and parenting informs their behavioral development. Furthermore, we demonstrated that digital audio-recordings are useful tools for home observation studies that seek to disentangle the complex relationships between early life home environments and child development.},
  file = {/Users/megcychosz/Zotero/storage/RU2FJCIB/d'Apice et al. - 2019 - A naturalistic home observational approach to chil.pdf},
  journal = {Developmental Psychology},
  language = {en},
  number = {7}
}

@book{dariaReductionCoarticulationVieillissement2018,
  title = {R\'eduction de La Coarticulation et Vieillissement},
  author = {Daria, D'Alessandro and Cecile, Fougeron},
  year = {2018},
  month = jun,
  pages = {418},
  doi = {10.21437/JEP.2018-47},
  file = {/Users/megcychosz/Zotero/storage/8J7V2QYL/Daria and Cecile - 2018 - Réduction de la coarticulation et vieillissement.pdf}
}

@article{davidsonEffectsStimulusLevel2006,
  title = {Effects of {{Stimulus Level}} on the {{Speech Perception Abilities}} of {{Children Using Cochlear Implants}} or {{Digital Hearing Aids}}:},
  shorttitle = {Effects of {{Stimulus Level}} on the {{Speech Perception Abilities}} of {{Children Using Cochlear Implants}} or {{Digital Hearing Aids}}},
  author = {Davidson, Lisa S.},
  year = {2006},
  month = oct,
  volume = {27},
  pages = {493--507},
  issn = {0196-0202},
  doi = {10.1097/01.aud.0000234635.48564.ce},
  abstract = {Objective: The present investigation was designed to provide information to facilitate the decision of whether a child should continue using digital signal processing (DSP) hearing aids with wide dynamic range compression (WDRC) or be recommended for a cochlear implant, based on the unaided pure-tone average (PTA at 500, 1000, and 2000 Hz). Design: Fifty-two children (ages 5 to 15 yr) with unaided PTAs in the moderately severe to profound range, wearing (DSP) hearing aids with (WDRC) or a Nucleus 24, Clarion 1.2, or CII cochlear implant system, participated: 26 with unaided PTAs from 60 to 98 dB HL using DSP hearing aids and 26 with pre-implant unaided PTAs from 93 to 120 dB HL, using cochlear implants. An open-set speech perception test, the Lexical Neighborhood Test (LNT; Kirk, Pisoni, \& Osberger, 1995), was administered at intensity levels representative of raised (70 dB SPL) and soft (50 dB SPL) speech at two different times approximately 1 mo apart. Minimum audibility of soft sounds was determined for the children with implants and with DSP hearing aids using warbletone thresholds at octave intervals between 250 and 4000 Hz. Results: Regression analyses and significance testing were used to determine the unaided PTA values at which the performance of the DSP Hearing Aid group (DSP HA group) and Cochlear Implant group on the LNT test were statistically different at the 0.05 significance level. For the 70 dB SPL presentation level, the statistically different PTAs were 113 and 97 dB HL at Time 1 and Time 2, respectively, and 96 and 88 dB HL at 50 dB SPL for Time 1 and Time 2, respectively. Conclusions: The Unaided PTA at which children in the cochlear implant group would be expected to score significantly better than the children in the DSP HA group was lowest (96 and 88 dB HL) for the lower signal level (50 dB SPL). Assuming that LNT scores at 50 dB SPL are representative of long-term hearing of soft incidental speech that is essential for language learning and fluent communication, the children with PTA values greater than the range from 88 to 96 dB HL would be expected to have significantly better LNT scores with a cochlear implant. These results should be further examined with re-},
  file = {/Users/megcychosz/Zotero/storage/K7NGQN6Q/Davidson - 2006 - Effects of Stimulus Level on the Speech Perception.pdf},
  journal = {Ear and Hearing},
  language = {en},
  number = {5}
}

@article{daviesComprehensionCopulaPreschoolers2019,
  title = {Comprehension of the Copula: Preschoolers (and Sometimes Adults) Ignore Subject\textendash Verb Agreement during Sentence Processing},
  shorttitle = {Comprehension of the Copula},
  author = {Davies, Benjamin and Xu Rattanasone, Nan and Demuth, Katherine},
  year = {2019},
  month = nov,
  pages = {1--14},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000919000680},
  abstract = {Subject\textendash verb (SV) agreement helps listeners interpret the number condition of ambiguous nouns (The sheep is/are fat), yet it remains unclear whether young children use agreement to comprehend newly encountered nouns. Preschoolers and adults completed a forced choice task where sentences contained singular vs. plural copulas (Where is/are the [novel noun(s)]?). Novel nouns were either morphologically unambiguous (tup/tups) or ambiguous (/geks/ = singular: gex / plural: gecks). Preschoolers (and some adults) ignored the singular copula, interpreting /ks/-final words as plural, raising questions about the role of SV agreement in learners' sentence comprehension and the status of is in Australian English.},
  file = {/Users/megcychosz/Zotero/storage/ZBAI8TFL/Davies et al. - 2019 - Comprehension of the copula preschoolers (and som.pdf},
  journal = {Journal of Child Language},
  language = {en}
}

@article{davisEmergenceDiscretePerceptualMotor2019,
  title = {The {{Emergence}} of {{Discrete Perceptual}}-{{Motor Units}} in a {{Production Model That Assumes Holistic Phonological Representations}}},
  author = {Davis, Maya and Redford, Melissa A.},
  year = {2019},
  volume = {10},
  pages = {1--19},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2019.02121},
  file = {/Users/megcychosz/Zotero/storage/T365YIQD/Davis and Redford - 2019 - The Emergence of Discrete Perceptual-Motor Units i.pdf},
  journal = {Frontiers in Psychology},
  language = {en},
  number = {2121}
}

@article{deandaLanguageExposureAssessment2016,
  title = {The {{Language Exposure Assessment Tool}}: {{Quantifying Language Exposure}} in {{Infants}} and {{Children}}},
  shorttitle = {The {{Language Exposure Assessment Tool}}},
  author = {DeAnda, Stephanie and Bosch, Laura and {Poulin-Dubois}, Diane and Zesiger, Pascal and Friend, Margaret},
  year = {2016},
  month = dec,
  volume = {59},
  pages = {1346--1356},
  issn = {1092-4388},
  doi = {10.1044/2016_JSLHR-L-15-0234},
  abstract = {Purpose The aim of this study was to develop the Language Exposure Assessment Tool (LEAT) and to examine its cross-linguistic validity, reliability, and utility. The LEAT is a computerized interview-style assessment that requests parents to estimate language exposure. The LEAT yields an automatic calculation of relative language exposure and captures qualitative aspects of early language experience. Method Relative language exposure as reported on the LEAT and vocabulary size at 17 months of age were measured in a group of bilingual language learners with varying levels of exposure to French and English or Spanish and English. Results The LEAT demonstrates high internal consistency and criterion validity. In addition, the LEAT's calculation of relative language exposure explains variability in vocabulary size above a single overall parent estimate. Conclusions The LEAT is a valid and efficient tool for characterizing early language experience across cultural settings and levels of language exposure. The LEAT could be a useful tool in clinical contexts to aid in determining whether assessment and intervention should be conducted in one or more languages.},
  file = {/Users/megcychosz/Zotero/storage/6JTNLAC4/DeAnda et al. - 2016 - The Language Exposure Assessment Tool Quantifying.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  number = {6},
  pmcid = {PMC5399762},
  pmid = {27784032}
}

@article{deboltRobustDataPower2020,
  title = {Robust Data and Power in Infant Research: {{A}} Case Study of the Effect of Number of Infants and Number of Trials in Visual Preference Procedures},
  shorttitle = {Robust Data and Power in Infant Research},
  author = {DeBolt, Michaela C. and Rhemtulla, Mijke and Oakes, Lisa M.},
  year = {2020},
  month = jul,
  volume = {25},
  pages = {393--419},
  issn = {1525-0008, 1532-7078},
  doi = {10.1111/infa.12337},
  abstract = {As in many areas of science, infant research suffers from low power. The problem is further compounded in infant research because of the difficulty in recruiting and testing large numbers of infant participants. Researchers have been searching for a solution and, as illustrated by this special section, have been focused on getting the most out of infant data. We illustrate one solution by showing how we can increase power in visual preference tasks by increasing the amount of data obtained from each infant. We discuss issues of power and present work examining how, under some circumstances, power is increased by increasing the precision of measurement. We report the results of a series of simulations based on a sample of visual preference task data collected from three infant laboratories showing how more powerful research designs can be achieved by including more trials per infant. Implications for infant procedures in general are discussed.},
  file = {/Users/megcychosz/Zotero/storage/QLBVVFWQ/DeBolt et al. - 2020 - Robust data and power in infant research A case s.pdf},
  journal = {Infancy},
  language = {en},
  number = {4}
}

@article{deboysson-bardiesAdaptationLanguageEvidence1991,
  title = {Adaptation to {{Language}}: {{Evidence}} from {{Babbling}} and {{First Words}} in {{Four Languages}}},
  shorttitle = {Adaptation to {{Language}}},
  author = {{de Boysson-Bardies}, B{\'e}n{\'e}dicte and Vihman, Marilyn May and {de Boysson-Bardies}, Benedicte},
  year = {1991},
  month = jun,
  volume = {67},
  pages = {297--319},
  issn = {00978507},
  doi = {10.2307/415108},
  file = {/Users/megcychosz/Zotero/storage/W2D4NCPV/de Boysson-Bardies et al. - 1991 - Adaptation to Language Evidence from Babbling and.pdf},
  journal = {Language},
  language = {en},
  number = {2}
}

@article{deboysson-bardiesAdaptationLanguageEvidence1991a,
  title = {Adaptation to {{Language}}: {{Evidence}} from {{Babbling}} and {{First Words}} in {{Four Languages}}},
  shorttitle = {Adaptation to {{Language}}},
  author = {{de Boysson-Bardies}, B{\'e}n{\'e}dicte and Vihman, Marilyn May and {de Boysson-Bardies}, Benedicte},
  year = {1991},
  month = jun,
  volume = {67},
  pages = {297},
  issn = {00978507},
  doi = {10.2307/415108},
  file = {/Users/megcychosz/Zotero/storage/AQHHHJPW/de Boysson-Bardies et al. - 1991 - Adaptation to Language Evidence from Babbling and.pdf},
  journal = {Language},
  language = {en},
  number = {2}
}

@article{deboysson-bardiesDiscernibleDifferencesBabbling1984,
  title = {Discernible Differences in the Babbling of Infants According to Target Language},
  author = {{de Boysson-Bardies} and Sagart, L. and Durand, C.},
  year = {1984},
  volume = {11},
  pages = {1--15},
  journal = {Journal of Child Language},
  number = {1}
}

@article{debreeLanguageLearningInconsistent2017,
  title = {Language Learning from Inconsistent Input: {{Bilingual}} and Monolingual Toddlers Compared: {{Language}} Learning from Inconsistent Input},
  shorttitle = {Language Learning from Inconsistent Input},
  author = {{de Bree}, Elise and Verhagen, Josje and Kerkhoff, Annemarie and Doedens, Willemijn and Unsworth, Sharon},
  year = {2017},
  month = jul,
  volume = {26},
  pages = {e1996},
  issn = {15227227},
  doi = {10.1002/icd.1996},
  abstract = {This study examines novel language learning from inconsistent input in monolingual and bilingual toddlers. We predicted an advantage for the bilingual toddlers on the basis of the structural sensitivity hypothesis. Monolingual and bilingual 24-month-olds performed two novel language learning experiments. The first contained consistent input, and the second occasionally contained inconsistent input (i.e., ``errors''). Neither group showed learning of the novel pattern in the consistent experiment. The bilingual toddlers, but not the monolinguals, showed learning in the inconsistent experiment, which suggests they are better at detecting regularities from inconsistent input than monolinguals.},
  file = {/Users/megcychosz/Zotero/storage/UW9DFBIC/de Bree et al. - 2017 - Language learning from inconsistent input Bilingu.pdf},
  journal = {Infant and Child Development},
  language = {en},
  number = {4}
}

@misc{debruinMethodsHealthPsychology2012,
  title = {Methods in Health Psychology: {{How}} Do We Know What We Really Know?: (544792013-009)},
  shorttitle = {Methods in Health Psychology},
  author = {{de Bruin}, Marijn and Johnston, Marie},
  year = {2012},
  publisher = {{American Psychological Association}},
  doi = {10.1037/e544792013-009},
  file = {/Users/megcychosz/Zotero/storage/4USUVELW/de Bruin and Johnston - 2012 - Methods in health psychology How do we know what .pdf},
  language = {en}
}

@article{debruinNotAllBilinguals2019,
  title = {Not {{All Bilinguals Are}} the {{Same}}: {{A Call}} for {{More Detailed Assessments}} and {{Descriptions}} of {{Bilingual Experiences}}},
  author = {{de Bruin}, Angela},
  year = {2019},
  volume = {9},
  pages = {1--13},
  file = {/Users/megcychosz/Zotero/storage/KWDVP6QQ/behavsci-09-00033.pdf},
  journal = {Behavioral Sciences},
  number = {33}
}

@article{dediuAntiquityLanguageReinterpretation2013,
  title = {On the Antiquity of Language: The Reinterpretation of {{Neandertal}} Linguistic Capacities and Its Consequences},
  shorttitle = {On the Antiquity of Language},
  author = {Dediu, Dan and Levinson, Stephen C.},
  year = {2013},
  volume = {4},
  publisher = {{Frontiers}},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.00397},
  abstract = {It is usually assumed that modern language is a recent phenomenon, coinciding with the emergence of modern humans themselves. Many assume as well that this is the result of a single, sudden mutation giving rise to the full ``modern package''. However, we argue here that recognizably modern language is likely an ancient feature of our genus pre-dating at least the common ancestor of modern humans and Neandertals about half a million years ago. To this end, we adduce a broad range of evidence from linguistics, genetics, palaeontology and archaeology clearly suggesting that Neandertals shared with us something like modern speech and language. This reassessment of the antiquity of modern language, from the usually quoted 50,000-100,000 years to half a million years, has profound consequences for our understanding of our own evolution in general and especially for the sciences of speech and language. As such, it argues against a saltationist scenario for the evolution of language, and towards a gradual process of culture-gene co-evolution extending to the present day. Another consequence is that the present-day linguistic diversity might better reflect the properties of the design space for language and not just the vagaries of history, and could also contain traces of the languages spoken by other human forms such as the Neandertals.},
  file = {/Users/megcychosz/Zotero/storage/HIKKMMGR/Dediu and Levinson - 2013 - On the antiquity of language the reinterpretation.pdf},
  journal = {Frontiers in Psychology},
  keywords = {Genetic admixture,human evolution,Language contact,language evolution,Neandertal speech},
  language = {English}
}

@article{dediuLanguageNotIsolated2017,
  title = {Language Is Not Isolated from Its Wider Environment: {{Vocal}} Tract Influences on the Evolution of Speech and Language},
  shorttitle = {Language Is Not Isolated from Its Wider Environment},
  author = {Dediu, Dan and Janssen, Rick and Moisik, Scott R.},
  year = {2017},
  month = may,
  volume = {54},
  pages = {9--20},
  issn = {02715309},
  doi = {10.1016/j.langcom.2016.10.002},
  abstract = {Language is not a purely cultural phenomenon somehow isolated from its wider environment, and we may only understand its origins and evolution by seriously considering its embedding in this environment as well as its multimodal nature. By environment here we understand other aspects of culture (such as communication technology, attitudes towards language contact, etc.), of the physical environment (ultraviolet light incidence, air humidity, etc.), and of the biological infrastructure for language and speech. We are specifically concerned in this paper with the latter, in the form of the biases, constraints and affordances that the anatomy and physiology of the vocal tract create on speech and language. In a nutshell, our argument is that (a) there is an under-appreciated amount of inter-individual variation in vocal tract (VT) anatomy and physiology, (b) variation that is non-randomly distributed across populations, and that (c) results in systematic differences in phonetics and phonology between languages. Relevant differences in VT anatomy include the overall shape of the hard palate, the shape of the alveolar ridge, the relationship between the lower and upper jaw, to mention just a few, and our data offer a new way to systematically explore such differences and their potential impact on speech. These differences generate very small biases that nevertheless can be amplified by the repeated use and transmission of language, affecting language diachrony and resulting in crosslinguistic synchronic differences. Moreover, the same type of biases and processes might have played an essential role in the emergence and evolution of language, and might allow us a glimpse into the speech and language of extinct humans by, for example, reconstructing the anatomy of parts of their vocal tract from the fossil record and extrapolating the biases we find in present-day humans.},
  file = {/Users/megcychosz/Zotero/storage/TAV5PMVR/Dediu et al. - 2017 - Language is not isolated from its wider environmen.pdf},
  journal = {Language \& Communication},
  language = {en}
}

@article{dediuLinguisticToneRelated2007,
  title = {Linguistic Tone Is Related to the Population Frequency of the Adaptive Haplogroups of Two Brain Size Genes, {{ASPM}} and {{Microcephalin}}},
  author = {Dediu, D. and Ladd, D. R.},
  year = {2007},
  month = jun,
  volume = {104},
  pages = {10944--10949},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0610848104},
  file = {/Users/megcychosz/Zotero/storage/2K83TTXE/Dediu and Ladd - 2007 - Linguistic tone is related to the population frequ.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {26}
}

@incollection{dehouwerLanguageInputEnvironments2011,
  title = {Language Input Environments and Language Development in Bilingual Acquisition},
  booktitle = {Applied {{Lingusitics Review}}},
  author = {{de Houwer}, A.},
  editor = {Wei, Li},
  year = {2011},
  pages = {221--240},
  publisher = {{De Gruyter Mouton}},
  address = {{Berlin/New York}},
  series = {2}
}

@article{delcenserieDevelopmentPhonologicalMemory2020,
  title = {The Development of Phonological Memory and Language: {{A}} Multiple Groups Approach},
  shorttitle = {The Development of Phonological Memory and Language},
  author = {Delcenserie, Audrey and Genesee, Fred and Trudeau, Natacha and Champoux, Fran{\c c}ois},
  year = {2020},
  month = jun,
  pages = {1--40},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000920000343},
  abstract = {Pierce et al. (2017) have proposed that variations in the timing, quality and quantity of language input during the earliest stages of development are related to variations in the development of phonological working memory and, in turn, to later language learning outcomes. To examine this hypothesis, three groups of children who are at-risk for language learning were examined: children with cochlear implants (CI), children with developmental language disorder (DLD), and internationally-adopted (IA) children, Comparison groups of typically-developing monolingual (MON) children and second language (L2) learners were also included. All groups were acquiring French as a first or second language and were matched on age, gender, and socioeconomic status, as well as other group-specific factors; they were between 5;0\textendash 7;3 years of age at time of testing. The CI and DLD groups scored significantly more poorly on the memory measures than the other groups; while the IA and L2 groups did not differ from one another. While the IA group performed more poorly than the MON group, there was no difference between the L2 and MON groups. We also found differential developmental relationships between phonological memory and language among the groups of interest in comparison to the typically-developing MON and L2 groups supporting the hypothesis that language experiences early in life are consequential for language development because of their effects on the development of phonological memory.},
  file = {/Users/megcychosz/Zotero/storage/MN2VWH9T/Delcenserie et al. - 2020 - The development of phonological memory and languag.pdf},
  journal = {Journal of Child Language},
  language = {en}
}

@article{deleonEmergentParticipantInteractive1998,
  title = {The {{Emergent Participant}}: {{Interactive Patterns}} in the {{Socialization}} of {{Tzotzil}} ({{Mayan}}) {{Infants}}},
  shorttitle = {The {{Emergent Participant}}},
  author = {{de Le{\'o}n}, Lourdes},
  year = {1998},
  volume = {8},
  pages = {131--161},
  issn = {1055-1360, 1548-1395},
  doi = {10.1525/jlin.1998.8.2.131},
  file = {/Users/megcychosz/Zotero/storage/F8RK2XGM/Leon - 1998 - The Emergent Participant Interactive Patterns in .pdf},
  journal = {Journal of Linguistic Anthropology},
  language = {en},
  number = {2}
}

@article{demir-liraParentsEarlyBook2019,
  title = {Parents' Early Book Reading to Children: {{Relation}} to Children's Later Language and Literacy Outcomes Controlling for Other Parent Language Input},
  shorttitle = {Parents' Early Book Reading to Children},
  author = {Demir-Lira, {\"O} Ece and Applebaum, Lauren R. and Goldin-Meadow, Susan and Levine, Susan C.},
  year = {2019},
  volume = {22},
  pages = {e12764},
  issn = {1467-7687},
  doi = {10.1111/desc.12764},
  abstract = {It is widely believed that reading to preschool children promotes their language and literacy skills. Yet, whether early parent\textendash child book reading is an index of generally rich linguistic input or a unique predictor of later outcomes remains unclear. To address this question, we asked whether naturally occurring parent\textendash child book reading interactions between 1 and 2.5 years-of-age predict elementary school language and literacy outcomes, controlling for the quantity of other talk parents provide their children, family socioeconomic status, and children's own early language skill. We find that the quantity of parent\textendash child book reading interactions predicts children's later receptive vocabulary, reading comprehension, and internal motivation to read (but not decoding, external motivation to read, or math skill), controlling for these other factors. Importantly, we also find that parent language that occurs during book reading interactions is more sophisticated than parent language outside book reading interactions in terms of vocabulary diversity and syntactic complexity.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.12764},
  file = {/Users/megcychosz/Zotero/storage/F93GPHQ7/Demir‐Lira et al. - 2019 - Parents’ early book reading to children Relation .pdf;/Users/megcychosz/Zotero/storage/DIPWPFVS/desc.html},
  journal = {Developmental Science},
  keywords = {book reading,language,language input,literacy},
  language = {en},
  number = {3}
}

@article{demuthCrosslinguisticPerspectivesDevelopment2006,
  title = {Crosslinguistic Perspectives on the Development of Prosodic Words},
  author = {Demuth, Katherine},
  year = {2006},
  volume = {49},
  pages = {129--135},
  file = {/Users/megcychosz/Zotero/storage/DDABC4UG/Demuth 2006.pdf},
  journal = {Language and Speech},
  number = {2}
}

@article{demuthPerceptionProductionIndividual2018,
  title = {Perception, Production, and Individual Differences},
  author = {Demuth, Katherine},
  year = {2018},
  month = jul,
  volume = {39},
  pages = {735--741},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716418000176},
  abstract = {In sum, recent findings suggest that there may be a closer connection between perception and production abilities than often thought, with individual differences emerging in both. This can be illuminated by collecting multiple language/gesture/cognitive measures on the same children, shedding light on the nature of individual differences (cf. Cristia, Seidl, Junge, Soderstrom, \& Hagoort, 2014). Such approaches are becoming more common in many other fields of psycholinguistic research (e.g., Montrul \& Tanner, 2017), and will hopefully become more common in infant/toddler research in years to come.},
  file = {/Users/megcychosz/Zotero/storage/WK6QG6ZY/Demuth - 2018 - Perception, production, and individual differences.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {04}
}

@article{demuthProsodicReOrganization2009,
  title = {The Prosodic (Re)Organization of Children's Early {{English}} Articles},
  author = {Demuth, Katherine and McCULLOUGH, Elizabeth},
  year = {2009},
  month = jan,
  volume = {36},
  pages = {173},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000908008921},
  abstract = {Researchers have long been puzzled by children's variable omission of grammatical morphemes, often attributing this to a lack of semantic or syntactic competence. Recent studies suggest that some of this variability may be due to phonological constraints. This paper explored this issue further by conducting a longitudinal study of five Englishspeaking one- to two-year-olds' acquisition of articles. It found that most children were more likely to produce articles when these could be produced as part of a disyllabic foot. However, acoustic analysis revealed that one child initially produced all articles as independent prosodic words. These findings confirm that some of the variable production of articles is conditioned by constraints on children's early phonologies, providing further support for the Prosodic Licensing Hypothesis. They also hold important implications for our understanding of the emergence of syntactic knowledge.},
  file = {/Users/megcychosz/Zotero/storage/ASIHZ2AW/Demuth and McCULLOUGH - 2009 - The prosodic (re)organization of children's early .pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {01}
}

@article{dennyImplicationsPeripheralMuscular2012,
  title = {Implications of {{Peripheral Muscular}} and {{Anatomical Development}} for the {{Acquisition}} of {{Lingual Control}} for {{Speech Production}}: {{A Review}}},
  shorttitle = {Implications of {{Peripheral Muscular}} and {{Anatomical Development}} for the {{Acquisition}} of {{Lingual Control}} for {{Speech Production}}},
  author = {Denny, Margaret and McGowan, Richard S.},
  year = {2012},
  volume = {64},
  pages = {105--115},
  issn = {1421-9972, 1021-7762},
  doi = {10.1159/000338611},
  file = {/Users/megcychosz/Zotero/storage/VVX55TLA/Denny and McGowan - 2012 - Implications of Peripheral Muscular and Anatomical.pdf},
  journal = {Folia Phoniatrica et Logopaedica},
  language = {en},
  number = {3}
}

@article{dennySagittalAreaVocal2012,
  title = {Sagittal {{Area}} of the {{Vocal Tract}} in {{Young Female Children}}},
  author = {Denny, Margaret and McGowan, Richard S.},
  year = {2012},
  volume = {64},
  pages = {297--303},
  issn = {1421-9972, 1021-7762},
  doi = {10.1159/000345646},
  abstract = {Objective: To measure the sagittal areas of the front and back cavities of the vocal tract in children acquiring speech. Patients and Methods: Ten female children were selected from the Serial Experimental collection of the Burlington Growth Centre in Toronto, Canada. Each of the 10 children was seen annually from ages 3 through 8. Data collections included lateral cephalograms in occlusion. We traced those cephalograms and identified landmarks to delineate the front and back cavities. The sagittal areas of the front and back cavities were calculated. A measure of the angle of the head to the cervical vertebrae was made. Results: Front cavities were larger and grew faster. For both front and back cavities, age, angle measure, and the interaction of age and angle measure were significant. Conclusion: Space available for the tongue to maneuver is greater anteriorly than posteriorly even when the jaw is maximally elevated.},
  file = {/Users/megcychosz/Zotero/storage/BQZWHYIG/Denny and McGowan - 2012 - Sagittal Area of the Vocal Tract in Young Female C.pdf},
  journal = {Folia Phoniatrica et Logopaedica},
  language = {en},
  number = {6}
}

@article{depaolisInfluenceBabblingPatterns2013,
  title = {The Influence of Babbling Patterns on the Processing of Speech},
  author = {DePaolis, Rory A. and Vihman, Marilyn M. and Nakai, Satsuki},
  year = {2013},
  month = dec,
  volume = {36},
  pages = {642--649},
  issn = {01636383},
  doi = {10.1016/j.infbeh.2013.06.007},
  abstract = {This study compared the preference of 27 British English- and 26 Welsh-learning infants for nonwords featuring consonants that occur with equal frequency in the input but that are produced either with equal frequency (Welsh) or with differing frequency (British English) in infant vocalizations. For the English infants a significant difference in looking times was related to the extent of production of the nonword consonants. The Welsh infants, who showed no production preference for either consonant, exhibited no such influence of production patterns on their response to the nonwords. The results are consistent with a previous study that suggested that pre-linguistic babbling helps shape the processing of input speech, serving as an articulatory filter that selectively makes production patterns more salient in the input.},
  file = {/Users/megcychosz/Zotero/storage/3IUTYCKL/DePaolis et al. - 2013 - The influence of babbling patterns on the processi.pdf},
  journal = {Infant Behavior and Development},
  language = {en},
  number = {4}
}

@article{depaolisProductionPatternsInfluence2011,
  title = {Do Production Patterns Influence the Processing of Speech in Prelinguistic Infants?},
  author = {DePaolis, Rory A. and Vihman, Marilyn M. and {Keren-Portnoy}, Tamar},
  year = {2011},
  month = dec,
  volume = {34},
  pages = {590--601},
  issn = {01636383},
  doi = {10.1016/j.infbeh.2011.06.005},
  abstract = {The headturn preference procedure was used to test 18 infants on their response to three different passages chosen to reflect their individual production patterns. The passages contained nonwords with consonants in one of three categories: (a) often produced by that infant (\^Oown\~O), (b) rarely produced by that infant but common at that age (\^Oother\~O), and (c) not generally produced by infants. Infants who had a single \^Oown\~O consonant showed no significant preference for either \~Oown\~O (a) or \^Oother\~O (b) passages. In contrast, infants\~O with two \^Oown\~O consonants exhibited greater attention to \^Oother\~O passages (b). Both groups attended equally to the passage featuring consonants rarely produced by infants of that age (c). An analysis of a sample of the infantdirected speech ruled out the mothers\~O speech as a source of the infant preferences. The production-based shift to a focus on the \^Oother\~O passage suggests that nascent production abilities combine with emergent perceptual experience to facilitate word learning.},
  file = {/Users/megcychosz/Zotero/storage/F95ITPDH/DePaolis et al. - 2011 - Do production patterns influence the processing of.pdf},
  journal = {Infant Behavior and Development},
  language = {en},
  number = {4}
}

@misc{departmentofhealthandhumanservicesGuidanceRegardingMethods2015,
  title = {Guidance {{Regarding Methods}} for {{De}}-Identification of {{Protected Health Information}} in {{Accordance}} with the {{Health Insurance Portability}} and {{Accountability Act}} ({{HIPAA}}) {{Privacy Rule}}},
  author = {{Department of Health {and} Human Services}},
  year = {2015}
}

@article{desjardinMaternalContributionsSupporting2007,
  title = {Maternal {{Contributions}}: {{Supporting Language Development}} in {{Young Children}} with {{Cochlear Implants}}:},
  shorttitle = {Maternal {{Contributions}}},
  author = {DesJardin, Jean L. and Eisenberg, Laurie S.},
  year = {2007},
  month = aug,
  volume = {28},
  pages = {456--469},
  issn = {0196-0202},
  doi = {10.1097/AUD.0b013e31806dc1ab},
  abstract = {Objective: The principal goal of this study was to investigate the relationships between maternal contributions (e.g., involvement, self-efficacy, linguistic input) and receptive and expressive (oral and sign) language skills in young children with cochlear implants. Design: Relationships between maternal contributions and children's language skills were investigated by using correlation and regression analyses. Thirty-two mothers (mean age ؍ 36.0 yr) and their children (mean age ؍ 4.8 yr) were videotaped during free play and storybook interactions. Mothers' and children's quantitative (MLU, number of wordtypes) and mothers' qualitative (facilitative language techniques) linguistic input were analyzed. Mothers completed a measurement tool specifically designed to quantify their sense of involvement and self-efficacy (Scale of Parental Involvement and Self-Efficacy). The Reynell Developmental Language Scales and data from videotaped transcription analyses were used to evaluate children's oral and sign language skills. Results: Maternal involvement and self-efficacy relating to children's speech-language development were positively related to mothers' quantitative and qualitative linguistic input. After controlling for child's age, mothers' MLU and two facilitative language techniques (recast and open-ended question) were positively related to children's language skills. Conclusions: The performance of young implant users may vary in part because of their mothers' sense of involvement and self-efficacy, as well as the ways in which mothers interact with their children. Given this information, it would be fruitful for professionals working with these families to incorporate goals that enhance caregivers' involvement, self-efficacy, and linguistic input to better support language development in young children after cochlear implantation.},
  file = {/Users/megcychosz/Zotero/storage/IZ69IT4T/DesJardin and Eisenberg - 2007 - Maternal Contributions Supporting Language Develo.pdf},
  journal = {Ear and Hearing},
  language = {en},
  number = {4}
}

@article{devaanLifespanLexicalTraces2011,
  title = {The Lifespan of Lexical Traces for Novel Morphologically Complex Words},
  author = {{deVaan}, Laura and Ernestus, Mirjam and Schreuder, Robert},
  year = {2011},
  volume = {6},
  pages = {374--392},
  issn = {1871-1340, 1871-1375},
  doi = {10.1075/ml.6.3.02dev},
  abstract = {This study investigates the lifespans of lexical traces for novel morphologically complex words. In two visual lexical decision experiments, a neologism was either primed by itself or by its stem. The target occurred 40 trials after the prime (Experiments 1 \& 2), after a 12 hour delay (Experiment 1), or after a one week delay (Experiment 2). Participants recognized neologisms more quickly if they had seen them before in the experiment. These results show that memory traces for novel morphologically complex words already come into existence after a very first exposure and that they last for at least a week. We did not find evidence for a role of sleep in the formation of memory traces. Interestingly, Base Frequency appeared to play a role in the processing of the neologisms also when they were presented a second time and had their own memory traces.},
  file = {/Users/megcychosz/Zotero/storage/G4A4MYY6/deVaan et al. - 2011 - The lifespan of lexical traces for novel morpholog.pdf},
  journal = {The Mental Lexicon},
  language = {en},
  number = {3}
}

@article{diamantiPreschoolPhonologicalMorphological2017,
  title = {Preschool {{Phonological}} and {{Morphological Awareness As Longitudinal Predictors}} of {{Early Reading}} and {{Spelling Development}} in {{Greek}}},
  author = {Diamanti, Vassiliki and Mouzaki, Angeliki and Ralli, Asimina and Antoniou, Faye and Papaioannou, Sofia and Protopapas, Athanassios},
  year = {2017},
  volume = {8},
  pages = {1--12},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2017.02039},
  abstract = {Different language skills are considered fundamental for successful reading and spelling acquisition. Extensive evidence has highlighted the central role of phonological awareness in early literacy experiences. However, many orthographic systems also require the contribution of morphological awareness. The goal of this study was to examine the morphological and phonological awareness skills of preschool children as longitudinal predictors of reading and spelling ability by the end of first grade, controlling for the effects of receptive and expressive vocabulary skills. At Time 1 preschool children from kindergartens in the Greek regions of Attika, Crete, Macedonia, and Thessaly were assessed on tasks tapping receptive and expressive vocabulary, phonological awareness (syllable and phoneme), and morphological awareness (inflectional and derivational). Tasks were administered through an Android application for mobile devices (tablets) featuring automatic application of ceiling rules. At Time 2 one year later the same children attending first grade were assessed on measures of word and pseudoword reading, text reading fluency, text reading comprehension, and spelling. Complete data from 104 children are available. Hierarchical linear regression and commonality analyses were conducted for each outcome variable. Reading accuracy for both words and pseudowords was predicted not only by phonological awareness, as expected, but also by morphological awareness, suggesting that understanding the functional role of word parts supports the developing phonology\textendash orthography mappings. However, only phonological awareness predicted text reading fluency at this age. Longitudinal prediction of reading comprehension by both receptive vocabulary and morphological awareness was already evident at this age, as expected. Finally, spelling was predicted by preschool phonological awareness, as expected, as well as by morphological awareness, the contribution of which is expected to increase due to the spelling demands of Greek inflectional and derivational suffixes introduced at later grades.},
  file = {/Users/megcychosz/Zotero/storage/E5TFYC38/Diamanti et al. - 2017 - Preschool Phonological and Morphological Awareness.pdf},
  journal = {Frontiers in Psychology},
  language = {en},
  number = {2039}
}

@article{dibenedettoAcousticPerceptualEvidence1994,
  title = {Acoustic and Perceptual Evidence of a Complex Relation between {{F1}} and {{F0}} in Determining Vowel Height},
  author = {Di Benedetto, Maria-Gabriella},
  year = {1994},
  month = jul,
  volume = {22},
  pages = {205--224},
  issn = {00954470},
  doi = {10.1016/S0095-4470(19)30201-3},
  file = {/Users/megcychosz/Zotero/storage/NLKQBINR/Benedetto - 1994 - Acoustic and perceptual evidence of a complex rela.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {3}
}

@article{diehlAuditoryBasisStimulus1989,
  title = {An Auditory Basis for the Stimulus-length Effect in the Perception of Stops and Glides},
  author = {Diehl, Randy L. and Walsh, Margaret A.},
  year = {1989},
  month = may,
  volume = {85},
  pages = {2154--2164},
  issn = {0001-4966},
  doi = {10.1121/1.397864},
  file = {/Users/megcychosz/Zotero/storage/YNPCMBGT/Diehl and Walsh - 1989 - An auditory basis for the stimulus‐length effect i.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@incollection{diesselGrammaticalizationLanguageAcquisition2011,
  title = {Grammaticalization and Language Acquisition},
  booktitle = {Handbook of {{Grammaticalization}}},
  author = {Diessel, Holger},
  editor = {Heine, Bernd and Norrog, Heike},
  year = {2011},
  publisher = {{Oxford University Press}},
  address = {{Oxford}},
  doi = {10.1093/oxfordhb/9780199586783.013.0011},
  abstract = {The paper compares the diachronic evolution of grammatical markers to their development in child language. It is shown that grammaticalization and first language acquisition frequently involve the same semantic changes. In both developments, abstract grammatical meanings are commonly derived from more concrete meanings. However, the morphosyntactic changes of grammaticalization do not have parallels in child language, suggesting that language acquisition does not simply recapitulate the diachronic evolution of grammar. The paper argues that the semantic developments are often parallel in grammaticalization and language acquisition because diachrony and ontogeny involve the same mechanisms of categorization.},
  file = {/Users/megcychosz/Zotero/storage/T5QHUIL8/Diessel - 2011 - Grammaticalization and language acquisition.pdf},
  language = {en}
}

@article{dijkstraMultilinkComputationalModel2019,
  title = {Multilink: A Computational Model for Bilingual Word Recognition and Word Translation},
  shorttitle = {Multilink},
  author = {Dijkstra, Ton and Wahl, Alexander and Buytenhuijs, Franka and Van Halem, Nino and {Al-Jibouri}, Zina and De Korte, Marcel and Rekk{\'e}, Steven},
  year = {2019},
  month = aug,
  volume = {22},
  pages = {657--679},
  issn = {1366-7289, 1469-1841},
  doi = {10.1017/S1366728918000287},
  abstract = {The computational BIA+ model (Dijkstra \& Van Heuven, 2002) has provided a useful account for bilingual word recognition, while the verbal (pre-quantitative) RHM (Kroll \& Stewart, 1994) has often served as a reference framework for bilingual word production and translation. According to Brysbaert and Duyck (2010), a strong need is felt for a unified implemented account of bilingual word comprehension, lexical-semantic processing, and word production. With this goal in mind, we built a localist-connectionist model, called Multilink, which integrates basic assumptions of both BIA+ and RHM. It simulates the recognition and production of cognates (form-similar translation equivalents) and non-cognates of different lengths and frequencies in tasks like monolingual and bilingual lexical decision, word naming, and word translation production. It also considers effects of lexical similarity, cognate status, relative L2-proficiency, and translation direction. Model-to-model comparisons show that Multilink provides higher correlations with empirical data than both IA and BIA+ models.},
  file = {/Users/megcychosz/Zotero/storage/LSATR4NT/Dijkstra et al. - 2019 - Multilink a computational model for bilingual wor.pdf},
  journal = {Bilingualism: Language and Cognition},
  language = {en},
  number = {04}
}

@article{dilleyAlteringContextSpeech2010,
  title = {Altering {{Context Speech Rate Can Cause Words}} to {{Appear}} or {{Disappear}}},
  author = {Dilley, Laura C. and Pitt, Mark A.},
  year = {2010},
  month = nov,
  volume = {21},
  pages = {1664--1670},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797610384743},
  abstract = {Speech is produced over time, and this makes sensitivity to timing between speech events crucial for understanding language. Two experiments investigated whether perception of function words (e.g., or, are) is rate dependent in casual speech, which often contains phonetic segments that are spectrally quite reduced. In Experiment 1, talkers spoke sentences containing a target function word; slowing talkers? speech rate around this word caused listeners to perceive sentences as lacking the word (e.g., leisure or time was perceived as leisure time). In Experiment 2, talkers spoke matched sentences lacking a function word; speeding talkers? speech rate around the region in which the function word had been embedded in Experiment 1 caused listeners to perceive a function word that was never spoken (e.g., leisure time was perceived as leisure or time). The results suggest that listeners formed expectancies based on speech rate, and these expectancies influenced the number of words and word boundaries perceived. These findings may help explain the robustness of speech recognition when speech signals are distorted (e.g., because of a casual speaking style).},
  journal = {Psychological Science},
  number = {11}
}

@article{dilleyIndividualDifferencesMothers2020,
  title = {Individual {{Differences}} in {{Mothers}}' {{Spontaneous Infant}}-{{Directed Speech Predict Language Attainment}} in {{Children With Cochlear Implants}}},
  author = {Dilley, Laura and Lehet, Matthew and Wieland, Elizabeth A. and Arjmandi, Meisam K. and Kondaurova, Maria and Wang, Yuanyuan and Reed, Jessa and Svirsky, Mario and Houston, Derek and Bergeson, Tonya},
  year = {2020},
  month = jul,
  volume = {63},
  pages = {2453--2467},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2020_JSLHR-19-00229},
  abstract = {Purpose               Differences across language environments of prelingually deaf children who receive cochlear implants (CIs) may affect language acquisition; yet, whether mothers show individual differences in how they modify infant-directed (ID) compared with adult-directed (AD) speech has seldom been studied. This study assessed individual differences in how mothers realized speech modifications in ID register and whether these predicted differences in language outcomes for children with CIs.                                         Method               Participants were 36 dyads of mothers and their children aged 0;8\textendash 2;5 (years;months) at the time of CI implantation. Mothers' spontaneous speech was recorded in a lab setting in ID or AD conditions before \textasciitilde 15 months postimplantation. Mothers' speech samples were characterized for acoustic\textendash phonetic and lexical properties established as canonical indices of ID speech to typically hearing infants, such as vowel space area differences, fundamental frequency variability, and speech rate. Children with CIs completed longitudinal administrations of one or more standardized language assessment instruments at variable intervals from 6 months to 9.5 years postimplantation. Standardized scores on assessments administered longitudinally were used to calculate linear regressions, which gave rise to predicted language scores for children at 2 years postimplantation and language growth over 2-year intervals.                                         Results               Mothers showed individual differences in how they modified speech in ID versus AD registers. Crucially, these individual differences significantly predicted differences in estimated language outcomes at 2 years postimplantation in children with CIs. Maternal speech variation in lexical quantity and vowel space area differences across ID and AD registers most frequently predicted estimates of language attainment in children with CIs, whereas prosodic differences played a minor role.                                         Conclusion               Results support that caregiver language behaviors play a substantial role in explaining variability in language attainment in children receiving CIs.                                         Supplemental Material                                https://doi.org/10.23641/asha.12560147},
  file = {/Users/megcychosz/Zotero/storage/KQ6XTG5R/Dilley et al. - 2020 - Individual Differences in Mothers' Spontaneous Inf.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {7}
}

@article{dilleyPhoneticVariationConsonants2014,
  title = {Phonetic Variation in Consonants in Infant-Directed and Adult-Directed Speech: The Case of Regressive Place Assimilation in Word-Final Alveolar Stops},
  shorttitle = {Phonetic Variation in Consonants in Infant-Directed and Adult-Directed Speech},
  author = {Dilley, Laura C. and Millett, Amanda L. and Mcauley, J. Devin and Bergeson, Tonya R.},
  year = {2014},
  month = jan,
  volume = {41},
  pages = {155--175},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000912000670},
  abstract = {ABSTRACT             Pronunciation variation is under-studied in infant-directed speech, particularly for consonants. Regressive place assimilation involves a word-final alveolar stop taking the place of articulation of a following word-initial consonant. We investigated pronunciation variation in word-final alveolar stop consonants in storybooks read by forty-eight mothers in adult-directed or infant-directed style to infants aged approximately 0;3, 0;9, 1;1, or 1;8. We focused on phonological environments where regressive place assimilation could occur, i.e., when the stop preceded a word-initial labial or velar consonant. Spectrogram, waveform, and perceptual evidence was used to classify tokens into four pronunciation categories: canonical, assimilated, glottalized, or deleted. Results showed a reliable tendency for canonical variants to occur in infant-directed speech more often than in adult-directed speech. However, the otherwise very similar distributions of variants across addressee and age group suggested that infants largely experience statistical distributions of non-canonical consonantal pronunciation variants that mirror those experienced by adults.},
  file = {/Users/megcychosz/Zotero/storage/23WZ6BJD/Dilley et al. - 2014 - Phonetic variation in consonants in infant-directe.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {1}
}

@article{dilleyQualityQuantityInfantdirected2018,
  title = {Quality and Quantity of Infant-Directed Speech by Maternal Caregivers Predicts Later Speech-Language Outcomes in Children with Cochlear Implants},
  author = {Dilley, Laura and Wieland, Elizabeth and Lehet, Matthew and Arjmandi, Meisam K. and Houston, Derek and Bergeson, Tonya},
  year = {2018},
  month = mar,
  volume = {143},
  pages = {1822--1822},
  issn = {0001-4966},
  doi = {10.1121/1.5035984},
  file = {/Users/megcychosz/Zotero/storage/GDN8CNNR/Dilley et al. - 2018 - Quality and quantity of infant-directed speech by .pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {3}
}

@article{dilleyStatisticalDistributionsConsonant2019,
  title = {Statistical Distributions of Consonant Variants in Infant-Directed Speech: Evidence That /t/ May Be Exceptional},
  shorttitle = {Statistical Distributions of Consonant Variants in Infant-Directed Speech},
  author = {Dilley, Laura and Gamache, Jessica and Wang, Yuanyuan and Houston, Derek M. and Bergeson, Tonya R.},
  year = {2019},
  month = jul,
  volume = {75},
  pages = {73--87},
  issn = {0095-4470},
  doi = {10.1016/j.wocn.2019.05.004},
  abstract = {Statistical distributions of phonetic variants in spoken language influence speech perception for both language learners and mature users. We theorized that patterns of phonetic variant processing of consonants demonstrated by adults might stem in part from patterns of early exposure to statistics of phonetic variants in infant-directed (ID) speech. In particular, we hypothesized that ID speech might involve greater proportions of canonical /t/ pronunciations compared to adult-directed (AD) speech in at least some phonological contexts. This possibility was tested using a corpus of spontaneous speech of mothers speaking to other adults, or to their typically-developing infant. Tokens of word-final alveolar stops \textendash{} including /t/, /d/, and the nasal stop /n/ \textendash{} were examined in assimilable contexts (i.e., those followed by a word-initial labial and/or velar); these were classified as canonical, assimilated, deleted, or glottalized. Results confirmed that there were significantly more canonical pronunciations in assimilable contexts in ID compared with AD speech, an effect which was driven by the phoneme /t/. These findings suggest that at least in phonological contexts involving possible assimilation, children are exposed to more canonical /t/ variant pronunciations than adults are. This raises the possibility that perceptual processing of canonical /t/ may be partly attributable to exposure to canonical /t/ variants in ID speech. Results support the need for further research into how statistics of variant pronunciations in early language input may shape speech processing across the lifespan.},
  file = {/Users/megcychosz/Zotero/storage/63PXXMJR/Dilley et al. - 2019 - Statistical distributions of consonant variants in.pdf},
  journal = {Journal of phonetics},
  pmcid = {PMC7467459},
  pmid = {32884162}
}

@article{dillonPhonologicalAwarenessReading2012,
  title = {Phonological {{Awareness}}, {{Reading Skills}}, and {{Vocabulary Knowledge}} in {{Children Who Use Cochlear Implants}}},
  author = {Dillon, C. M. and {de Jong}, K. and Pisoni, D. B.},
  year = {2012},
  month = apr,
  volume = {17},
  pages = {205--226},
  issn = {1081-4159, 1465-7325},
  doi = {10.1093/deafed/enr043},
  file = {/Users/megcychosz/Zotero/storage/VDVR6E7D/Dillon et al. - 2012 - Phonological Awareness, Reading Skills, and Vocabu.pdf},
  journal = {Journal of Deaf Studies and Deaf Education},
  language = {en},
  number = {2}
}

@incollection{dinnsenOptimalityTheoryClinical2008,
  title = {Optimality {{Theory}}: {{A Clinical Perspective}}},
  shorttitle = {Optimality {{Theory}}},
  booktitle = {The {{Handbook}} of {{Clinical Linguistics}}},
  author = {Dinnsen, Daniel A. and Gierut, Judith A.},
  editor = {Ball, Martin J. and Perkins, Michael R. and Mller, Nicole and Howard, Sara},
  year = {2008},
  month = mar,
  pages = {439--451},
  publisher = {{Blackwell Publishing Ltd.}},
  address = {{Oxford, UK}},
  doi = {10.1002/9781444301007.ch27},
  file = {/Users/megcychosz/Zotero/storage/SPEQ87KX/Dinnsen and Gierut - 2008 - Optimality Theory A Clinical Perspective.pdf},
  isbn = {978-1-4443-0100-7 978-1-4051-3522-1},
  language = {en}
}

@misc{Doi101016,
  title = {Doi:10.1016/j.Ijporl.2008.01.026 | {{Elsevier Enhanced Reader}}},
  shorttitle = {Doi},
  doi = {10.1016/j.ijporl.2008.01.026},
  file = {/Users/megcychosz/Zotero/storage/GAJ7ZIP2/S0165587608000645.html},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S0165587608000645?token=9A73A379E76ED4F92CD9531DD309291C53544A7D3F6E4A5682B49AC25ADCBF6953E9F39958919BE712D1DD284E9B7A23},
  language = {en}
}

@article{dombroskiToddlersAbilityMap2014,
  title = {Toddlers' Ability to Map the Meaning of New Words in Multi-Talker Environments},
  author = {Dombroski, Justine and Newman, Rochelle S.},
  year = {2014},
  month = nov,
  volume = {136},
  pages = {2807--2815},
  issn = {0001-4966},
  doi = {10.1121/1.4898051},
  file = {/Users/megcychosz/Zotero/storage/VD5V7WLP/Dombroski and Newman - 2014 - Toddlers' ability to map the meaning of new words .pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{dossantosNonwordRepetitionTask2018,
  title = {A {{Nonword Repetition Task}} to {{Assess Bilingual Children}}'s {{Phonology}}},
  author = {{dos Santos}, Christophe and Ferr{\'e}, Sandrine},
  year = {2018},
  month = jan,
  volume = {25},
  pages = {58--71},
  issn = {1048-9223, 1532-7817},
  doi = {10.1080/10489223.2016.1243692},
  abstract = {Children with specific language impairment (SLI) are particularly sensitive to phonological complexity in their language. Their performance drops when there are specific phonological structures or when complexity increases. A nonword repetition (NWR) test, which aims to assess the phonology of bilingual speakers with and without SLI, should include phonological properties that are independent of the language and phonological properties whose complexity is quantifiable. The methodology and constraints related to the creation of a NWR test named LITMUS-NWR-FRENCH, which combines these two objectives, are presented. This task was tested on a population of 67 children, 5{$\frac{1}{2}$} to 8{$\frac{1}{2}$} years old, bilingual and monolingual, with and without SLI, having in common French as L1 or L2. Results show that the LITMUS-NWR-FRENCH task differentiates between children with and without SLI in the context of bilingualism. It also shows the influence and importance of phonological complexity in children with SLI.},
  file = {/Users/megcychosz/Zotero/storage/Z89X3Y53/dos Santos and Ferré - 2018 - A Nonword Repetition Task to Assess Bilingual Chil.pdf},
  journal = {Language Acquisition},
  language = {en},
  number = {1}
}

@article{dragerSociophoneticVariationLemma2011,
  title = {Sociophonetic Variation and the Lemma},
  author = {Drager, Katie K.},
  year = {2011},
  month = oct,
  volume = {39},
  pages = {694--707},
  issn = {00954470},
  doi = {10.1016/j.wocn.2011.08.005},
  abstract = {This paper reports on lemma-based phonetic variation observed during a year-long sociophonetic ethnography of an all girls' high school in New Zealand. In-depth acoustic analysis was conducted on tokens of the word like from the girls' speech. This is a word with a number of different grammatical functions, such as quotative like (I was LIKE ``yeah okay''), discourse particle like (It was LIKE so boring), and lexical verb like (I LIKE your socks). The results provide evidence that the different functions of like can vary systematically in terms of their phonetic realisations and that the realisations of some phonetic variables may vary depending on a combination of a word's function and the social group of the speaker who produced it. Additionally, the results provide evidence of a relationship between phonetic reduction and an individual speaker's probability of using like when producing a quotative. This finding lends support to probabilistic models of speech production where activation is not filtered through a phonological buffer and where there is a link between lemma-based and acoustically rich information.},
  file = {/Users/megcychosz/Zotero/storage/5BHUFBW6/Drager - 2011 - Sociophonetic variation and the lemma.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {4}
}

@article{draheimReactionTimeDifferential2019,
  title = {Reaction Time in Differential and Developmental Research: {{A}} Review and Commentary on the Problems and Alternatives.},
  shorttitle = {Reaction Time in Differential and Developmental Research},
  author = {Draheim, Christopher and Mashburn, Cody A. and Martin, Jessie D. and Engle, Randall W.},
  year = {2019},
  month = may,
  volume = {145},
  pages = {508--535},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/bul0000192},
  abstract = {This review identifies and discusses the problems with the use of RT, particularly RT differences, in assessing how individuals differ from one another. Given these problems, a variety of conclusions and theoretical accounts stemming from RTs in individual differences studies may be misinformed. Examples include the efficacy of some clinical techniques, the measurement of racial bias, and the measurement of attention.},
  file = {/Users/megcychosz/Zotero/storage/ASDD6HIL/Draheim et al. - 2019 - Reaction time in differential and developmental re.pdf},
  journal = {Psychological Bulletin},
  language = {en},
  number = {5}
}

@article{dunbarGenerativeGrammarNeural2019,
  title = {Generative {{Grammar}}, {{Neural Networks}}, and the {{Implementational Mapping Problem}}: {{Response}} to {{Pater}}},
  shorttitle = {Generative {{Grammar}}, {{Neural Networks}}, and the {{Implementational Mapping Problem}}},
  author = {Dunbar, Ewan},
  year = {2019},
  issn = {1535-0665},
  doi = {10.1353/lan.2019.0000},
  file = {/Users/megcychosz/Zotero/storage/N99NFWNE/Dunbar - 2019 - Generative Grammar, Neural Networks, and the Imple.pdf},
  journal = {Language},
  language = {en}
}

@article{dunbarQUANTITATIVEMETHODSCOMPARING,
  title = {{{QUANTITATIVE METHODS FOR COMPARING FEATURAL REPRESENTATIONS}}},
  author = {Dunbar, Ewan and Synnaeve, Gabriel and Dupoux, Emmanuel},
  pages = {5},
  abstract = {The basic representational hypothesis in phonology is that segments are coded using a universal set of discrete features. We propose a method for quantitatively measuring how well such features align with arbitrary segment representations. We assess articulatory, spectral, and phonotactic representations of English consonants. Our procedure constructs a concrete representation of a feature in terms of the pairs it distinguishes, and can be extended to any pair of representations to test the consistency of one with the individual dimensions of the other. We validate the method on our phonetic representations and then show that major natural classes are not well represented in the surface phonotactics.},
  file = {/Users/megcychosz/Zotero/storage/YD9IZMWT/Dunbar et al. - QUANTITATIVE METHODS FOR COMPARING FEATURAL REPRES.pdf},
  language = {en}
}

@article{dunnLongitudinalSpeechPerception2014,
  title = {Longitudinal {{Speech Perception}} and {{Language Performance}} in {{Pediatric Cochlear Implant Users}}: {{The Effect}} of {{Age}} at {{Implantation}}},
  shorttitle = {Longitudinal {{Speech Perception}} and {{Language Performance}} in {{Pediatric Cochlear Implant Users}}},
  author = {Dunn, Camille C. and Walker, Elizabeth A. and Oleson, Jacob and Kenworthy, Maura and Van Voorst, Tanya and Tomblin, J. Bruce and Ji, Haihong and Kirk, Karen I. and McMurray, Bob and Hanson, Marlan and Gantz, Bruce J.},
  year = {2014},
  volume = {35},
  pages = {148--160},
  issn = {0196-0202},
  doi = {10.1097/AUD.0b013e3182a4a8f0},
  abstract = {Objectives\textemdash Few studies have examined the long-term effect of age at implantation on outcomes using multiple data points in children with cochlear implants. The goal of this study was to determine if age at implantation has a significant, lasting impact on speech perception, language, and reading performance for children with prelingual hearing loss. Design\textemdash A linear mixed model framework was utilized to determine the effect of age at implantation on speech perception, language, and reading abilities in 83 children with prelingual hearing loss who received cochlear implants by age 4. The children were divided into two groups based on their age at implantation: 1) under 2 years of age and 2) between 2 and 3.9 years of age. Differences in model specified mean scores between groups were compared at annual intervals from 5 to 13 years of age for speech perception, and 7 to 11 years of age for language and reading. Results\textemdash After controlling for communication mode, device configuration, and pre-operative pure-tone average, there was no significant effect of age at implantation for receptive language by 8 years of age, expressive language by 10 years of age, reading by 7 years of age. In terms of speech perception outcomes, significance varied between 7 and 13 years of age, with no significant difference in speech perception scores between groups at ages 7, 11 and 13 years. Children who utilized oral communication (OC) demonstrated significantly higher speech perception scores than children who used total communication (TC). OC users tended to have higher expressive language scores than TC users, although this did not reach significance. There was no significant difference between OC and TC users for receptive language or reading scores. Conclusions\textemdash Speech perception, language, and reading performance continue to improve over time for children implanted before 4 years of age. The current results indicate that the effect of age},
  file = {/Users/megcychosz/Zotero/storage/TSXMXD47/Dunn et al. - 2014 - Longitudinal Speech Perception and Language Perfor.pdf},
  journal = {Ear and Hearing},
  language = {en},
  number = {2}
}

@book{dunnPeabodyPictureVocabulary2019,
  title = {Peabody {{Picture Vocabulary Test}}},
  author = {Dunn, D. M.},
  year = {2019},
  edition = {5th Edition},
  publisher = {{NCS Pearson}},
  address = {{Bloomington, MN}},
  annotation = {[Measurement Instrument]}
}

@book{dunnPPVT4PeabodyPicture2007,
  title = {{{PPVT}}-4: {{Peabody}} Picture Vocabulary Test},
  author = {Dunn, L. M. and Dunn, D. M.},
  year = {2007},
  publisher = {{Pearson Assessments}}
}

@article{dupouxCognitiveScienceEra2018,
  title = {Cognitive {{Science}} in the Era of {{Artificial Intelligence}}: {{A}} Roadmap for Reverse-Engineering the Infant Language-Learner},
  shorttitle = {Cognitive {{Science}} in the Era of {{Artificial Intelligence}}},
  author = {Dupoux, Emmanuel},
  year = {2018},
  month = apr,
  volume = {173},
  pages = {43--59},
  issn = {00100277},
  doi = {10.1016/j.cognition.2017.11.008},
  abstract = {Spectacular progress in the information processing sciences (machine learning, wearable sensors) promises to revolutionize the study of cognitive development. Here, we analyse the conditions under which 'reverse engineering' language development, i.e., building an effective system that mimics infant's achievements, can contribute to our scientific understanding of early language development. We argue that, on the computational side, it is important to move from toy problems to the full complexity of the learning situation, and take as input as faithful reconstructions of the sensory signals available to infants as possible. On the data side, accessible but privacy-preserving repositories of home data have to be setup. On the psycholinguistic side, specific tests have to be constructed to benchmark humans and machines at different linguistic levels. We discuss the feasibility of this approach and present an overview of current results.},
  archiveprefix = {arXiv},
  eprint = {1607.08723},
  eprinttype = {arxiv},
  file = {/Users/megcychosz/Zotero/storage/926DU2SS/Dupoux - 2018 - Cognitive Science in the era of Artificial Intelli.pdf},
  journal = {Cognition},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  language = {en},
  note = {Comment: 27 pages, 5 figures, 3 tables, supplementary materials}
}

@article{duranCanRobotHelp,
  title = {Can a Robot Help Save an Endangered Language?},
  author = {Duran, Maximiliano},
  pages = {4},
  abstract = {A robot using artificial intelligence, a comprehensive set of linguistic resources and pedagogical functionalities may help to preserve Quechua. It can help in M.T of school texts and general culture documentation into Quechua. Written documentation, is essential to keep this language alive. I have been working on such a robot, for several years. I named it Yachaj/expert. The first stage of this project has the following functions: Automatic conjugation, lexical queries of Quechua-FR-SP; elementary spelling checking; and transliteration (alpha version) of texts written in the official spelling of Cuzco, Ecuador or Bolivia to that of Ayacucho and vice-versa.},
  file = {/Users/megcychosz/Zotero/storage/N9SVJVHJ/Duran - Can a robot help save an endangered language.pdf},
  language = {en}
}

@article{durrantFormulaicityAgglutinatingLanguage2013,
  title = {Formulaicity in an Agglutinating Language: The Case of {{Turkish}}},
  shorttitle = {Formulaicity in an Agglutinating Language},
  author = {Durrant, Philip},
  year = {2013},
  month = jan,
  volume = {9},
  pages = {1--38},
  issn = {1613-7035, 1613-7027},
  doi = {10.1515/cllt-2013-0009},
  abstract = {This study examines the extent to which complex inflectional patterns found in Turkish, a language with a rich agglutinating morphology, can be described as formulaic. It is found that many prototypically formulaic phenomena previously attested at the multi-word level in English \textendash{} frequent co-occurrence of specific elements, fixed `bundles' of elements, and associations between lexis and grammar \textendash{} also play an important role at the morphological level in Turkish. It is argued that current psycholinguistic models of agglutinative morphology need to be complexified to incorporate such patterns. Conclusions are also drawn for the practice of Turkish as a Foreign Language teaching and for the methodology of Turkish corpus linguistics.},
  file = {/Users/megcychosz/Zotero/storage/7M45UK3K/Durrant - 2013 - Formulaicity in an agglutinating language the cas.pdf},
  journal = {Corpus Linguistics and Linguistic Theory},
  language = {en},
  number = {1}
}

@article{edwardsCrosslinguisticEvidenceModulation2008,
  title = {Some Cross-Linguistic Evidence for Modulation of Implicational Universals by Language-Specific Frequency Effects in Phonological Development},
  author = {Edwards, Jan and Beckman, Mary E.},
  year = {2008},
  month = apr,
  volume = {4},
  pages = {122--156},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475440801922115},
  abstract = {While broad-focus comparisons of consonant inventories across children acquiring different language can suggest that phonological development follows a universal sequence, finer-grained statistical comparisons can reveal systematic differences. This cross-linguistic study of word-initial lingual obstruents examined some effects of language-specific frequencies on consonant mastery. Repetitions of real words were elicited from 2- and 3-year-old children who were monolingual speakers of English, Cantonese, Greek, or Japanese. The repetitions were recorded and transcribed by an adult native speaker for each language. Results found support for both language-universal effects in phonological acquisition and for language-specific influences related to phoneme and phoneme sequence frequency. These results suggest that acquisition patterns that are common across languages arise in two ways. One influence is direct, via the universal constraints imposed by the physiology and physics of speech production and perception, and how these predict which contrasts will be easy and which will be difficult for the child to learn to control. The other influence is indirect, via the way universal principles of ease of perception and production tend to influence the lexicons of many languages through commonly attested sound changes.},
  file = {/Users/megcychosz/Zotero/storage/XQZ6RHW6/Edwards and Beckman - 2008 - Some Cross-Linguistic Evidence for Modulation of I.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {2}
}

@article{edwardsFrequencyEffectsPhonological2015,
  title = {Frequency Effects in Phonological Acquisition},
  author = {Edwards, Jan and Beckman, Mary E. and Munson, Benjamin},
  year = {2015},
  month = mar,
  volume = {42},
  pages = {306--311},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000914000634},
  file = {/Users/megcychosz/Zotero/storage/RYY4LW4X/Edwards et al. - 2015 - Frequency effects in phonological acquisition.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {2}
}

@article{edwardsInteractionVocabularySize2004,
  title = {The Interaction between Vocabulary Size and Phonotactic Probability Effects on Children's Production Accuracy and Fluency in Novel Word Repetition},
  author = {Edwards, Jan and Beckman, Mary E. and Munson, Benjamin},
  year = {2004},
  volume = {57},
  pages = {421--436},
  abstract = {Adult performance on a variety of tasks suggests that phonological processing of nonwords is grounded in generalizations about sublexical patterns over all known words. To test this account of phonological processing, production accuracy and fluency were examined in nonword repetitions by children and adults. Stimuli were 22 pairs of nonwords, in which one contained a low-frequency or unattested two-phoneme sequence while the other contained a high-frequency sequence. For a subset of these nonword pairs, segment durations were measured. The same sound was produced with a longer duration (less fluently) when it appeared in a low-frequency sequence, as compared to a high-frequency sequence. Low-frequency sequences were also repeated with lower accuracy than high-frequency sequences. Moreover, children with larger vocabularies showed a smaller influence of frequency on accuracy than children with smaller vocabularies. These results support the claim that speakers develop a phonological system based on incremental generalizations over the lexicon.},
  file = {/Users/megcychosz/Zotero/storage/TMFTVZG6/edwards_etal_2004.pdf},
  journal = {Journal of Speech Language and Hearing Research}
}

@article{edwardsLexiconPhonologyRelationships2011,
  title = {Lexicon\textendash Phonology Relationships and Dynamics of Early Language Development \textendash{} a Commentary on {{Stoel}}-{{Gammon}}'s `{{Relationships}} between Lexical and Phonological Development in Young Children'},
  author = {Edwards, Jan and Munson, Benjamin and Beckman, Mary E.},
  year = {2011},
  month = jan,
  volume = {38},
  pages = {35--40},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000910000450},
  file = {/Users/megcychosz/Zotero/storage/RKHSC9FF/Edwards et al. - 2011 - Lexicon–phonology relationships and dynamics of ea.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {01}
}

@article{edwardsNonwordRepetitionsChildren1998,
  title = {Nonword Repetitions of Children with Specific Language Impairment: {{Exploration}} of Some Explanations for Their Inaccuracies},
  shorttitle = {Nonword Repetitions of Children with Specific Language Impairment},
  author = {Edwards, Jan and Lahey, Margaret},
  year = {1998},
  month = apr,
  volume = {19},
  pages = {279--309},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716400010079},
  abstract = {To examine possible explanations of the reported inaccuracies of children with specific language impairment (SLJ) on nonword repetition, we compared the repetitions of 54 children with SLI and their peers in terms of number and type of error as well as latency and duration of response. We found no evidence of differences between the groups in auditory discrimination or response processes, but we did find some evidence suggesting differences in either the formation or storage of phonological representations in working memory. Because repetition accuracy was significantly correlated with expressive, but not receptive, measures of language, we hypothesized that the problem lay with the nature of phonological representations in working memory and not with the ability to hold phonological information in working memory.},
  file = {/Users/megcychosz/Zotero/storage/NWHJ4ATI/Edwards and Lahey - 1998 - Nonword repetitions of children with specific lang.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {2}
}

@article{eguchiDevelopmentSpeechSounds1969,
  title = {Development of Speech Sounds in Children},
  author = {Eguchi, S. and Hirsh, I.J.},
  year = {1969},
  volume = {(suppl 257)},
  pages = {21--51},
  file = {/Users/megcychosz/Zotero/storage/7KYPU7VW/eguchi & Hirsh.pdf},
  journal = {Acta Otolaryngolica}
}

@article{eilersInfantVocalizationsEarly1994,
  title = {Infant Vocalizations and the Early Diagnosis of Severe Hearing Impairment},
  author = {Eilers, Rebecca E. and Oller, D.Kimbrough},
  year = {1994},
  month = feb,
  volume = {124},
  pages = {199--203},
  issn = {00223476},
  doi = {10.1016/S0022-3476(94)70303-5},
  file = {/Users/megcychosz/Zotero/storage/4BCV2QFL/Eilers and Oller - 1994 - Infant vocalizations and the early diagnosis of se.pdf},
  journal = {The Journal of Pediatrics},
  language = {en},
  number = {2}
}

@article{eilersRolePrematuritySocioeconomic1993,
  title = {The Role of Prematurity and Socioeconomic Status in the Onset of Canonical Babbling in Infants},
  author = {Eilers, Rebecca E. and Oller, D. Kimbrough and Levine, Sharyse and Basinger, Devorah and Lynch, Michael P. and Urbano, Richard},
  year = {1993},
  month = jul,
  volume = {16},
  pages = {297--315},
  issn = {01636383},
  doi = {10.1016/0163-6383(93)80037-9},
  file = {/Users/megcychosz/Zotero/storage/6T4A6XHT/Eilers et al. - 1993 - The role of prematurity and socioeconomic status i.pdf},
  journal = {Infant Behavior and Development},
  language = {en},
  number = {3}
}

@misc{ELAN2018,
  title = {{{ELAN}}},
  year = {2018},
  address = {{Max Planck Institute for Psycholinguistics, The Language Archive, Nijmegen, The Netherlands}}
}

@book{eloAcquiringLanguageTwin2016,
  title = {Acquiring Language as a Twin: {{Twin}} Children's Early Health, Social Environment and Emerging Language Skills},
  author = {Elo, H.},
  year = {2016},
  publisher = {{Tampere University Press}},
  address = {{Tampere, Finland}}
}

@article{engeldeabreuWorkingMemoryFluid2010,
  title = {Working Memory and Fluid Intelligence in Young Children},
  author = {{Engel de Abreu}, Pascale M.J. and Conway, Andrew R.A. and Gathercole, Susan E.},
  year = {2010},
  month = nov,
  volume = {38},
  pages = {552--561},
  issn = {01602896},
  doi = {10.1016/j.intell.2010.07.003},
  abstract = {The present study investigates how working memory and fluid intelligence are related in young children and how these links develop over time. The major aim is to determine which aspect of the working memory system \textendash{} short-term storage or cognitive control - drives the relationship with fluid intelligence. A sample of 119 children was followed from kindergarten to second grade and completed multiple assessments of working memory, short-term memory, and fluid intelligence. The data showed that working memory, short-term memory, and fluid intelligence were highly related but separate constructs in young children. The results further showed that when the common variance between working memory and shortterm memory was controlled, the residual working memory factor manifested significant links with fluid intelligence whereas the residual short-term memory factor did not. These findings suggest that in young children cognitive control mechanisms rather than the storage component of working memory span tasks are the source of their link with fluid intelligence.},
  file = {/Users/megcychosz/Zotero/storage/F8PSJLCM/Engel de Abreu et al. - 2010 - Working memory and fluid intelligence in young chi.pdf},
  journal = {Intelligence},
  language = {en},
  number = {6}
}

@article{englundChangesInfantDirected2006,
  title = {Changes in Infant Directed Speech in the First Six Months},
  author = {Englund, Kjellrun and Behne, Dawn},
  year = {2006},
  volume = {15},
  pages = {139--160},
  issn = {1522-7219},
  doi = {10.1002/icd.445},
  abstract = {The Mother\textendash Infant Phonetic Interaction model (MIPhI) predicts that, compared with adult directed speech (ADS), in infant directed speech (IDS) vowels will be overspecified and consonants underspecified during the infants' first 6 months. In a longitudinal natural study, six mothers' ADS and IDS were recorded on 10 occasions during the first 6 months after their infants were born. Acoustic\textendash phonetic measures, including the first two formant frequencies and duration for vowels and the duration of the fricative /s/, were used to test the MIPhI model with differences between IDS and ADS during the infants' first 6 months. Repeated measures analyses showed the fricative /s/ duration was stably longer in IDS, corresponding to an overspecification throughout the 6 months. The unexpected smaller vowel space for IDS than ADS was stably maintained over the six months, suggesting an underspecification of vowels. Vowel duration, which was generally longer in IDS than ADS, however, changed over time, decreasing in difference between IDS and ADS during month 3 and 4. Results invite adjustments to the MIPhI model, in particular related to infants' needs for perceptual enhancement of speech segments, and to the course of infant neurological and communicative development throughout the first 6 months. Copyright \textcopyright{} 2006 John Wiley \& Sons, Ltd.},
  file = {/Users/megcychosz/Zotero/storage/ZGVVDQ5C/Englund and Behne - 2006 - Changes in infant directed speech in the first six.pdf;/Users/megcychosz/Zotero/storage/3K9G2FEG/icd.html},
  journal = {Infant and Child Development},
  keywords = {development,infant directed speech},
  language = {en},
  number = {2}
}

@article{ericksonInfluencesBackgroundNoise2017,
  title = {Influences of {{Background Noise}} on {{Infants}} and {{Children}}},
  author = {Erickson, Lucy C. and Newman, Rochelle S.},
  year = {2017},
  month = oct,
  volume = {26},
  pages = {451--457},
  issn = {0963-7214, 1467-8721},
  doi = {10.1177/0963721417709087},
  abstract = {The goal of this review is to provide a high-level, selected overview of the consequences of background noise on health, perception, cognition, and learning during early development, with a specific focus on how noise may impair speech comprehension and language learning (e.g., via masking). Although much of the existing literature has focused on adults, research shows that infants and young children are relatively disadvantaged at listening in noise. Consequently, a major goal is to consider how background noise may affect young children, who must learn and develop language in noisy environments despite being simultaneously less equipped to do so.},
  file = {/Users/megcychosz/Zotero/storage/42BRMJG6/Erickson and Newman - 2017 - Influences of Background Noise on Infants and Chil.pdf},
  journal = {Current Directions in Psychological Science},
  language = {en},
  number = {5}
}

@article{erskineRelationshipEarlyPhonological2020,
  title = {Relationship between Early Phonological Processing and Later Phonological Awareness: {{Evidence}} from Nonword Repetition},
  shorttitle = {Relationship between Early Phonological Processing and Later Phonological Awareness},
  author = {Erskine, Michelle E. and Munson, Benjamin and Edwards, Jan R.},
  year = {2020},
  month = mar,
  volume = {41},
  pages = {319--346},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716419000547},
  abstract = {This study investigated whether individual differences in receptive vocabulary, speech perception and production, and nonword repetition at age 2 years, 4 months to 3 years, 4 months predicted phonological awareness 2 years later. One hundred twenty-one children were tested twice. During the first testing period (Time 1), children's receptive vocabulary, speech perception and production, and nonword repetition were measured. Nonword repetition accuracy in the present study was distinct from other widely used measures of nonword repetition in that it focused on narrow transcription of diphone sequences in each nonword that differed systematically in phonotactic probability. At the second testing period (Time 2), children's phonological awareness was measured. The best predictors of phonological awareness were a measure of speech production and a measure of phonological processing derived from performance on the nonword repetition task. The results of this study suggest that nonword repetition accuracy provides an implicit measure of phonological skills that are indicative of later phonological awareness at an age when children are too young to perform explicit phonological awareness tasks reliably.},
  file = {/Users/megcychosz/Zotero/storage/ZFIIK74K/Erskine et al. - 2020 - Relationship between early phonological processing.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {2}
}

@incollection{escobarSpanishContactQuechua2011,
  title = {Spanish in {{Contact}} with {{Quechua}}},
  booktitle = {The {{Handbook}} of {{Hispanic Sociolinguistics}}},
  author = {Escobar, Anna Mar{\'i}a},
  editor = {{D{\'i}az-Campos}, Manuel},
  year = {2011},
  month = apr,
  pages = {321--352},
  publisher = {{Wiley-Blackwell}},
  address = {{Oxford, UK}},
  doi = {10.1002/9781444393446.ch16},
  file = {/Users/megcychosz/Zotero/storage/MHPDRK9R/Escobar - 2011 - Spanish in Contact with Quechua.pdf},
  isbn = {978-1-4443-9344-6 978-1-4051-9500-3},
  language = {en}
}

@misc{EstimatingReducedBenefit,
  title = {Estimating the Reduced Benefit of Infant-Directed Speech in Cochlear Implant-Related Speech Processing | {{Elsevier Enhanced Reader}}},
  doi = {10.1016/j.neures.2021.01.007},
  file = {/Users/megcychosz/Zotero/storage/MSRYVG8R/S0168010221000213.html},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S0168010221000213?token=8AB318A089605FCC80C29D002E46672FB6EE1E48AE76EE68423C85507E884A9A39A2C0A0549B154EE450A8C9EC58AF65},
  language = {en}
}

@article{fabiano-smithEarlyMiddleLateDeveloping2010,
  title = {Early-, {{Middle}}-, and {{Late}}-{{Developing Sounds}} in {{Monolingual}} and {{Bilingual Children}}: {{An Exploratory Investigation}}},
  shorttitle = {Early-, {{Middle}}-, and {{Late}}-{{Developing Sounds}} in {{Monolingual}} and {{Bilingual Children}}},
  author = {{Fabiano-Smith}, Leah and Goldstein, Brian A.},
  year = {2010},
  month = feb,
  volume = {19},
  pages = {66--77},
  issn = {1058-0360, 1558-9110},
  doi = {10.1044/1058-0360(2009/08-0036)},
  abstract = {Purpose: To examine the accuracy of early-, middle-, and late-developing (EML) sounds in Spanish-English bilingual children and their monolingual peers. Method: Twenty-four typically developing children, age 3\textendash 4 years, were included in this study: 8 bilingual Spanish-English-speaking children, 8 monolingual Spanish speakers, and 8 monolingual English speakers. Single-word speech samples were obtained to examine (a) differences on the accuracy of EML sounds between SpanishEnglish bilingual children and monolingual Spanish and monolingual English children and (b) the developmental trend on the accuracy of EML sounds within languages for Spanish-English bilingual children and monolingual Spanish and monolingual English children. Results: Findings support those of Shriberg (1993) for English-speaking children and suggest possible EML categories for monolingual Spanish-speaking children and bilingual Spanish-English-speaking children. Conclusions: These exploratory findings indicate the need for longitudinal examination of EML categories with a larger cohort of children to observe similarities and differences between monolingual and bilingual development.},
  file = {/Users/megcychosz/Zotero/storage/5JRQSQEU/Fabiano-Smith and Goldstein - 2010 - Early-, Middle-, and Late-Developing Sounds in Mon.pdf},
  journal = {American Journal of Speech-Language Pathology},
  language = {en},
  number = {1}
}

@article{fabiano-smithInteractionBilingualPhonological2010,
  title = {Interaction in Bilingual Phonological Acquisition: Evidence from Phonetic Inventories},
  shorttitle = {Interaction in Bilingual Phonological Acquisition},
  author = {{Fabiano-Smith}, Leah and Barlow, Jessica A.},
  year = {2010},
  month = jan,
  volume = {13},
  pages = {81--97},
  issn = {1367-0050, 1747-7522},
  doi = {10.1080/13670050902783528},
  file = {/Users/megcychosz/Zotero/storage/2FD9SH7J/Fabiano-Smith and Barlow - 2010 - Interaction in bilingual phonological acquisition.pdf},
  journal = {International Journal of Bilingual Education and Bilingualism},
  language = {en},
  number = {1}
}

@article{fabiano-smithPhonologicalAcquisitionBilingual2010a,
  title = {Phonological {{Acquisition}} in {{Bilingual Spanish}}\textendash{{English Speaking Children}}},
  author = {{Fabiano-Smith}, Leah and Goldstein, Brian A.},
  year = {2010},
  month = feb,
  volume = {53},
  pages = {160--178},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2009/07-0064)},
  abstract = {Temple University, Philadelphia, PA Purpose: In this study, the authors aimed to determine how between-language interaction contributes to phonological acquisition in bilingual Spanish\textendash English speaking children. Method: A total of 24 typically developing children, ages 3;0 (years;months) to 4;0, were included in this study: 8 bilingual Spanish\textendash English speaking children, 8 monolingual Spanish speakers, and 8 monolingual English speakers. Single word and connected speech samples were obtained for each child. This study examined interaction between the two languages of bilingual children during phonological acquisition through the measurement of (a) transfer (the frequency and types of phonological transfer present in the speech of bilingual children); (b) deceleration (a slower rate of acquisition for bilinguals as compared with monolinguals); and (c) acceleration (a faster rate of acquisition for bilinguals as compared with monolinguals. Results: Findings demonstrated that (a) transfer was evident in the productions of bilingual children, (b) differences were found in accuracy between monolingual and bilingual children, and (c) sound frequency did not predict differential accuracy of either phonetically similar sounds between languages or phonetically dissimilar sounds specific to Spanish or English. Implications: The results from this study indicate that transfer, deceleration, and a possible variation of the acceleration hypothesis occur in bilingual phonological acquisition. Evidence was found for separation and interaction between the bilingual children's 2 languages (J. Paradis \& F. Genesee, 1996).},
  file = {/Users/megcychosz/Zotero/storage/UVBFPB6B/Fabiano-Smith and Goldstein - 2010 - Phonological Acquisition in Bilingual Spanish–Engl.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {1}
}

@article{fabiano-smithVoiceOnsetTime2012,
  title = {Voice Onset Time of Voiceless Bilabial and Velar Stops in 3-Year-Old Bilingual Children and Their Age-Matched Monolingual Peers},
  author = {{Fabiano-Smith}, Leah and Bunta, Ferenc},
  year = {2012},
  month = feb,
  volume = {26},
  pages = {148--163},
  issn = {0269-9206, 1464-5076},
  doi = {10.3109/02699206.2011.595526},
  abstract = {This study investigates aspects of voice onset time (VOT) of voiceless bilabial and velar stops in monolingual and bilingual children. VOT poses a special challenge for bilingual Spanish- and English-speaking children because although this VOT distinction exists in both languages, the values differ for the same contrast across Spanish and English. Twenty-four 3-year-olds participated in this study (8 bilingual Spanish\textendash English, 8 monolingual Spanish and 8 monolingual English). The VOT productions of /p/ and /k/ in syllable-initial stressed singleton position were compared across participants. Non-parametric statistical analyses were performed to examine differences (1) between monolinguals and bilinguals and (2) between English and Spanish. The main findings of the study were that monolingual and bilingual children generally differed on VOT in English, but not in Spanish. No statistically significant differences were found between the Spanish and the English VOT of the bilingual children, but the VOT values did differ significantly for monolingual Spanish- versus monolingual English-speaking participants. Our findings were interpreted in terms of Flege's Speech Learning Model, finding possible evidence for equivalence classification.},
  file = {/Users/megcychosz/Zotero/storage/GC5QAQ9I/Fabiano-Smith and Bunta - 2012 - Voice onset time of voiceless bilabial and velar s.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {2}
}

@article{faesWordInitialFricative2016,
  title = {Word Initial Fricative Production in Children with Cochlear Implants and Their Normally Hearing Peers Matched on Lexicon Size},
  author = {Faes, Jolien and Gillis, Steven},
  year = {2016},
  month = dec,
  volume = {30},
  pages = {959--982},
  issn = {0269-9206, 1464-5076},
  doi = {10.1080/02699206.2016.1213882},
  abstract = {Fricative production is affected in children with cochlear implants (CI) as compared to age-matched normally hearing (NH) children. However, the phonological development of children with CI is rarely compared to that of NH peers matched on lexicon size. We compare the early word initial fricative development of 10 children with CI and 30 NH children matched on lexicon size and on chronological age. Children with CI are expected to differ from their NH peers when they are matched on chronological age. But, are lexical development and phonological development commensurate in children with CI as they have been shown to be in NH children? Results show that fricative production in children with CI deviates from that of age-matched NH peers. The differences between both groups disappear when they were matched on lexicon size. Thus, phonological development in children with CI is similar to that of their NH peers with comparable lexicon sizes.},
  file = {/Users/megcychosz/Zotero/storage/AXFM9PCY/Faes and Gillis - 2016 - Word initial fricative production in children with.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {12}
}

@article{faganFrequencyVocalizationCochlear2014,
  title = {Frequency of Vocalization before and after Cochlear Implantation: {{Dynamic}} Effect of Auditory Feedback on Infant Behavior},
  shorttitle = {Frequency of Vocalization before and after Cochlear Implantation},
  author = {Fagan, Mary K.},
  year = {2014},
  month = oct,
  volume = {126},
  pages = {328--338},
  issn = {0022-0965},
  doi = {10.1016/j.jecp.2014.05.005},
  abstract = {The motivation for infants' non-word vocalizations in the second half of the first year and later is unclear. This study of hearing infants and infants with profound hearing loss with and without cochlear implants addressed the hypothesis that vocalizations are primarily motivated by auditory feedback. Early access to cochlear implants has created unique conditions of auditory manipulation that permit empirical tests of relations between auditory perception and infant behavior. Evidence from two separate tests of the research hypothesis showed, before cochlear implantation, infants with profound hearing loss vocalized significantly less often than hearing infants; however, soon after cochlear implantation, they vocalized at levels commensurate with hearing peers. In contrast, vocal behaviors that are typically considered reflexive or emotion-based signals (e.g., crying) were infrequent overall and did not vary with auditory access. These results support the hypothesis that auditory feedback is a critical component motivating early vocalization frequency.},
  file = {/Users/megcychosz/Zotero/storage/DEPGZEKW/Fagan - 2014 - Frequency of vocalization before and after cochlea.pdf},
  journal = {Journal of experimental child psychology},
  pmcid = {PMC4107128},
  pmid = {24980742}
}

@article{faganMeanLengthUtterance2009,
  title = {Mean {{Length}} of {{Utterance}} before Words and Grammar: {{Longitudinal}} Trends and Developmental Implications of Infant Vocalizations},
  shorttitle = {Mean {{Length}} of {{Utterance}} before Words and Grammar},
  author = {Fagan, Mary K.},
  year = {2009},
  month = jun,
  volume = {36},
  pages = {495--527},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000908009070},
  abstract = {This study measured longitudinal change in six parameters of infant utterances (i.e. number of sounds, CV syllables, supraglottal consonants, and repetitions per utterance, temporal duration, and seconds per sound), investigated previously unexplored characteristics of repetition (i.e. number of vowel and CV syllable repetitions per utterance) and analyzed change in vocalizations in relation to age and developmental milestones using multilevel models. Infants (N=18) were videotaped bimonthly during naturalistic and semi-structured activities between 0 ; 3 and the onset of word use (M=11.8 months). Results showed that infant utterances changed in predictable ways both in relation to age and in relation to language milestones (i.e. reduplicated babble onset, word comprehension and word production). Looking at change in relation to the milestones of language development led to new views of babbling, the transition from babbling to first words, and processes that may underlie these transitions.},
  file = {/Users/megcychosz/Zotero/storage/F6KLM53B/Fagan - 2009 - Mean Length of Utterance before words and grammar.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {3}
}

@article{faganSynchronyComplexityDirectiveness2014,
  title = {Synchrony, {{Complexity}} and {{Directiveness}} in {{Mothers}}' {{Interactions}} with {{Infants Pre}}- and {{Post}}-{{Cochlear Implantation}}},
  author = {Fagan, Mary K. and Bergeson, Tonya R. and Morris, Kourtney J.},
  year = {2014},
  month = aug,
  volume = {37},
  pages = {249--257},
  issn = {0163-6383},
  doi = {10.1016/j.infbeh.2014.04.001},
  abstract = {This study investigated effects of profound hearing loss on mother-infant interactions before and after cochlear implantation with a focus on maternal synchrony, complexity, and directiveness. Participants included two groups of mother-infant dyads: 9 dyads of mothers and infants with normal hearing; and 9 dyads of hearing mothers and infants with profound hearing loss. Dyads were observed at two time points: Time 1, scheduled to occur before cochlear implantation for infants with profound hearing loss (mean age = 13.6 months); and Time 2 (mean age = 23.3 months), scheduled to occur approximately six months after cochlear implantation. Hearing infants were age-matched to infants with hearing loss at both time points. Dependent variables included the proportion of maternal utterances that overlapped infant vocalizations, maternal mean length of utterance, infant word use, and combined maternal directives and prohibitions. Results showed mothers' utterances overlapped the vocalizations of infants with hearing loss more often before cochlear implantation than after, mothers used less complex utterances with infants with cochlear implants compared to hearing peers (Time 2), and mothers of infants with profound hearing loss used frequent directives and prohibitions both before and after cochlear implantation. Together, mothers and infants adapted relatively quickly to infants' access to cochlear implants, showing improved interactional synchrony, increased infant word use, and levels of maternal language complexity compatible with infants' word use, all within seven months of cochlear implant activation.},
  file = {/Users/megcychosz/Zotero/storage/7P4X7EM5/Fagan et al. - 2014 - Synchrony, Complexity and Directiveness in Mothers.pdf},
  journal = {Infant behavior \& development},
  number = {3},
  pmcid = {PMC4108344},
  pmid = {24793733}
}

@article{faganWhyRepetitionRepetitive2015,
  title = {Why Repetition? {{Repetitive}} Babbling, Auditory Feedback, and Cochlear Implantation},
  shorttitle = {Why Repetition?},
  author = {Fagan, Mary K.},
  year = {2015},
  month = sep,
  volume = {137},
  pages = {125--136},
  issn = {0022-0965},
  doi = {10.1016/j.jecp.2015.04.005},
  abstract = {This study investigated the reduplicated, or repetitive vocalizations of hearing infants and infants with profound hearing loss with and without cochlear implants using a new measure of repetition in order to address questions not only about the effects of cochlear implantation on repetitive babbling, but also the reason that repetitive vocalizations occur at all and why they emerge around 7 to 8 months of age in hearing infants. Participants included 16 infants with profound hearing loss and 27 hearing infants who participated at a mean age of 9.9 months and/or a mean age of 17.7 months. Mean age at cochlear implantation for infants with profound hearing loss was 12.9 months and mean duration of implant use was 4.2 months. Before cochlear implantation, the data show repetitive vocalizations were rare. However, four months after cochlear implant activation, infants with hearing loss produced both repetitive vocalizations, and repetitions per vocalization, at levels commensurate with hearing peers. The results support the hypothesis that repetition emerges as a means of vocal exploration during the time that hearing infants (and infants with cochlear implants) form auditory-motor representations and neural connections between cortical areas active in syllable production and syllable perception, during the transition from non-linguistic to linguistic vocalization.},
  file = {/Users/megcychosz/Zotero/storage/IQ4U2JCP/Fagan - 2015 - Why repetition Repetitive babbling, auditory feed.pdf},
  journal = {Journal of experimental child psychology},
  pmcid = {PMC4442053},
  pmid = {25974171}
}

@article{fantNonuniformVowelNormalization1975,
  title = {Non-Uniform Vowel Normalization},
  author = {Fant, G},
  year = {1975},
  volume = {2-3},
  pages = {1--19},
  abstract = {A study of f e m a l e - m a l e differences i n F F2: and F 3 of v a r i o u s vowels within eight different languages reveals univer sal tendencies of d e p a r t u r e f r o m a simple uniform scaling. T h e s e have been quantified and adopted a s a basis for a vowel-category-specific normalization procedure which, on the average, reduces the female-male v a r i a n c e to one-half of that r e m a i n i n g a f t e r a s i m p l e uniform scaling of the type suggested by N o r d s t r o m and Lindblom (paper 212 p r e s e n t e d a t the 8th International C o n g r e s s of Phonetic Sciences, L e e d s 1975). Dialectal v a r i a t i o n s within a speaker group a r e thus of the s a m e o r d e r of magnitude a s a u n i v e r s a l p a t t e r n of deviations f r o m a simple s c a l e f a c t o r . P a r t s of this p a t t e r n can be a s c r i b e d to non-uniform scaling of vocal- t r a c t dimensions. Other p a r t s r e q u i r e the assumption of sex- specific articulation which may have developed to satisfy per ceptual c r i t e r i a . I t i s interesting to note that the scaling of tenor formants versus bass singers' formants a r e similar to the female-male scaling ( d e m o n s t r a t e d by Tom Cleveland i n a forthcoming paper).},
  file = {/Users/megcychosz/Zotero/storage/FEJVR2UB/Fant - Non-uniform vowel normalization.pdf},
  journal = {Speech Transactions Laboratory Quarterly Progress and Status Report},
  language = {en}
}

@article{fantNoteVocalTract1966,
  title = {A Note on Vocal Tract Size Factors and Non-Uniform {{F}}-Pattern Scalings},
  author = {Fant, G},
  year = {1966},
  volume = {1},
  pages = {22--30},
  file = {/Users/megcychosz/Zotero/storage/96SMXX3U/Fant - A note on vocal tract size factors and non-uniform.pdf},
  journal = {Speech Transactions Laboratory Quarterly Progress and Status Report},
  language = {en}
}

@article{faraboliniNonwordRepetitionBilingual2021,
  title = {Non-Word Repetition in Bilingual Children: The Role of Language Exposure, Vocabulary Scores and Environmental Factors},
  shorttitle = {Non-Word Repetition in Bilingual Children},
  author = {Farabolini, Gianmatteo and Rinaldi, Pasquale and Caselli, Maria Cristina and Cristia, Alejandrina},
  year = {2021},
  month = feb,
  pages = {1--16},
  issn = {2050-571X, 2050-5728},
  doi = {10.1080/2050571X.2021.1879609},
  abstract = {Assessing language development in bilingual children is challenging in geographical areas where bilinguals have different native languages. Lexical development measures are often used as a starting point to study linguistic abilities in bilingual children. Non-word repetition (NWR) has been found to be very informative in detecting variation. The present study contributes to the broader research aim of documenting bilinguals' language skills. In a sample of 19 Italian-speaking bilingual children with different native languages, correlations among performance on an Italian-like NWR and receptive vocabulary score (Italian PPVT-R), cumulative exposure, age of first exposure to Italian, current Italian exposure, maternal education, parental concerns and vocabulary in toddlerhood (MB-CDI) were calculated. NWR performances correlated with PPVT-R and parental concerns, but not with maternal education and language exposure measures. Neither NWR scores nor PPVT-R scores were related to Italian vocabulary size in toddlerhood (MB-CDI). We integrate our results with those of others and discuss the advantages and disadvantages of administering NWR to bilingual children, and more generally how to perform early bilingual language assessments.},
  file = {/Users/megcychosz/Zotero/storage/ZSKJAJCQ/Farabolini et al. - 2021 - Non-word repetition in bilingual children the rol.pdf},
  journal = {Speech, Language and Hearing},
  language = {en}
}

@book{farrellComputationalModelingCognition2018,
  title = {Computational {{Modeling}} of {{Cognition}} and {{Behavior}}},
  shorttitle = {Computational {{Modeling}} of {{Cognition}} and {{Behavior}}},
  author = {Farrell, Simon and Lewandowsky, Stephan},
  year = {2018},
  month = feb,
  edition = {First},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9781316272503},
  file = {/Users/megcychosz/Zotero/storage/625EEH9W/ch1. part II From words to models.pdf;/Users/megcychosz/Zotero/storage/7EJ3MDTT/bayesian_parameter_estimation-3.pdf;/Users/megcychosz/Zotero/storage/9PYBBAIX/ch2 bayesian_parameter_estimation basic concepts.pdf;/Users/megcychosz/Zotero/storage/FU3FZY9Q/ch1. part I Introduction.pdf;/Users/megcychosz/Zotero/storage/GGXCJLNZ/multilevel_or_hierarchical_modeling.pdf;/Users/megcychosz/Zotero/storage/IBHD2HIG/maximum_likelihood_parameter_estimation.pdf;/Users/megcychosz/Zotero/storage/P5X9QUTB/ch2. part I basic_parameter_estimation_techniques.pdf;/Users/megcychosz/Zotero/storage/S6VX7YD8/Greek symbols.pdf;/Users/megcychosz/Zotero/storage/W3DJC67W/bayesian_parameter_estimation-2.pdf;/Users/megcychosz/Zotero/storage/YYYEQJY3/Mathematical terminology.pdf},
  isbn = {978-1-107-10999-5 978-1-316-27250-3 978-1-107-52561-0},
  language = {en}
}

@article{fasickUsesUntranscribedTape24,
  title = {Some {{Uses}} of {{Untranscribed Tape Recordings}} in {{Survey Research}}},
  author = {Fasick, Frank A.},
  year = {24},
  volume = {41},
  pages = {549},
  issn = {0033362X},
  doi = {10.1086/268415},
  file = {/Users/megcychosz/Zotero/storage/GN4XTTLW/Fasick - 1977 - Some Uses of Untranscribed Tape Recordings in Surv.pdf},
  journal = {Public Opinion Quarterly},
  language = {en},
  number = {4}
}

@article{faulPowerFlexibleStatistical2007,
  title = {G*{{Power}} 3: {{A}} Flexible Statistical Power Analysis Program for the Social, Behavioral, and Biomedical Sciences},
  shorttitle = {G*{{Power}} 3},
  author = {Faul, Franz and Erdfelder, Edgar and Lang, Albert-Georg and Buchner, Axel},
  year = {2007},
  month = may,
  volume = {39},
  pages = {175--191},
  issn = {1554-351X, 1554-3528},
  doi = {10.3758/BF03193146},
  file = {/Users/megcychosz/Zotero/storage/D4PQC5N6/Faul et al. - 2007 - GPower 3 A flexible statistical power analysis p.pdf},
  journal = {Behavior Research Methods},
  language = {en},
  number = {2}
}

@article{feldmanRoleDevelopingLexicon2013,
  title = {A Role for the Developing Lexicon in Phonetic Category Acquisition.},
  author = {Feldman, Naomi H. and Griffiths, Thomas L. and Goldwater, Sharon and Morgan, James L.},
  year = {2013},
  volume = {120},
  pages = {751--778},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/a0034245},
  abstract = {Infants segment words from fluent speech during the same period when they are learning phonetic categories, yet accounts of phonetic category acquisition typically ignore information about the words in which sounds appear. We use a Bayesian model to illustrate how feedback from segmented words might constrain phonetic category learning by providing information about which sounds occur together in words. Simulations demonstrate that word-level information can successfully disambiguate overlapping English vowel categories. Learning patterns in the model are shown to parallel human behavior from artificial language learning tasks. These findings point to a central role for the developing lexicon in phonetic category acquisition and provide a framework for incorporating top-down constraints into models of category learning.},
  file = {/Users/megcychosz/Zotero/storage/8KFYLLNF/Feldman et al. - 2013 - A role for the developing lexicon in phonetic cate.pdf},
  journal = {Psychological Review},
  language = {en},
  number = {4}
}

@book{fensonMacArthurBatesCommunicativeDevelopment2007,
  title = {{{MacArthur}}-{{Bates Communicative Development Inventories User}}'s {{Guide}} and {{Technical Manual}}},
  author = {Fenson, L. and Marchman, V.A. and Thal, D. J. and Dale, P.S. and Reznick, J.S. and Bates, E.},
  year = {2007},
  edition = {2nd Edition},
  publisher = {{Singular}},
  address = {{San Diego, CA}}
}

@article{fergadiotisMeasuringLexicalDiversity2013,
  title = {Measuring {{Lexical Diversity}} in {{Narrative Discourse}} of {{People With Aphasia}}},
  author = {Fergadiotis, Gerasimos and Wright, Heather H. and West, Thomas M.},
  year = {2013},
  month = may,
  volume = {22},
  issn = {1058-0360},
  doi = {10.1044/1058-0360(2013/12-0083)},
  abstract = {Purpose A microlinguistic content analysis for assessing lexical semantics in people with aphasia (PWA) is lexical diversity (LD). Sophisticated techniques have been developed to measure LD. However, validity evidence for these methodologies when applied to the discourse of PWA is lacking. The purpose of this study was to evaluate four measures of LD to determine how effective they were at measuring LD in PWA. Method Four measures of LD were applied to short discourse samples produced by 101 PWA: (a) the Measure of Textual Lexical Diversity (MTLD; ), (b) the Moving-Average Type-Token Ratio (MATTR; ), (c) D (), and (d) the Hypergeometric Distribution (HD-D; ). LD was estimated using each method, and the scores were subjected to a series of analyses (e.g., curve-fitting, analysis of variance, confirmatory factor analysis). Results Results from the confirmatory factor analysis suggested that MTLD and MATTR reflect LD and little of anything else. Further, two indices (HD-D and D) were found to be equivalent, suggesting that either one can be used when samples are {$>$}50 tokens. Conclusion MTLD and MATTR yielded the strongest evidence for producing unbiased LD scores, suggesting that they may be the best measures for capturing LD in PWA.},
  file = {/Users/megcychosz/Zotero/storage/VCHTJEM4/Fergadiotis et al. - 2013 - Measuring Lexical Diversity in Narrative Discourse.pdf},
  journal = {American journal of speech-language pathology / American Speech-Language-Hearing Association},
  number = {2},
  pmcid = {PMC3813439},
  pmid = {23695912}
}

@incollection{fergusonBabyTalkSimplified1977,
  title = {Baby Talk as a Simplified Register.},
  booktitle = {Talking to Children: {{Language}} Input and Acquisition},
  author = {Ferguson, C.A.},
  editor = {Snow, C.E and Ferguson, C.A.},
  year = {1977},
  pages = {209--235},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, UK}},
  file = {/Users/megcychosz/Zotero/storage/B3IRHERF/Ferguson - 1977 - Baby talk as a simplified register..pdf}
}

@article{fergusonWordsSoundsEarly1975,
  title = {Words and Sounds in Early Language Acquisition},
  author = {Ferguson, C.A. and Farwell, C.B.},
  year = {1975},
  volume = {51},
  pages = {419--439},
  journal = {Language},
  number = {2}
}

@article{ferjanramirezParentCoaching102019,
  title = {Parent Coaching at 6 and 10 Months Improves Language Outcomes at 14 Months: {{A}} Randomized Controlled Trial},
  shorttitle = {Parent Coaching at 6 and 10 Months Improves Language Outcomes at 14 Months},
  author = {Ferjan Ram{\'i}rez, Naja and Lytle, Sarah Roseberry and Fish, Melanie and Kuhl, Patricia K.},
  year = {2019},
  month = may,
  volume = {22},
  pages = {e12762},
  issn = {1363-755X, 1467-7687},
  doi = {10.1111/desc.12762},
  file = {/Users/megcychosz/Zotero/storage/ZPLDCKHW/Ferjan Ramírez et al. - 2019 - Parent coaching at 6 and 10 months improves langua.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {3}
}

@article{ferjanramirezParentCoachingIncreases2020,
  title = {Parent Coaching Increases Conversational Turns and Advances Infant Language Development},
  author = {Ferjan Ram{\'i}rez, Naja and Lytle, Sarah Roseberry and Kuhl, Patricia K.},
  year = {2020},
  month = feb,
  volume = {117},
  pages = {3484--3491},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1921653117},
  abstract = {Parental language input is one of the best predictors of children's language achievement. Parentese, a near-universal speaking style distinguished by higher pitch, slower tempo, and exaggerated intonation, has been documented in speech directed toward young children in many countries. Previous research shows that the use of parentese and parent\textendash child turn-taking are both associated with advances in children's language learning. We conducted a randomized controlled trial to determine whether a parent coaching intervention delivered when the infants are 6, 10, and 14 mo of age can enhance parental language input and whether this, in turn, changes the trajectory of child language development between 6 and 18 mo of age. Families of typically developing 6-mo-old infants (               n               = 71) were randomly assigned to intervention and control groups. Naturalistic first-person audio recordings of the infants' home language environment and vocalizations were recorded when the infants were 6, 10, 14, and 18 mo of age. After the 6-, 10-, and 14-mo recordings, intervention, but not control parents attended individual coaching appointments to receive linguistic feedback, listen to language input in their own recordings, and discuss age-appropriate activities that promote language growth. Intervention significantly enhanced parental use of parentese and parent\textendash child turn-taking between 6 and 18 mo. Increases in both variables were significantly correlated with children's language growth during the same period, and children's language outcomes at 18 mo. Using parentese, a socially and linguistically enhanced speaking style, improves children's social language turn-taking and language skills. Research-based interventions targeting social aspects of parent\textendash child interactions can enhance language outcomes.},
  file = {/Users/megcychosz/Zotero/storage/NW8I29E8/Ferjan Ramírez et al. - 2020 - Parent coaching increases conversational turns and.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {7}
}

@article{ferjanramirezParentCoachingIncreases2020a,
  title = {Parent Coaching Increases Conversational Turns and Advances Infant Language Development},
  author = {Ferjan Ram{\'i}rez, Naja and Lytle, Sarah Roseberry and Kuhl, Patricia K.},
  year = {2020},
  month = feb,
  volume = {117},
  pages = {3484--3491},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1921653117},
  abstract = {Parental language input is one of the best predictors of children's language achievement. Parentese, a near-universal speaking style distinguished by higher pitch, slower tempo, and exaggerated intonation, has been documented in speech directed toward young children in many countries. Previous research shows that the use of parentese and parent\textendash child turn-taking are both associated with advances in children's language learning. We conducted a randomized controlled trial to determine whether a parent coaching intervention delivered when the infants are 6, 10, and 14 mo of age can enhance parental language input and whether this, in turn, changes the trajectory of child language development between 6 and 18 mo of age. Families of typically developing 6-mo-old infants (               n               = 71) were randomly assigned to intervention and control groups. Naturalistic first-person audio recordings of the infants' home language environment and vocalizations were recorded when the infants were 6, 10, 14, and 18 mo of age. After the 6-, 10-, and 14-mo recordings, intervention, but not control parents attended individual coaching appointments to receive linguistic feedback, listen to language input in their own recordings, and discuss age-appropriate activities that promote language growth. Intervention significantly enhanced parental use of parentese and parent\textendash child turn-taking between 6 and 18 mo. Increases in both variables were significantly correlated with children's language growth during the same period, and children's language outcomes at 18 mo. Using parentese, a socially and linguistically enhanced speaking style, improves children's social language turn-taking and language skills. Research-based interventions targeting social aspects of parent\textendash child interactions can enhance language outcomes.},
  file = {/Users/megcychosz/Zotero/storage/IXS73M92/Ferjan Ramírez et al. - 2020 - Parent coaching increases conversational turns and.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {7}
}

@article{fernaldCrosslanguageStudyProsodic1989,
  title = {A Cross-Language Study of Prosodic Modifications in Mothers' and Fathers' Speech to Preverbal Infants},
  author = {Fernald, Anne and Taeschner, Traute and Dunn, Judy and Papousek, Mechthild and {de Boysson-Bardies}, B{\'e}n{\'e}dicte and Fukui, Ikuko},
  year = {1989},
  month = oct,
  volume = {16},
  pages = {477--501},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000900010679},
  abstract = {ABSTRACT                            This study compares the prosodie modifications in mothers' and fathers' speech to preverbal infants in French, Italian, German, Japanese, British English, and American English. At every stage of data collection and analysis, standardized procedures were used to enhance the comparability across data sets that is essential for valid cross-language comparison of the prosodie features of parental speech. In each of the six language groups, five mothers and five fathers were recorded in semi-structured home observations while speaking to their infant aged 0; 10\textendash 1;2 and to an adult. Speech samples were instrumentally analysed to measure seven prosodic parameters: mean fundamental frequency (f               0               ), f               0               -minimum, f               0               -maximum, f               0               -range, f               0               -variability, utterance duration, and pause duration. Results showed cross-language consistency in the patterns of prosodic modification used in parental speech to infants. Across languages, both mothers and fathers used higher mean-f               0               , f               0               -minimum, and f               0               -maximum, greater f               0               -variability, shorter utterances, and longer pauses in infant-directed speech than in adult-directed speech. Mothers, but not fathers, used a wider f               0               -range in speech to infants. American English parents showed the most extreme prosodic modifications, differing from the other language groups in the extent of intonational exaggeration in Speech to infants. These results reveal common patterns in caretaker's use of intonation across languages, which may function developmentally to regulate infant arousal and attention, to communicate affect, and to facilitate speech perception and language comprehension. In addition to providing evidence for possibly universal prosodic features of speech to infants, these results suggest that language-specific variations are also important, and that the findings of the numerous studies of early language input based on American English are not necessarily generalisable to other cultures.},
  file = {/Users/megcychosz/Zotero/storage/H4HBR8PN/Fernald et al. - 1989 - A cross-language study of prosodic modifications i.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {3}
}

@article{fernaldExpandedIntonationContours1984,
  title = {Expanded {{Intonation Contours}} in {{Mothers}}' {{Speech}} to {{Newborns}}},
  author = {Fernald, Anne and Simon, Thomas},
  year = {1984},
  volume = {20},
  pages = {104--113},
  file = {/Users/megcychosz/Zotero/storage/28QQUR5D/Fernald and Simon - Expanded Intonation Contours in Mothers' Speech to.pdf},
  language = {en},
  number = {1}
}

@article{fernaldFourmontholdInfantsPrefer1985,
  title = {Four-Month-Old Infants Prefer to Listen to Motherese},
  author = {Fernald, Anne},
  year = {1985},
  month = apr,
  volume = {8},
  pages = {181--195},
  issn = {01636383},
  doi = {10.1016/S0163-6383(85)80005-9},
  file = {/Users/megcychosz/Zotero/storage/4QRPFEUG/Fernald - 1985 - Four-month-old infants prefer to listen to mothere.pdf},
  journal = {Infant Behavior and Development},
  language = {en},
  number = {2}
}

@incollection{fernaldLookingListeningUsing2008,
  title = {Looking While Listening: {{Using}} Eye Movements to Monitor Spoken Language Comprehension by Infants and Young Children},
  shorttitle = {Looking While Listening},
  booktitle = {Language {{Acquisition}} and {{Language Disorders}}},
  author = {Fernald, Anne E. and Zangl, Renate and Portillo, Ana Luz and Marchman, Virginia A.},
  editor = {Sekerina, Irina A. and Fern{\'a}ndez, Eva M. and Clahsen, Harald},
  year = {2008},
  volume = {44},
  pages = {97--135},
  publisher = {{John Benjamins Publishing Company}},
  address = {{Amsterdam}},
  doi = {10.1075/lald.44.06fer},
  abstract = {The ``looking-while-listening'' methodology uses real-time measures of the time course of young children's gaze patterns in response to speech. This procedure is low in task demands and does not require automated eye-tracking technology, similar to ``preferential looking'' procedures. However, the looking-while-listening methodology differs critically from preferential-looking procedures in the methods used for data reduction and analysis, yielding high-resolution measures of speech processing from moment to moment, rather than relying on summary measures of looking preference. Because children's gaze patterns are time-locked to the speech signal and coded frame-by-frame, response latencies can be coded with millisecond precision on multiple trials over multiple items, based on data from thousands of frames in each experiment. The meticulous procedures required in the collection, reduction, and multiple levels of analysis of such detailed data are demanding, but well worth the effort, revealing a dynamic and nuanced picture of young children's developing skill in finding meaning in spoken language.},
  file = {/Users/megcychosz/Zotero/storage/BCU6N84Z/Fernald et al. - 2008 - Looking while listening Using eye movements to mo.pdf},
  isbn = {978-90-272-5304-0 978-90-272-5305-7 978-90-272-9150-9},
  language = {en}
}

@article{fernaldSpeechInfantsHyperspeech2000,
  title = {Speech to Infants as Hyperspeech: {{Knowledge}}-Driven Processes in Early Word Recognitiion},
  author = {Fernald, Anne},
  year = {2000},
  volume = {57},
  pages = {242--254},
  journal = {Phonetica}
}

@article{fernandezStatisticalConsiderationsCrowdsourced2019,
  title = {Statistical Considerations for Crowdsourced Perceptual Ratings of Human Speech Productions},
  author = {Fern{\'a}ndez, Daniel and Harel, Daphna and Ipeirotis, Panos and McAllister, Tara},
  year = {2019},
  month = jun,
  volume = {46},
  pages = {1364--1384},
  issn = {0266-4763, 1360-0532},
  doi = {10.1080/02664763.2018.1547692},
  abstract = {Crowdsourcing has become a major tool for scholarly research since its introduction to the academic sphere in 2008. However, unlike in traditional laboratory settings, it is nearly impossible to control the conditions under which workers on crowdsourcing platforms complete tasks. In the study of communication disorders, crowdsourcing has provided a novel solution to the collection of perceptual ratings of human speech production. Such ratings allow researchers to gauge whether a treatment yields meaningful change in how human listeners' perceive disordered speech. This paper will explore some statistical considerations of crowdsourced data with specific focus on collecting perceptual ratings of human speech productions. Random effects models are applied to crowdsourced perceptual ratings collected in both a continuous and binary fashion. A simulation study is conducted to test the reliability of the proposed models under differing numbers of workers and tasks. Finally, this methodology is applied to a data set from the study of communication disorders.},
  file = {/Users/megcychosz/Zotero/storage/GZE5ISQ8/Fernández et al. - 2019 - Statistical considerations for crowdsourced percep.pdf},
  journal = {Journal of Applied Statistics},
  language = {en},
  number = {8}
}

@article{fieldTouchSocioemotionalPhysical2010,
  title = {Touch for Socioemotional and Physical Well-Being: {{A}} Review},
  shorttitle = {Touch for Socioemotional and Physical Well-Being},
  author = {Field, Tiffany},
  year = {2010},
  volume = {30},
  pages = {367--383},
  issn = {02732297},
  doi = {10.1016/j.dr.2011.01.001},
  abstract = {This review briefly summarizes recent empirical research on touch. The research includes the role of touch in early development, touch deprivation, touch aversion, emotions that can be conveyed by touch, the importance of touch for interpersonal relationships and how friendly touch affects compliance in different situations. MRI data are reviewed showing activation of the orbitofrontal cortex and the caudate cortex during affective touch. Physiological and biochemical effects of touch are also reviewed including decreased heart rate, blood pressure and cortisol and increased oxytocin. Similar changes noted following moderate pressure massage appear to be mediated by the stimulation of pressure receptors and increased vagal activity. Increased serotonin and decreased substance P may explain its pain-alleviating effects. Positive shifts in frontal EEG also accompany moderate pressure massage along with increased attentiveness, decreased depression and enhanced immune function including increased natural killer cells, making massage therapy one of the most effective forms of touch.},
  file = {/Users/megcychosz/Zotero/storage/B86LQFEW/Field - 2010 - Touch for socioemotional and physical well-being .pdf},
  journal = {Developmental Review},
  language = {en},
  number = {4}
}

@book{fikkertAcquisitionProsodicStructure1994,
  title = {On the Acquisition of Prosodic Structure},
  author = {Fikkert, Paula},
  year = {1994},
  publisher = {{Holland Institute of Generative Linguistics}},
  address = {{Leiden \& Amsterdam}}
}

@book{fikkertAcquisitionProsodicStructure1994a,
  title = {On the Acquisition of Prosodic Structure},
  author = {Fikkert, P.},
  year = {1994},
  publisher = {{Holland Institute of Generative Linguistics}},
  address = {{Leiden \& Amsterdam}},
  series = {Unpublished Doctoral Dissertation}
}

@incollection{fikkertHowDoesPlace2008,
  title = {How Does {{Place}} Fall into {{Place}}? {{The}} Lexicon and Emergent Constraints in Children's Developing Phonological Grammar.},
  booktitle = {Contrast in Phonology: {{Theory}}, Perception, and Acquisition},
  author = {Fikkert, Paula and Levelt, Clara},
  editor = {Dresher, B. E. and Rice, K.},
  year = {2008},
  pages = {231--270},
  publisher = {{Walter de Gruyter}}
}

@article{fillmoreWhenLearningSecond1991,
  title = {When Learning a Second Language Means Losing the First},
  author = {Fillmore, Lily Wong},
  year = {1991},
  month = sep,
  volume = {6},
  pages = {323--346},
  issn = {08852006},
  doi = {10.1016/S0885-2006(05)80059-6},
  file = {/Users/megcychosz/Zotero/storage/BVP4UY46/Fillmore - 1991 - When learning a second language means losing the f.pdf},
  journal = {Early Childhood Research Quarterly},
  language = {en},
  number = {3}
}

@article{fisherAbstractionSpecificityPreschoolers2001,
  title = {Abstraction and {{Specificity}} in {{Preschoolers}}' {{Representations}} of {{Novel Spoken Words}}},
  author = {Fisher, Cynthia and Hunt, Caroline and Chambers, Kyle and Church, Barbara},
  year = {2001},
  month = nov,
  volume = {45},
  pages = {665--687},
  issn = {0749596X},
  doi = {10.1006/jmla.2001.2794},
  abstract = {Four experiments explored long-term auditory priming for novel words (nonwords) in preschoolers. In Experiment 1, 2.5-year-olds more accurately identified novel words that had been presented just twice in an initial study phase than nonwords that had not been presented, showing auditory priming for nonwords. Experiments 2, 3, and 4 revealed that the sound representations underlying auditory priming in young children, as in adults, include both abstract and token-specific information about the sounds of new words. In Experiment 2, 3-year-olds showed priming for studied nonsense syllables that changed both token and recorded context from study to test, compared to entirely new test syllables. In Experiment 3, 3-year-olds more accurately identified nonsense syllables that were the same tokens in the same context at study and test than syllables that changed token and context from study to test. In Experiment 4, 3year-olds more accurately identified the same-token syllables from Experiment 3, even when those syllables were presented in isolation, spliced out of their original contexts. Thus children's rapidly formed representations of new spoken words include both components abstract enough to identify the same sound sequence across changes in word token and changes in phonetic context, and components specific to the originally presented token. We argue that the powerful perceptual learning mechanism underlying auditory word priming has the right properties to play a central role in the development of the auditory lexicon.},
  file = {/Users/megcychosz/Zotero/storage/45CZIBC3/Fisher et al. - 2001 - Abstraction and Specificity in Preschoolers' Repre.pdf},
  journal = {Journal of Memory and Language},
  language = {en},
  number = {4}
}

@article{fisherBreakingLinguisticCode,
  title = {Breaking the Linguistic Code: Current Issues in Early Language Learning},
  author = {Fisher, Cynthia and Gleitman, Lila R},
  pages = {54},
  file = {/Users/megcychosz/Zotero/storage/XFFA8AZU/Fisher and Gleitman - BREAKING THE LINGUISTIC CODE CURRENT ISSUES IN EA.pdf},
  language = {en}
}

@article{fitchMorphologyDevelopmentHuman1999,
  title = {Morphology and Development of the Human Vocal Tract: {{A}} Study Using Magnetic Resonance Imaging},
  shorttitle = {Morphology and Development of the Human Vocal Tract},
  author = {Fitch, W. Tecumseh and Giedd, Jay},
  year = {1999},
  month = sep,
  volume = {106},
  pages = {1511--1522},
  issn = {0001-4966},
  doi = {10.1121/1.427148},
  file = {/Users/megcychosz/Zotero/storage/3EP7PF5W/Fitch and Giedd - 1999 - Morphology and development of the human vocal trac.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {3}
}

@article{fitzpatrickPediatricCochlearImplantation2015,
  title = {Pediatric {{Cochlear Implantation}}: {{Why Do Children Receive Implants Late}}?},
  author = {Fitzpatrick, Elizabeth M and Ham, Julia and Whittingham, JoAnne},
  year = {2015},
  volume = {36},
  pages = {688--694},
  abstract = {Objectives: Early cochlear implantation has been widely promoted for children who derive inadequate benefit from conventional acoustic amplification. Universal newborn hearing screening has led to earlier identification and intervention, including cochlear implantation in much of the world. The purpose of this study was to examine age and time to cochlear implantation and to understand the factors that affected late cochlear implantation in children who received cochlear implants. Design: In this population-based study, data were examined for all children who underwent cochlear implant surgery in one region of Canada from 2002 to 2013. Clinical characteristics were collected prospectively as part of a larger project examining outcomes from newborn hearing screening. For this study, audiologic details including age and severity of hearing loss at diagnosis, age at cochlear implant candidacy, and age at cochlear implantation were documented. Additional detailed medical chart information was extracted to identify the factors associated with late implantation for children who received cochlear implants more than 12 months after confirmation of hearing loss. Results: The median age of diagnosis of permanent hearing loss for 187 children was 12.6 (interquartile range: 5.5, 21.7) months, and the age of cochlear implantation over the 12-year period was highly variable with a median age of 36.2 (interquartile range: 21.4, 71.3) months. A total of 118 (63.1\%) received their first implant more than 12 months after confirmation of hearing loss. Detailed analysis of clinical profiles for these 118 children revealed that late implantation could be accounted for primarily by progressive hearing loss (52.5\%), complex medical conditions (16.9\%), family indecision (9.3\%), geographical location (5.9\%), and other miscellaneous known (6.8\%) and unknown factors (8.5\%). Conclusions: This study confirms that despite the trend toward earlier implantation, a substantial number of children can be expected to receive their first cochlear implant well beyond their first birthday because they do not meet audiologic criteria of severe to profound hearing loss for cochlear implantation at the time of identification of permanent hearing loss. This study underscores the importance of carefully monitoring all children with permanent hearing loss to ensure that optimal intervention including cochlear implantation occurs in a timely manner.},
  file = {/Users/megcychosz/Zotero/storage/GNYA2B9A/Fitzpatrick et al. - 2015 - Pediatric Cochlear Implantation Why Do Children R.pdf},
  journal = {Ear and Hearing},
  language = {en},
  number = {6}
}

@article{flegeAnticipatoryCarryoverNasal1988,
  title = {Anticipatory and Carry-over Nasal Coarticulation in the Speech of Children and Adults},
  author = {Flege, James Emil},
  year = {1988},
  month = dec,
  volume = {31},
  pages = {525--536},
  file = {/Users/megcychosz/Zotero/storage/4VHHX4IF/Flege_nasal_coarticulation_JSHR_1988.pdf},
  journal = {Journal of Speech Language and Hearing Research}
}

@article{fletcherMaturationSpeechMechanism1973,
  title = {Maturation of the {{Speech Mechanism}}},
  author = {Fletcher, S.G.},
  year = {1973},
  volume = {25},
  pages = {161--172},
  issn = {1421-9972, 1021-7762},
  doi = {10.1159/000263684},
  file = {/Users/megcychosz/Zotero/storage/2L7AZEJB/Fletcher - 1973 - Maturation of the Speech Mechanism.pdf},
  journal = {Folia Phoniatrica et Logopaedica},
  language = {en},
  number = {3}
}

@article{fletcherMaturationSpeechMechanism1973a,
  title = {Maturation of the {{Speech Mechanism}}},
  author = {Fletcher, S.G.},
  year = {1973},
  volume = {25},
  pages = {161--172},
  issn = {1421-9972, 1021-7762},
  doi = {10.1159/000263684},
  file = {/Users/megcychosz/Zotero/storage/4C3C4FQ6/Fletcher - 1973 - Maturation of the Speech Mechanism.pdf},
  journal = {Folia Phoniatrica et Logopaedica},
  language = {en},
  number = {3}
}

@article{flipsenIntelligibilitySpontaneousConversational2008,
  title = {Intelligibility of Spontaneous Conversational Speech Produced by Children with Cochlear Implants: {{A}} Review},
  shorttitle = {Intelligibility of Spontaneous Conversational Speech Produced by Children with Cochlear Implants},
  author = {Flipsen, Peter},
  year = {2008},
  month = may,
  volume = {72},
  pages = {559--564},
  issn = {01655876},
  doi = {10.1016/j.ijporl.2008.01.026},
  abstract = {Objective: The emergence of cochlear implant technology has raised hopes about improved outcomes for children with severe and profound hearing impairments. This study sought to examine the current literature to help evaluate whether the new technology is living up to its promise specifically relative to the intelligibility of conversational speech produced by these children. Method: At least 20 studies to date have reported findings for the intelligibility of speech produced by children fitted with cochlear implants. The current review involved a descriptive, summary examination of 10 of these studies that analyzed spontaneous conversational speech. Results: The review suggested that intelligibility outcomes for these children appear to be considerably better than we have historically seen in this population (i.e., prior to the development of cochlear implant technology). For children implanted very early it appears that progress toward intelligible speech is more rapid, and the development of fully intelligible speech may be a reasonable goal for many such children. Even for children implanted somewhat later, progress on speech intelligibility appears to continue for at least 10 years post-implantation. Conclusion: It would appear that cochlear implants are providing much better outcomes compared to older intervention approaches, at least relative to the intelligibility of spontaneous conversation.},
  file = {/Users/megcychosz/Zotero/storage/7HGMF8D6/Flipsen - 2008 - Intelligibility of spontaneous conversational spee.pdf},
  journal = {International Journal of Pediatric Otorhinolaryngology},
  language = {en},
  number = {5}
}

@article{fogelBenchReasonableExpectation2014,
  title = {From the {{Bench}}: {{A Reasonable Expectation}} of {{Privacy}}},
  author = {Fogel, Jeremy},
  year = {2014},
  volume = {Spring},
  journal = {The American Bar Association Litigation Journal}
}

@article{fontenotResidualCochlearFunction2018,
  title = {Residual {{Cochlear Function}} in {{Adults}} and {{Children Receiving Cochlear Implants}}: {{Correlations With Speech Perception Outcomes}}},
  author = {Fontenot, Tatyana Elizabeth and Giardina, Christopher Kenneth and Dillon, Megan T and Rooth, Meredith A and Teagle, Holly F and Park, Lisa R and Brown, Kevin David and Adunka, Oliver F and Buchman, Craig A and Pillsbury, Harold C and Fitzpatrick, Douglas C},
  year = {2018},
  volume = {40},
  pages = {15},
  abstract = {Objectives: Variability in speech perception outcomes with cochlear implants remains largely unexplained. Recently, electrocochleography, or measurements of cochlear potentials in response to sound, has been used to assess residual cochlear function at the time of implantation. Our objective was to characterize the potentials recorded preimplantation in subjects of all ages, and evaluate the relationship between the responses, including a subjective estimate of neural activity, and speech perception outcomes. Design: Electrocochleography was recorded in a prospective cohort of 284 candidates for cochlear implant at University of North Carolina (10 months to 88 years of ages). Measurement of residual cochlear function called the ``total response'' (TR), which is the sum of magnitudes of spectral components in response to tones of different stimulus frequencies, was obtained for each subject. The TR was then related to results on age-appropriate monosyllabic word score tests presented in quiet. In addition to the TR, the electrocochleography results were also assessed for neural activity in the forms of the compound action potential and auditory nerve neurophonic. Results: The TR magnitude ranged from a barely detectable response of about 0.02 \textmu V to more than 100 \textmu V. In adults (18 to 79 years old), the TR accounted for 46\% of variability in speech perception outcome by linear regression (r2 = 0.46; p {$<$} 0.001). In children between 6 and 17 years old, the variability accounted for was 36\% (p {$<$} 0.001). In younger children, the TR accounted for less of the variability, 15\% (p = 0.012). Subjects over 80 years old tended to perform worse for a given TR than younger adults at the 6-month testing interval. The subjectively assessed neural activity did not increase the information compared with the TR alone, which is primarily composed of the cochlear microphonic produced by hair cells. Conclusions: The status of the auditory periphery, particularly of hair cells rather than neural activity, accounts for a large fraction of variability in speech perception outcomes in adults and older children. In younger children, the relationship is weaker, and the elderly differ from other adults. This simple measurement can be applied with high throughput so that peripheral status can be assessed to help manage patient expectations, create individually-tailored treatment plans, and identify subjects performing below expectations based on residual cochlear function.},
  file = {/Users/megcychosz/Zotero/storage/R589FDH2/Fontenot et al. - 2018 - Residual Cochlear Function in Adults and Children .pdf},
  language = {en},
  number = {3}
}

@article{fontenotResidualCochlearFunction2019,
  title = {Residual {{Cochlear Function}} in {{Adults}} and {{Children Receiving Cochlear Implants}}: {{Correlations With Speech Perception Outcomes}}},
  shorttitle = {Residual {{Cochlear Function}} in {{Adults}} and {{Children Receiving Cochlear Implants}}},
  author = {Fontenot, Tatyana Elizabeth and Giardina, Christopher Kenneth and Dillon, Megan T. and Rooth, Meredith A. and Teagle, Holly F. and Park, Lisa R. and Brown, Kevin David and Adunka, Oliver F. and Buchman, Craig A. and Pillsbury, Harold C. and Fitzpatrick, Douglas C.},
  year = {2019},
  volume = {40},
  pages = {577--591},
  issn = {0196-0202},
  doi = {10.1097/AUD.0000000000000630},
  abstract = {Objectives\textemdash Variability in speech perception outcomes with cochlear implants (CI) remains largely unexplained. Recently, electrocochleography, or measurements of cochlear potentials in response to sound, has been used to assess residual cochlear function at the time of implantation. Our objective was to characterize the potentials recorded pre-implantation in subjects of all ages, and evaluate the relationship between the responses, including a subjective estimate of neural activity, and speech perception outcomes.},
  file = {/Users/megcychosz/Zotero/storage/HYV63H4E/Fontenot et al. - 2019 - Residual Cochlear Function in Adults and Children .pdf},
  journal = {Ear and Hearing},
  language = {en},
  number = {3}
}

@article{forssbergDevelopmentHumanPrecision1991,
  title = {Development of Human Precision Grip {{I}}: {{Basic}} Coordination of Force},
  shorttitle = {Development of Human Precision Grip {{I}}},
  author = {Forssberg, H. and Eliasson, A.C. and Kinoshita, H. and Johansson, R.S. and Westling, G.},
  year = {1991},
  month = jun,
  volume = {85},
  issn = {0014-4819, 1432-1106},
  doi = {10.1007/BF00229422},
  abstract = {The coordination of manipulative forces was examined while children and adults repeatedly lifted a small object between the thumb and index finger. Grip force, load force (vertical lifting force), grip force rate and the vertical position of the test object were continuously measured. In adults, the force generation was highly automatized and was nearly invariant between trials. After a preload phase in which the grip was established, the grip and load forces increased in parallel under isometric conditions until the load force overcame the force of gravity and the object started to move. During this loading phase, the force rate profiles were essentially bell shaped and single peaked, suggesting that the force increases were programmed as one coordinated event. Children below the age of two exhibited a prolonged preload phase and a loading phase during which the grip and load forces did not increase in parallel. A major increase in grip force preceded the increase in load force, and at the start of the loading phase, the grip force was usually several Newtons (N). The force rate profiles were multi peaked with stepwise force increases most likely allowing peripheral feedback to play an important role in the control of the forces. After the age of two, the grip force increased less during the preload phase. The loading phase was more regularly characterized by a parallel increase of the grip force and load force and the duration of the various phases decreased. The older children programmed the forces in one force rate pulse indicating the emergence of an anticipatory strategy. Yet, the mature coordination of forces was not fully developed until several years later. It was concluded that the development of the precision grip was based upon the formation of a lift synergy coupling grip and load force generating circuits and that it seems to involve a transition from feedback control to feedforward control.},
  file = {/Users/megcychosz/Zotero/storage/P7U3FXZ3/Forssberg et al. - 1991 - Development of human precision grip I Basic coord.pdf},
  journal = {Experimental Brain Research},
  language = {en},
  number = {2}
}

@article{foster-johnsonPredictingGrouplevelOutcome2018,
  title = {Predicting Group-Level Outcome Variables: {{An}} Empirical Comparison of Analysis Strategies},
  shorttitle = {Predicting Group-Level Outcome Variables},
  author = {{Foster-Johnson}, Lynn and Kromrey, Jeffrey D.},
  year = {2018},
  month = dec,
  volume = {50},
  pages = {2461--2479},
  issn = {1554-3528},
  doi = {10.3758/s13428-018-1025-8},
  abstract = {This study provides a review of two methods for analyzing multilevel data with group-level outcome variables and compares them in a simulation study. The analytical methods included an unadjusted ordinary least squares (OLS) analysis of group means and a two-step adjustment of the group means suggested by Croon and van Veldhoven (2007). The Type I error control, power, bias, standard errors, and RMSE in parameter estimates were compared across design conditions that included manipulations of number of predictor variables, level of correlation between predictors, level of intraclass correlation, predictor reliability, effect size, and sample size. The results suggested that an OLS analysis of the group means, with White's heteroscedasticity adjustment, provided more power for tests of group-level predictors, but less power for tests of individual-level predictors. Furthermore, this simple analysis avoided the extreme bias in parameter estimates and inadmissible solutions that were encountered with other strategies. These results were interpreted in terms of recommended analytical methods for applied researchers.},
  file = {/Users/megcychosz/Zotero/storage/8X96EXYH/Foster-Johnson and Kromrey - 2018 - Predicting group-level outcome variables An empir.pdf},
  journal = {Behavior Research Methods},
  language = {en},
  number = {6}
}

@book{foulkesFirstLanguageAcquisition2015,
  title = {First {{Language Acquisition}} and {{Phonological Change}}},
  author = {Foulkes, Paul and Vihman, Marilyn},
  editor = {Honeybone, Patrick and Salmons, Joseph},
  year = {2015},
  month = nov,
  publisher = {{Oxford University Press}},
  doi = {10.1093/oxfordhb/9780199232819.013.001},
  abstract = {This chapter presents new data from first language studies of acquisition, some of them sociolinguistically informed. We challenge various longstanding ideas about the role of first language acquisition in phonological change, in particular the assumption that cross-generational change reflects errors in first language learning, for which our data provide no support.},
  file = {/Users/megcychosz/Zotero/storage/RIMW8YJD/Foulkes and Vihman - 2015 - First Language Acquisition and Phonological Change.pdf},
  language = {en}
}

@unpublished{foulkesLanguageAcquisitionPhonological,
  title = {Language Acquisition and Phonological Change},
  author = {Foulkes, Paul and Vihman, Marilyn M.},
  address = {{University of York}},
  file = {/Users/megcychosz/Zotero/storage/3M6F4BSU/gaskins2006cultural.pdf;/Users/megcychosz/Zotero/storage/NTXBWXW4/Foulkes_Vihman_histphon.pdf}
}

@article{foulkesPhonologicalVariationChildDirected2005,
  title = {Phonological {{Variation}} in {{Child}}-{{Directed Speech}}},
  author = {Foulkes, Paul and Docherty, Gerard and Watt, Dominic},
  year = {2005},
  volume = {81},
  pages = {177--206},
  publisher = {{Linguistic Society of America}},
  issn = {0097-8507},
  abstract = {Segmental features of child-directed speech (CDS) were studied in a corpus drawn from thirty-nine mothers living in Tyneside, England. Focus was on the phonetic variants used for (t) in word-medial and word-final prevocalic contexts since it is known that these variants display clear sociolinguistic patterning in the adult community. Variant usage in CDS was found to differ markedly from that in interadult speech. Effects were also found with respect to the age and gender of the children being addressed. Speech to girls generally contained more standard variants than speech to boys, which, by contrast, contained higher rates of vernacular variants. The differentiation by gender was most apparent for the youngest children. The findings are assessed in comparison to other studies of CDS. It has previously been claimed that modifications made in the CDS register help children to learn linguistic structures and also to learn that speech is a social activity. Our findings suggest that CDS may play an additional role, providing boys and girls as young as 2;0 with differential opportunities to learn the social-indexical values of sociolinguistic variables.},
  file = {/Users/megcychosz/Zotero/storage/NSWLQY53/Foulkes et al. - 2005 - Phonological Variation in Child-Directed Speech.pdf},
  journal = {Language},
  number = {1}
}

@article{foulkesTrackingEmergenceStructured1999,
  title = {Tracking the Emergence of Structured Variation - Realisations of (t) by {{Newcastle}} Children},
  author = {Foulkes, Paul and Docherty, Gerry and Watt, Dominic},
  year = {1999},
  volume = {7},
  pages = {1--18},
  abstract = {This paper describes an investigation of the speech of children aged 2 to 4 from Newcastle upon Tyne. Our aim is to understand how variant phonetic patterns come to be acquired. These patterns include both phonologically governed alternations, such as the aspirated allophone of word-initial (t), and also sociolinguistically correlated variants. A baseline for this study is provided by a previous project focusing on Newcastle adults, which revealed variation and change in the pronunciation of several consonants and vowels. We concentrate here on 10 children's productions of (t), a particularly complex variable in adult speech. The children demonstrate a sophisticated mastery of many aspects of the adult patterns, producing qualitatively different phonetic variants in appropriate phonological contexts. The acoustic qualities of the allophones in general closely resemble those of adults. Where gender-based differences occur in the local adult community, both boys and girls adhere more closely to the patterns typical of women. This suggests that at this stage of development children are most influenced by the phonological/phonetic patterns of their mothers. We conclude that it is problematic to view acquisition of language-specific phonological units as separate from the accent-specific variation which is important in the construction of a sociolinguistic identity. We also suggest that structured variation in the adult input, although usually characterised as dysfunctional in child-centred research, may in fact serve a positive function in the acquisition process. Specifically, children may exploit recurrent patterns in the input signal to help them locate the phonological components of words and achieve the transition from a system of holistic lexical representation to one involving more abstract categorial units.},
  file = {/Users/megcychosz/Zotero/storage/WIUBCTXC/Foulkes et al. - TRACKING THE EMERGENCE OF STRUCTURED VARIATION – R.pdf},
  journal = {Leeds Working Papers in Linguistics},
  language = {en}
}

@article{fourakisTempoStressVowel1991,
  title = {Tempo, Stress, and Vowel Reduction in {{American English}}},
  author = {Fourakis, Marios},
  year = {1991},
  month = oct,
  volume = {90},
  pages = {1816--1827},
  issn = {0001-4966},
  doi = {10.1121/1.401662},
  file = {/Users/megcychosz/Zotero/storage/AAJFQ3NM/Fourakis - 1991 - Tempo, stress, and vowel reduction in American Eng.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@incollection{fowlerHowEarlyPhonological1991,
  title = {How {{Early Phonological Development Might Set}} the {{Stage}} for {{Phoneme Awareness}}},
  booktitle = {Phonological Processing in Literacy: {{A}} Tribute to {{Isabelle Y Liberman}}},
  author = {Fowler, Anne E},
  year = {1991},
  pages = {91--117},
  publisher = {{LEA}},
  address = {{Hillsdale, NJ}},
  file = {/Users/megcychosz/Zotero/storage/UH8A4UK4/Fowler - How Early Phonological Development Might Set the S.pdf},
  language = {en}
}

@article{fowlerListenersPerceptionCompensatory2010,
  title = {Listeners' Perception of Compensatory Shortening},
  author = {Fowler, Carol A. and Thompson, Jaqueline M.},
  year = {2010},
  month = feb,
  volume = {72},
  pages = {481--491},
  issn = {1943-3921, 1943-393X},
  doi = {10.3758/APP.72.2.481},
  abstract = {English exhibits ``compensatory shortening'' whereby a stressed syllable followed by an unstressed syllable is measured to be shorter than the same stressed syllable alone. This ``anticipatory'' shortening is much greater than ``backward'' shortening whereby an unstressed syllable is measured to shorten a following stressed syllable. We speculated that measured shortening reflects, not true shortening, but coarticulatory hiding. Hence, we asked whether listeners are sensitive to parts of stressed syllables hidden by following or preceding unstressed syllables. In two experiments, we found the point of subjective equality, that is the durational difference between a stressed syllable in isolation and one followed by an unstressed syllable, at which listeners cannot tell which is longer. A third experiment found the point of subjective equality for stressed monosyllables and disyllables with a weak-strong stress pattern. In all experiments, the points of subjective equality occurred when stressed syllables in disyllables were measured to be shorter than those in monosyllables as if listeners hear the coarticulatory onsest or continuation of a stressed syllable within unstressed syllables.},
  file = {/Users/megcychosz/Zotero/storage/35A243PP/Fowler and Thompson - 2010 - Listeners’ perception of compensatory shortening.pdf},
  journal = {Attention, Perception, \& Psychophysics},
  language = {en},
  number = {2}
}

@article{fowlerRelationshipCoarticulationCompensatory1981,
  title = {A {{Relationship}} between {{Coarticulation}} and {{Compensatory Shortening}}},
  author = {Fowler, Carol A.},
  year = {1981},
  volume = {38},
  pages = {35--50},
  issn = {1423-0321, 0031-8388},
  doi = {10.1159/000260013},
  abstract = {A comparison of the literatures on coarticulatory influences of a stressed vowel on consonants and unstressed vowels and on `compensatory shortening' of stressed vowels in the contexts of consonants and unstressed vowels suggests that the two timing effects may be related. An experiment was conducted to provide an explicit comparison and to test a hypothesis that compensatory shortening aand coarticulation are not separate timing phenomena. The two timing effects were found to pattern very similarly and both to be predicted by Lindblom and Rapp's compensatory shortening formula. 5 of 6 subjects showed significant correlations between coarticulation and shortening.},
  file = {/Users/megcychosz/Zotero/storage/94KI6YIY/Fowler - 1981 - A Relationship between Coarticulation and Compensa.pdf},
  journal = {Phonetica},
  language = {en},
  number = {1-3}
}

@article{foyHomeLiteracyEnvironment2003,
  title = {Home Literacy Environment and Phonological Awareness in Preschool Children: {{Differential}} Effects for Rhyme and Phoneme Awareness},
  shorttitle = {Home Literacy Environment and Phonological Awareness in Preschool Children},
  author = {Foy, Judith G. and Mann, Virginia},
  year = {2003},
  month = mar,
  volume = {24},
  pages = {59--88},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716403000043},
  abstract = {The literature to date suggests that the best predictor of early reading ability, phonological awareness, appears to be associated with the acquisition of letter-sound and vocabulary knowledge and with the development of well-defined phonological representations. It further suggests that at least some aspects of phonological awareness critically depend upon literacy exposure. In this study of 4- to 6-year-olds, we examine whether aspects of the home literacy environment are differentially associated with phonological awareness. Parental responses to a questionnaire about the home literacy environment are compared to children's awareness of rhyme and phonemes, as well as to their vocabulary, letter knowledge, and performance on measures of phonological strength (nonword repetition, rapid naming skill, phonological distinctness, and auditory discrimination). The results showed that a teaching focus in the home literacy environment and exposure to reading-related media are directly associated with phoneme awareness and indirectly associated via letter knowledge and vocabulary. Exposure to reading-related media and parents' active involvement in children's literature were also directly and indirectly linked with rhyme awareness skills via their association with letter and vocabulary knowledge.},
  file = {/Users/megcychosz/Zotero/storage/LP4CBYDI/Foy and Mann - 2003 - Home literacy environment and phonological awarene.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {01}
}

@inproceedings{franichEffectCognitiveLoad2015,
  title = {The Effect of Cognitive Load on Tonal Coarticulation},
  booktitle = {Proceedings of the 18th {{International Congress}} of {{Phonetic Sciences}}},
  author = {Franich, Kathryn},
  year = {2015},
  address = {{Glasgow, UK}},
  file = {/Users/megcychosz/Zotero/storage/W42P2SWE/Franich - THE EFFECT OF COGNITIVE LOAD ON TONAL COARTICULATI.pdf},
  language = {en}
}

@article{franklinEffectsParentalInteraction2014,
  title = {Effects of {{Parental Interaction}} on {{Infant Vocalization Rate}}, {{Variability}} and {{Vocal Type}}},
  author = {Franklin, Beau and Warlaumont, Anne S. and Messinger, Daniel and Bene, Edina and Nathani Iyer, Suneeti and Lee, Chia-Chang and Lambert, Brittany and Oller, D. Kimbrough},
  year = {2014},
  month = jul,
  volume = {10},
  pages = {279--296},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2013.849176},
  file = {/Users/megcychosz/Zotero/storage/VNXDISE3/Franklin et al. - 2014 - Effects of Parental Interaction on Infant Vocaliza.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {3}
}

@article{freemanSpeechRateRatematching2017,
  title = {Speech Rate, Rate-Matching, and Intelligibility in Early-Implanted Cochlear Implant Users},
  author = {Freeman, Valerie and Pisoni, David B.},
  year = {2017},
  month = aug,
  volume = {142},
  pages = {1043--1054},
  issn = {0001-4966},
  doi = {10.1121/1.4998590},
  file = {/Users/megcychosz/Zotero/storage/JMY7L7H2/Freeman and Pisoni - 2017 - Speech rate, rate-matching, and intelligibility in.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@article{frickeMeasuringCoarticulationSpontaneous2012,
  title = {Measuring Coarticulation in Spontaneous Speech: A Preliminary Report},
  author = {Fricke, Melinda and Johnson, Keith},
  year = {2012},
  volume = {8},
  pages = {306--320},
  file = {/Users/megcychosz/Zotero/storage/3MI4R6JZ/Fricke and Johnson - 2012 - Measuring coarticulation in spontaneous speech a .pdf},
  journal = {UC Berkeley PhonLab Annual Report},
  language = {en}
}

@article{friesenSpeechRecognitionNoise2001,
  title = {Speech Recognition in Noise as a Function of the Number of Spectral Channels: {{Comparison}} of Acoustic Hearing and Cochlear Implants},
  shorttitle = {Speech Recognition in Noise as a Function of the Number of Spectral Channels},
  author = {Friesen, Lendra M. and Shannon, Robert V. and Baskent, Deniz and Wang, Xiaosong},
  year = {2001},
  month = aug,
  volume = {110},
  pages = {1150--1163},
  issn = {0001-4966},
  doi = {10.1121/1.1381538},
  file = {/Users/megcychosz/Zotero/storage/LB3LBWSR/Friesen et al. - 2001 - Speech recognition in noise as a function of the n.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@article{fritcheAdultsProducePhonetic2021,
  title = {Do Adults Produce Phonetic Variants of /t/ Less Often in Speech to Children?},
  author = {Fritche, Robin and {Shattuck-Hufnagel}, Stefanie and Song, Jae Yung},
  year = {2021},
  month = jul,
  volume = {87},
  pages = {101056},
  issn = {00954470},
  doi = {10.1016/j.wocn.2021.101056},
  abstract = {The surface phonetic details of an utterance affect how `native' a speaker sounds. However, studies have shown that children's acquisition of context-appropriate variation (sometimes called allophones) is late. This study's goal was to understand how caregivers use phonetic variation in the production of American English /t/ in child-directed speech (CDS), compared to in adult-directed speech (ADS). We hypothesized that mothers modify their input to children in order to produce more limited variation in CDS than in ADS, to potentially assist children in the development of contrastive phonemic categories. To this end, we recorded eight mothers of children under the age of 2 years in both ADS and CDS conditions. Results reveal that CDS contains significantly more canonical cues to /t/ than ADS does, and fewer non-canonical cue patterns, including fewer unreleased tokens and fewer glottalized tokens in utterance-medial position. Also, we found larger aspiration duration differences in CDS between aspirated singleton [th] vs. unaspirated [t] in /st/ contexts, suggesting that mothers exaggerate this cue to the phonemic context in which the /t/ occurs. Overall, the findings suggest that CDS more clearly signals the phonemic category, which could in turn assist children learn the relationship between the underlying and surface forms.},
  file = {/Users/megcychosz/Zotero/storage/8LPAEQC7/Fritche et al. - 2021 - Do adults produce phonetic variants of t less of.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{fuchsRespiratoryFoundationsSpoken2021,
  title = {The {{Respiratory Foundations}} of {{Spoken Language}}},
  author = {Fuchs, Susanne and {Rochet-Capellan}, Am{\'e}lie},
  year = {2021},
  month = jan,
  volume = {7},
  pages = {-1314663915},
  issn = {2333-9683, 2333-9691},
  doi = {10.1146/annurev-linguistics-031720-103907},
  abstract = {Why is breathing relevant in linguistics? In this review, we approach this question from different perspectives. The most popular view is that breathing adapts to speech because respiratory behavior has astonishing flexibility. We review research that shows that breathing pauses occur mostly at meaningful places, that breathing adapts to cognitive load during speech perception, and that breathing adapts to communicative needs in dialogue. However, speech may also adapt to breathing (e.g., the larynx can compensate for air loss, breathing can partially affect f0 declination). Enhanced breathing control may have played a role in vocalization and language evolution. These views are not mutually exclusive but, rather, reveal that speech production and breathing have an interwoven relationship that depends on communicative and physical constraints. We suggest that breathing should become an important topic for different linguistic areas and that future work should investigate the interaction between breathing and speech in different situational contexts.},
  file = {/Users/megcychosz/Zotero/storage/55XVEM4C/Fuchs and Rochet-Capellan - 2021 - The Respiratory Foundations of Spoken Language.pdf},
  journal = {Annual Review of Linguistics},
  language = {en},
  number = {1}
}

@article{fungDevelopmentGenderedSpeech2021,
  title = {The Development of Gendered Speech in Children: {{Insights}} from Adult {{L1}} and {{L2}} Perceptions},
  shorttitle = {The Development of Gendered Speech in Children},
  author = {Fung, Priscilla and Schertz, Jessamyn and Johnson, Elizabeth K.},
  year = {2021},
  month = jan,
  volume = {1},
  pages = {014407},
  issn = {2691-1191},
  doi = {10.1121/10.0003322},
  abstract = {Past studies have shown that boys and girls sound distinct by 4 years old, long before sexual dimorphisms in vocal anatomy develop. These gender differences are thought to be learned within a particular speech community. However, no study has asked whether listeners' sensitivity to gender in child speech is modulated by language experience. This study shows that gendered speech emerges at 2.5 years old, and that L1 listeners outperform L2 listeners in detecting these differences. The findings highlight the role of language-specific sociolinguistic factors in both speech perception and production, and show that gendered speech emerges earlier than previously suggested. VC 2021 Author(s). All article content, except where otherwise noted, is licensed under a Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).},
  file = {/Users/megcychosz/Zotero/storage/6LMC6TJG/Fung et al. - 2021 - The development of gendered speech in children In.pdf},
  journal = {JASA Express Letters},
  language = {en},
  number = {1}
}

@article{furrowMothersSpeechChildren1979,
  title = {Mothers' Speech to Children and Syntactic Development: {{Some}} Simple Relationships},
  author = {Furrow, D. and Nelson, K and Benedict, H},
  year = {1979},
  volume = {6},
  pages = {423--442},
  file = {/Users/megcychosz/Zotero/storage/DGLYXQGD/Furrow et al. - 1979 - Mothers' speech to children and syntactic developm.pdf},
  journal = {Journal of Child Language}
}

@article{gagliardiStatisticalInsensitivityAcquisition2014,
  title = {Statistical Insensitivity in the Acquisition of {{Tsez}} Noun Classes},
  author = {Gagliardi, Annie and Lidz, Jeffrey},
  year = {2014},
  volume = {90},
  pages = {58--89},
  publisher = {{Linguistic Society of America}},
  issn = {0097-8507},
  abstract = {This article examines the acquisition of noun classes in Tsez, looking in particular at the role of noun-internal distributional cues to class. We present a new corpus of child-directed Tsez speech, analyzing it to determine the proportion of nouns that children hear with this predictive information and how often this is heard in conjunction with overt information about noun class agreement. Additionally, we present an elicited production experiment that uncovers asymmetries in the classification of nouns with versus without predictive features and by children versus adults. We show that children use noun-internal distributional information as a cue to noun class out of proportion with its reliability. Children are biased to use phonological over semantic information, despite a statistical asymmetry in the other direction. We end with a discussion of where such a bias could come from.},
  file = {/Users/megcychosz/Zotero/storage/BATLZ82C/Gagliardi and Lidz - 2014 - STATISTICAL INSENSITIVITY IN THE ACQUISITION OF TS.pdf},
  journal = {Language},
  number = {1}
}

@article{gahlBilingualismPurportedRisk2020,
  title = {Bilingualism as a {{Purported Risk Factor}} for {{Stuttering}}: {{A Close Look}} at a {{Seminal Study}} ({{Travis}} et al., 1937)},
  shorttitle = {Bilingualism as a {{Purported Risk Factor}} for {{Stuttering}}},
  author = {Gahl, Susanne},
  year = {2020},
  month = sep,
  pages = {1--5},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2020_JSLHR-20-00364},
  file = {/Users/megcychosz/Zotero/storage/E4DSPLUC/Gahl - 2020 - Bilingualism as a Purported Risk Factor for Stutte.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en}
}

@article{gahlKnowledgeGrammarKnowledge2004,
  title = {Knowledge of {{Grammar}}, {{Knowledge}} of {{Usage}}: {{Syntactic Probabilities Affect Pronunciation Variation}}},
  shorttitle = {Knowledge of {{Grammar}}, {{Knowledge}} of {{Usage}}},
  author = {Gahl, Susanne and Garnsey, Susan Marie},
  year = {2004},
  volume = {80},
  pages = {748--775},
  issn = {1535-0665},
  doi = {10.1353/lan.2004.0185},
  file = {/Users/megcychosz/Zotero/storage/K7XGJZ9V/Gahl and Garnsey - 2004 - Knowledge of Grammar, Knowledge of Usage Syntacti.pdf},
  journal = {Language},
  language = {en},
  number = {4}
}

@article{gahlTimeThymeAre2008,
  title = {Time and Thyme Are Not Homophones: {{The}} Effect of Lemma Frequency on Word Durations in Spontaneous Speech},
  shorttitle = {{\emph{Time}} and {{{\emph{Thyme}}}} {{Are}} Not {{Homophones}}},
  author = {Gahl, S.},
  year = {2008},
  volume = {84},
  pages = {474--496},
  issn = {1535-0665},
  doi = {10.1353/lan.0.0035},
  file = {/Users/megcychosz/Zotero/storage/3Y4EVRPM/Susanne Gahl - 2008 - iTimei and iThymei Are not Homophones T.pdf},
  journal = {Language},
  language = {en},
  number = {3}
}

@article{gahlWhyReducePhonological2012,
  title = {Why Reduce? {{Phonological}} Neighborhood Density and Phonetic Reduction in Spontaneous Speech},
  shorttitle = {Why Reduce?},
  author = {Gahl, Susanne and Yao, Yao and Johnson, Keith},
  year = {2012},
  month = may,
  volume = {66},
  pages = {789--806},
  issn = {0749596X},
  doi = {10.1016/j.jml.2011.11.006},
  abstract = {Frequent or contextually predictable words are often phonetically reduced, i.e. shortened and produced with articulatory undershoot. Explanations for phonetic reduction of predictable forms tend to take one of two approaches: Intelligibility-based accounts hold that talkers maximize intelligibility of words that might otherwise be difficult to recognize; production-based accounts hold that variation reflects the speed of lexical access and retrieval in the language production system. Here we examine phonetic variation as a function of phonological neighborhood density, capitalizing on the fact that words from dense phonological neighborhoods tend to be relatively difficult to recognize, yet easy to produce. We show that words with many phonological neighbors tend to be phonetically reduced (shortened in duration and produced with more centralized vowels) in connected speech, when other predictors of phonetic variation are brought under statistical control. We argue that our findings are consistent with the predictions of production-based accounts of pronunciation variation.},
  file = {/Users/megcychosz/Zotero/storage/W5VPWT5H/Gahl et al. - 2012 - Why reduce Phonological neighborhood density and .pdf},
  journal = {Journal of Memory and Language},
  language = {en},
  number = {4}
}

@article{gallagherIdentityBiasPhonotactics2014,
  title = {An Identity Bias in Phonotactics: {{Evidence}} from {{Cochabamba Quechua}}},
  shorttitle = {An Identity Bias in Phonotactics},
  author = {Gallagher, Gillian},
  year = {2014},
  month = jan,
  volume = {5},
  issn = {1868-6354, 1868-6346},
  doi = {10.1515/lp-2014-0012},
  abstract = {Speakers of Cochabamba Quechua (CQ) participated in two tasks involving phonotactically illegal nonce forms with pairs of identical (e.g., [p'ap'u) and non-identical ejectives (e.g., [k'ap'u]). In a repetition task, speakers were more accurate on identical than non-identical ejective pairs, though no asymmetry was found an ABX discrimination task, nor in acoustic analysis of nonce roots with identical and non-identical ejective pairs. The latent preference for identical ejectives is unexpected given the phonotactics of CQ, which categorically disallows both identical and non-identical ejective pairs. The asymmetry is in accord with the typology, however. Many languages systematically exempt identical segments from a phonotactic restriction that applies to non-identical segments. It is argued that this cross-linguistic identity preference has its roots in a synchronic bias in favor of identical segments.},
  file = {/Users/megcychosz/Zotero/storage/KH3BVMLE/Gallagher - 2014 - An identity bias in phonotactics Evidence from Co.pdf},
  journal = {Laboratory Phonology},
  language = {en},
  number = {3}
}

@article{gallagherVowelHeightAllophony2016,
  title = {Vowel Height Allophony and Dorsal Place Contrasts in {{Cochabamba Quechua}}},
  author = {Gallagher, Gillian},
  year = {2016},
  volume = {73},
  pages = {101--119},
  abstract = {This paper reports on the results of two studies investigating vowel height allophony triggered by uvular stops in Cochabamba Quechua. An acoustic study documents the lowering effect of a preceding tautomorphemic or a following heteromorphemic uvular on the high vowels /i u/. A discrimination study finds that vowel height is a significant cue to the velar-uvular place contrast.},
  file = {/Users/megcychosz/Zotero/storage/5RBVYTEL/Vowel height allophony and dorsal place contrsats in Cochabamba Quechua.pdf},
  journal = {Phonetica},
  number = {2}
}

@article{ganekConciseProtocolValidation2018,
  title = {A {{Concise Protocol}} for the {{Validation}} of {{Language ENvironment Analysis}} ({{LENA}}) {{Conversational Turn Counts}} in {{Vietnamese}}},
  author = {Ganek, Hillary V. and {Eriks-Brophy}, Alice},
  year = {2018},
  month = feb,
  volume = {39},
  pages = {371--380},
  issn = {1525-7401, 1538-4837},
  doi = {10.1177/1525740117705094},
  abstract = {The aim of this study was to present a protocol for the validation of the Language ENvironment Analysis (LENA) System's conversational turn count (CTC) for Vietnamese speakers. Ten families of children aged between 22 and 42 months, recruited near Ho Chi Minh City, participated in this project. Each child wore the LENA audio recorder for a full day. Two native speakers listened to 10-min extracts of the recordings from each family and labeled conversational turns according to the coding protocol. Their results were compared with the findings from the LENA software. A Spearman rank correlation test indicated a strong level of correlation between the LENA software and the human coders, r (18) = .70, p {$<$} .001. The LENA System's CTC provides a reasonably s accurate estimate of conversational turns in Vietnamese recordings, showing that this protocol can yield significant results. Discrepancies between the coders and the software are discussed, and the strengths and weaknesses of the proposed protocol are highlighted.},
  file = {/Users/megcychosz/Zotero/storage/U9349D6N/A Concise Protocol for the Validation of Language .pdf},
  journal = {Communication Disorders Quarterly},
  language = {en},
  number = {2}
}

@article{ganekLanguageENvironmentAnalysis2016,
  title = {The {{Language ENvironment Analysis}} ({{LENA}}) {{System}}:},
  author = {Ganek, Hillary and Eriks, Alice},
  year = {2016},
  pages = {9},
  abstract = {The Language ENvironment Analysis (LENA) System is a relatively new recording technology that can be used to investigate typical child language acquisition and populations with language disorders. The purpose of this paper is to familiarize language acquisition researchers and speech-language pathologists with how the LENA System is currently being used in research. The authors outline issues in peer-reviewed research based on the device. Considerations when using the LENA System are discussed.},
  file = {/Users/megcychosz/Zotero/storage/JQE78BD8/Ganek and Eriks - 2016 - The Language ENvironment Analysis (LENA) System.pdf},
  language = {en}
}

@article{ganekUsingLanguageENvironment2018,
  title = {Using the {{Language ENvironment Analysis}} ({{LENA}}) {{System}} to {{Investigate Cultural Differences}} in {{Conversational Turn Count}}},
  author = {Ganek, Hillary and Smyth, Ron and Nixon, Stephanie and {Eriks-Brophy}, Alice},
  year = {2018},
  month = sep,
  volume = {61},
  pages = {2246--2258},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2018_JSLHR-L-17-0370},
  file = {/Users/megcychosz/Zotero/storage/YXQNAXAK/Ganek et al. - 2018 - Using the Language ENvironment Analysis (LENA) Sys.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {9}
}

@article{garcia-sierraRelationshipsQuantityLanguage2016,
  title = {Relationships between Quantity of Language Input and Brain Responses in Bilingual and Monolingual Infants},
  author = {{Garcia-Sierra}, Adrian and {Ram{\'i}rez-Esparza}, Nairan and Kuhl, Patricia K.},
  year = {2016},
  month = dec,
  volume = {110},
  pages = {1--17},
  issn = {01678760},
  doi = {10.1016/j.ijpsycho.2016.10.004},
  abstract = {The present investigation explored the relation between the amount of language input and neural responses in English monolingual (N = 18) and Spanish-English bilingual (N = 19) infants. We examined the mismatch negativity (MMN); both the positive mismatch response (pMMR) and the negative mismatch response (nMMR), and identify a relationship between amount of language input and brain measures of speech discrimination for native and non-native speech sounds (i.e., Spanish, English and Chinese). Brain responses differed as a function of language input for native speech sounds in both monolinguals and bilinguals. Monolingual infants with high language input showed nMMRs to their native English contrast. Bilingual infants with high language input in Spanish and English showed pMMRs to both their native contrasts. The non-native speech contrast showed different patterns of brain activation for monolinguals and bilinguals regardless of amount of language input. Our results indicate that phonological representations of non-native speech sounds in bilingual infants are dependent on the phonetic similarities between their native languages.},
  file = {/Users/megcychosz/Zotero/storage/RFDJ7KM3/Garcia-Sierra et al. - 2016 - Relationships between quantity of language input a.pdf},
  journal = {International Journal of Psychophysiology},
  language = {en}
}

@incollection{gaskinsCulturalPerspectivesInfantcaregiver2006,
  title = {Cultural Perspectives on Infant-Caregiver Interaction},
  booktitle = {Roots of Human Sociality: {{Culture}}, Cognition, and Interaction},
  author = {Gaskins, Suzanne},
  editor = {Enfield, N. J. and Levinson, S.},
  year = {2006},
  pages = {279--298},
  publisher = {{Berg}},
  address = {{Oxford, New York}},
  file = {/Users/megcychosz/Zotero/storage/SCG7QX3K/gaskins2006cultural.pdf}
}

@article{gathercoleBilingualFirstlanguageDevelopment2009,
  title = {Bilingual First-Language Development: {{Dominant}} Language Takeover, Threatened Minority Language Take-Up},
  shorttitle = {Bilingual First-Language Development},
  author = {Gathercole, Virginia C. Mueller and Thomas, Enlli M{\^o}n},
  year = {2009},
  month = apr,
  volume = {12},
  pages = {213--237},
  issn = {1366-7289, 1469-1841},
  doi = {10.1017/S1366728909004015},
  abstract = {This study explores the extent to which bilingual speakers in stable bilingual communities become fully bilingual in their two community languages. Growing evidence shows that in bilingual communities in which one language is very dominant, acquisition of the dominant language may be quite unproblematic across sub-groups, while acquisition of the minority language can be hampered under conditions of reduced input. In Wales, children are exposed to both English and Welsh from an early age, either in the home or at school, or both. The data reported here indicate that regardless of home language background, speakers develop equivalent, mature command of English, but that command of Welsh is directly correlated with the level of input in Welsh in the home and at school. Furthermore, maintenance of Welsh in adulthood may be contingent on continued exposure to the language. The data have implications for theories of bilingual acquisition in stable versus immigrant bilingual communities, for optimal conditions for bringing up bilingual children, and for theories of critical periods of acquisition.},
  file = {/Users/megcychosz/Zotero/storage/S78GN5KK/Gathercole and Thomas - 2009 - Bilingual first-language development Dominant lan.pdf},
  journal = {Bilingualism: Language and Cognition},
  language = {en},
  number = {2}
}

@article{gathercoleEvaluationRolePhonological1989a,
  title = {Evaluation of the Role of Phonological {{STM}} in the Development of Vocabulary in Children: {{A}} Longitudinal Study},
  author = {Gathercole, Susan E. and Baddeley, Alan D.},
  year = {1989},
  volume = {28},
  pages = {200--213},
  file = {/Users/megcychosz/Zotero/storage/2ZDCKTVJ/1437996.pdf},
  journal = {Journal of Memory and Language},
  number = {2}
}

@article{gathercoleInfluencesNumberSyllables1991b,
  title = {The Influences of Number of Syllables and Wordlikeness on Children's Repetition of Nonwords},
  author = {Gathercole, Susan E. and Willis, Cath and Emslie, Hazel and Baddeley, Alan D.},
  year = {1991},
  month = sep,
  volume = {12},
  pages = {349--367},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716400009267},
  abstract = {It has recently been suggested that the developmental association between nonword repetition performance and vocabulary knowledge reflects the contribution of phonological memory processes to vocabulary acquisition (e.g., Gathercole \& Baddeley, 1989). An alternative account of the association is that the child uses existing vocabulary knowledge to support memory for nonwords. The present article tests between these two alternative accounts by evaluating the role of phonological memory and linguistic factors in nonword repetition. In a longitudinal database, repetition accuracy in 4-, 5-, and 6-year-olds was found to be sensitive to two independent factors: a phonological memory factor, nonword length, and a linguistic factor, wordlikeness. To explain these combined influences, it is suggested that repeating nonwords involves temporary phonological memory storage which may be supported by either a specific lexical analogy or by an appropriate abstract phonological frame generated from structurally similar vocabulary items.},
  file = {/Users/megcychosz/Zotero/storage/CYCMNKB2/Gathercole et al. - 1991 - The influences of number of syllables and wordlike.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {3}
}

@article{gathercoleNonwordRepetitionWord2006,
  title = {Nonword Repetition and Word Learning: {{The}} Nature of the Relationship},
  shorttitle = {Nonword Repetition and Word Learning},
  author = {Gathercole, Susan E.},
  year = {2006},
  month = oct,
  volume = {27},
  pages = {513--543},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716406060383},
  abstract = {This article presents a theoretical framework designed to accommodate core evidence that the abilities to repeat nonwords and to learn the phonological forms of new words are closely linked. Basic findings relating nonword repetition and word learning both in typical samples of children and adults and in individuals with disorders of language learning are described. The theoretical analysis of this evidence is organized around the following claims: first, that nonword repetition and word learning both rely on phonological storage; second, that they are both multiply determined, constrained also by auditory, phonological, and speech\textendash motor output processes; third, that a phonological storage deficit alone may not be sufficient to impair language learning to a substantial degree. It is concluded that word learning mediated by temporary phonological storage is a primitive learning mechanism that is particularly important in the early stages of acquiring a language, but remains available to support word learning across the life span.},
  file = {/Users/megcychosz/Zotero/storage/6D58PVTM/Gathercole - 2006 - Nonword repetition and word learning The nature o.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {4}
}

@article{gaudrainDiscriminationVoicePitch2018,
  title = {Discrimination of {{Voice Pitch}} and {{Vocal}}-{{Tract Length}} in {{Cochlear Implant Users}}},
  author = {Gaudrain, Etienne and Ba{\c s}kent, Deniz},
  year = {2018},
  month = mar,
  volume = {39},
  pages = {226--237},
  issn = {0196-0202},
  doi = {10.1097/AUD.0000000000000480},
  abstract = {Objectives: When listening to two competing speakers, normal-hearing (NH) listeners can take advantage of voice differences between the speakers. Users of cochlear implants (CIs) have difficulty in perceiving speech on speech. Previous literature has indicated sensitivity to voice pitch (related to fundamental frequency, F0) to be poor among implant users, while sensitivity to vocal-tract length (VTL; related to the height of the speaker and formant frequencies), the other principal voice characteristic, has not been directly investigated in CIs. A few recent studies evaluated F0 and VTL perception indirectly, through voice gender categorization, which relies on perception of both voice cues. These studies revealed that, contrary to prior literature, CI users seem to rely exclusively on F0 while not utilizing VTL to perform this task. The objective of the present study was to directly and systematically assess raw sensitivity to F0 and VTL differences in CI users to define the extent of the deficit in voice perception. Design: The just-noticeable differences (JNDs) for F0 and VTL were measured in 11 CI listeners using triplets of consonant\textendash vowel syllables in an adaptive three-alternative forced choice method. Results: The results showed that while NH listeners had average JNDs of 1.95 and 1.73 semitones (st) for F0 and VTL, respectively, CI listeners showed JNDs of 9.19 and 7.19 st. These JNDs correspond to differences of 70\% in F0 and 52\% in VTL. For comparison to the natural range of voices in the population, the F0 JND in CIs remains smaller than the typical male\textendash female F0 difference. However, the average VTL JND in CIs is about twice as large as the typical male\textendash female VTL difference. Conclusions: These findings, thus, directly confirm that CI listeners do not seem to have sufficient access to VTL cues, likely as a result of limited spectral resolution, and, hence, that CI listeners' voice perception deficit goes beyond poor perception of F0. These results provide a potential common explanation not only for a number of deficits observed in CI listeners, such as voice identification and gender categorization, but also for competing speech perception.},
  file = {/Users/megcychosz/Zotero/storage/P88DUP7X/Gaudrain and Başkent - 2018 - Discrimination of Voice Pitch and Vocal-Tract Leng.pdf},
  journal = {Ear and Hearing},
  number = {2},
  pmcid = {PMC5839701},
  pmid = {28799983}
}

@book{gavrilovNormtestTestsNormality2014,
  title = {Normtest: {{Tests}} for {{Normality}}},
  author = {Gavrilov, Ilya and Pusev, Ruslan},
  year = {2014}
}

@article{gayEffectSpeakingRate1978,
  title = {Effect of Speaking Rate on Vowel Formant Movements},
  author = {Gay, Thomas},
  year = {1978},
  volume = {63},
  pages = {223--230},
  file = {/Users/megcychosz/Zotero/storage/BPDYSDMQ/Gay - Effect of speaking rate on vowel formant movements.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{gayMechanismsControlSpeech1981,
  title = {Mechanisms in the Control of Speech Rate},
  author = {Gay, Thomas},
  year = {1981},
  volume = {38},
  pages = {148--158},
  file = {/Users/megcychosz/Zotero/storage/Z5P73AXE/260020.pdf},
  journal = {Phonetica}
}

@article{geersEnduringAdvantagesEarly2013,
  title = {Enduring {{Advantages}} of {{Early Cochlear Implantation}} for {{Spoken Language Development}}},
  author = {Geers, Ann E. and Nicholas, Johanna G.},
  year = {2013},
  month = apr,
  volume = {56},
  pages = {643--655},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2012/11-0347)},
  abstract = {Purpose\textemdash To determine whether the precise age of implantation (AOI) remains an important predictor of spoken language outcomes in later childhood for those who received a cochlear implant (CI) between 12\textendash 38 months of age. Relative advantages of receiving a bilateral CI after age 4.5, better pre-CI aided hearing, and longer CI experience were also examined. Method\textemdash Sixty children participated in a prospective longitudinal study of outcomes at 4.5 and 10.5 years of age. Twenty-nine children received a sequential second CI. Test scores were compared to normative samples of hearing age-mates and predictors of outcomes identified. Results\textemdash Standard scores on language tests at 10.5 years of age remained significantly correlated with age of first cochlear implantation. Scores were not associated with receipt of a second, sequentially-acquired CI. Significantly higher scores were achieved for vocabulary as compared with overall language, a finding not evident when the children were tested at younger ages. Conclusion\textemdash Age-appropriate spoken language skills continued to be more likely with younger AOI, even after an average of 8.6 years of additional CI use. Receipt of a second implant between ages 4\textendash 10 years and longer duration of device use did not provide significant added benefit.},
  file = {/Users/megcychosz/Zotero/storage/PUUEG557/Geers and Nicholas - 2013 - Enduring Advantages of Early Cochlear Implantation.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {2}
}

@inproceedings{gerosaAnalyzingChildrenSpeech2006,
  title = {Analyzing Children's Speech: {{An}} Acoustic Study of Consonants and Consonant-Vowel Transition},
  booktitle = {2006 {{IEEE International Conference}} on {{Acoustics Speed}} and {{Signal Processing Proceedings}}},
  author = {Gerosa, M. and Lee, S. and Giuliani, D. and Narayanan, S.},
  year = {2006},
  volume = {1},
  pages = {393--396},
  publisher = {{IEEE}},
  address = {{Toulouse, France}},
  doi = {10.1109/ICASSP.2006.1660040},
  abstract = {This paper presents several acoustic analyses on read speech, collected from 5 adults and 35 children aged 5 to 17 years, focusing on consonants and consonant-vowel transition. Characteristics of consonants such as duration, intra-speaker variability and, for stop consonants, voice onset time are analyzed and compared with results achieved on vowels.},
  file = {/Users/megcychosz/Zotero/storage/FABWJNRG/Gerosa et al. - 2006 - Analyzing Children's Speech An Acoustic Study of .pdf},
  isbn = {978-1-4244-0469-8},
  language = {en}
}

@article{gierutMarkednessGrammarLexical2002,
  title = {Markedness and the Grammar in Lexical Diffusion of Fricatives},
  author = {Gierut, Judith A. and Storkel, Holly L.},
  year = {2002},
  month = jan,
  volume = {16},
  pages = {115--134},
  issn = {0269-9206, 1464-5076},
  doi = {10.1080/0269920011011287},
  abstract = {This paper examines the contributions of markedness and a child's grammar to the process of lexical di\OE usion in phonological acquisition. Archival data from 19 preschoolers with functional phonological delays were submitted to descriptive analyses of productive sound change in fricatives. Children's presenting fricative inventory, the fricatives newly learned, and their position of occurrence were varied, with word frequency and neighbourhood density measured. Results indicated that lexical di\OE usion of fricatives occurred di\OE erentially by word position. Positional, featural and structural markedness further converged such that change in unmarked structure of any type was implemented in low frequency words. A child's presenting fricative inventory was not directly a liated with systematic patterns of di\OE usion. These results have clinical applications for the evaluation of productive sound change and theoretical implications for deterministic models of lexical di\OE usion and processing models of word recognition.},
  file = {/Users/megcychosz/Zotero/storage/IH74FBWG/Gierut and Storkel - 2002 - Markedness and the grammar in lexical diffusion of.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {2}
}

@article{gildersleeve-neumannSyllabicPatternsEarly2013,
  title = {Syllabic Patterns in the Early Vocalizations of {{Quichua}} Children},
  author = {{Gildersleeve-Neumann}, Christina E. and Davis, Barbara L. and Macneilage, Peter F.},
  year = {2013},
  month = jan,
  volume = {34},
  pages = {111--134},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716411000634},
  abstract = {To understand the interactions between production patterns common to children regardless of language environment and the early appearance of production effects based on perceptual learning from the ambient language requires the study of languages with diverse phonological properties. Few studies have evaluated early phonological acquisition patterns of children in non-Indo-European language environments. In the current study, across- and within-syllable consonant\textendash vowel co-occurrence patterns in babbling were analyzed for a 6-month period for seven Ecuadorean Quichua learning children who were between 9 and 17 months of age at study onset. Their babbling utterances were compared to the babbling of six English-learning children between 9 and 22 months of age. Child patterns for both languages were compared with Quichua and English ambient language patterns. Babbling output was highly similar for the child groups: Quichua and English children's babbling demonstrated similar predicted within-syllable (coronal-front vowel, labial-central vowel, dorsal-back vowel) patterns, and across-syllable manner variegation patterns for consonants. These patterns were observed at significantly greater rates in the child groups than in the respective adult language input patterns, suggesting production system influences common to children across languages rather than ambient language perceptual learning effects during these children's babbling period.},
  file = {/Users/megcychosz/Zotero/storage/9NUCBLE3/Gildersleeve-Neumann et al. - 2013 - Syllabic patterns in the early vocalizations of Qu.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {1}
}

@article{gilkersonEvaluationLENABasedOnline2017,
  title = {Evaluation of a {{LENA}}-{{Based Online Intervention}} for {{Parents}} of {{Young Children}}},
  author = {Gilkerson, Jill and Richards, Jeffrey A. and Topping, Keith},
  year = {2017},
  month = dec,
  volume = {39},
  pages = {281--298},
  issn = {1053-8151, 2154-3992},
  doi = {10.1177/1053815117718490},
  abstract = {The efficacy of a pilot version of an online parent intervention that combined Language ENvironment Analysis (LENA)\textendash based automated language environment feedback technology with Internet capabilities was investigated. Seventy-two parents of typically developing children aged 9 to 21 months were assigned to immediate- or delayed-treatment (control) conditions. During the treatment phase, parents completed 10 recordings over a 3-month period while engaging in a web-based program supporting interpretation of LENA feedback reports and strategies for increasing talk and interaction. Parents completed additional recordings and language assessments over a 9-month follow-up phase. Aggregate analyses found no differences in language behaviors between immediate-treatment versus delayed-treatment groups. However, parents who started from below average ratings on automated language measures demonstrated significant postintervention increases which held longitudinally. Importantly, participant children showed significant elevations in language ability. Results suggest that an online intervention approach can help some parents increase talk and interaction in the home. Implications for research and clinical practice are discussed.},
  file = {/Users/megcychosz/Zotero/storage/7P3PYAAZ/Gilkerson et al. - 2017 - Evaluation of a LENA-Based Online Intervention for.pdf},
  journal = {Journal of Early Intervention},
  language = {en},
  number = {4}
}

@book{gilkersonImpactAdultTalk2009,
  title = {Impact of {{Adult Talk}}, {{Conversational Turns}}, and {{TV During}} the {{Critical}} 0-4 {{Years}} of {{Child Development}}},
  author = {Gilkerson, Jill and Richards, J.},
  year = {2009},
  edition = {2nd Edition},
  file = {/Users/megcychosz/Zotero/storage/KPTGW5UU/Gilkerson - Impact of Adult Talk, Conversational Turns, and TV.pdf},
  language = {en},
  number = {ITR-01-2},
  series = {{{LENA Foundation Technical Report}}}
}

@article{gilkersonLENANaturalLanguage2008,
  title = {The {{LENA Natural Language Study}}},
  author = {Gilkerson, Jill and Richards, Jeffrey A},
  year = {2008},
  pages = {26},
  file = {/Users/megcychosz/Zotero/storage/C7KA8S9E/Gilkerson and Richards - 2008 - The LENA Natural Language Study.pdf},
  language = {en}
}

@article{glasActivityTypesChilddirected2018,
  title = {Activity Types and Child-Directed Speech: A Comparison between {{French}}, {{Tunisian Arabic}} and {{English}}},
  shorttitle = {Activity Types and Child-Directed Speech},
  author = {Glas, Ludivine and Rossi, Caroline and {Hamdi-Sultan}, Rim and Batailler, C{\'e}dric and Bellemmouche, Hacene},
  year = {2018},
  month = dec,
  volume = {63},
  pages = {633--666},
  issn = {0008-4131, 1710-1115},
  doi = {10.1017/cnj.2018.20},
  abstract = {Abstract             Quantity and quality of input affect language development, but input features also depend on the context of language emission. Previous research has described mother-child interactions and their impact on language development according to activity types like mealtimes, book reading, and free play. Nevertheless, few studies have sought to quantify activity types in naturalistic datasets including less-studied languages and cultures. Our research questions are the following: we ask whether regularities emerge in the distribution of activity types across languages and recordings, and whether activities have an impact on mothers' linguistic productions. We analyse input for two children per language, at three developmental levels. We distinguish three activity types: solitary, social and maintenance activities, and measure mothers' linguistic productions within each type. Video-recorded activities differ across families and developmental levels. Linguistic features of child-directed speech (CDS) also vary across activities \textendash{} notably for measures of diversity and complexity \textendash{} which points to complex interactions between activity and language.           ,              R\'esum\'e             La quantit\'e et la qualit\'e de l'input ont un impact sur le d\'eveloppement du langage, mais certaines caract\'eristiques de l'input d\'ependent aussi du contexte situationnel, autrement dit du type d'activit\'e, dans lequel les \'enonc\'es sont produits. Certains travaux ont d\'ecrit l'impact des interactions m\`ere-enfant sur le d\'eveloppement du langage en fonction du type d'activit\'e comme les repas, la lecture ou le jeu libre. Cependant, tr\`es peu de travaux ont cherch\'e \`a quantifier la r\'epartition des diff\'erents types d'activit\'es dans des suivis longitudinaux, en int\'egrant des langues moins souvent \'etudi\'ees. Nos questions de recherche sont les suivantes : le codage par types d'activit\'es r\'ev\`elera-t-il des r\'egularit\'es ind\'ependantes des langues et des enregistrements, et les types d'activit\'es observ\'es ont-ils un impact sur le langage adress\'e \`a l'enfant (LAE) ? Les enregistrements analys\'es concernent l'input de deux enfants par langue (tunisien, anglais am\'ericain et fran\c{c}ais), \`a trois \'etapes d\'eveloppementales. Nous distinguons trois types d'activit\'es : les activit\'es sociales, solitaires et de maintenance, et les productions des m\`eres sont mesur\'ees au sein de chaque type. Les activit\'es enregistr\'ees varient d'une famille \`a l'autre, et \`a chaque \'etape d\'eveloppementale. Des variations du LAE sont \'egalement observ\'ees d'un type d'activit\'e \`a l'autre : elles concernent la diversit\'e et la complexit\'e mesur\'ees, et sugg\`erent qu'il n'existe pas de lien univoque entre type d'activit\'e et caract\'eristique de l'input.},
  file = {/Users/megcychosz/Zotero/storage/6GBSI9AD/Glas et al. - 2018 - Activity types and child-directed speech a compar.pdf},
  journal = {Canadian Journal of Linguistics/Revue canadienne de linguistique},
  language = {en},
  number = {4}
}

@article{glazeAcousticCharacteristicsChildren1988,
  title = {Acoustic Characteristics of Children's Voice},
  author = {Glaze, Leslie E. and Bless, Diane M. and Milenkovic, Paul and Susser, Robin D.},
  year = {1988},
  volume = {2},
  pages = {312--319},
  issn = {08921997},
  doi = {10.1016/S0892-1997(88)80023-7},
  abstract = {F o u r acoustic measures were taken from voice recordings of 121 children between the ages of 64 and 134 months.'Acoustic parameters were measured on a sustained neutral /aJ vowel, produced imitatively at normal pitch and loudness. Samples were analyzed for fundamental frequency, jitter, shimmer, and signal-to-noise ratio (SNR). Data are presented to characterize effects of age, sex, height, and weight on these acoustic parameters. Results indicate statistically significant relationships between frequency and sex, with higher frequencies for girls. Also significant is a positive relationship between shimmer and height and a negative relationship between SNR and height. Key Words: Fundamental frequency--Jitter--Shimmer--Signal-to-noise ratio--Children--Acoustic analysis--Voice.},
  file = {/Users/megcychosz/Zotero/storage/KWKUHKDJ/Glaze et al. - 1988 - Acoustic characteristics of children's voice.pdf},
  journal = {Journal of Voice},
  language = {en},
  number = {4}
}

@article{gleitmanStructuralSourcesVerb1990,
  title = {The {{Structural Sources}} of {{Verb Meanings}}},
  author = {Gleitman, Lila},
  year = {1990},
  volume = {1},
  pages = {3--55},
  file = {/Users/megcychosz/Zotero/storage/AAV8VTDP/Gleitman - The Structural Sources of Verb Meanings.pdf},
  journal = {Language Acquisition},
  language = {en},
  number = {1}
}

@incollection{gleitmanWhereLearningBegins1988,
  title = {Where Learning Begins: {{Initial}} Representations for Language Learning.},
  booktitle = {Linguistics: {{The Cambridge Survey}}: {{Volume}} 3, {{Language}}: {{Psychological}} and {{Biological Aspects}}},
  author = {Gleitman, Lila R and Gleitman, H. and Landau, B. and Wanner, E. and Newmeyer, F.},
  editor = {Newmeyer, F. J.},
  year = {1988},
  pages = {150--193},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, MA}}
}

@article{goffmanBreadthCoarticulatoryUnits2008,
  title = {The {{Breadth}} of {{Coarticulatory Units}} in {{Children}} and {{Adults}}},
  author = {Goffman, Lisa and Smith, Anne and Heisler, Lori and Ho, Michael},
  year = {2008},
  volume = {51},
  pages = {1424--1437},
  issn = {1092-4388},
  doi = {10.1044/1092-4388(2008/07-0020)},
  abstract = {Purpose\textemdash To assess, in children and adults, the breadth of coarticulatory movements associated with a single rounded vowel. Method\textemdash Upper and lower lip movements were recorded from 8 young adults and 8 children (aged 4\textendash 5 years). A single rounded versus unrounded vowel was embedded in the medial position of pairs of 7-word/7-syllable sentences. Results\textemdash Both children and adults produced movement trajectories associated with lip rounding that were very broad temporally (i.e., movement duration lasting 45\% to 56\% of the sentence). Some effects appeared to extend across the entire utterance. There were no differences between children and adults in the extent of the coarticulatory effect. However, children produced relatively variable movements associated with lip rounding. Conclusions\textemdash These data support the hypothesis that, for young children and adults, broad chunks of output have been planned by the onset of implementation of a sentence. This implies that, based on a change in a single phoneme, the motor commands to the muscles are altered for the production of the entire sentence.},
  file = {/Users/megcychosz/Zotero/storage/E2B5UYLI/Goffman et al. - 2008 - The Breadth of Coarticulatory Units in Children an.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {6}
}

@article{goffmanRelationsSegmentalMotor2007,
  title = {Relations {{Between Segmental}} and {{Motor Variability}} in {{Prosodically Complex Nonword Sequences}}},
  author = {Goffman, Lisa and Gerken, LouAnn and Lucchesi, Julie},
  year = {2007},
  month = apr,
  volume = {50},
  pages = {444--458},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2007/031)},
  abstract = {Purpose: To assess how prosodic prominence and hierarchical foot structure influence segmental and articulatory aspects of speech production, specifically segmental accuracy and variability, and oral movement trajectory variability. Method: Thirty individuals participated: 10 young adults, 10 children who are normally developing, and 10 children diagnosed with specific language impairment. Segmental error and segmental variability and movement trajectory variability were compared in low and high prosodic prominence conditions (i.e., strong and weak syllables) and in different prosodic foot structures. Results: Between-participants findings were that both groups of children showed more segmental error and segmental variability and more movement trajectory variability than did adults. A similar within-participant pattern of results was observed for all 3 groups. Prosodic prominence influenced both segmental and motor levels of analysis, with weak syllables produced less accurately and with more lip and jaw movement trajectory variability than strong syllables. However, hierarchical foot structure affected segmental but not motor measures of speech production accuracy and variability. Conclusions: Motor and segmental variables were not consistently aligned. This pattern of results has clinical implication because inferences about motor variability may not directly follow from observations of segmental variability.},
  file = {/Users/megcychosz/Zotero/storage/A7K2YMGV/Goffman et al. - 2007 - Relations Between Segmental and Motor Variability .pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {2}
}

@article{goldin-meadowSpontaneousSignSystems1998,
  title = {Spontaneous Sign Systems Created by Deaf Children in Two Cultures},
  author = {{Goldin-Meadow}, Susan and Mylander, Carolyn},
  year = {1998},
  month = jan,
  volume = {391},
  pages = {279--281},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/34646},
  file = {/Users/megcychosz/Zotero/storage/P43LGRDN/Goldin-Meadow and Mylander - 1998 - Spontaneous sign systems created by deaf children .pdf},
  journal = {Nature},
  language = {en},
  number = {6664}
}

@article{goldingerPuzzlesolvingScienceQuixotic2003,
  title = {Puzzle-Solving Science: The Quixotic Quest for Units in Speech Perception},
  shorttitle = {Puzzle-Solving Science},
  author = {Goldinger, Stephen D. and Azuma, Tamiko},
  year = {2003},
  month = jul,
  volume = {31},
  pages = {305--320},
  issn = {00954470},
  doi = {10.1016/S0095-4470(03)00030-5},
  abstract = {Although speech signals are continuous and variable, listeners experience segmentation and linguistic structure in perception. For years, researchers have tried to identify the basic buildingblock of speech perception. In that time, experimental methods have evolved, constraints on stimulus materials have evolved, sources of variance have been identified, and computational models have been advanced. As a result, the slate of candidate units has increased, each with its own empirical support. In this article, we endorse Grossberg's adaptive resonance theory (ART), proposing that speech units are emergent properties of perceptual dynamics. By this view, units only ``exist'' when disparate features achieve resonance, a level of perceptual coherence that allows conscious encoding. We outline basic principles of ART, then summarize five experiments. Three experiments assessed the power of social influence to affect phoneme-syllable competitions. Two other experiments assessed repetition effects in monitoring data. Together the data suggest that ``primary'' speech units are strongly and symmetrically affected by bottom-up and top-down knowledge sources.},
  file = {/Users/megcychosz/Zotero/storage/YUUD5SSZ/Goldinger and Azuma - 2003 - Puzzle-solving science the quixotic quest for uni.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {3-4}
}

@article{goldingerWordsVoicesEpisodic,
  title = {Words and {{Voices}}: {{Episodic Traces}} in {{Spoken Word Identification}} and {{Recognition Memory}}},
  author = {Goldinger, Stephen D},
  pages = {18},
  file = {/Users/megcychosz/Zotero/storage/LGRED646/Goldinger - Words and Voices Episodic Traces in Spoken Word I.pdf},
  language = {en}
}

@book{goldmanGFTA3GoldmanFristoe2015,
  title = {{{GFTA}}-3: {{Goldman Fristoe}} 3 {{Test}} of {{Articulation}}},
  author = {Goldman, Ronald and Fristoe, Macalyne},
  year = {2015},
  edition = {Third},
  publisher = {{Pearson Assessments}},
  address = {{Bloomington, MN}}
}

@book{goldmanGoldmanFristoeTestArticulationSecond2000,
  title = {Goldman-{{Fristoe Test}} of {{Articulation}}-{{Second Edition}} ({{GFTA}}-2)},
  author = {Goldman, Ronald and Fristoe, Macalyne},
  year = {2000},
  edition = {Second},
  publisher = {{American Guidance Service}},
  address = {{Circle Pines, MN}}
}

@article{goldrickPhonotacticProbabilityInfluences2008,
  title = {Phonotactic Probability Influences Speech Production},
  author = {Goldrick, Matthew and Larson, Meredith},
  year = {2008},
  month = jun,
  volume = {107},
  pages = {1155--1164},
  issn = {00100277},
  doi = {10.1016/j.cognition.2007.11.009},
  abstract = {Speakers are faster and more accurate at processing certain sound sequences within their language. Does this reflect the fact that these sequences are frequent or that they are phonetically less complex (e.g., easier to articulate)? It has been difficult to contrast these two factors given their high correlation in natural languages. In this study, participants were exposed to novel phonotactic constraints de-correlating complexity and frequency by subjecting the same phonological structure to varying degrees of probabilistic constraint. Participants' behavior was sensitive to variations in frequency, demonstrating that phonotactic probability influences speech production independent of phonetic complexity.},
  file = {/Users/megcychosz/Zotero/storage/UI85TI8A/Goldrick and Larson - 2008 - Phonotactic probability influences speech producti.pdf},
  journal = {Cognition},
  language = {en},
  number = {3}
}

@book{goldsteinArticulatoryModelVocal1980,
  title = {An Articulatory Model for the Vocal Tracts of Growing Children},
  author = {Goldstein, U. G.},
  year = {1980},
  publisher = {{MIT}},
  series = {Unpublished Doctoral Dissertation}
}

@article{goldsteinEffectsMeasuresLanguage2010,
  title = {The {{Effects}} of {{Measures}} of {{Language Experience}} and {{Language Ability}} on {{Segmental Accuracy}} in {{Bilingual Children}}},
  author = {Goldstein, B. and Bunta, F. and Lange, J. and Rodriguez, J. and Burrows, L.},
  year = {2010},
  volume = {19},
  pages = {238--247},
  journal = {American Journal of Speech-Language Pathology},
  number = {3}
}

@article{goldsteinSocialFeedbackInfants2008,
  title = {Social {{Feedback}} to {{Infants}}' {{Babbling Facilitates Rapid Phonological Learning}}},
  author = {Goldstein, Michael H. and Schwade, Jennifer A.},
  year = {2008},
  month = may,
  volume = {19},
  pages = {515--523},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/j.1467-9280.2008.02117.x},
  abstract = {Infants' prelinguistic vocalizations are rarely considered relevant for communicative development. As a result, there are few studies of mechanisms underlying developmental changes in prelinguistic vocal production. Here we report the first evidence that caregivers' speech to babbling infants provides crucial, real-time guidance to the development of prelinguistic vocalizations. Mothers of 9.5-month-old infants were instructed to provide models of vocal production timed to be either contingent or noncontingent on their infants' babbling. Infants given contingent feedback rapidly restructured their babbling, incorporating phonological patterns from caregivers' speech, but infants given noncontingent feedback did not. The new vocalizations of the infants in the contingent condition shared phonological form but not phonetic content with their mothers' speech. Thus, prelinguistic infants learned new vocal forms by discovering phonological patterns in their mothers' contingent speech and then generalizing from these patterns.},
  file = {/Users/megcychosz/Zotero/storage/N8AR6L9T/Goldstein and Schwade - 2008 - Social Feedback to Infants' Babbling Facilitates R.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {5}
}

@article{golinkoffInfantdirectedSpeechFacilitates1995,
  title = {Infant-Directed Speech Facilitates Lexical Learning in Adults Hearing {{Chinese}}: Implications for Language Acquisition},
  shorttitle = {Infant-Directed Speech Facilitates Lexical Learning in Adults Hearing {{Chinese}}},
  author = {Golinkoff, Roberta Michnick and Alioto, Anthony},
  year = {1995},
  month = oct,
  volume = {22},
  pages = {703--726},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000900010011},
  abstract = {ABSTRACT                            Experiments 1 and 2 examined the effects of infant-directed (ID) speech on adults' ability to learn an individual target word in sentences in an unfamiliar, non-Western language (Chinese). English-speaking adults heard pairs of sentences read by a female, native Chinese speaker in either ID or adult-directed (AD) speech. The pairs of sentences described slides of 10 common objects. The Chinese name for the object (the target word) was placed in an utterance-final position in experiment? (               n               = 61) and in a medial position in experiment 2 (               n               = 79). At test, each Chinese target word was presented in isolation in AD speech in a recognition task. Only subjects who heard ID speech with the target word in utterance-final position demonstrated learning of the target words. The results support assertions that ID speech, which tends to put target words in sentence-final position, may assist infants in segmenting and remembering portions of the linguistic stream. In experiment 3 (               n               = 23), subjects judged whether each of the ID and AD speech samples prepared for experiments ? and 2 were directed to an adult or to an infant. Judgements were above chance for two types of sentence: ID speech with the target word in the final position and AD speech with the target word in a medial position. In addition to indirectly confirming the results of experiments 1 and 2, these findings suggest that at least some of the prosodic features which comprise ID speech in Chinese and English must overlap.},
  file = {/Users/megcychosz/Zotero/storage/CXUGECBU/Golinkoff and Alioto - 1995 - Infant-directed speech facilitates lexical learnin.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {3}
}

@article{gomezLanguageUniversalsBirth2014,
  title = {Language Universals at Birth},
  author = {Gomez, D. M. and Berent, I. and {Benavides-Varela}, S. and Bion, R. A. H. and Cattarossi, L. and Nespor, M. and Mehler, J.},
  year = {2014},
  month = apr,
  volume = {111},
  pages = {5837--5841},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1318261111},
  file = {/Users/megcychosz/Zotero/storage/TQ8SX49G/Gomez et al. - 2014 - Language universals at birth.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {16}
}

@article{gonzalesMachineLearningDisambiguation,
  title = {Machine {{Learning Disambiguation}} of {{Quechua Verb Morphology}}},
  author = {Gonzales, Annette Rios and Gohring, Anne},
  pages = {6},
  abstract = {We have implemented a rule-based prototype of a Spanish-to-Cuzco Quechua MT system enhanced through the addition of statistical components. The greatest difficulty during the translation process is to generate the correct Quechua verb form in subordinated clauses. The prototype has several rules that decide which verb form should be used in a given context. However, matching the context in order to apply the correct rule depends crucially on the parsing quality of the Spanish input. As the form of the subordinated verb depends heavily on the conjunction in the subordinated Spanish clause and the semantics of the main verb, we extracted this information from two treebanks and trained different classifiers on this data. We tested the best classifier on a set of 4 texts, increasing the correct subordinated verb forms from 80\% to 89\%.},
  file = {/Users/megcychosz/Zotero/storage/2FWKQHB9/Gonzales and Gohring - Machine Learning Disambiguation of Quechua Verb Mo.pdf},
  language = {en}
}

@article{goodellAcousticEvidenceDevelopment1992,
  title = {Acoustic {{Evidence}} for the {{Development}} of {{Gestural Coordination}} in the {{Speech}} of 2-{{Year}}-{{Olds}}: {{A Longitudinal Study}}},
  author = {Goodell, Elizabeth Whitney and {Studdert-Kennedy}, Michael},
  year = {1992},
  volume = {SR-111/1123},
  pages = {63--88},
  abstract = {Studies of child phonology have often assumed that young children first master a repertoire of phonemes and then build their lexicon by forming combinations of these abstract, contrastive units. However, evidence from children's systematic errors suggests that children first build a repertoire of words as integral sequences of gestures and then gradually differentiate these sequences into their gestural and segmental components. Recently, experimental support for this position has been found in the acoustic records of the speech of 3-, 5- and 7-year-old children suggesting that even in older children some phonemes have not yet fully segregated as units of gestural organization and control. The present longitudinal study extends this work to younger children (22- and 32-month-olds). Results demonstrate clear differences in the duration and coordination of gestures between children and adults, and a clear shift toward the patterns of adult speakers during roughly the third year of life. Details of the child-adult differences and developmental changes vary from one aspect of an utterance to another.},
  file = {/Users/megcychosz/Zotero/storage/Z836WFBC/Acoustic Evidence for the Development of Gestural Coordination in the Speech of 2-Year-Olds A Longitudinal Study.pdf},
  journal = {Haskins Laboratories Status Report on Speech Research}
}

@article{gordinskyNewFactsRegression2016,
  title = {New {{Facts}} in {{Regression Estimation}} under {{Conditions}} of {{Multicollinearity}}},
  author = {Gordinsky, Anatoly},
  year = {2016},
  volume = {06},
  pages = {842--861},
  issn = {2161-718X, 2161-7198},
  doi = {10.4236/ojs.2016.65070},
  abstract = {This paper considers the approaches and methods for reducing the influence of multicollinearity. Great attention is paid to the question of using shrinkage estimators for this purpose. Two classes of regression models are investigated, the first of which corresponds to systems with a negative feedback, while the second class presents systems without the feedback. In the first case the use of shrinkage estimators, especially the Principal Component estimator, is inappropriate but is possible in the second case with the right choice of the regularization parameter or of the number of principal components included in the regression model. This fact is substantiated by the study of the distribution of the random variable b{${'}$}b - {$\beta$} {${'}\beta$} , where b is the LS estimate and {$\beta$} is the true coefficient, since the form of this distribution is the basic characteristic of the specified classes. For this study, a regression approximation of the distribution of the event b{${'}$}b - {$\beta$} {${'}\beta$} {$<$} 0 based on the Edgeworth series was developed. Also, alternative approaches are examined to resolve the multicollinearity issue, including an application of the known Inequality Constrained Least Squares method and the Dual estimator method proposed by the author. It is shown that with a priori information the Euclidean distance between the estimates and the true coefficients can be significantly reduced.},
  file = {/Users/megcychosz/Zotero/storage/5N4GI9X2/Gordinsky - 2016 - New Facts in Regression Estimation under Condition.pdf},
  journal = {Open Journal of Statistics},
  language = {en},
  number = {05}
}

@article{gowWordRecognitionPhonology2007,
  title = {Word Recognition and Phonology: {{The}} Case of {{English}} Coronal Place Assimilation},
  author = {Gow, David. W and McMurray, Bob},
  year = {2007},
  volume = {9},
  pages = {173--200},
  file = {/Users/megcychosz/Zotero/storage/IHN4Q8MS/Jr and McMurray - Chapter 1 Word recognition and phonology The case.pdf},
  journal = {Papers in Laboratory Phonology},
  language = {en}
}

@article{grandonDevelopmentFricativeProduction2020,
  title = {Development of Fricative Production in {{French}}-Speaking School-Aged Children Using Cochlear Implants and Children with Normal Hearing},
  author = {Grandon, B{\'e}n{\'e}dicte and Vilain, Anne},
  year = {2020},
  month = jul,
  volume = {86},
  pages = {105996},
  issn = {00219924},
  doi = {10.1016/j.jcomdis.2020.105996},
  file = {/Users/megcychosz/Zotero/storage/8WK7JG8R/Grandon and Vilain - 2020 - Development of fricative production in French-spea.pdf},
  journal = {Journal of Communication Disorders},
  language = {en}
}

@article{gratierImitationRepetitionProsodic2011,
  title = {Imitation and Repetition of Prosodic Contour in Vocal Interaction at 3 Months.},
  author = {Gratier, Maya and Devouche, Emmanuel},
  year = {2011},
  volume = {47},
  pages = {67--76},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/a0020722},
  abstract = {This study investigates vocal imitation of prosodic contour in ongoing spontaneous interaction with 10to 13-week-old infants. Audio recordings from naturalistic interactions between 20 mothers and infants were analyzed using a vocalization coding system that extracted the pitch and duration of individual vocalizations. Using these data, the authors categorized a sample of 1,359 vocalizations on the basis of 7 predetermined contours. Pairs of identical successive vocalizations were considered to be imitations if they involved both partners or repetitions if they were produced by the same partner. Results show that not only do mothers and infants imitate and repeat prosodic contour types in the course of vocal interaction but they do so selectively. Indeed, different contours are imitated and repeated by each partner. These findings suggest that imitation and repetition of prosodic contours have specific functions for communication and vocal development in the 3rd month of life.},
  file = {/Users/megcychosz/Zotero/storage/68DUHX8H/Gratier and Devouche - 2011 - Imitation and repetition of prosodic contour in vo.pdf},
  journal = {Developmental Psychology},
  language = {en},
  number = {1}
}

@article{grechPhonologicalAcquisitionMalta2008a,
  title = {Phonological Acquisition in {{Malta}}: {{A}} Bilingual Language Learning Context},
  shorttitle = {Phonological Acquisition in {{Malta}}},
  author = {Grech, Helen and Dodd, Barbara},
  year = {2008},
  month = sep,
  volume = {12},
  pages = {155--171},
  publisher = {{SAGE Publications Ltd}},
  issn = {1367-0069},
  doi = {10.1177/1367006908098564},
  abstract = {A total of 241 Maltese children aged 2;0?6;0 years, drawn randomly from the public registry of births, were assessed on a picture naming task to evaluate phone articulation, phonology and consistency of word production. Children were allowed to use the language they chose (either Maltese or English). Ninety-three children (38.6\%) were reported by parents to speak both Maltese and English at home, 137 (56.9\%) were reported to speak Maltese and 11 (4.7\%) only English at home. The data gained were analyzed for percent consonants and vowels correct, adult phonemes absent, developmental speech error patterns, number of English and Maltese words used, and the percentage of children using translation equivalents. The children who were reported to be only exposed to English at home were not compared statistically with other children because of the small number in that group. The data showed an increase in phonological competence over the age range and differences between children reported to be exposed to one as opposed to two languages at home. Many children, irrespective of reported home language context, used both English and Maltese during assessment. The results were interpreted as showing independent phonological systems that nevertheless interacted; a bilingual language learning context affected word naming language choice.},
  file = {/Users/megcychosz/Zotero/storage/DEFF3NRB/Grech and Dodd - 2008 - Phonological acquisition in Malta A bilingual lan.pdf},
  journal = {International Journal of Bilingualism},
  number = {3}
}

@article{greenLipMovementExaggerations2010,
  title = {Lip {{Movement Exaggerations During Infant}}-{{Directed Speech}}},
  author = {Green, Jordan R. and Nip, Ignatius S. B. and Wilson, Erin M. and Mefferd, Antje S. and Yunusova, Yana},
  year = {2010},
  month = dec,
  volume = {53},
  pages = {1529--1542},
  issn = {1092-4388},
  doi = {10.1044/1092-4388(2010/09-0005)},
  abstract = {Purpose Although a growing body of literature has indentified the positive effects of visual speech on speech and language learning, oral movements of infant-directed speech (IDS) have rarely been studied. This investigation used 3-dimensional motion capture technology to describe how mothers modify their lip movements when talking to their infants. Method Lip movements were recorded from 25 mothers as they spoke to their infants and other adults. Lip shapes were analyzed for differences across speaking conditions. The maximum fundamental frequency, duration, acoustic intensity, and first and second formant frequency of each vowel also were measured. Results Lip movements were significantly larger during IDS than during adult-directed speech, although the exaggerations were vowel specific. All of the vowels produced during IDS were characterized by an elevated vocal pitch and a slowed speaking rate when compared with vowels produced during adult-directed speech. Conclusion The pattern of lip-shape exaggerations did not provide support for the hypothesis that mothers produce exemplar visual models of vowels during IDS. Future work is required to determine whether the observed increases in vertical lip aperture engender visual and acoustic enhancements that facilitate the early learning of speech.},
  file = {/Users/megcychosz/Zotero/storage/5NGDN6MH/Green et al. - 2010 - Lip Movement Exaggerations During Infant-Directed .pdf},
  journal = {Journal of speech, language, and hearing research : JSLHR},
  number = {6},
  pmcid = {PMC3548446},
  pmid = {20699342}
}

@article{greenPhysiologicDevelopmentSpeech2000,
  title = {The {{Physiologic Development}} of {{Speech Motor Control}}: {{Lip}} and {{Jaw Coordination}}},
  author = {Green, Jordan R and Moore, Christopher A and Higashikawa, Masahiko and Steeve, Roger W},
  year = {2000},
  volume = {43},
  pages = {239--255},
  abstract = {This investigation was designed to describe the development of lip and jaw coordination during speech and to evaluate the potential influence of speech motor development on phonologic development. Productions of syllables containing bilabial consonants were observed from speakers in four age groups (i.e., 1-year-olds, 2-year-olds, 6-year-olds, and young adults). A video-based movement tracking system was used to transduce movement of the upper lip, lower lip, and jaw. The coordinative organization of these articulatory gestures was shown to change dramatically during the first several years of life and to continue to undergo refinement past age 6. The present results are consistent with three primary phases in the development of lip and jaw coordination for speech: integration, differentiation, and refinement. Each of these developmental processes entails the existence of distinct coordinative constraints on early articulatory movement. It is suggested that these constraints will have predictable consequences for the sequence of phonologic development.},
  file = {/Users/megcychosz/Zotero/storage/YRD8PQ2A/Green et al. - 2010 - The Physiologic Development of Speech Motor Contro.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {1}
}

@article{greenwoodAssessingChildrenHome2011,
  title = {Assessing {{Children}}'s {{Home Language Environments Using Automatic Speech Recognition Technology}}},
  author = {Greenwood, Charles R. and {Thiemann-Bourque}, Kathy and Walker, Dale and Buzhardt, Jay and Gilkerson, Jill},
  year = {2011},
  month = feb,
  volume = {32},
  pages = {83--92},
  issn = {1525-7401, 1538-4837},
  doi = {10.1177/1525740110367826},
  abstract = {The purpose of this research was to replicate and extend some of the findings of Hart and Risley using automatic speech processing instead of human transcription of language samples. The long-term goal of this work is to make the current approach to speech processing possible by researchers and clinicians working on a daily basis with families and young children.Twelve hour-long, digital audio recordings were obtained repeatedly in the homes of middle to upper SES families for a sample of typically developing infants and toddlers (N = 30). These recordings were processed automatically using a measurement framework based on the work of Hart and Risley. Like Hart and Risley, the current findings indicated vast differences in individual children's home language environments (i.e., adult word count), children's vocalizations, and conversational turns.Automated processing compared favorably to the original Hart and Risley estimates that were based on transcription. Adding to Hart and Risley's findings were new descriptions of patterns of daily talk and relationships to widely used outcome measures, among others. Implications for research and practice are discussed.},
  file = {/Users/megcychosz/Zotero/storage/RU5C6GE3/Greenwood et al. - 2011 - Assessing Children’s Home Language Environments Us.pdf},
  journal = {Communication Disorders Quarterly},
  language = {en},
  number = {2}
}

@article{grigosChangesArticulatorMovement2009,
  title = {Changes in {{Articulator Movement Variability During Phonemic Development}}: {{A Longitudinal Study}}},
  shorttitle = {Changes in {{Articulator Movement Variability During Phonemic Development}}},
  author = {Grigos, Maria I.},
  year = {2009},
  month = feb,
  volume = {52},
  pages = {164--177},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2008/07-0220)},
  abstract = {Purpose: The present study explored articulator movement variability during voicing contrast acquisition. The purpose was to examine whether oral articulator movement trajectories associated with the production of voiced/voiceless bilabial phonemes in children became less variable over time. Method: Jaw, lower lip, and upper lip movements were recorded longitudinally in six, 19 month-old children as they began producing the voiceless phoneme /p/. Displacement signals were time and amplitude normalized. The spatiotemporal index (A. Smith, L. Goffman, H. Zelaznik, S. Ying, \& C. McGillem, 1995) was computed to examine the variability in movement trajectories across repeated productions of target utterances. Results: Spatiotemporal variability of lip and jaw movements significantly decreased as children began producing the voiceless phoneme /p/. A significant negative correlation between the STI and the length of voice onset time ( VOT) was also found in the voiceless productions in 4 of the 6 participants. Conclusions: Oral articulator movement variability is reduced in children across the stabilization of voicing contrast acquisition. Further, the relationship between VOT contrast production and movement variability suggests that a coordinate system between the oral and laryngeal articulators may be refined as children acquire the voicing contrast.},
  file = {/Users/megcychosz/Zotero/storage/6U3S6RQK/Grigos - 2009 - Changes in Articulator Movement Variability During.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {1}
}

@article{gros-louisMothersProvideDifferential2006,
  title = {Mothers Provide Differential Feedback to Infants' Prelinguistic Sounds},
  author = {{Gros-Louis}, Julie and West, Meredith J. and Goldstein, Michael H. and King, Andrew P.},
  year = {2006},
  month = nov,
  volume = {30},
  pages = {509--516},
  issn = {0165-0254, 1464-0651},
  doi = {10.1177/0165025406071914},
  abstract = {Few studies have focused on mechanisms of developmental change during the prelinguistic period. The lack of focus on early vocal development is surprising given that maternal responsiveness to infants during the first two years has been found to influence later language development. In addition, in a variety of species, social feedback is essential for vocal development. Previous research demonstrated that maternal feedback to prelinguistic vocalizations influenced the production of more developmentally advanced vocalizations, suggesting that effects of maternal responsiveness on vocal development may start during the prelinguistic phase; however, because mothers were instructed how and when to respond to their infants' vocalizations, the timing and type of typical maternal feedback is unknown. In the present study, we analyzed unstructured play sessions for 10 mother\textendash infant dyads to explore the relationship between prelinguistic vocal production and maternal responsiveness. Mothers responded contingently to prelinguistic vocalizations over 70\% of the time. Mothers responded with more vocal responses compared to interactive responses (e.g., gazes, smiling, physical contact). Investigation of specific types of vocal responses revealed that mothers responded mainly with acknowledgments to both vowel-like sounds and consonant\textendash vowel clusters. Mothers also showed differential responding to vocalizations that varied in quality. Mothers responded with play vocalizations to vowel-like vocalizations significantly more than to consonant\textendash vowel clusters, whereas they responded with imitations to consonant\textendash vowel clusters more than to vowel-like sounds. Mothers, therefore, appeared to regulate their contingent feedback relative to the speech-like quality of infants' vocalizations which may provide relevant stimulation to guide communicative development.},
  file = {/Users/megcychosz/Zotero/storage/ERL5PUY6/Gros-Louis et al. - 2006 - Mothers provide differential feedback to infants' .pdf},
  journal = {International Journal of Behavioral Development},
  language = {en},
  number = {6}
}

@article{grossbergTheoryHumanMemory1978,
  title = {A Theory of Human Memory: {{Self}}-Organization and Performance of Sensory-Motor Codes, Maps, and Plans.},
  author = {Grossberg, S.},
  year = {1978},
  volume = {5},
  pages = {233--274},
  journal = {Progress in theoretical biology}
}

@article{guentherCorticalInteractionsUnderlying2006,
  title = {Cortical Interactions Underlying the Production of Speech Sounds},
  author = {Guenther, Frank H.},
  year = {2006},
  month = sep,
  volume = {39},
  pages = {350--365},
  issn = {00219924},
  doi = {10.1016/j.jcomdis.2006.06.013},
  abstract = {Speech production involves the integration of auditory, somatosensory, and motor information in the brain. This article describes a model of speech motor control in which a feedforward control system, involving premotor and primary motor cortex and the cerebellum, works in concert with auditory and somatosensory feedback control systems that involve both sensory and motor cortical areas. New speech sounds are learned by first storing an auditory target for the sound, then using the auditory feedback control system to control production of the sound in early repetitions. Repeated production of the sound leads to tuning of feedforward commands which eventually supplant the feedback-based control signals. Although parts of the model remain speculative, it accounts for a wide range of kinematic, acoustic, and neuroimaging data collected during speech production and provides a framework for investigating communication disorders that involve malfunction of the cerebral cortex and interconnected subcortical structures.},
  file = {/Users/megcychosz/Zotero/storage/AUK8W7AC/Guenther - 2006 - Cortical interactions underlying the production of.pdf},
  journal = {Journal of Communication Disorders},
  language = {en},
  number = {5}
}

@article{guentherSpeechSoundAcquisition1995,
  title = {Speech Sound Acquisition, Coarticulation, and Rate Effects in a Neural Network Model of Speech Production},
  author = {Guenther, Frank H.},
  year = {1995},
  volume = {102},
  pages = {594--621},
  abstract = {This article describes a neural network model of speech motor skill acquisition and speech production that explains a wide range of data on contextual variability, motor equivalence, coarticulation, and speaking rate effects. Model parameters are learned during a babbling phase. To explain how infants learn phonemespecific and language-specific limits on acceptable articulatory variability, the learned speech sound targets take the form of multidimensional convex regions in orosensory coordinates. Reduction of target size for better accuracy during slower speech (in the spirit of the speed-accuracy trade-off described by Fitts ' law) leads to differential effects for vowels and consonants, as seen in speaking rate experiments that have been previously taken as evidence for separate control processes for the two sound types. An account of anticipatory coarticulation is posited wherein the target for a speech sound is reduced in size based on context to provide a more efficient sequence of articulator movements. This explanation generalizes the well-known look-ahead model of coarticulation to incorporate convex region targets. Computer simulations verify the model's properties, including linear velocity/distance relationships, motor equivalence, speaking rate effects, and carryover and anticipatory coarticulation.},
  journal = {Psychological Review}
}

@article{guentherSpeechSoundAcquisition2000,
  title = {Speech {{Sound Acquisition}}, {{Coarticulation}}, and {{Rate Effects}} in a {{Neural Network Model}} of {{Speech Production}}},
  author = {Guenther, Frank H},
  year = {2000},
  pages = {50},
  abstract = {This article describes a neural network model of speech motor skill acquisition and speech production that explains a wide range of data on contextual variability, motor equivalence, coarticulation, and speaking rate effects. Model parameters are learned during a babbling phase. To explain how infants learn phonemespecific and language-specific limits on acceptable articulatory variability, the learned speech sound targets take the form of multidimensional convex regions in orosensory coordinates. Reduction of target size for better accuracy during slower speech (in the spirit of the speed-accuracy trade-off described by Fitts' law) leads to differential effects for vowels and consonants, as seen in speaking rate experiments that have been previously taken as evidence for separate control processes for the two sound types. An account of anticipatory coarticulation is posited wherein the target for a speech sound is reduced in size based on context to provide a more efficient sequence of articulator movements. This explanation generalizes the well-known look-ahead model of coarticulation to incorporate convex region targets. Computer simulations verify the model's properties, including linear velocity/distance relationships, motor equivalence, speaking rate effects, and carryover and anticipatory coarticulation.},
  file = {/Users/megcychosz/Zotero/storage/TK7JUP5P/Guenther - 2000 - Speech Sound Acquisition, Coarticulation, and Rate.pdf},
  language = {en}
}

@article{guoAreYoungChildren2015,
  title = {Are {{Young Children With Cochlear Implants Sensitive}} to the {{Statistics}} of {{Words}} in the {{Ambient Spoken Language}}?},
  author = {Guo, Ling-Yu and McGregor, Karla K. and Spencer, Linda J.},
  year = {2015},
  month = jun,
  volume = {58},
  pages = {987--1000},
  issn = {1092-4388},
  doi = {10.1044/2015_JSLHR-H-14-0135},
  abstract = {Purpose The purpose of this study was to determine whether children with cochlear implants (CIs) are sensitive to statistical characteristics of words in the ambient spoken language, whether that sensitivity changes in expected ways as their spoken lexicon grows, and whether that sensitivity varies with unilateral or bilateral implantation. Method We analyzed archival data collected from the parents of 36 children who received cochlear implantation (20 unilateral, 16 bilateral) before 24 months of age. The parents reported their children's word productions 12 months after implantation using the MacArthur Communicative Development Inventories: Words and Sentences (). We computed the number of words, out of 292 possible monosyllabic nouns, verbs, and adjectives, that each child was reported to say and calculated the average phonotactic probability, neighborhood density, and word frequency of the reported words. Results Spoken vocabulary size positively correlated with average phonotactic probability and negatively correlated with average neighborhood density, but only in children with bilateral CIs. Conclusion At 12 months postimplantation, children with bilateral CIs demonstrate sensitivity to statistical characteristics of words in the ambient spoken language akin to that reported for children with normal hearing during the early stages of lexical development. Children with unilateral CIs do not.},
  file = {/Users/megcychosz/Zotero/storage/T7DYZHC8/Guo et al. - 2015 - Are Young Children With Cochlear Implants Sensitiv.pdf},
  journal = {Journal of Speech, Language, and Hearing Research : JSLHR},
  number = {3},
  pmcid = {PMC4490103},
  pmid = {25677929}
}

@article{guyDevelopmentMorphologicalClass1990,
  title = {The Development of a Morphological Class},
  author = {Guy, Gregory R. and Boyd, Sally},
  year = {1990},
  volume = {2},
  pages = {1--18},
  journal = {Language Variation and Change},
  number = {1}
}

@article{guyExplanationVariablePhonology1991,
  title = {Explanation in Variable Phonology: {{An}} Exponential Model of Morphological Constraints},
  shorttitle = {Explanation in Variable Phonology},
  author = {Guy, Gregory R.},
  year = {1991},
  month = mar,
  volume = {3},
  pages = {1--22},
  issn = {0954-3945, 1469-8021},
  doi = {10.1017/S0954394500000429},
  abstract = {Variationist treatments of phonological processes typically provide precise quantitative accounts of the effects of conditioning environmental factors on the occurrence of the process, and these effects have been shown to be robust for several well-studied processes. But comparable precision in theoretical explanation is usually elusive, at the current state of the discipline. That is, the analyst is usually unable to say why the parameters should have the particular values that they do, although one can often explain relative ordering of environments. This article attempts to give a precise explanation \textemdash in the form of a quantitative theoretical prediction \textemdash of one robust quantitative observation about English phonology. The reduction of final consonant clusters (often called -t,d deletion) is well-known to be conditioned by the morphological structure of a target word. Deletion applies more in monomorphemic words (e.g., mist) than in inflected words (e.g., missed). In the theory of lexical phonology, these classes of words are differentiated by derivational history, acquiring their final clusters at different levels of the morphology. The theory further postulates that rules may apply at more than one level of the derivation. If -t,d deletion is treated as a variable rule with a fixed rate of application (p0) in a phonology with this architecture, then higher rates of application in underived forms (where the final cluster is present underlyingly and throughout the derivation) are a consequence of multiple exposures to the deletion rule, whereas inflected forms (which only meet the structural description of the rule late in the derivation) have fewer exposures and lower cumulative deletion. This further allows a precise quantitative prediction concerning surface deletion rates in the different morphological categories. They should be related as an exponential function of p0, depending on the number of exposures to the rule. The prediction is empirically verified in a study of -t,d deletion in seven English speakers.},
  file = {/Users/megcychosz/Zotero/storage/W8RCV9SB/Guy - 1991 - Explanation in variable phonology An exponential .pdf},
  journal = {Language Variation and Change},
  language = {en},
  number = {1}
}

@article{haasDevelopmentOffeedbackFeedforward1989,
  title = {Development {{Offeedback}} and {{Feedforward Control}} of {{Upright Stance}}},
  author = {Haas, G. and Diener, H. C. and Rapp, H. and Dichgans, J.},
  year = {1989},
  volume = {31},
  pages = {481--488},
  issn = {1469-8749},
  doi = {10.1111/j.1469-8749.1989.tb04026.x},
  abstract = {Feedback and feedforward (anticipatory) adjustments of stance were investigated in 58 children with normal development aged between seven months and 14 years, and in 14 children with motor and mental retardation aged between 21 months and seven years. Feedback responses after tilting the body were elicited in all but the two youngest children, aged seven and nine months. The observed rapid decrease in feedback response latency with age suggests considerable acceleration of central transmission. Effective anticipatory postural adjustments (feedforward) were elicited only in the normal children over four years of age. The development of both feedback and feedforward continued until adolescence. R\'ESUM\'E D\'eveloppement des contr\^oles en retour et anticipateurs de la tenue debout Les ajustements de posture en retour et anticipateurs ont \'et\'e etudies chez 58 enfants de developpement normal, \^ag\`es de sept mois \`a 14 ans, et chez 14 enfants avec retard moteur et mental, \^ag\`es de 21 mois \`a sept ans. Les r\'eponses en retour apr\`es pouss\'ee sur le corps ont \'et\'e obtenues chez tous les enfants, sauf les deux plus jeunes, de sept et neuf mois. Une d\'ecroissance rapide de la latence des r\'eponses en retour en fonction de l'\^age sugg\`erent une acc\'el\'eration consid\'erable de la transmission centrale. Les ajustements anticipateurs efficaces n'\'etaient obtenus chez les enfants normaux qu'apr\`es l'\^age de quatre ans. Le d\'eveloppement des r\'eponses en retour et anticipatrices continuait jusq'\`a l'adolescence. ZUSAMMENFASSUNG Die Entwicklung der Feedback- und Feedforwardkontrolle des aufrechten Stehens Bei 58 Kindern mit normaler Entwicklung im Alter zwischen sieben Monaten und 14 Jahren und bei 14 Kindern mit motorischer und geistiger Retardierung im Alter zwischen 21 Monaten und sieben Jahren wurden die R\"uckkopplungsmechanismen (feedback) und die anticipatorischen (feedforward) RESUMEN Desarrolio del control retroalimentado y prealimentado de la postura erecta Se investigaron los ajustes retroalimentados y prealimentados (anticipatorios) de la postura erecta en 58 ni{\"n}os con desarrolio normal y de edad de siete meses a 14 a{\"n}os, y en 14 ni{\"n}os con retraso motor y mental de entre 21 meses y siete a{\"n}os. Las respuestas retro despu\'es de una inclinaci\'en del cuerpo se observaron en todos los casos, excepto en los dos ni\~nos mis pequeflos, que tenian siete y nueve meses. La r\'apida disminuci\'on de la latencia de la retrorespuesta con la edad sugiere una acentuada aceleraci\'on de la transmisi\'en central. Ajustes posturales anticipatorios (pre-alimentaci\'on) efectivos s\'olo se demonstraron en los ni\~nos normales de m\'as de cuatro a\~nos de edad. El desarrolio de la retro y pre-alimentaci\'en continua hasta la adolescencia.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-8749.1989.tb04026.x},
  file = {/Users/megcychosz/Zotero/storage/WQVNFYEF/Haas et al. - 1989 - Development Offeedback and Feedforward Control of .pdf},
  journal = {Developmental Medicine \& Child Neurology},
  language = {en},
  number = {4}
}

@article{hacquardEffectsInventoryVowel2007,
  title = {The Effects of Inventory on Vowel Perception in {{French}} and {{Spanish}}: {{An MEG}} Study},
  author = {Hacquard, V. and Walter, M. A. and Marantz, A.},
  year = {2007},
  volume = {100},
  pages = {295--300},
  journal = {Brain and language},
  number = {3}
}

@article{haCrosslinguisticComparisonUtterance2021,
  title = {Cross-Linguistic Comparison of Utterance Shapes in {{Korean}}- and {{English}}-Learning Children: {{An}} Ambient Language Effect},
  shorttitle = {Cross-Linguistic Comparison of Utterance Shapes in {{Korean}}- and {{English}}-Learning Children},
  author = {Ha, Seunghee and Johnson, Cynthia J. and Oller, Kimbrough D. and Yoo, Hyunjoo},
  year = {2021},
  month = feb,
  volume = {62},
  pages = {101528},
  issn = {01636383},
  doi = {10.1016/j.infbeh.2021.101528},
  abstract = {This study compared vocal development in Korean- and English-learning infants and examined ambient-language effects focusing on predominant utterance shapes. Vocalization samples were obtained from 14 Korean-learning children and 14 English-learning children, who ranged in age from 9 to 21 months, in monolingual environments using day-long audio recordings. The ana\- lyzers, who were blind to participants' demographic information, identified utterance shapes to determine functional vocal repertoires through naturalistic listening simulating the caregiver's natural mode of listening. The results showed no cross-linguistic differences in the amount of vocal output or the proportion of canonical syllables. However, the infants from the two language backgrounds showed differences regarding the predominant canonical utterance shapes. The percentage of VCV utterances in Korean-learning children was higher than in English-learning children while CV syllables predominated in the English-learning children. We speculate that the difference between the predominant utterance shapes of Korean- and English-learning chil\- dren could be associated with differences in early lexical items typically acquired in the two language groups.},
  file = {/Users/megcychosz/Zotero/storage/WKSYME7L/Ha et al. - 2021 - Cross-linguistic comparison of utterance shapes in.pdf},
  journal = {Infant Behavior and Development},
  language = {en}
}

@article{hadleyInputSubjectDiversity2017,
  title = {Input {{Subject Diversity Accelerates}} the {{Growth}} of {{Tense}} and {{Agreement}}: {{Indirect Benefits From}} a {{Parent}}-{{Implemented Intervention}}},
  shorttitle = {Input {{Subject Diversity Accelerates}} the {{Growth}} of {{Tense}} and {{Agreement}}},
  author = {Hadley, Pamela A. and Rispoli, Matthew and Holt, Janet K.},
  year = {2017},
  month = sep,
  volume = {60},
  pages = {2619--2635},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2017_JSLHR-L-17-0008},
  file = {/Users/megcychosz/Zotero/storage/DLHN8GUP/Hadley et al. - 2017 - Input Subject Diversity Accelerates the Growth of .pdf;/Users/megcychosz/Zotero/storage/PIFIEFWZ/Toy Talk Description, Rationale, and Parent Handout, June 2015.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {9}
}

@article{hainesChronicAircraftNoise2001,
  title = {Chronic Aircraft Noise Exposure, Stress Responses, Mental Health and Cognitive Performance in School Children},
  author = {Haines, M. M. and Stansfeld, S. A. and Job, R. F. S. and Berglund, B. and Head, J.},
  year = {2001},
  month = feb,
  volume = {31},
  pages = {265--277},
  issn = {0033-2917, 1469-8978},
  doi = {10.1017/S0033291701003282},
  abstract = {Background. Previous research suggests that children are a high risk group vulnerable to the effects of chronic noise exposure. However, questions remain about the nature of the noise effects and the underlying causal mechanisms. This study addresses the effects of aircraft noise exposure on children around London Heathrow airport, in terms of stress responses, mental health and cognitive performance. The research also focuses on the underlying causal mechanisms contributing to the cognitive effects and potential confounding factors. Methods. The cognitive performance and health of 340 children aged 8\textendash 11 years attending four schools in high aircraft noise areas (16 h outdoor Leq 66 dBA) was compared with children attending four matched control schools exposed to lower levels of aircraft noise (16 h outdoor Leq 57 dBA). Mental health and cognitive tests were group administered to the children in the schools. Salivary cortisol was measured in a subsample of children. Results. Chronic aircraft noise exposure was associated with higher levels of noise annoyance and poorer reading comprehension measured by standardized scales with adjustments for age, deprivation and main language spoken. Chronic aircraft noise was not associated with mental health problems and raised cortisol secretion. The association between aircraft noise exposure and reading comprehension could not be accounted for by the mediating role of annoyance, confounding by social class, deprivation, main language or acute noise exposure. Conclusions. These results suggest that chronic aircraft noise exposure is associated with impaired reading comprehension and high levels of noise annoyance but not mental health problems in children.},
  file = {/Users/megcychosz/Zotero/storage/QWDFYBNF/Haines et al. - 2001 - Chronic aircraft noise exposure, stress responses,.pdf},
  journal = {Psychological Medicine},
  language = {en},
  number = {2}
}

@article{haleFormalEmpiricalArguments1998,
  title = {Formal and {{Empirical Arguments}} Concerning {{Phonological Acquisition}}},
  author = {Hale, Mark and Reiss, Charles},
  year = {1998},
  volume = {29},
  pages = {656--683},
  file = {/Users/megcychosz/Zotero/storage/7VFIBKCH/Hale and Reiss - 1998 - Formal and Empirical Arguments concerning Phonolog.pdf},
  journal = {Linguistic Inquiry},
  language = {en},
  number = {4}
}

@article{haleFormalEmpiricalArguments1998a,
  title = {Formal and {{Empirical Arguments}} Concerning {{Phonological Acquisition}}},
  author = {Hale, Mark and Reiss, Charles},
  year = {1998},
  month = oct,
  volume = {29},
  pages = {656--683},
  issn = {0024-3892, 1530-9150},
  doi = {10.1162/002438998553914},
  abstract = {Smolensky (1996a) has proposed an ingenious solution to the wellknown ``comprehension/production'' dilemma in phonological acquisition. In this article we argue that Smolensky's model encounters serious difficulties with respect to the parsing algorithm proposed and the learnability of underlying representations. Drawing on the generative literature in phonological acquisition, as well as the work of phoneticians and psycholinguists, we offer alternative parsing algorithms and examine their implications for learnability and the initial ranking of Optimality Theory constraints. Finally, we propose that the resolution of the comprehension/production dilemma lies not in the phonological domain (linguistic competence), but in the domain of the implementation of linguistic knowledge (performance).},
  file = {/Users/megcychosz/Zotero/storage/FJ3P8AMD/Hale and Reiss - 1998 - Formal and Empirical Arguments concerning Phonolog.pdf},
  journal = {Linguistic Inquiry},
  language = {en},
  number = {4}
}

@article{hallChildParticipationLinguistic,
  title = {Child Participation in Linguistic Changes in Progress in {{Ontario English}}},
  author = {Hall, Erin Kathleen},
  pages = {140},
  file = {/Users/megcychosz/Zotero/storage/I6SBGHCQ/Hall - Child participation in linguistic changes in progr.pdf},
  language = {en}
}

@inproceedings{haniqueFinalReductionDutch2011,
  title = {Final /t/ Reduction in {{Dutch}} Past-Participles: The Role of Word Predictability and Morphological Decomposability},
  booktitle = {Proceedings of {{Interspeech}} 2011},
  author = {Hanique, Iris and Ernestus, Mirjam},
  year = {2011},
  address = {{Florence, Italy}},
  abstract = {This corpus study demonstrates that the realization of wordfinal /t/ in Dutch past-participles in various speech styles is affected by a word's predictability and paradigmatic relative frequency. In particular, /t/s are shorter and more often absent if the two preceding words are more predictable. In addition, /t/s, especially in irregular verbs, are more reduced, the lower the verb's lemma frequency relative to the past-participle's frequency. Both effects are more pronounced in more spontaneous speech. These findings are expected if speech planning plays an important role in speech reduction.},
  file = {/Users/megcychosz/Zotero/storage/5K7EJDTG/Hanique and Ernestus - Final t reduction in Dutch past-participles the.pdf},
  language = {en}
}

@article{haniqueRoleMorphologyAcoustic2012,
  title = {The Role of Morphology in Acoustic Reduction},
  author = {Hanique, Iris and Ernestus, Mirjam},
  year = {2012},
  volume = {11},
  pages = {147--164},
  abstract = {This paper examines the role of morphological structure in the reduced pronunciation of morphologically complex words by discussing and re-analyzing data from the literature. Acoustic reduction refers to the phenomenon that, in spontaneous speech, phonemes may be shorter or absent. We review studies investigating effects of the repetition of a morpheme, of whether a segment plays a crucial role in the identification of its morpheme, and of a word's morphological decomposability. We conclude that these studies report either no effects of morphological structure or effects that are open to alternative interpretations. Our analysis also reveals the need for a uniform definition of morphological decomposability. Furthermore, we examine whether the reduction of segments in morphologically complex words correlates with these segments' contribution to the identification of the whole word, and discuss previous studies and new analyses supporting this hypothesis. We conclude that the data show no convincing evidence that morphological structure conditions reduction, which contrasts with the expectations of several models of speech production and of morphological processing (e.g., WEAVER++ and dual-route models). The data collected so far support psycholinguistic models which assume that all morphologically complex words are processed as complete units.},
  file = {/Users/megcychosz/Zotero/storage/JX22GYHX/The role of morphology in acoustic reduction.pdf},
  journal = {Lingue e linguaggio},
  language = {en},
  number = {2}
}

@article{hanLexicalTonesMandarin2018,
  title = {Lexical {{Tones}} in {{Mandarin Chinese Infant}}-{{Directed Speech}}: {{Age}}-{{Related Changes}} in the {{Second Year}} of {{Life}}},
  shorttitle = {Lexical {{Tones}} in {{Mandarin Chinese Infant}}-{{Directed Speech}}},
  author = {Han, Mengru and {de Jong}, Nivja H. and Kager, Ren{\'e}},
  year = {2018},
  month = apr,
  volume = {9},
  pages = {434},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2018.00434},
  file = {/Users/megcychosz/Zotero/storage/ISH4YWXH/Han et al. - 2018 - Lexical Tones in Mandarin Chinese Infant-Directed .pdf},
  journal = {Frontiers in Psychology},
  language = {en}
}

@article{harelFindingExpertsCrowd2017,
  title = {Finding the Experts in the Crowd: {{Validity}} and Reliability of Crowdsourced Measures of Children's Gradient Speech Contrasts},
  shorttitle = {Finding the Experts in the Crowd},
  author = {Harel, Daphna and Hitchcock, Elaine Russo and Szeredi, Daniel and Ortiz, Jos{\'e} and McAllister Byun, Tara},
  year = {2017},
  month = jan,
  volume = {31},
  pages = {104--117},
  issn = {0269-9206, 1464-5076},
  doi = {10.3109/02699206.2016.1174306},
  abstract = {Perceptual ratings aggregated across multiple non-expert listeners can be used to measure covert contrast in child speech. Online crowdsourcing provides access to a large pool of raters, but for practical purposes, researchers may wish to use smaller samples. The ratings obtained from these smaller samples may not maintain the high levels of validity seen in larger samples.},
  file = {/Users/megcychosz/Zotero/storage/GUMLZX69/Harel et al. - 2017 - Finding the experts in the crowd Validity and rel.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {1}
}

@article{harringtonFrontingAgentbasedModeling2017,
  title = {/U/-Fronting and Agent-Based Modeling: {{The}} Relationship between the Origin and Spread of Sound Change},
  shorttitle = {/U/-Fronting and Agent-Based Modeling},
  author = {Harrington, Jonathan and Schiel, Florian},
  year = {2017},
  volume = {93},
  pages = {414--445},
  issn = {1535-0665},
  doi = {10.1353/lan.2017.0019},
  file = {/Users/megcychosz/Zotero/storage/USQTWCMU/Harrington and Schiel - 2017 - u-fronting and agent-based modeling The relatio.pdf},
  journal = {Language},
  language = {en},
  number = {2}
}

@article{harringtonRelationshipMisParsing,
  title = {The {{Relationship Between}} the ({{Mis}})-{{Parsing}} of {{Coarticulation}} in {{Perception}} and {{Sound Change}}: {{Evidence}} from {{Dissimilation}} and {{Language Acquisition}}},
  author = {Harrington, Jonathan and Kleber, Felicitas and Stevens, Mary},
  pages = {20},
  abstract = {The study is concerned with whether historical sound change is more likely to occur when coarticulation, or the way that speech sounds overlap with and influence each other in time, is misaligned in production and perception. The focus of the first experiment was on long-range coarticulatory lip-rounding that has been linked with historical dissimilation. A perception experiment based on present-day Italian showed that inherently lip-rounded segments were more likely to be masked\textemdash and thereby erroneously deleted\textemdash in hypoarticulated speech. The second experiment tested whether the mismatch between the modalities was more likely in young children than in adults. For this purpose, first language German speakers participated in a forced-choice perception experiment in which they categorised German back and front vowels in coarticulatory non-fronting and fronting consonantal contexts. Children's ability to normalise for coarticulation was shown to be less than that of the adults. Taken together, the results suggest that sound change can occur when coarticulatory relationships are perceptually obscured due to a hypoarticulated speaking style causing consonants to be camouflaged in the case of dissimilation and variants to approximate those that are strongly influenced by coarticulation in the case of diachronic back vowel fronting.},
  file = {/Users/megcychosz/Zotero/storage/V4PSDFR5/Harrington et al. - The Relationship Between the (Mis)-Parsing of Coar.pdf},
  language = {en}
}

@incollection{harringtonRelationshipMisParsing2016,
  title = {The {{Relationship Between}} the ({{Mis}})-{{Parsing}} of {{Coarticulation}} in {{Perception}} and {{Sound Change}}: {{Evidence}} from {{Dissimilation}} and {{Language Acquisition}}},
  shorttitle = {The {{Relationship Between}} the ({{Mis}})-{{Parsing}} of {{Coarticulation}} in {{Perception}} and {{Sound Change}}},
  booktitle = {Recent {{Advances}} in {{Nonlinear Speech Processing}}},
  author = {Harrington, Jonathan and Kleber, Felicitas and Stevens, Mary},
  editor = {Esposito, Anna and {Faundez-Zanuy}, Marcos and Esposito, Antonietta M. and Cordasco, Gennaro and Drugman, Thomas and {Sol{\'e}-Casals}, Jordi and Morabito, Francesco Carlo},
  year = {2016},
  volume = {48},
  pages = {15--34},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-28109-4_3},
  abstract = {The study is concerned with whether historical sound change is more likely to occur when coarticulation, or the way that speech sounds overlap with and influence each other in time, is misaligned in production and perception. The focus of the first experiment was on long-range coarticulatory lip-rounding that has been linked with historical dissimilation. A perception experiment based on present-day Italian showed that inherently lip-rounded segments were more likely to be masked\textemdash and thereby erroneously deleted\textemdash in hypoarticulated speech. The second experiment tested whether the mismatch between the modalities was more likely in young children than in adults. For this purpose, first language German speakers participated in a forced-choice perception experiment in which they categorised German back and front vowels in coarticulatory non-fronting and fronting consonantal contexts. Children's ability to normalise for coarticulation was shown to be less than that of the adults. Taken together, the results suggest that sound change can occur when coarticulatory relationships are perceptually obscured due to a hypoarticulated speaking style causing consonants to be camouflaged in the case of dissimilation and variants to approximate those that are strongly influenced by coarticulation in the case of diachronic back vowel fronting.},
  file = {/Users/megcychosz/Zotero/storage/43XFTKNE/Harrington et al. - 2016 - The Relationship Between the (Mis)-Parsing of Coar.pdf},
  isbn = {978-3-319-28107-0 978-3-319-28109-4},
  language = {en}
}

@article{harringtonRelationshipProsodicWeakening2015,
  title = {The Relationship between Prosodic Weakening and Sound Change: Evidence from the {{German}} Tense/Lax Vowel Contrast},
  shorttitle = {The Relationship between Prosodic Weakening and Sound Change},
  author = {Harrington, Jonathan and Kleber, Felicitas and Reubold, Ulrich and Siddins, Jessica},
  year = {2015},
  month = jan,
  volume = {6},
  issn = {1868-6346, 1868-6354},
  doi = {10.1515/lp-2015-0002},
  abstract = {The study tests a model of sound change based on how prosodic weakening affects shortening in polysyllabic words. Twenty-nine L1-German speakers produced minimal pairs differing in vowel tensity in both monosyllables /zakt, za{$\Elzlmrk$}kt/ and disyllables /zakt{$\Elzschwa$}, za{$\Elzlmrk$}kt{$\Elzschwa$}/. The target words were produced in accented and deaccented contexts. The duration ratio between the vowel and the following /kt/ cluster was less for lax than tense vowels and less for disyllables than monosyllables. Under deaccentuation, there was an approximation of tense and lax vowels towards each other but no influence due to the mono- vs. disyllabic difference. On the other hand, Gaussian /a/ vs. /a{$\Elzlmrk$}/ classifications of these data showed a lesser influence due to the syllable count in deaccented words. Compatibly, when the same speakers as listeners classified synthetic sackt-sagt and sackte-sagte continua, they were shown to compensate for the syllable count differences, but to a lesser extent in a deaccented context. Deaccentuation may therefore provide the conditions for sound change to take place by which /a{$\Elzlmrk$}/ shortens in polysyllabic words; it may do so because the association between coarticulation and the source that gives rise to it is hidden to a greater extent than in accented contexts.},
  file = {/Users/megcychosz/Zotero/storage/U3EJ4WA6/Harrington et al. - 2015 - The relationship between prosodic weakening and so.pdf},
  journal = {Laboratory Phonology},
  language = {en},
  number = {1}
}

@article{hartmanInfantdirectedSpeechIDS2017,
  title = {Infant-Directed Speech ({{IDS}}) Vowel Clarity and Child Language Outcomes},
  author = {Hartman, Kelly M. and Ratner, Nan Bernstein and Newman, Rochelle S.},
  year = {2017},
  month = sep,
  volume = {44},
  pages = {1140--1162},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000916000520},
  abstract = {There have been many studies examining the differences between infant-directed speech (IDS) and adult-directed speech (ADS). However, investigations asking whether mothers clarify vowel articulation in IDS have reached equivocal findings. Moreover, it is unclear whether maternal speech clarification has any effect on a child's developing language skills. This study examined vowel clarification in mothers' IDS at ;\textendash , ;, and ;, as compared to their vowel production in ADS. Relationships between vowel space, vowel duration, and vowel variability and child language outcomes at two years were also explored. Results show that vowel space and vowel duration tended to be greater in IDS than in ADS, and that one measure of vowel clarity, a mother's vowel space at ;, was significantly related to receptive as well as expressive child language outcomes at two years of age.},
  file = {/Users/megcychosz/Zotero/storage/PP3KNBVZ/Hartman et al. - 2017 - Infant-directed speech (IDS) vowel clarity and chi.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {5}
}

@book{hartMeaningfulDifferencesEveryday1995,
  title = {Meaningful Differences in the Everyday Experience of Young {{American}} Children},
  author = {Hart, B. and Risley, T.R.},
  year = {1995},
  publisher = {{Paul H. Brookes Publishing}},
  address = {{Baltimore, MD}}
}

@article{hartNurtureMightBe2021,
  title = {Nurture Might Be Nature: Cautionary Tales and Proposed Solutions},
  shorttitle = {Nurture Might Be Nature},
  author = {Hart, Sara A. and Little, Callie and {van Bergen}, Elsje},
  year = {2021},
  month = jan,
  volume = {6},
  pages = {1--12},
  publisher = {{Nature Publishing Group}},
  issn = {2056-7936},
  doi = {10.1038/s41539-020-00079-z},
  abstract = {Across a wide range of studies, researchers often conclude that the home environment and children's outcomes are causally linked. In contrast, behavioral genetic studies show that parents influence their children by providing them with both environment and genes, meaning the environment that parents provide should not be considered in the absence of genetic influences, because that can lead to erroneous conclusions on causation. This article seeks to provide behavioral scientists with a synopsis of numerous methods to estimate the direct effect of the environment, controlling for the potential of genetic confounding. Ideally, using genetically sensitive designs can fully disentangle this genetic confound, but these require specialized samples. In the near future, researchers will likely have access to measured DNA variants (summarized in a polygenic scores), which could serve as a partial genetic control, but that is currently not an option that is ideal or widely available. We also propose a work around for when genetically sensitive data are not readily available: the Familial Control Method. In this method, one measures the same trait in the parents as the child, and the parents' trait is then used as a covariate (e.g., a genetic proxy). When these options are all not possible, we plead with our colleagues to clearly mention genetic confound as a limitation, and to be cautious with any environmental causal statements which could lead to unnecessary parent blaming.},
  copyright = {2021 The Author(s)},
  file = {/Users/megcychosz/Zotero/storage/RRBP9HQY/Hart et al. - 2021 - Nurture might be nature cautionary tales and prop.pdf},
  journal = {npj Science of Learning},
  language = {en},
  number = {1}
}

@article{hartshorneWhyGirlsSay2006,
  title = {Why Girls Say 'holded' More than Boys},
  author = {Hartshorne, Joshua K. and Ullman, Michael T.},
  year = {2006},
  month = jan,
  volume = {9},
  pages = {21--32},
  issn = {1363-755X, 1467-7687},
  doi = {10.1111/j.1467-7687.2005.00459.x},
  abstract = {Women are better than men at verbal memory tasks, such as remembering word lists. These tasks depend on declarative memory. The declarative/procedural model of language, which posits that the lexicon of stored words is part of declarative memory, while grammatical composition of complex forms depends on procedural memory, predicts a female superiority in aspects of lexical memory. Other neurocognitive models of language have not made this prediction. Here we examine the prediction in past-tense over-regularizations (e.g. holded) produced by children. We expected that girls would remember irregular past-tense forms (held) better than boys, and thus would over-regularize less. To our surprise, girls over-regularized far more than boys. We investigated potential explanations for this sex difference. Analyses showed that in girls but not boys, over-regularization rates correlated with measures of the number of similar-sounding regulars (folded, molded). This sex difference in phonological neighborhood effects is taken to suggest that girls tend to produce over-regularizations in associative lexical memory, generalizing over stored neighboring regulars, while boys are more likely to depend upon rule-governed affixation (hold + -ed). The finding is consistent with the hypothesis that, likely due to their superior lexical abilities, females tend to retrieve from memory complex forms (walked) that men generally compose with the grammatical system (walk + -ed). The results suggest that sex may be an important factor in the acquisition and computation of language.},
  file = {/Users/megcychosz/Zotero/storage/JHEP6Q9Q/Hartshorne and Ullman - 2006 - Why girls say 'holded' more than boys.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {1}
}

@article{havronEffectOlderSiblings2019,
  title = {The {{Effect}} of {{Older Siblings}} on {{Language Development}} as a {{Function}} of {{Age Difference}} and {{Sex}}},
  author = {Havron, Naomi and Ramus, Franck and Heude, Barbara and Forhan, Anne and Cristia, Alejandrina and Peyre, Hugo and {the EDEN Mother-Child Cohort Study Group} and {Annesi-Maesano}, I. and Bernard, J. Y. and Botton, J. and Charles, M. A. and {Dargent-Molina}, P. and {de Lauzon-Guillain}, B. and Ducimeti{\`e}re, P. and De Agostini, M. and Foliguet, B. and Forhan, A. and Fritel, X. and Germa, A. and Goua, V. and Hankard, R. and Heude, B. and Kaminski, M. and Larroque, B. and Lelong, N. and Lepeule, J. and Magnin, G. and Marchand, L. and Nabet, C. and Pierre, F. and Slama, R. and {Saurel-Cubizolles}, M. J. and Schweitzer, M. and Thiebaugeorges, O.},
  year = {2019},
  month = sep,
  volume = {30},
  pages = {1333--1343},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797619861436},
  abstract = {The number of older siblings a child has is negatively correlated with the child's verbal skills, perhaps because of competition for parents' attention. In the current study, we examined the role of siblings' sex and age gap as moderating factors, reasoning that they affect older siblings' tendency to compensate for reduced parental attention. We hypothesized that children with an older sister have better language abilities than children with an older brother, especially when there is a large age gap between the two siblings. We reanalyzed data from the EDEN cohort (N = 1,154) and found that children with an older sister had better language skills than those with an older brother. Contrary to predictions, results showed that the age gap between siblings was not associated with language skills and did not interact with sex. Results suggest that the negative effect of older siblings on language development may be entirely due to the role of older brothers. Our findings invite further research on the mechanisms involved in this effect.},
  file = {/Users/megcychosz/Zotero/storage/BDRVJ5PQ/Havron et al. - 2019 - The Effect of Older Siblings on Language Developme.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {9}
}

@article{havyRoleAuditoryVisual2017,
  title = {The {{Role}} of {{Auditory}} and {{Visual Speech}} in {{Word Learning}} at 18 {{Months}} and in {{Adulthood}}},
  author = {Havy, M{\'e}lanie and Foroud, Afra and Fais, Laurel and Werker, Janet F.},
  year = {2017},
  month = nov,
  volume = {88},
  pages = {2043--2059},
  issn = {00093920},
  doi = {10.1111/cdev.12715},
  abstract = {Visual information influences speech perception both in infants and adults. It is still unknown whether lexical representations are multisensory. To address this question, we exposed 18-monthold infants (n=32) and adults (n=32) to new word-object pairings: participants either heard the acoustic form of the words, or saw the talking face in silence. They were then tested on recognition in the same or the other modality. Both 18-month-old infants and adults learned the lexical mappings when the words were presented auditorily and recognized the mapping at test when the word was presented in either modality, but only adults learned new words in a visualonly presentation. These results suggest developmental changes in the sensory format of lexical representations.},
  file = {/Users/megcychosz/Zotero/storage/RRIC5FC5/Havy et al. - 2017 - The Role of Auditory and Visual Speech in Word Lea.pdf},
  journal = {Child Development},
  language = {en},
  number = {6}
}

@book{hayCausesConsequencesWord2003,
  title = {Causes and {{Consequences}} of {{Word Structure}}},
  author = {Hay, Jennifer},
  year = {2003},
  publisher = {{Routledge}},
  address = {{New York and London}},
  file = {/Users/megcychosz/Zotero/storage/HRVZAH53/Causes and Consequences of Word Structure.pdf},
  language = {en}
}

@article{hayHearingRsandhiRole2018,
  title = {Hearing R-Sandhi: {{The}} Role of Past Experience},
  shorttitle = {Hearing R-Sandhi},
  author = {Hay, Jennifer and Drager, Katie and Gibson, Andy},
  year = {2018},
  volume = {94},
  pages = {360--404},
  issn = {1535-0665},
  doi = {10.1353/lan.2018.0020},
  file = {/Users/megcychosz/Zotero/storage/JU6FD6LG/Hay et al. - 2018 - Hearing r-sandhi The role of past experience.pdf},
  journal = {Language},
  language = {en},
  number = {2}
}

@incollection{hayParsingProductivity2002,
  title = {Parsing and Productivity},
  booktitle = {Yearbook of {{Morphology}} 2001},
  author = {Hay, Jennifer and Baayen, Harald},
  editor = {Booij, Geert and {van Marle}, Jaap and Anderson, Stephen and Aronoff, Mark and Baker, Mark and Bauer, Laurie and Botha, Rudie and Bybee, Joan and {Carstairs-McCarthy}, Andrew and Corbett, Greville and Dressler, Wolfgang and Haspelmath, Martin and Hoeksema, Jack and Lieber, Rochelle and Matthews, Peter and Rainer, Franz and Scalise, Sergio and Schultink, Henk and Spencer, Andrew and Booij, Geert and Van Marle, Jaap},
  year = {2002},
  pages = {203--235},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  doi = {10.1007/978-94-017-3726-5_8},
  file = {/Users/megcychosz/Zotero/storage/MKBQDLV5/Hay and Baayen - 2002 - Parsing and productivity.pdf},
  isbn = {978-90-481-6061-7 978-94-017-3726-5},
  language = {en}
}

@article{hayPhonemeInventorySize2007,
  title = {Phoneme Inventory Size and Population Size},
  author = {Hay, Jennifer. and Bauer, Laurie},
  year = {2007},
  volume = {83},
  pages = {388--400},
  issn = {1535-0665},
  doi = {10.1353/lan.2007.0071},
  file = {/Users/megcychosz/Zotero/storage/82BXAGUI/Hay and Bauer - 2007 - Phoneme inventory size and population size.pdf},
  journal = {Language},
  language = {en},
  number = {2}
}

@article{hayTrackingWordFrequency2015,
  title = {Tracking Word Frequency Effects through 130 Years of Sound Change},
  author = {Hay, Jennifer B. and Pierrehumbert, Janet B. and Walker, Abby J. and LaShell, Patrick},
  year = {2015},
  month = jun,
  volume = {139},
  pages = {83--91},
  issn = {00100277},
  doi = {10.1016/j.cognition.2015.02.012},
  abstract = {Contemporary New Zealand English has distinctive pronunciations of three characteristic vowels. Did the evolution of these distinctive pronunciations occur in all words at the same time or were different words affected differently? We analyze the changing pronunciation of New Zealand English in a large set of recordings of speakers born over a 130 year period. We show that low frequency words were at the forefront of these changes and higher frequency words lagged behind. A long-standing debate exists between authors claiming that high frequency words lead regular sound change and others claiming that there are no frequency effects. The leading role of low frequency words is surprising in this context. It can be elucidated in models of lexical processing that include detailed word-specific memories. \'O 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).},
  file = {/Users/megcychosz/Zotero/storage/WDWNI64K/Hay et al. - 2015 - Tracking word frequency effects through 130years o.pdf},
  journal = {Cognition},
  language = {en}
}

@article{hazanDevelopmentPhonemicCategorization2000,
  title = {The Development of Phonemic Categorization in Children Aged 6\textendash 12},
  author = {Hazan, Valerie and Barrett, Sarah},
  year = {2000},
  month = oct,
  volume = {28},
  pages = {377--396},
  issn = {00954470},
  doi = {10.1006/jpho.2000.0121},
  file = {/Users/megcychosz/Zotero/storage/XSIU7DJD/Hazan and Barrett - 2000 - The development of phonemic categorization in chil.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {4}
}

@article{hazanSpeechCommunicationLife,
  title = {Speech {{Communication Across}} the {{Life Span}}},
  author = {Hazan, Valerie},
  pages = {8},
  file = {/Users/megcychosz/Zotero/storage/9J9WTGZ4/Hazan - Speech Communication Across the Life Span.pdf},
  language = {en}
}

@article{hedrickWeightingCuesFricative2011,
  title = {Weighting of Cues for Fricative Place of Articulation Perception by Children Wearing Cochlear Implants},
  author = {Hedrick, Mark and Bahng, Junghwa and {von Hapsburg}, Deborah and Younger, Mary Sue},
  year = {2011},
  month = aug,
  volume = {50},
  pages = {540--547},
  issn = {1499-2027, 1708-8186},
  doi = {10.3109/14992027.2010.549515},
  abstract = {Objective: To determine how children wearing cochlear implants weight cues for fricative perception compared to age-matched children with normal hearing. Design: Two seven-step continua of synthetic CV syllables were constructed, with frication pole varied from /s/ to /{$\int$}/ within the continuum, and appropriate formant transition values varied across continua. Relative weights applied to the frication, transition, and interaction cues were determined. Study Sample: Ten 5\textendash 7-year-old children with normal hearing and ten 5\textendash 8-year-old children wearing cochlear implants participated. Results: Both groups of children gave more perceptual weight to the frication spectral cue than to the formant transition cue. Children with normal hearing gave small but significant weight to formant transitions, but the children wearing cochlear implants did not. The degree of cue interaction was significant for children with normal hearing but was not for children wearing cochlear implants. Conclusions: Children wearing a cochlear implant use similar cue-weighting strategies as normal listeners (i.e. all apply more weight to the frication noise than to the transition cue), but may have limitations in processing formant transitions and in cue interaction.},
  file = {/Users/megcychosz/Zotero/storage/FTJ928GT/Hedrick et al. - 2011 - Weighting of cues for fricative place of articulat.pdf},
  journal = {International Journal of Audiology},
  language = {en},
  number = {8}
}

@misc{heggartyQuechuaLanguagePeople2006,
  title = {Quechua - the Language of the People Who Built This ({{Machu Pikchu}})},
  author = {Heggarty, P.},
  year = {2006}
}

@article{heinzSentenceWordComplexity2011,
  title = {Sentence and {{Word Complexity}}},
  author = {Heinz, Jeffrey and Idsardi, William},
  year = {2011},
  month = jul,
  volume = {333},
  pages = {295--297},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1210358},
  file = {/Users/megcychosz/Zotero/storage/WKZ9WBBI/Heinz and Idsardi - 2011 - Sentence and Word Complexity.pdf},
  journal = {Science},
  language = {en},
  number = {6040}
}

@article{heinzWhatComplexityDifferences2013,
  title = {What {{Complexity Differences Reveal About Domains}} in {{Language}}*},
  author = {Heinz, Jeffrey and Idsardi, William},
  year = {2013},
  month = jan,
  volume = {5},
  pages = {111--131},
  issn = {17568757},
  doi = {10.1111/tops.12000},
  abstract = {An important distinction between phonology and syntax has been overlooked. All phonological patterns belong to the regular region of the Chomsky Hierarchy, but not all syntactic patterns do. We argue that the hypothesis that humans employ distinct learning mechanisms for phonology and syntax currently offers the best explanation for this difference.},
  file = {/Users/megcychosz/Zotero/storage/2UD88DZG/Heinz and Idsardi - 2013 - What Complexity Differences Reveal About Domains i.pdf},
  journal = {Topics in Cognitive Science},
  language = {en},
  number = {1}
}

@article{heislerInfluencePhonotacticProbability2016,
  title = {The {{Influence}} of {{Phonotactic Probability}} and {{Neighborhood Density}} on {{Children}}'s {{Production}} of {{Newly Learned Words}}},
  author = {Heisler, Lori and Goffman, Lisa},
  year = {2016},
  month = jul,
  volume = {12},
  pages = {338--356},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2015.1117977},
  abstract = {A word learning paradigm was used to teach children novel words that varied in phonotactic probability and neighborhood density. The effects of frequency and density on speech production were examined when phonetic forms were nonreferential (i.e., when no referent was attached) and when phonetic forms were referential (i.e., when a referent was attached through fast mapping). Two methods of analysis were included: kinematic variability of speech movement patterning and measures of segmental accuracy. Results showed that phonotactic frequency influenced the stability of movement patterning whereas neighborhood density influenced phoneme accuracy. Motor learning was observed in both nonreferential and referential novel words. Forms with low phonotactic probability and low neighborhood density showed a word learning effect when a referent was assigned during fast mapping. These results elaborate on and specify the nature of interactivity observed across lexical, phonological, and articulatory domains.},
  file = {/Users/megcychosz/Zotero/storage/5X3HVM86/Heisler and Goffman - 2016 - The Influence of Phonotactic Probability and Neigh.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {3}
}

@article{hellwigChilddirectedLanguageHow2020,
  title = {Child-Directed Language \textendash{} and How It Informs the Documentation and Description of the Adult Language},
  author = {Hellwig, Birgit and Jung, Dagmar},
  year = {2020},
  volume = {14},
  pages = {27},
  file = {/Users/megcychosz/Zotero/storage/2DDE8VUA/Hellwig and Jung - 2020 - Child-directed language – and how it informs the d.pdf},
  journal = {Language Documentation},
  language = {en}
}

@article{hellwigChildLanguageDocumentation,
  title = {Child {{Language Documentation}}: {{A Pilot Project}} in {{Papua New Guinea}}},
  author = {Hellwig, Birgit},
  pages = {20},
  abstract = {The central aim of language documentation is to comprehensively document the characteristic speech practices of a community. Such practices necessarily also include child language and child-directed speech-and yet there are only very few documentation projects that focus on language from tand with children. This paper argues for studying first language acquisition and socialization within a language documentation context, focusing on the types of data needed for such a study and drawing on the insights from a pilot project among the Qaqet of Papua New Guinea. The aim of this pilot project was to investigate the feasibility of a comprehensive child language documentation project, and this paper discusses the central challenges to such an endeavour and shows how they were addressed in the project.},
  file = {/Users/megcychosz/Zotero/storage/LM423K3N/Hellwig - Child Language Documentation A Pilot Project in P.pdf},
  language = {en}
}

@article{hellwigMethodologicalToolsLinguistic2019,
  title = {Methodological {{Tools}} for {{Linguistic Description}} and {{Typology}}},
  author = {Hellwig, Birgit},
  editor = {Lahaussois, Aim{\'e}e and Vuillermet, Marine},
  year = {2019},
  volume = {16},
  file = {/Users/megcychosz/Zotero/storage/4TV9SVNX/Lahaussois and Vuillermet - Methodological Tools for Linguistic Description an.pdf},
  journal = {Language Documentation \& Conservation},
  language = {en},
  series = {Methodological {{Tools}} for {{Linguistic Description}} and {{Typology}}}
}

@article{hermesResoundingClarionCall2017,
  title = {Resounding the Clarion Call: {{Indigenous}} Language Learners and Documentation},
  author = {Hermes, Mary and Engman, Mel M},
  year = {2017},
  volume = {14},
  pages = {59--87},
  file = {/Users/megcychosz/Zotero/storage/D4TXQPCQ/Hermes and Engman - Resounding the clarion call Indigenous language l.pdf},
  journal = {Resounding the clarion call: Indigenous language learners and documentation},
  language = {en}
}

@article{hicksListeningEffortFatigue2002,
  title = {Listening {{Effort}} and {{Fatigue}} in {{School}}-{{Age Children With}} and {{Without Hearing Loss}}},
  author = {Hicks, Candace Bourland and Tharpe, Anne Marie},
  year = {2002},
  month = jun,
  volume = {45},
  pages = {573--584},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2002/046)},
  abstract = {Vanderbilt Bill Wilkerson Center for Otolaryngology and Communication Sciences Nashville, TN Parents, audiologists, and educators have long speculated that children with hearing loss must expend more effort and, therefore, fatigue more easily than their peers with normal hearing when listening in adverse acoustic conditions. Until now, however, very few studies have been conducted to substantiate these speculations. Two experiments were conducted with school-age children with mild-to-moderate hearing loss and with normal hearing. In the first experiment, salivary cortisol levels and a self-rating measure were used to measure fatigue. Neither cortisol measurements nor self-rated measures of fatigue revealed significant differences between children with hearing loss and their normalhearing peers. In the second experiment, however, a dual-task paradigm used to study listening effort indicated that children with hearing loss expend more effort in listening than children with normal hearing. Results are discussed in terms of clinical application and future research needs.},
  file = {/Users/megcychosz/Zotero/storage/WCS449XK/Hicks and Tharpe - 2002 - Listening Effort and Fatigue in School-Age Childre.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {3}
}

@article{hillenbrandAcousticCharacteristicsAmerican1995,
  title = {Acoustic Characteristics of {{American English}} Vowels},
  author = {Hillenbrand, James and Getty, Laura A. and Wheeler, Kimberlee and Clark, Michael J.},
  year = {1995},
  volume = {97},
  pages = {3099--3111},
  issn = {0001-4966},
  doi = {10.1121/1.409456},
  file = {/Users/megcychosz/Zotero/storage/NHWEDHPZ/Hillenbrand et al. - 1994 - Acoustic characteristics of American English vowel.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@incollection{himmelmannLanguageDocumentationWhat2006,
  title = {Language Documentation: {{What}} Is It and What Is It Good For?},
  shorttitle = {Chapter 1 {{Language}} Documentation},
  booktitle = {Essentials of {{Language Documentation}}},
  author = {Himmelmann, Nikolaus P.},
  editor = {Gippert, Jost and Himmelmann, Nikolaus P. and Mosel, Ulrike},
  year = {2006},
  publisher = {{Mouton de Gruyter}},
  address = {{Berlin, New York}},
  doi = {10.1515/9783110197730.1},
  file = {/Users/megcychosz/Zotero/storage/9EVP3LMJ/Gippert et al. - 2006 - Chapter 1 Language documentation What is it and w.pdf},
  isbn = {978-3-11-019773-0},
  language = {en},
  series = {Trends in {{Linguistics}}: {{Studies}} and {{Monographs}} 178}
}

@article{hintzEvidentialSystemSihuas,
  title = {The Evidential System in {{Sihuas Quechua}}: Personal vs. Shared Knowledge},
  author = {Hintz, Diane and International, SIL},
  pages = {6},
  file = {/Users/megcychosz/Zotero/storage/36KV2QLV/Hintz and International - The evidential system in Sihuas Quechua personal .pdf;/Users/megcychosz/Zotero/storage/WV33NQPF/Hintz evidentiality quechua notes.pdf},
  language = {en}
}

@article{hirsh-pasekContributionEarlyCommunication2015,
  title = {The {{Contribution}} of {{Early Communication Quality}} to {{Low}}-{{Income Children}}'s {{Language Success}}},
  author = {{Hirsh-Pasek}, Kathy and Adamson, Lauren B. and Bakeman, Roger and Owen, Margaret Tresch and Golinkoff, Roberta Michnick and Pace, Amy and Yust, Paula K. S. and Suma, Katharine},
  year = {2015},
  month = jul,
  volume = {26},
  pages = {1071--1083},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797615581493},
  abstract = {The disparity in the amount and quality of language that low-income children hear relative to their more-affluent peers is often referred to as the 30-million-word gap. Here, we expand the literature about this disparity by reporting the relative contributions of the quality of early parent-child communication and the quantity of language input in 60 low-income families. Including both successful and struggling language learners from the National Institute of Child Health and Human Development Study of Early Child Care and Youth Development, we noted wide variation in the quality of nonverbal and verbal interactions (symbol-infused joint engagement, routines and rituals, fluent and connected communication) at 24 months, which accounted for 27\% of the variance in expressive language 1 year later. These indicators of quality were considerably more potent predictors of later language ability than was the quantity of mothers' words during the interaction or sensitive parenting. Bridging the word gap requires attention to how caregivers and children establish a communication foundation within low-income families.},
  file = {/Users/megcychosz/Zotero/storage/HY2LIG8V/Hirsh-Pasek et al. - 2015 - The Contribution of Early Communication Quality to.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {7}
}

@article{hitchWorkingMemoryChildren1983,
  title = {Working Memory in Children},
  author = {Hitch, G. J. and Halliday, M. S.},
  year = {1983},
  volume = {302},
  pages = {325--340},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  number = {1110}
}

@book{hlavacStargazerWellFormattedRegression2018,
  title = {Stargazer: {{Well}}-{{Formatted Regression}} and {{Summary Statistics Tables}}},
  author = {Hlavac, Marek},
  year = {2018},
  publisher = {{Central European Labour Studies Institute (CELSI)}},
  address = {{Bratislava, Slovakia}}
}

@article{hoffNonwordRepetitionAssesses2008,
  title = {Non-Word Repetition Assesses Phonological Memory and Is Related to Vocabulary Development in 20- to 24-Month-Olds},
  author = {Hoff, Erika and Core, Cynthia and Bridges, Kelly},
  year = {2008},
  month = nov,
  volume = {35},
  pages = {903--916},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000908008751},
  abstract = {Two studies test the hypotheses that individual differences in phonological memory among children younger than two years can be assessed using a non-word repetition task (NWR) and that these differences are related to the children's rates of vocabulary development. NWR accuracy, real word repetition accuracy and productive vocabulary were assessed in 15 children between 1; 9 and 2;0 in Study 1 and in 21 children between 1; 8 and 2 ; 0 in Study 2. In both studies, NWR accuracy was significantly related to vocabulary percentile and, furthermore, uniquely accounted for a substantial portion of the variance in vocabulary when real word repetition accuracy was held constant. The findings establish NWR as a valid measure of phonological memory in very young children, and they open the door for further studies of the role of phonological memory in early word learning.},
  file = {/Users/megcychosz/Zotero/storage/IWPKE9IZ/Hoff et al. - 2008 - Non-word repetition assesses phonological memory a.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {4}
}

@article{hoffSpecificityEnvironmentalInfluence2003,
  title = {The {{Specificity}} of {{Environmental Influence}}: {{Socioeconomic Status Affects Early Vocabulary Development Via Maternal Speech}}},
  shorttitle = {The {{Specificity}} of {{Environmental Influence}}},
  author = {Hoff, Erika},
  year = {2003},
  month = oct,
  volume = {74},
  pages = {1368--1378},
  issn = {0009-3920, 1467-8624},
  doi = {10.1111/1467-8624.00612},
  file = {/Users/megcychosz/Zotero/storage/6YZLDKSD/Hoff - 2003 - The Specificity of Environmental Influence Socioe.pdf},
  journal = {Child Development},
  language = {en},
  number = {5}
}

@article{hollidayQuantifyingRobustnessEnglish2015,
  title = {Quantifying the {{Robustness}} of the {{English Sibilant Fricative Contrast}} in {{Children}}},
  author = {Holliday, Jeffrey J. and Reidy, Patrick F. and Beckman, Mary E. and Edwards, Jan},
  year = {2015},
  month = jun,
  volume = {58},
  pages = {622--637},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2015_JSLHR-S-14-0090},
  abstract = {Purpose               Four measures of children's developing robustness of phonological contrast were compared to see how they correlated with age, vocabulary size, and adult listeners' correctness ratings.                                         Method               Word-initial sibilant fricative productions from eighty-one 2- to 5-year-old children and 20 adults were phonetically transcribed and acoustically analyzed. Four measures of robustness of contrast were calculated for each speaker on the basis of the centroid frequency measured from each fricative token. Productions that were transcribed as correct from different children were then used as stimuli in a perception experiment in which adult listeners rated the goodness of each production.                                         Results               Results showed that the degree of category overlap, quantified as the percentage of a child's productions whose category could be correctly predicted from the output of a mixed-effects logistic regression model, was the measure that correlated best with listeners' goodness judgments.                                         Conclusions               Even when children's productions have been transcribed as correct, adult listeners are sensitive to within-category variation quantified by the child's degree of category overlap. Further research is needed to explore the relationship between the age of a child and adults' sensitivity to different types of within-category variation in children's speech.},
  file = {/Users/megcychosz/Zotero/storage/A94PJ7ZS/Holliday et al. - 2015 - Quantifying the Robustness of the English Sibilant.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {3}
}

@article{holloApplyingGeneralizabilityTheory2020,
  title = {Applying {{Generalizability Theory}} to {{Optimize Analysis}} of {{Spontaneous Teacher Talk}} in {{Elementary Classrooms}}},
  author = {Hollo, Alexandra and Staubitz, Johanna L. and Chow, Jason C.},
  year = {2020},
  month = jun,
  volume = {63},
  pages = {1947--1957},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2020_JSLHR-19-00118},
  file = {/Users/megcychosz/Zotero/storage/BALDWB62/Hollo et al. - 2020 - Applying Generalizability Theory to Optimize Analy.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {6}
}

@article{holtContributionFamilyEnvironment2012,
  title = {Contribution of {{Family Environment}} to {{Pediatric Cochlear Implant Users}}' {{Speech}} and {{Language Outcomes}}: {{Some Preliminary Findings}}},
  shorttitle = {Contribution of {{Family Environment}} to {{Pediatric Cochlear Implant Users}}' {{Speech}} and {{Language Outcomes}}},
  author = {Holt, Rachael Frush and Beer, Jessica and Kronenberger, William G. and Pisoni, David B. and Lalonde, Kaylah},
  year = {2012},
  month = jun,
  volume = {55},
  pages = {848--864},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2011/11-0143)},
  abstract = {Purpose\textemdash To evaluate the family environments of children with cochlear implants and to examine relationships between family environment and post-implant language development and executive function. Method\textemdash Forty-five families of children with cochlear implants completed a self-report family environment questionnaire (FES) and an inventory of executive function (BRIEF/BRIEF-P). Children's receptive vocabulary (PPVT-4) and global language skills (PLS-4/CELF-4) were also evaluated. Results\textemdash The family environments of children with cochlear implants differed from those of normal-hearing children, but not in clinically significant ways. Language development and executive function were found to be atypical, but not uncharacteristic of this clinical population. Families with higher levels of self-reported control had children with smaller vocabularies. Families reporting a higher emphasis on achievement had children with fewer executive function and working memory problems. Finally, families reporting a higher emphasis on organization had children with fewer problems related to inhibition. Conclusions\textemdash Some of the variability in cochlear implantation outcomes that have protracted periods of development is related to family environment. Because family environment can be modified and enhanced by therapy or education, these preliminary findings hold promise for future work in helping families to create robust language-learning environments that can maximize their child's potential with a cochlear implant.},
  file = {/Users/megcychosz/Zotero/storage/V6QT2LLH/Holt et al. - 2012 - Contribution of Family Environment to Pediatric Co.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {3}
}

@article{holtDevelopmentalEffectsFamily2013,
  title = {Developmental {{Effects}} of {{Family Environment}} on {{Outcomes}} in {{Pediatric Cochlear Implant Recipients}}:},
  shorttitle = {Developmental {{Effects}} of {{Family Environment}} on {{Outcomes}} in {{Pediatric Cochlear Implant Recipients}}},
  author = {Holt, Rachael Frush and Beer, Jessica and Kronenberger, William G. and Pisoni, David B.},
  year = {2013},
  month = apr,
  volume = {34},
  pages = {388--395},
  issn = {1531-7129},
  doi = {10.1097/MAO.0b013e318277a0af},
  abstract = {Objective\textemdash To examine and compare the family environment of preschool- and school-age children with cochlear implants and assess its influence on children's executive function and spoken language skills. Study Design\textemdash Retrospective between-subjects design. Setting\textemdash Outpatient research laboratory. Patients\textemdash Prelingually deaf children with cochlear implants and no additional disabilities, and their families. Intervention(s)\textemdash Cochlear implantation and speech-language therapy. Main Outcome Measures\textemdash Parents completed the Family Environment Scale and the Behavior Rating Inventory of Executive Function (or the preschool version). Children were tested using the Peabody Picture Vocabulary Test-4 and either the Preschool Language Scales-4 or the Clinical Evaluation of Language Fundamentals\textendash 4. Results\textemdash The family environments of children with cochlear implants differed from normative data obtained from hearing children, but average scores were within one standard deviation of norms on all subscales. Families of school-age children reported higher levels of control than those of preschool-age children. Preschool-age children had fewer problems with emotional control when families reported higher levels of support and lower levels of conflict. School-age children had fewer problems with inhibition but more problems with shifting of attention when families reported lower levels of conflict. School-age children's receptive vocabularies were enhanced by families with lower levels of control and higher levels of organization. Conclusions\textemdash Family environment and its relation to language skills and executive function development differed across the age groups in this sample of children with cochlear implants. Because family dynamics is one developmental/environmental factor that can be altered with},
  file = {/Users/megcychosz/Zotero/storage/RYNBPWFT/Holt et al. - 2013 - Developmental Effects of Family Environment on Out.pdf},
  journal = {Otology \& Neurotology},
  language = {en},
  number = {3}
}

@article{holzingerImpactFamilyEnvironment2020,
  title = {The {{Impact}} of {{Family Environment}} on {{Language Development}} of {{Children With Cochlear Implants}}: {{A Systematic Review}} and {{Meta}}-{{Analysis}}},
  shorttitle = {The {{Impact}} of {{Family Environment}} on {{Language Development}} of {{Children With Cochlear Implants}}},
  author = {Holzinger, Daniel and Dall, Magdalena and {Sanduvete-Chaves}, Susana and Salda{\~n}a, David and {Chac{\'o}n-Moscoso}, Salvador and Fellinger, Johannes},
  year = {2020},
  month = sep,
  volume = {41},
  pages = {1077--1091},
  issn = {0196-0202},
  doi = {10.1097/AUD.0000000000000852},
  abstract = {The results on the impact of family involvement/participation in intervention on child language development were more heterogeneous. The meta-analysis included mainly cross-sectional studies and identified low to moderate benefits, r = 0.380, p {$\leq$} 0.052, 95\% CI = -0.004 to 0.667, that almost attained significance level. Socioeconomic status, mainly operationalized by parental level of education, showed a positive correlation with child language development in most studies. The meta-analysis confirmed an overall low and nonsignificant average correlation coefficient, r = 0.117, p = 0.262, 95\% CI = -0.087 to 0.312. A limitation of the study was the lack of some potentially relevant variables, such as multilingualism or family screen time. Conclusions: These data support the hypothesis that parental linguistic input during the first years after cochlear implantation strongly predicts later child language outcomes. Effects of parental involvement in intervention and parental education are comparatively weaker and more heterogeneous. These findings underscore the need for early-intervention programs for children with cochlear implants focusing on providing support to parents for them to increase their children's exposure to highquality conversation.},
  file = {/Users/megcychosz/Zotero/storage/GKDZKTWL/Holzinger et al. - 2020 - The Impact of Family Environment on Language Devel.pdf},
  journal = {Ear \& Hearing},
  language = {en},
  number = {5}
}

@article{hoodPreschoolHomeLiteracy2008,
  title = {Preschool Home Literacy Practices and Children's Literacy Development: {{A}} Longitudinal Analysis},
  author = {Hood, Michelle and Conlon, Elizabeth and Andrews, Glenda},
  year = {2008},
  volume = {100},
  pages = {252--271},
  journal = {Journal of Educational Psychology},
  number = {2}
}

@article{hooleComparativeInvestigationCoarticulation1993,
  title = {A {{Comparative Investigation}} of {{Coarticulation}} in {{Fricatives}}: {{Electropalatographic}}, {{Electromagnetic}}, and {{Acoustic Data}}},
  shorttitle = {A {{Comparative Investigation}} of {{Coarticulation}} in {{Fricatives}}},
  author = {Hoole, Philip and {Nguyen-Trong}, Noel and Hardcastle, William},
  year = {1993},
  month = apr,
  volume = {36},
  pages = {235--260},
  issn = {0023-8309, 1756-6053},
  doi = {10.1177/002383099303600307},
  file = {/Users/megcychosz/Zotero/storage/U5NCFIXA/Hoole et al. - 1993 - A Comparative Investigation of Coarticulation in F.pdf},
  journal = {Language and Speech},
  language = {en},
  number = {2-3}
}

@article{hornbergerLanguageRevitalisationAndes1996,
  title = {Language {{Revitalisation}} in the {{Andes}}: {{Can}} the {{Schools Reverse Language Shift}}?},
  shorttitle = {Language {{Revitalisation}} in the {{Andes}}},
  author = {Hornberger, Nancy H. and King, Kendall A.},
  year = {1996},
  month = dec,
  volume = {17},
  pages = {427--441},
  issn = {0143-4632, 1747-7557},
  doi = {10.1080/01434639608666294},
  file = {/Users/megcychosz/Zotero/storage/AZ788DG2/Hornberger and King - 1996 - Language Revitalisation in the Andes Can the Scho.pdf},
  journal = {Journal of Multilingual and Multicultural Development},
  language = {en},
  number = {6}
}

@article{hornbergerMultilingualEducationPolicy2009,
  title = {Multilingual Education Policy and Practice: {{Ten}} Certainties (Grounded in {{Indigenous}} Experience)},
  shorttitle = {Multilingual Education Policy and Practice},
  author = {Hornberger, Nancy H.},
  year = {2009},
  month = apr,
  volume = {42},
  pages = {197--211},
  issn = {0261-4448, 1475-3049},
  doi = {10.1017/S0261444808005491},
  abstract = {Although multilingualism and multilingual education have existed for centuries, our 21st-century entrance into the new millennium has brought renewed interest and contestation around this educational alternative. Ethnolinguistic diversity and inequality, intercultural communication and contact, and global political and economic interdependence are more than ever acknowledged realities of today's world, and all of them put pressures on our educational systems. Now, as throughout history, multilingual education offers the best possibilities for preparing coming generations to participate in constructing more just and democratic societies in our globalized and intercultural world; however, it is not unproblematically achieved. There are many unanswered questions and doubts as to policy and implementation, program and curricular design, classroom instruction practices, pedagogy, and teacher professional development, but there is also much that we understand and know very well, based on empirical research in many corners of the world. Here I highlight Bolivian and other Indigenous educational experiences with which I am most familiar, and which capture certainties that hold beyond the particular instances I describe. My emphasis is on what we know and are sure of, and my goal is to convey my deep conviction that multilingual education constitutes a wide and welcoming educational doorway toward peaceful coexistence of peoples and especially restoration and empowerment of those who have been historically oppressed.},
  file = {/Users/megcychosz/Zotero/storage/PP7HLY73/Hornberger - 2009 - Multilingual education policy and practice Ten ce.pdf},
  journal = {Language Teaching},
  language = {en},
  number = {2}
}

@article{houdeSpeechProductionState2011,
  title = {Speech {{Production}} as {{State Feedback Control}}},
  author = {Houde, John F. and Nagarajan, Srikantan S.},
  year = {2011},
  volume = {5},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2011.00082},
  abstract = {Spoken language exists because of a remarkable neural process. Inside a speaker's brain, an intended message gives rise to neural signals activating the muscles of the vocal tract. The process is remarkable because these muscles are activated in just the right way that the vocal tract produces sounds a listener understands as the intended message. What is the best approach to understanding the neural substrate of this crucial motor control process? One of the key recent modeling developments in neuroscience has been the use of state feedback control (SFC) theory to explain the role of the CNS in motor control. SFC postulates that the CNS controls motor output by (1) estimating the current dynamic state of the thing (e.g., arm) being controlled, and (2) generating controls based on this estimated state. SFC has successfully predicted a great range of non-speech motor phenomena, but as yet has not received attention in the speech motor control community. Here, we review some of the key characteristics of speech motor control and what they say about the role of the CNS in the process. We then discuss prior efforts to model the role of CNS in speech motor control, and argue that these models have inherent limitations \textendash{} limitations that are overcome by an SFC model of speech motor control which we describe. We conclude by discussing a plausible neural substrate of our model.},
  file = {/Users/megcychosz/Zotero/storage/QELCBZZL/Houde and Nagarajan - 2011 - Speech Production as State Feedback Control.pdf},
  journal = {Frontiers in Human Neuroscience},
  language = {en}
}

@article{houstonInfantsLongTermMemory2003,
  title = {Infants' {{Long}}-{{Term Memory}} for the {{Sound Patterns}} of {{Words}} and {{Voices}}.},
  author = {Houston, Derek M. and Jusczyk, Peter W.},
  year = {2003},
  volume = {29},
  pages = {1143--1154},
  issn = {1939-1277, 0096-1523},
  doi = {10.1037/0096-1523.29.6.1143},
  file = {/Users/megcychosz/Zotero/storage/MZTCYMY9/Houston and Jusczyk - 2003 - Infants' Long-Term Memory for the Sound Patterns o.pdf},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  language = {en},
  number = {6}
}

@article{houstonWordLearningDeaf2012,
  title = {Word Learning in Deaf Children with Cochlear Implants: Effects of Early Auditory Experience: {{Word}} Learning in Children with Cochlear Implants},
  shorttitle = {Word Learning in Deaf Children with Cochlear Implants},
  author = {Houston, Derek M. and Stewart, Jessica and Moberly, Aaron and Hollich, George and Miyamoto, Richard T.},
  year = {2012},
  month = may,
  volume = {15},
  pages = {448--461},
  issn = {1363755X},
  doi = {10.1111/j.1467-7687.2012.01140.x},
  file = {/Users/megcychosz/Zotero/storage/CVFFAMIF/Houston et al. - 2012 - Word learning in deaf children with cochlear impla.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {3}
}

@article{howsonPsycholinguisticMethodMeasuring2020,
  title = {A Psycholinguistic Method for Measuring Coarticulation in Child and Adult Speech},
  author = {Howson, Phil J. and Kallay, Jeffrey E. and Redford, Melissa A.},
  year = {2020},
  month = sep,
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01464-7},
  abstract = {A perceiver's ability to accurately predict target sounds in a forward-gated AV speech task indexes the strength and scope of anticipatory coarticulation in adult speech (Redford et al., JASA, 144, 2447\textendash 2461, 2018). This suggests a perception-based method for studying coarticulation in populations who may poorly tolerate the more invasive or restrictive techniques used to measure speech movements directly. But the use of perception to measure production begs the question of confounding influences on perceiver performance and thus on the reliability and generalizability of the proposed method. The present study was therefore designed to test whether a gated AV speech method for measuring coarticulation provides reliable results across different study populations (child versus adult), different task environments (in-lab versus online), and different coarticulatory directions (forward/anticipatory versus backward/carryover). The results indicated excellent measurement reliability across age groups in the forward/anticipatory measurement direction, though more perceivers are needed to achieve the same levels of agreement and consistency when the task is completed online. Accuracy was lower in the backward/carryover direction, and although agreement and consistency were still reasonably high across perceivers, the effect of age group differed between the laboratory and online environments, suggesting measurement error in one or both environments. Overall, the results support using in-lab or online perceptual judgments to measure anticipatory coarticulation in developmental studies of speech production. Further validation study is needed before the method can be extended to measure carryover coarticulation.},
  file = {/Users/megcychosz/Zotero/storage/767ZQU9C/Howson et al. - 2020 - A psycholinguistic method for measuring coarticula.pdf},
  journal = {Behavior Research Methods},
  language = {en}
}

@article{hseihDifferencesEnglishPlural1999,
  title = {Some Differences between {{English}} Plural Noun Inflections and Third Singular Verb Inflections in the Input: {{The}} Contributions of Frequency, Sentence Position, and Duration},
  author = {Hseih, L. and Leonard, L. B. and Swanson, L.},
  year = {1999},
  volume = {26},
  pages = {531--543},
  journal = {Journal of Child Language},
  number = {3}
}

@article{huangEvidenceVisualWorld2020,
  title = {Evidence from the Visual World Paradigm Raises Questions about Unaccusativity and Growth Curve Analyses},
  author = {Huang, Yujing and Snedeker, Jesse},
  year = {2020},
  month = jul,
  volume = {200},
  pages = {104251},
  issn = {00100277},
  doi = {10.1016/j.cognition.2020.104251},
  abstract = {Many syntactic theories posit a fundamental structural difference between intransitive verbs with agentive subjects (unergative verbs) and those with theme subjects (unaccusative verbs). This claim garners support from studies finding differences in the online comprehension of these verbs. The present experiments seek to replicate one such finding using the visual world paradigm (Koring, Mak, \& Reuland, 2012). We control for several factors that were uncontrolled in previous studies. We find no differences in the processing of unergative and unaccusative sentences in logistic regressions and cluster analyses. However, in growth curve analyses, modeled closely on the original paper, we find differences between the verb conditions that appear to be statistically significant but are unstable across experiments. A resampling analysis reveals that the growth curve analyses are highly anticonservative, suggesting that the earlier finding was a false positive. We conclude that there is no strong evidence that unaccusatives are processed differently from unergatives. We suggest that growth curve analyses only be used with visual world paradigm data when the underlying assumptions of the analysis can be validated via resampling.},
  file = {/Users/megcychosz/Zotero/storage/4JHPACIA/Huang and Snedeker - 2020 - Evidence from the visual world paradigm raises que.pdf},
  journal = {Cognition},
  language = {en}
}

@article{huangUsingProsodyInfer2017,
  title = {Using Prosody to Infer Discourse Prominence in Cochlear-Implant Users and Normal-Hearing Listeners},
  author = {Huang, Yi Ting and Newman, Rochelle S. and Catalano, Allison and Goupell, Matthew J.},
  year = {2017},
  month = sep,
  volume = {166},
  pages = {184--200},
  issn = {00100277},
  doi = {10.1016/j.cognition.2017.05.029},
  abstract = {Cochlear implants (CIs) provide speech perception to adults with severe-to-profound hearing loss, but the acoustic signal remains severely degraded. Limited access to pitch cues is thought to decrease sensitivity to prosody in CI users, but co-occurring changes in intensity and duration may provide redundant cues. The current study investigates how listeners use these cues to infer discourse prominence. CI users and normal-hearing (NH) listeners were presented with sentences varying in prosody (accented vs. unaccented words) while their eye-movements were measured to referents varying in discourse status (given vs. new categories). In Experiment 1, all listeners inferred prominence when prosody on nouns distinguished categories (``SANDAL'' \textrightarrow{} not sandwich). In Experiment 2, CI users and NH listeners presented with natural speech inferred prominence when prosody on adjectives implied contrast across both categories and properties (``PINK horse'' \textrightarrow{} not the orange horse). In contrast, NH listeners presented with simulated CI (vocoded) speech were sensitive to acoustic differences in prosody, but did not use these cues to infer discourse status. Together, this suggests that exploiting redundant cues for comprehension varies with the demands of language processing and prior experience with the degraded signal.},
  file = {/Users/megcychosz/Zotero/storage/T3927M75/Huang et al. - 2017 - Using prosody to infer discourse prominence in coc.pdf},
  journal = {Cognition},
  language = {en}
}

@article{huberFormantsChildrenWomen1999,
  title = {Formants of Children, Women, and Men: {{The}} Effects of Vocal Intensity Variation},
  shorttitle = {Formants of Children, Women, and Men},
  author = {Huber, Jessica E. and Stathopoulos, Elaine T. and Curione, Gina M. and Ash, Theresa A. and Johnson, Kenneth},
  year = {1999},
  month = sep,
  volume = {106},
  pages = {1532--1542},
  issn = {0001-4966},
  doi = {10.1121/1.427150},
  file = {/Users/megcychosz/Zotero/storage/L79UQDFT/Huber et al. - 1999 - Formants of children, women, and men The effects .pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {3}
}

@article{hudsonkamGettingItRight2009,
  title = {Getting It Right by Getting It Wrong: {{When}} Learners Change Languages},
  shorttitle = {Getting It Right by Getting It Wrong},
  author = {Hudson Kam, Carla L. and Newport, Elissa L.},
  year = {2009},
  month = aug,
  volume = {59},
  pages = {30--66},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2009.01.001},
  abstract = {When natural language input contains grammatical forms that are used probabilistically and inconsistently, learners will sometimes reproduce the inconsistencies; but sometimes they will instead regularize the use of these forms, introducing consistency in the language that was not present in the input. In this paper we ask what produces such regularization. We conducted three artificial language experiments, varying the use of determiners in the types of inconsistency with which they are used, and also comparing adult and child learners. In Experiment 1 we presented adult learners with scattered inconsistency \textendash{} the use of multiple determiners varying in frequency in the same context \textendash{} and found that adults will reproduce these inconsistencies at low levels of scatter, but at very high levels of scatter will regularize the determiner system, producing the most frequent determiner form almost all the time. In Experiment 2 we showed that this is not merely the result of frequency: when determiners are used with low frequencies but in consistent contexts, adults will learn all of the determiners veridically. In Experiment 3 we compared adult and child learners, finding that children will almost always regularize inconsistent forms, whereas adult learners will only regularize the most complex inconsistencies. Taken together, these results suggest that regularization processes in natural language learning, such as those seen in the acquisition of language from non-native speakers or in the formation of young languages, may depend crucially on the nature of language learning by young children.},
  file = {/Users/megcychosz/Zotero/storage/F87HATG2/nihms93598.pdf},
  journal = {Cognitive psychology},
  number = {1},
  pmcid = {PMC2703698},
  pmid = {19324332}
}

@book{huertas-abrilInternationalApproachesBridging2020,
  title = {International {{Approaches}} to {{Bridging}} the {{Language Gap}}:},
  shorttitle = {International {{Approaches}} to {{Bridging}} the {{Language Gap}}},
  editor = {{Huertas-Abril}, Cristina-Ar{\'a}nzazu and {G{\'o}mez-Parra}, Mar{\'i}a Elena and Scheg, Abigail},
  year = {2020},
  publisher = {{IGI Global}},
  doi = {10.4018/978-1-7998-1219-7},
  abstract = {The language gap is one of the most widely cited explanations for existing socioeconomic disparities in educational performance. Since Hart and Risley's 1995 publication on the socioeconomic differences in language input among children living in the United States, the language gap has permeated research, education, policy, and public awareness both in the United States and abroad. Since then, critiques have emerged that question the validity of the language gap as a concept and as means to close educational disparities. In this chapter, the authors build upon existing critiques by highlighting the cultural assumptions and ideologies that underpin the language gap and challenging these assumptions by drawing upon cross-cultural research on human development. Future directions are discussed on ways to move research forward using methodology that attends to cultural variability, builds on families' funds of knowledge, and recognizes societal contexts and structures that address systemic inequities.},
  file = {/Users/megcychosz/Zotero/storage/X2I8ZW7E/Huertas-Abril and Gómez-Parra - 2020 - International Approaches to Bridging the Language .pdf},
  isbn = {978-1-79981-219-7 978-1-79981-221-0},
  language = {en},
  series = {Advances in {{Linguistics}} and {{Communication Studies}}}
}

@article{hurtadoDoesInputInfluence2008,
  title = {Does Input Influence Uptake? {{Links}} between Maternal Talk, Processing Speed and Vocabulary Size in {{Spanish}}-Learning Children},
  shorttitle = {Does Input Influence Uptake?},
  author = {Hurtado, Nereyda and Marchman, Virginia A. and Fernald, Anne},
  year = {2008},
  month = nov,
  volume = {11},
  pages = {F31-F39},
  issn = {1363755X, 14677687},
  doi = {10.1111/j.1467-7687.2008.00768.x},
  abstract = {It is well established that variation in caregivers' speech is associated with language outcomes, yet little is known about the learning principles that mediate these effects. This longitudinal study (n = 27) explores whether Spanish-learning children's early experiences with language predict efficiency in real-time comprehension and vocabulary learning. Measures of mothers' speech at 18 months were examined in relation to children's speech processing efficiency and reported vocabulary at 18 and 24 months. Children of mothers who provided more input at 18 months knew more words and were faster in word recognition at 24 months. Moreover, multiple regression analyses indicated that the influences of caregiver speech on speed of word recognition and vocabulary were largely overlapping. This study provides the first evidence that input shapes children's lexical processing efficiency and that vocabulary growth and increasing facility in spoken word comprehension work together to support the uptake of the information that rich input affords the young language learner.},
  file = {/Users/megcychosz/Zotero/storage/RLXMTMIZ/Hurtado et al. - 2008 - Does input influence uptake Links between materna.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {6}
}

@article{hustadDevelopmentSpeechIntelligibility2020,
  title = {Development of {{Speech Intelligibility Between}} 30 and 47 {{Months}} in {{Typically Developing Children}}: {{A Cross}}-{{Sectional Study}} of {{Growth}}},
  shorttitle = {Development of {{Speech Intelligibility Between}} 30 and 47 {{Months}} in {{Typically Developing Children}}},
  author = {Hustad, Katherine C. and Mahr, Tristan and Natzke, Phoebe E. M. and Rathouz, Paul J.},
  year = {2020},
  month = jun,
  volume = {63},
  pages = {1675--1687},
  publisher = {{American Speech-Language-Hearing Association}},
  issn = {10924388},
  doi = {10.1044/2020_JSLHR-20-00008},
  abstract = {Purpose: We sought to establish normative growth curves for intelligibility development for the speech of typically developing children as revealed by objectively based orthographic transcription of elicited singleword and multiword utterances by na\~A\textasciimacron ve listeners. We also examined sex differences, and we compared differences between single-word and multiword intelligibility growth. Method: One hundred sixty-four typically developing children (92 girls, 72 boys) contributed speech samples for this study. Children were between the ages of 30 and 47 months, and analyses examined 1-month age increments between these ages. Two different na\~A\textasciimacron ve listeners heard each child and made orthographic transcriptions of child-produced words and sentences (n = 328 listeners). Average intelligibility scores for singleword productions and multiword productions were modeled using linear regression, which estimated normalmodel quantile age trajectories for single- and multiword utterances. Results: We present growth curves showing steady linear change over time in 1-month increments from 30 to 47 months for 5th, 10th, 25th, 50th, 75th, 90th, and 95th percentiles. Results showed that boys did not differ from girls and that, prior to 35 months of age, single words were more intelligible than multiword productions. Starting at 41 months of age, the reverse was true. Multiword intelligibility grew at a faster rate than single-word intelligibility. Conclusions: Children make steady progress in intelligibility development through 47 months, and only a small number of children approach 100\% intelligibility by this age. Intelligibility continues to develop past the fourth year of life. There is considerable variability among children with regard to intelligibility development.},
  file = {/Users/megcychosz/Zotero/storage/KCWWWI33/Hustad et al. - 2020 - Development of Speech Intelligibility Between 30 a.pdf},
  journal = {Journal of Speech, Language \& Hearing Research},
  keywords = {CHILD development deviations,GROWTH curves (Statistics),INTELLIGIBILITY of speech,LANGUAGE acquisition,SPEECH disorders},
  number = {6}
}

@article{huttenlocherLanguageInputChild2002,
  title = {Language Input and Child Syntax},
  author = {Huttenlocher, Janellen and Vasilyeva, Marina and Cymerman, Elina and Levine, Susan},
  year = {2002},
  volume = {45},
  pages = {337--374},
  abstract = {Existing work on the acquisition of syntax has been concerned mainly with the early stages of syntactic development. In the present study we examine later syntactic development in children. Also, existing work has focused on commonalities in the emergence of syntax. Here we explore individual differences among children and their relation to variations in language input. In Study 1 we find substantial individual differences in children\~Os mastery of multiclause sentences and a significant relation between those differences and the proportion of multiclause sentences in parent speech. We also find individual differences in the number of noun phrases in children\~Os utterances and a significant relation between those differences and the number of noun phrases in parent speech. In Study 2 we find greater syntactic growth over a year of preschool in classes where teachers\~O speech is more syntactically complex. The implications of our findings for the understanding of the sources of syntactic development are discussed.},
  file = {/Users/megcychosz/Zotero/storage/UBR9Z2YP/Huttenlocher et al. - 2002 - Language input and child syntaxq.pdf},
  journal = {Cognitive Psychology},
  language = {en}
}

@article{huttenlocherSourcesVariabilityChildren2010,
  title = {Sources of {{Variability}} in {{Children}}'s {{Language Growth}}},
  author = {Huttenlocher, Janellen and Waterfall, Heidi and Vasilyeva, Marina and Vevea, Jack and Hedges, Larry V.},
  year = {2010},
  month = dec,
  volume = {61},
  pages = {343--365},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2010.08.002},
  abstract = {The present longitudinal study examines the role of caregiver speech in language development, especially syntactic development, using 47 parent-child pairs of diverse SES background from 14 to 46 months. We assess the diversity (variety) of words and syntactic structures produced by caregivers and children. We use lagged correlations to examine language growth and its relation to caregiver speech. Results show substantial individual differences among children, and indicate that diversity of earlier caregiver speech significantly predicts corresponding diversity in later child speech. For vocabulary, earlier child speech also predicts later caregiver speech, suggesting mutual influence. However, for syntax, earlier child speech does not significantly predict later caregiver speech, suggesting a causal flow from caregiver to child. Finally, demographic factors, notably SES, are related to language growth, and are, at least partially, mediated by differences in caregiver speech, showing the pervasive influence of caregiver speech on language growth.},
  file = {/Users/megcychosz/Zotero/storage/ILKPSBHE/Huttenlocher et al. - 2010 - Sources of Variability in Children’s Language Grow.pdf},
  journal = {Cognitive psychology},
  number = {4},
  pmcid = {PMC2981670},
  pmid = {20832781}
}

@article{huttenlocherVarietiesSpeechYoung2007,
  title = {The Varieties of Speech to Young Children},
  author = {Huttenlocher, Janellen and Vasilyeva, Marina and Waterfall, Heidi R. and Vevea, Jack L. and Hedges, Larry V.},
  year = {2007},
  volume = {43},
  pages = {1062--1083},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-0599(Electronic),0012-1649(Print)},
  doi = {10.1037/0012-1649.43.5.1062},
  abstract = {This article examines caregiver speech to young children. The authors obtained several measures of the speech used to children during early language development (14-30 months). For all measures, they found substantial variation across individuals and subgroups. Speech patterns vary with caregiver education, and the differences are maintained over time. While there are distinct levels of complexity for different caregivers, there is a common pattern of increase across age within the range that characterizes each educational group. Thus, caregiver speech exhibits both long-standing patterns of linguistic behavior and adjustment for the interlocutor. This information about the variability of speech by individual caregivers provides a framework for systematic study of the role of input in language acquisition. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/megcychosz/Zotero/storage/6AT6WU63/Huttenlocher et al. - 2007 - The varieties of speech to young children.pdf},
  journal = {Developmental Psychology},
  keywords = {Caregivers,Early Childhood Development,Educational Attainment Level,Language Development,Oral Communication,Parent Child Communication},
  number = {5}
}

@article{huttunenEffectCognitiveLoad2011,
  title = {Effect of Cognitive Load on Articulation Rate and Formant Frequencies during Simulator Flights},
  author = {Huttunen, Kerttu H. and Ker{\"a}nen, Heikki I. and P{\"a}{\"a}kk{\"o}nen, Rauno J. and {P{\"a}ivikki Eskelinen-R{\"o}nk{\"a}}, R. and Leino, Tuomo K.},
  year = {2011},
  volume = {129},
  pages = {1580--1593},
  issn = {0001-4966},
  doi = {10.1121/1.3543948},
  file = {/Users/megcychosz/Zotero/storage/ILVL5ZYV/Huttunen et al. - 2011 - Effect of cognitive load on articulation rate and .pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {3}
}

@misc{ibmcorporationWatsonSpeechText2018,
  title = {Watson Speech to Text},
  author = {IBM Corporation},
  year = {2018},
  howpublished = {IBM Corporation}
}

@article{ichtProductionEffectMemory2015,
  title = {The Production Effect in Memory: A Prominent Mnemonic in Children},
  shorttitle = {The Production Effect in Memory},
  author = {Icht, Michal and Mama, Yaniv},
  year = {2015},
  month = sep,
  volume = {42},
  pages = {1102--1124},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000914000713},
  abstract = {The `Production Effect' (PE) refers to a memory advantage for items studied aloud over items studied silently. Thus, vocalizing may serve as a mnemonic that can be used to assist learners in improving their memory for new concepts. Although many other types of mnemonic have been suggested in the literature, the PE seems especially appropriate for young children, as it does not involve literacy skills. The present study is a first investigation of the PE in children. In two experiments we tested five-year-olds in a PE paradigm using pictures of objects as stimuli. In Experiment , pictures of familiar objects were presented to be remembered, and in Experiment  we used pictures of unfamiliar objects (evaluating new vocabulary acquisition). In both experiments we showed a memory advantage for vocally produced words (`look and say') over other types of learning (`look', `look and listen'), suggesting the PE as a prominent memory and learning tool.},
  file = {/Users/megcychosz/Zotero/storage/TI3ISTRY/Icht and Mama - 2015 - The production effect in memory a prominent mnemo.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {5}
}

@book{imbrieAcousticalStudyDevelopment2005,
  title = {Acoustical Study of the Development of Stop Consonants in Children},
  author = {Imbrie, A.K.K.},
  year = {2005},
  publisher = {{Massachusetts Institute of Technology}},
  series = {Unpublished Doctoral Dissertation}
}

@article{ingoplagSuffixOrderingMorphological2009,
  title = {Suffix {{Ordering}} and {{Morphological Processing}}},
  author = {{Ingo Plag} and {Harald Baayen}},
  year = {2009},
  volume = {85},
  pages = {109--152},
  issn = {1535-0665},
  doi = {10.1353/lan.0.0087},
  file = {/Users/megcychosz/Zotero/storage/IVDELBFV/Ingo Plag and Harald Baayen - 2009 - Suffix Ordering and Morphological Processing.pdf},
  journal = {Language},
  language = {en},
  number = {1}
}

@article{inkelasPositionalNeutralizationCase2007,
  title = {Positional {{Neutralization}}: {{A Case Study}} from {{Child Language}}},
  shorttitle = {Positional {{Neutralization}}},
  author = {Inkelas, Sharon. and Rose, Yvan},
  year = {2007},
  volume = {83},
  pages = {707--736},
  issn = {1535-0665},
  doi = {10.1353/lan.2008.0000},
  file = {/Users/megcychosz/Zotero/storage/Y3CDU9TL/Inkelas and Rose - 2008 - Positional Neutralization A Case Study from Child.pdf},
  journal = {Language},
  language = {en},
  number = {4}
}

@article{irvinExploringClassroomBehavioral2017,
  title = {Exploring {{Classroom Behavioral Imaging}}: {{Moving Closer}} to {{Effective}} and {{Data}}-{{Based Early Childhood Inclusion Planning}}},
  shorttitle = {Exploring {{Classroom Behavioral Imaging}}},
  author = {Irvin, Dwight W. and Crutchfield, Stephen A. and Greenwood, Charles R. and Simpson, Richard L. and Sangwan, Abhijeet and Hansen, John H. L.},
  year = {2017},
  month = jun,
  volume = {1},
  pages = {95--104},
  issn = {2366-7532, 2366-7540},
  doi = {10.1007/s41252-017-0014-8},
  file = {/Users/megcychosz/Zotero/storage/TSQJ8CIA/Irvin et al. - 2017 - Exploring Classroom Behavioral Imaging Moving Clo.pdf},
  journal = {Advances in Neurodevelopmental Disorders},
  language = {en},
  number = {2}
}

@article{iskarousCoarticulationInvarianceScale2013,
  title = {The Coarticulation/Invariance Scale: {{Mutual}} Information as a Measure of Coarticulation Resistance, Motor Synergy, and Articulatory Invariance},
  shorttitle = {The Coarticulation/Invariance Scale},
  author = {Iskarous, Khalil and Mooshammer, Christine and Hoole, Phil and Recasens, Daniel and Shadle, Christine H. and Saltzman, Elliot and Whalen, D. H.},
  year = {2013},
  month = aug,
  volume = {134},
  pages = {1271--1282},
  issn = {0001-4966},
  doi = {10.1121/1.4812855},
  file = {/Users/megcychosz/Zotero/storage/BDM924ZB/Iskarous et al. - 2013 - The coarticulationinvariance scale Mutual inform.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@article{iuzzini-seigelRelianceAuditoryFeedback2015,
  title = {Reliance on Auditory Feedback in Children with Childhood Apraxia of Speech},
  author = {{Iuzzini-Seigel}, Jenya and Hogan, Tiffany P. and Guarino, Anthony J. and Green, Jordan R.},
  year = {2015},
  month = mar,
  volume = {54},
  pages = {32--42},
  issn = {00219924},
  doi = {10.1016/j.jcomdis.2015.01.002},
  file = {/Users/megcychosz/Zotero/storage/SDEBLGRA/Iuzzini-Seigel et al. - 2015 - Reliance on auditory feedback in children with chi.pdf},
  journal = {Journal of Communication Disorders},
  language = {en}
}

@article{iversonEvaluatingFunctionPhonetic2003,
  title = {Evaluating the Function of Phonetic Perceptual Phenomena within Speech Recognition: {{An}} Examination of the Perception of /d/\textendash/t/ by Adult Cochlear Implant Users},
  shorttitle = {Evaluating the Function of Phonetic Perceptual Phenomena within Speech Recognition},
  author = {Iverson, Paul},
  year = {2003},
  month = feb,
  volume = {113},
  pages = {1056--1064},
  issn = {0001-4966},
  doi = {10.1121/1.1531985},
  file = {/Users/megcychosz/Zotero/storage/MG9H2XD7/Iverson - 2003 - Evaluating the function of phonetic perceptual phe.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@article{iyerPrelinguisticVocalDevelopment2008,
  title = {Prelinguistic {{Vocal Development}} in {{Infants}} with {{Typical Hearing}} and {{Infants}} with {{Severe}}-to-{{Profound Hearing Loss}}},
  author = {Iyer, Suneeti Nathani and Oller, D. Kimbrough},
  year = {2008},
  month = sep,
  volume = {108},
  pages = {115--138},
  issn = {0042-8639},
  abstract = {Delays in the onset of canonical babbling with hearing loss are extensively documented. Relatively little is known about other aspects of prelinguistic vocal development and hearing loss. Eight infants with typical hearing and eight with severe-to-profound hearing loss were matched with regard to a significant vocal development milestone, the onset of canonical babbling, and were examined at three points in time: before, at, and after the onset of canonical babbling. No differences in volubility were noted between the two infant groups. Growth in canonical babbling appeared to be slower for infants with hearing loss than infants with typical hearing. Glottal and glide production was similar in both groups. The results add to a body of information delineating aspects of prelinguistic vocal development that seem to differ or to be similar in infants with hearing loss compared to infants with typical hearing.},
  file = {/Users/megcychosz/Zotero/storage/VZEYYKWB/Iyer and Oller - 2008 - Prelinguistic Vocal Development in Infants with Ty.pdf},
  journal = {The Volta review},
  number = {2},
  pmcid = {PMC3076954},
  pmid = {21499444}
}

@article{jabbourHealthcareDisparitiesPediatric2018,
  title = {Healthcare Disparities in Pediatric Otolaryngology: {{A}} Systematic Review: {{Disparities}} in {{Pediatric Otolaryngology}}},
  shorttitle = {Healthcare Disparities in Pediatric Otolaryngology},
  author = {Jabbour, Jad and Robey, Thomas and Cunningham, Michael J.},
  year = {2018},
  month = jul,
  volume = {128},
  pages = {1699--1713},
  issn = {0023852X},
  doi = {10.1002/lary.26995},
  abstract = {Objectives: Multiple studies have reported healthcare disparities in particular settings and conditions within pediatric otolaryngology, but a systematic examination of the breadth of the problem within the field is lacking. This study's objectives are to synthesize the available evidence regarding healthcare disparities in pediatric otolaryngology, highlight recurrent themes with respect to etiologies and manifestations, and demonstrate potential impacts from patient and provider standpoints. Methods: A qualitative systematic review of the PubMed, Ovid, and Cochrane databases for articles focusing on racial, ethnic, or socioeconomic disparities related to pediatric otolaryngology conditions or settings was conducted. United Statesbased studies of any design or publication date with analysis of children 0 to 18 years old were included. Results: Of 711 abstracts identified, 39 met inclusion criteria. Manual review of references from these articles yielded 22 additional studies, for a total of 61. Disparities were identified in nearly every subspecialty within pediatric otolaryngology, with otologic conditions the most frequently studied (33 of 61). The most commonly cited disparities involved low socioeconomic status (25 of 61), inadequate insurance (23 of 61), nonwhite race (21 of 61), and barriers to accessing care (21 of 61). Only six articles found no disparities regarding the condition examined in their study. Conclusion: Through a variety of study topics, designs, and settings, a growing body of literature documents disparities across the spectrum of pediatric otolaryngology care. The etiologies and manifestations of such disparities are myriad. This evidence suggests the need for interventions to address these disparities at various professional and institutional levels, ideally with methodological rigor to assess the effectiveness of such interventions.},
  file = {/Users/megcychosz/Zotero/storage/TVF6DGXR/Jabbour et al. - 2018 - Healthcare disparities in pediatric otolaryngology.pdf},
  journal = {The Laryngoscope},
  language = {en},
  number = {7}
}

@article{jadoulIntroducingParselmouthPython2018,
  title = {Introducing {{Parselmouth}}: {{A Python}} Interface to {{Praat}}},
  shorttitle = {Introducing {{Parselmouth}}},
  author = {Jadoul, Yannick and Thompson, Bill and {de Boer}, Bart},
  year = {2018},
  month = nov,
  volume = {71},
  pages = {1--15},
  issn = {00954470},
  doi = {10.1016/j.wocn.2018.07.001},
  abstract = {This paper introduces Parselmouth, an open-source Python library that facilitates access to core functionality of Praat in Python, in an efficient and programmer-friendly way. We introduce and motivate the package, and present simple usage examples. Specifically, we focus on applications in data visualisation, file manipulation, audio manipulation, statistical analysis, and integration of Parselmouth into a Python-based experimental design for automated, in-the-loop manipulation of acoustic data. Parselmouth is available at https://github.com/YannickJadoul/ Parselmouth.},
  file = {/Users/megcychosz/Zotero/storage/R2BG2IEN/Jadoul et al. - 2018 - Introducing Parselmouth A Python interface to Pra.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{jaekelAgeEffectsPerceptual2018,
  title = {Age Effects on Perceptual Restoration of Degraded Interrupted Sentences.},
  author = {Jaekel, Brittany N. and Newman, Rochelle S. and Goupell, Matthew J.},
  year = {2018},
  volume = {143},
  pages = {84--97},
  journal = {Journal of the Acoustical Society of America},
  number = {1}
}

@article{jaekelSpeechRateNormalization2017,
  title = {Speech {{Rate Normalization}} and {{Phonemic Boundary Perception}} in {{Cochlear}}-{{Implant Users}}},
  author = {Jaekel, Brittany N. and Newman, Rochelle S. and Goupell, Matthew J.},
  year = {2017},
  month = may,
  volume = {60},
  pages = {1398--1416},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2016_JSLHR-H-15-0427},
  file = {/Users/megcychosz/Zotero/storage/BJU9PZPD/Jaekel et al. - 2017 - Speech Rate Normalization and Phonemic Boundary Pe.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {5}
}

@article{jaroszInputFrequencyAcquisition2017,
  title = {Input Frequency and the Acquisition of Syllable Structure in {{Polish}}},
  author = {Jarosz, Gaja and Calamaro, Shira and Zentz, Jason},
  year = {2017},
  month = oct,
  volume = {24},
  pages = {361--399},
  issn = {1048-9223, 1532-7817},
  doi = {10.1080/10489223.2016.1179743},
  abstract = {This article examines phonological development and its relationship to input statistics. Using novel data from a longitudinal corpus of spontaneous child speech in Polish, we evaluate and compare the predictions of a variety of input-based phonotactic models for syllable structure acquisition. We find that many commonly examined input statistics can make dramatically different predictions, as do different assumptions about the representational units over which statistics are calculated. We find that development is sensitive to multiple abstract units of phonological representation, supporting a crucial role for feature-based generalization. We also identify departures between the predictions of the best phonotactic models and children's production patterns that indicate that input sensitivity alone cannot fully explain the developmental patterns. We discuss the role of universal markedness and phonetic difficulty and argue that a full explanation requires reference to these biases.},
  file = {/Users/megcychosz/Zotero/storage/AYWZI4Z8/Jarosz et al. - 2017 - Input frequency and the acquisition of syllable st.pdf},
  journal = {Language Acquisition},
  language = {en},
  number = {4}
}

@article{jeannerodMotorRepresentationControl,
  title = {Motor {{Representation}} and {{Control}}},
  author = {Jeannerod, M},
  pages = {16},
  abstract = {Methods Results Discussion Acknowled References 9 19. Contribution Proprioceptio1 J. P. Roll, J. J. L. Velay. Abstract lntroductio\textasciitilde{} Results Conclusion},
  file = {/Users/megcychosz/Zotero/storage/5SPTX5AJ/Jeannerod - Motor Representation and Control.pdf},
  language = {en}
}

@article{jesneyLocalityCumulativeComplexity,
  title = {Locality and {{Cumulative Complexity Effects}} in {{Child Phonology}}: {{Evidence}} from {{Dutch}}},
  author = {Jesney, Karen},
  pages = {2},
  file = {/Users/megcychosz/Zotero/storage/NMPKBSUH/Jesney - Locality and Cumulative Complexity Effects in Chil.pdf},
  language = {en}
}

@article{johnsonAuditoryVisualIntegration1999,
  title = {Auditory\textendash Visual Integration of Talker Gender in Vowel Perception},
  author = {Johnson, Keith and Strand, Elizabeth A and D'Imperio, Mariapaola},
  year = {1999},
  month = oct,
  volume = {27},
  pages = {359--384},
  issn = {00954470},
  doi = {10.1006/jpho.1999.0100},
  file = {/Users/megcychosz/Zotero/storage/FWKBIHH4/Johnson et al. - 1999 - Auditory–visual integration of talker gender in vo.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {4}
}

@article{johnsonDFMethodVocal2020,
  title = {The {{$\Delta$F}} Method of Vocal Tract Length Normalization for Vowels},
  author = {Johnson, Keith},
  year = {2020},
  month = jul,
  volume = {11},
  pages = {10},
  issn = {1868-6354},
  doi = {10.5334/labphon.196},
  file = {/Users/megcychosz/Zotero/storage/XMWREZQH/Johnson - 2020 - The ΔF method of vocal tract length normalization .pdf},
  journal = {Laboratory Phonology: Journal of the Association for Laboratory Phonology},
  language = {en},
  number = {1}
}

@article{johnsonGenderDifferencesAdultInfant2014,
  title = {Gender {{Differences}} in {{Adult}}-{{Infant Communication}} in the {{First Months}} of {{Life}}},
  author = {Johnson, Katharine and Caskey, Melinda and Rand, Katherine and Tucker, Richard and Vohr, Betty},
  year = {2014},
  month = dec,
  volume = {134},
  pages = {e1603-e1610},
  issn = {0031-4005, 1098-4275},
  doi = {10.1542/peds.2013-4289},
  abstract = {OBJECTIVES: To evaluate the verbal interactions of parents with their infants in the first months of life and to test the hypothesis that reciprocal vocalizations of mother-infant dyads would be more frequent than those of father-infant dyads. METHODS: This prospective cohort study included 33 late preterm and term infants. Sixteen-hour language recordings during the birth hospitalization and in the home at 44 weeks' postmenstrual age (PMA) and 7 months were analyzed for adult word count, infant vocalizations, and conversational exchanges. RESULTS: Infants were exposed to more female adult speech than male adult speech from birth through 7 months (P , .0001). Compared with male adults, female adults responded more frequently to their infant's vocalizations from birth through 7 months (P , .0001). Infants preferentially responded to female adult speech compared with male adult speech (P = .01 at birth, P , .0001 at 44 weeks PMA and 7 months). Mothers responded preferentially to girls versus boys at birth (P = .04) and 44 weeks PMA (P = .0003) with a trend at 7 months (P = .15), and there were trends for fathers to respond preferentially to boys at 44 weeks PMA (P = .10) and 7 months (P = .15). CONCLUSIONS: Mothers provide the majority of language input and respond more readily to their infant's vocal cues than fathers; infants show a preferential vocal response to their mothers in the first months. Findings also suggest that parents may also respond preferentially to infants based on gender. Informing parents of the power of early talking with their young infants is recommended. Pediatrics 2014;134: e1603\textendash e1610},
  file = {/Users/megcychosz/Zotero/storage/6MNEJ44K/Johnson et al. - 2014 - Gender Differences in Adult-Infant Communication i.pdf},
  journal = {Pediatrics},
  language = {en},
  number = {6}
}

@article{johnsonHyperspaceEffectPhonetic1993,
  title = {The {{Hyperspace Effect}}: {{Phonetic Targets Are Hyperarticulated}}},
  shorttitle = {The {{Hyperspace Effect}}},
  author = {Johnson, Keith and Flemming, Edward and Wright, Richard},
  year = {1993},
  volume = {69},
  pages = {505--528},
  publisher = {{Linguistic Society of America}},
  issn = {0097-8507},
  doi = {10.2307/416697},
  abstract = {A commonly made, but rarely defended, assumption is that phonetic reduction processes apply to hyperarticulated phonetic targets. Results from experiments reported in this paper support this assumption. In various experimental conditions, listeners adjusted the input parameters of a speech synthesizer until the vowels it produced sounded like the vowels found in a set of example words. A preliminary study indicated that the method of adjustment is a feasible tool for studying vowel systems. Interestingly, listeners in the study chose vowels that were systematically different from those measured in productions of the set of example words: high vowels were higher, low vowels were lower, front vowels were farther front, and back vowels were farther back. We hypothesized that this extreme vowel space corresponds to phonetic targets that are hyperarticulated: HYPERSPACE. This hypothesis was tested in the two main experiments. The first experiment controlled for possible effects of instructions and phonetic training on the listeners' choices. In the second experiment, we improved the naturalness and distinctiveness of the synthetic vowels. The results indicate that the extreme vowels chosen by the listeners were consistent with those produced in hyperarticulated speech; moreover, the hyperspace effect is robust across experimental conditions. These results validate the hypothesis that phonetic targets are hyperarticulated, and are consistent with a two-stage model of phonetic implementation: at the first stage distinctive features are mapped to hyperarticulated phonetic targets, and at the second stage these phonetic targets are reduced.},
  file = {/Users/megcychosz/Zotero/storage/KTYTFI3P/Johnson et al. - 1993 - The Hyperspace Effect Phonetic Targets Are Hypera.pdf},
  journal = {Language},
  number = {3}
}

@inproceedings{johnsonMassiveReductionConversational2004,
  title = {Massive Reduction in Conversational {{American English}}},
  booktitle = {Proceedings of the 1st Session of the 10th {{International Symposium}}},
  author = {Johnson, Keith},
  editor = {Yoneyama, Kiyoko and Maekawa, K.},
  year = {2004},
  pages = {29--54},
  address = {{The National International Institute for Japanese Language}},
  file = {/Users/megcychosz/Zotero/storage/49BUP6UV/Johnson and Stampe - Massive reduction in conversational American Engli.pdf},
  language = {en}
}

@article{johnsonPerceptualBasisDistinctive2010,
  title = {On the Perceptual Basis of Distinctive Features: {{Evidence}} from the Perception of Fricatives by {{Dutch}} and {{English}} Speakers},
  shorttitle = {On the Perceptual Basis of Distinctive Features},
  author = {Johnson, Keith and Babel, Molly},
  year = {2010},
  month = jan,
  volume = {38},
  pages = {127--136},
  issn = {00954470},
  doi = {10.1016/j.wocn.2009.11.001},
  abstract = {Two speech perception experiments explored the auditory basis of distinctive features. Experiment 1 found that Dutch listeners rated [s] and [P] as more similar to each other than American English listeners did. We attributed this to the lack of a phonemic distinction between [s] and [P] in Dutch phonology in addition to their relationship via a productive phonological rule in Dutch. Experiment 1 also found that Dutch listeners rated [y] and [s], and [y] and [P] as more similar to each other than did American English listeners. We attributed this to the lack of [y] in the Dutch inventory. Experiment 2 found that Dutch and American English listeners did not significantly differ from each other in a speeded discrimination task with the same stimuli as Experiment 1. Reaction times in Experiment 2 were highly correlated with the rating data of Experiment 1 indicating that the general pattern of response in Experiment 1 was based on auditory similarity, with language-specific effects superimposed on the general pattern. The auditory basis of distinctive features found here accords with Stevens' (1989) quantal theory account of the feature [ 7 anterior]. We conclude that phonetic similarity is comprised of three components: (1) auditory similarity, (2) phonetic inventory, and (3) language-specific patterns of alternation.},
  file = {/Users/megcychosz/Zotero/storage/8P7EJK7Q/Johnson and Babel - 2010 - On the perceptual basis of distinctive features E.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {1}
}

@article{johnsonPhonologicalAwarenessVocabulary2010,
  title = {Phonological {{Awareness}}, {{Vocabulary}}, and {{Reading}} in {{Deaf Children With Cochlear Implants}}},
  author = {Johnson, Carol and Goswami, Usha},
  year = {2010},
  month = apr,
  volume = {53},
  pages = {237--261},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2009/08-0139)},
  abstract = {Purpose: To explore the phonological awareness skills of deaf children with cochlear implants (CIs) and relationships with vocabulary and reading development. Method: Forty-three deaf children with implants who were between 5 and 15 years of age were tested; 21 had been implanted at around 2.5 years of age (Early CI group), and 22 had been implanted at around 5 years of age (Late CI group). Two control groups\textemdash a deaf hearing aided group (16 children) and a typically developing group of hearing children (19 children)\textemdash were also tested. All children received a battery of phonological processing tasks along with measures of reading, vocabulary, and speechreading. Analyses focus on deaf children within the normal IQ range (n = 53). Results: Age at cochlear implantation had a significant effect on vocabulary and reading outcomes when quotient scores were calculated. Individual differences in age at implant, duration of fit, phonological development, vocabulary development, auditory memory, visual memory, and speech intelligibility were all strongly associated with progress in reading for the deaf implanted children. Patterns differed somewhat depending on whether quotient scores or standard scores were used. Conclusions: Cochlear implantation is associated with development of the oral language, auditory memory, and phonological awareness skills necessary for developing efficient word recognition skills. There is a benefit of earlier implantation.},
  file = {/Users/megcychosz/Zotero/storage/KEFZ3TRF/Johnson and Goswami - 2010 - Phonological Awareness, Vocabulary, and Reading in.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {2}
}

@phdthesis{johnsonProcessesSpeakerNormalizaton1988,
  title = {Processes of Speaker Normalizaton in Vowel Perception},
  author = {Johnson, K.},
  year = {1988},
  address = {{Columbus, OH}},
  school = {Ohio State University},
  type = {Dissertation}
}

@article{johnsonQuantifyingRobustnessContrast2018,
  title = {Quantifying Robustness of the /t/-/k/ Contrast Using a Single, Static Spectral Feature},
  author = {Johnson, Allison A. and Reidy, Patrick F. and Edwards, Jan R.},
  year = {2018},
  month = aug,
  volume = {144},
  pages = {EL105-EL111},
  issn = {0001-4966},
  doi = {10.1121/1.5049702},
  abstract = {Dynamic spectral shape features accurately classify /t/ and /k/ productions across speakers and contexts. This paper shows that wordinitial /t/ and /k/ tokens produced by 21 adults can be differentiated using a single, static spectral feature when spectral energy concentration is considered relative to expectations within a given speaker and vowel context. Centroid and peak frequency\textemdash calculated from both acoustic and psychoacoustic spectra\textemdash were compared to determine whether one feature could reliably differentiate /t/ and /k/, and, if so, which feature best differentiated them. Centroid frequency from both acoustic and psychoacoustic spectra accurately classified productions of /t/ and /k/.},
  file = {/Users/megcychosz/Zotero/storage/ZGLGG5JM/Johnson et al. - 2018 - Quantifying robustness of the t-k contrast usi.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@article{johnsonResonanceExemplarbasedLexicon2006,
  title = {Resonance in an Exemplar-Based Lexicon: {{The}} Emergence of Social Identity and Phonology},
  shorttitle = {Resonance in an Exemplar-Based Lexicon},
  author = {Johnson, Keith},
  year = {2006},
  month = oct,
  volume = {34},
  pages = {485--499},
  issn = {00954470},
  doi = {10.1016/j.wocn.2005.08.004},
  abstract = {Two sets of data are discussed in terms of an exemplar-resonance model of the lexicon. First, a cross-linguistic review of vowel formant measurements indicate that phonetic differences between male and female talkers are a function of language, dissociated to a certain extent from vocal tract length. Second, an auditory word recognition study [Strand (2000). Gender Stereotype Effects in Speech Processing. Ph.D. Dissertation, Ohio State University] indicates that listeners can process words faster when the talker has a stereotypical sounding voice. An exemplar-resonance model of perception derives these effects suggesting that reentrant pathways [Edelman (1987). Neural Darwinism: The theory of neuronal group selection. New York: Basic Books] between cognitive categories and detailed exemplars of them leads to the emergence of social and linguistic entities.},
  file = {/Users/megcychosz/Zotero/storage/SU3W3B86/Johnson - 2006 - Resonance in an exemplar-based lexicon The emerge.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {4}
}

@article{johnsonReviewPhoneticData2006,
  title = {Review of ``{{Phonetic Data Analysis}}'' by {{Peter Ladefoged}}.},
  author = {Johnson, Keith},
  year = {2006},
  pages = {5},
  file = {/Users/megcychosz/Zotero/storage/UXKAHMB9/Johnson - 2006 - Review of “Phonetic Data Analysis” by Peter Ladefo.pdf},
  language = {en}
}

@article{johnsonSpeakerNormalizationSpeech2018,
  title = {Speaker {{Normalization}} in {{Speech Perception}}},
  author = {Johnson, Keith and Sjerps, M.},
  year = {2018},
  pages = {32--64},
  doi = {10.1002/9780470757024.ch15},
  file = {/Users/megcychosz/Zotero/storage/SBAYCSMJ/Johnson - 2005 - Speaker Normalization in Speech Perception.pdf},
  journal = {UC Berkeley Phonetics and Phonology Lab Annual Report},
  language = {en}
}

@incollection{johnsonSpeechPerceptionSpeaker1997,
  title = {Speech Perception without Speaker Normalization: {{An}} Exemplar Model},
  booktitle = {Talker Variability in Speech Processing},
  author = {Johnson, Keith},
  year = {1997},
  pages = {145--166},
  publisher = {{Academic Press}},
  address = {{San Diego}}
}

@article{jonesChildrenReallyAcquire2019,
  title = {Do Children Really Acquire Dense Neighbourhoods?},
  author = {Jones, Samuel David and Brandt, Silke},
  year = {2019},
  month = nov,
  volume = {46},
  pages = {1260--1273},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000919000473},
  abstract = {Children learn high phonological neighbourhood density words more easily than low phonological neighbourhood density words (Storkel, 2004). However, the strength of this effect relative to alternative predictors of word acquisition is unclear. We addressed this issue using communicative inventory data from 300 British English-speaking children aged 12 to 25 months. Using Bayesian regression, we modelled word understanding and production as a function of: (i) phonological neighbourhood density, (ii) frequency, (iii) length, (iv) babiness, (v) concreteness, (vi) valence, (vii) arousal, and (viii) dominance. Phonological neighbourhood density predicted word production but not word comprehension, and this effect was stronger in younger children.},
  file = {/Users/megcychosz/Zotero/storage/7P3LNE2H/Jones and Brandt - 2019 - Do children really acquire dense neighbourhoods.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {6}
}

@article{jonesDiversityNotQuantity2017,
  title = {Diversity Not Quantity in Caregiver Speech: {{Using}} Computational Modeling to Isolate the Effects of the Quantity and the Diversity of the Input on Vocabulary Growth},
  shorttitle = {Diversity Not Quantity in Caregiver Speech},
  author = {Jones, Gary and Rowland, Caroline F.},
  year = {2017},
  month = nov,
  volume = {98},
  pages = {1--21},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2017.07.002},
  abstract = {Children who hear large amounts of diverse speech learn language more quickly than children who do not. However, high correlations between the amount and the diversity of the input in speech samples makes it difficult to isolate the influence of each. We overcame this problem by controlling the input to a computational model so that amount of exposure to linguistic input (quantity) and the quality of that input (lexical diversity) were independently manipulated. Sublexical, lexical, and multi-word knowledge were charted across development (Study 1), showing that while input quantity may be important early in learning, lexical diversity is ultimately more crucial, a prediction confirmed against children's data (Study 2). The model trained on a lexically diverse input also performed better on nonword repetition and sentence recall tests (Study 3) and was quicker to learn new words over time (Study 4). A language input that is rich in lexical diversity outperforms equivalent richness in quantity for learned sublexical and lexical knowledge, for wellestablished language tests, and for acquiring words that have never been encountered before.},
  file = {/Users/megcychosz/Zotero/storage/YN72BXYK/Jones and Rowland - 2017 - Diversity not quantity in caregiver speech Using .pdf},
  journal = {Cognitive Psychology},
  language = {en}
}

@article{jonesHowEffectiveLENA2019,
  title = {How Effective Is {{LENA}} in Detecting Speech Vocalizations and Language Produced by Children and Adolescents with {{ASD}} in Different Contexts?},
  author = {Jones, Rebecca M. and Plesa Skwerer, Daniela and Pawar, Rahul and Hamo, Amarelle and Carberry, Caroline and Ajodan, Eliana L. and Caulley, Desmond and Silverman, Melanie R. and McAdoo, Shannon and Meyer, Steven and Yoder, Anne and Clements, Mark and Lord, Catherine and Tager-Flusberg, Helen},
  year = {2019},
  month = apr,
  volume = {12},
  pages = {628--635},
  issn = {1939-3792, 1939-3806},
  doi = {10.1002/aur.2071},
  abstract = {The LENA system was designed and validated to provide information about the language environment in children 0 to 4 years of age and its use has been expanded to populations with a number of communication profiles. Its utility in children 5 years of age and older is not yet known. The present study used acoustic data from two samples of children with autism spectrum disorders (ASD) to evaluate the reliability of LENA automated analyses for detecting speech utterances in older, school age children, and adolescents with ASD, in clinic and home environments. Participants between 5 and 18 years old who were minimally verbal (study 1) or had a range of verbal abilities (study 2) completed standardized assessments in the clinic (study 1 and 2) and in the home (study 2) while speech was recorded from a LENA device. We compared LENA segment labels with manual ground truth coding by human transcribers using two different methods. We found that the automated LENA algorithms were not successful ({$<$}50\% reliable) in detecting vocalizations from older children and adolescents with ASD, and that the proportion of speaker misclassifications by the automated system increased significantly with the target-child's age. The findings in children and adolescents with ASD suggest possibly misleading results when expanding the use of LENA beyond the age ranges for which it was developed and highlight the need to develop novel automated methods that are more appropriate for older children.},
  file = {/Users/megcychosz/Zotero/storage/JXQM6NHZ/Jones et al. - 2019 - How effective is LENA in detecting speech vocaliza.pdf},
  journal = {Autism Research},
  language = {en},
  number = {4}
}

@article{jonesInfluenceChildrenExposure2016,
  title = {The Influence of Children's Exposure to Language from Two to Six Years: {{The}} Case of Nonword Repetition},
  shorttitle = {The Influence of Children's Exposure to Language from Two to Six Years},
  author = {Jones, Gary},
  year = {2016},
  month = aug,
  volume = {153},
  pages = {79--88},
  issn = {00100277},
  doi = {10.1016/j.cognition.2016.04.017},
  abstract = {Nonword repetition (NWR) is highly predictive of vocabulary size, has strong links to language and reading ability, and is a clinical marker of language impairment. However, it is unclear what processes provide major contributions to NWR performance. This paper presents a computational model of NWR based on Chunking Lexical and Sub-lexical Sequences in Children (CLASSIC) that focuses on the child's exposure to language when learning lexical phonological knowledge. Based on language input aimed at 2\textendash 6 year old children, CLASSIC shows a substantial fit to children's NWR performance for 6 different types of NWR test across 6 different NWR studies that use children of various ages from 2;1 to 6;1. Furthermore, CLASSIC's repetitions of individual nonwords correlate significantly with children's repetitions of the same nonwords, NWR performance shows strong correlations to vocabulary size, and interaction effects seen in the model are consistent with those found in children. Such a fit to the data is achieved without any need for developmental parameters, suggesting that between the ages of two and six years, NWR performance measures the child's current level of linguistic knowledge that arises from their exposure to language over time and their ability to extract lexical phonological knowledge from that exposure.},
  file = {/Users/megcychosz/Zotero/storage/JH9UFVPT/1-s2.0-S0010027716301056-main-2.pdf},
  journal = {Cognition},
  language = {en}
}

@article{jonesLinkingWorkingMemory2007,
  title = {Linking Working Memory and Long-Term Memory: A Computational Model of the Learning of New Words},
  shorttitle = {Linking Working Memory and Long-Term Memory},
  author = {Jones, Gary and Gobet, Fernand and Pine, Julian M.},
  year = {2007},
  month = nov,
  volume = {10},
  pages = {853--873},
  issn = {1363-755X, 1467-7687},
  doi = {10.1111/j.1467-7687.2007.00638.x},
  abstract = {The nonword repetition (NWR) test has been shown to be a good predictor of children's vocabulary size. NWR performance has been explained using phonological working memory, which is seen as a critical component in the learning of new words. However, no detailed specification of the link between phonological working memory and long-term memory (LTM) has been proposed. In this paper, we present a computational model of children's vocabulary acquisition (EPAM-VOC) that specifies how phonological working memory and LTM interact. The model learns phoneme sequences, which are stored in LTM and mediate how much information can be held in working memory. The model's behaviour is compared with that of children in a new study of NWR, conducted in order to ensure the same nonword stimuli and methodology across ages. EPAM-VOC shows a pattern of results similar to that of children: performance is better for shorter nonwords and for wordlike nonwords, and performance improves with age. EPAM-VOC also simulates the superior performance for single consonant nonwords over clustered consonant nonwords found in previous NWR studies. EPAM-VOC provides a simple and elegant computational account of some of the key processes involved in the learning of new words: it specifies how phonological working memory and LTM interact; makes testable predictions; and suggests that developmental changes in NWR performance may reflect differences in the amount of information that has been encoded in LTM rather than developmental changes in working memory capacity.},
  file = {/Users/megcychosz/Zotero/storage/YFLX5CC6/Jones et al. - 2007 - Linking working memory and long-term memory a com.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {6}
}

@article{jonesWhyComputationalModels2014,
  title = {Why Computational Models Are Better than Verbal Theories: The Case of Nonword Repetition},
  shorttitle = {Why Computational Models Are Better than Verbal Theories},
  author = {Jones, Gary and Gobet, Fernand and Freudenthal, Daniel and Watson, Sarah E. and Pine, Julian M.},
  year = {2014},
  month = mar,
  volume = {17},
  pages = {298--310},
  issn = {1363755X},
  doi = {10.1111/desc.12111},
  abstract = {Tests of nonword repetition (NWR) have often been used to examine children's phonological knowledge and word learning abilities. However, theories of NWR primarily explain performance either in terms of phonological working memory or longterm knowledge, with little consideration of how these processes interact. One theoretical account that focuses specifically on the interaction between short-term and long-term memory is the chunking hypothesis. Chunking occurs because of repeated exposure to meaningful stimulus items, resulting in the items becoming grouped (or chunked); once chunked, the items can be represented in short-term memory using one chunk rather than one chunk per item. We tested several predictions of the chunking hypothesis by presenting 5\textendash 6-year-old children with three tests of NWR that were either high, medium, or low in wordlikeness. The results did not show strong support for the chunking hypothesis, suggesting that chunking fails to fully explain children's NWR behavior. However, simulations using a computational implementation of chunking (namely CLASSIC, or Chunking Lexical And Sub-lexical Sequences In Children) show that, when the linguistic input to 5\textendash 6-year-old children is estimated in a reasonable way, the children's data are matched across all three NWR tests. These results have three implications for the field: (a) a chunking account can explain key NWR phenomena in 5\textendash 6-year-old children; (b) tests of chunking accounts require a detailed specification both of the chunking mechanism itself and of the input on which the chunking mechanism operates; and (c) verbal theories emphasizing the role of long-term knowledge (such as chunking) are not precise enough to make detailed predictions about experimental data, but computational implementations of the theories can bridge the gap.},
  file = {/Users/megcychosz/Zotero/storage/QGSIE8DU/Jones et al. - 2014 - Why computational models are better than verbal th.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {2}
}

@book{josephHandbookHistoricalLinguistics2003,
  title = {The Handbook of Historical Linguistics},
  editor = {Joseph, Brian D. and Janda, Richard D.},
  year = {2003},
  publisher = {{Blackwell Pub}},
  address = {{Malden, MA}},
  file = {/Users/megcychosz/Zotero/storage/6J96P38C/Joseph and Janda - 2003 - The handbook of historical linguistics.pdf},
  isbn = {978-0-631-19571-9},
  keywords = {Historical linguistics},
  language = {en},
  lccn = {P140 .H35 2003},
  series = {Blackwell Handbooks in Linguistics}
}

@article{juddExperimentsMoreOne2017,
  title = {Experiments with {{More Than One Random Factor}}: {{Designs}}, {{Analytic Models}}, and {{Statistical Power}}},
  shorttitle = {Experiments with {{More Than One Random Factor}}},
  author = {Judd, Charles M. and Westfall, Jacob and Kenny, David A.},
  year = {2017},
  month = jan,
  volume = {68},
  pages = {601--625},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev-psych-122414-033702},
  abstract = {Traditional methods of analyzing data from psychological experiments are based on the assumption that there is a single random factor (normally participants) to which generalization is sought. However, many studies involve at least two random factors (e.g., participants and the targets to which they respond, such as words, pictures, or individuals). The application of traditional analytic methods to the data from such studies can result in serious bias in testing experimental effects. In this review, we develop a comprehensive typology of designs involving two random factors, which may be either crossed or nested, and one fixed factor, condition. We present appropriate linear mixed models for all designs and develop effect size measures. We provide the tools for power estimation for all designs. We then discuss issues of design choice, highlighting power and feasibility considerations. Our goal is to encourage appropriate analytic methods that produce replicable results for studies involving new samples of both participants and targets.},
  file = {/Users/megcychosz/Zotero/storage/FYTR9CGL/Judd et al. - 2017 - Experiments with More Than One Random Factor Desi.pdf},
  journal = {Annual Review of Psychology},
  language = {en},
  number = {1}
}

@article{julienModifyingSpeechChildren2012,
  title = {Modifying {{Speech}} to {{Children}} Based on Their {{Perceived Phonetic Accuracy}}},
  author = {Julien, Hannah M. and Munson, Benjamin},
  year = {2012},
  month = dec,
  volume = {55},
  pages = {1836--1849},
  issn = {1092-4388},
  doi = {10.1044/1092-4388(2012/11-0131)},
  abstract = {Purpose We examined the relationship between adults' perception of the accuracy of children's speech, and acoustic detail in their subsequent productions to children. Methods Twenty-two adults participated in a task in which they rated the accuracy of 2- and 3-year-old children's word-initial /s/and /{$\int$}/ using a visual analog scale (VAS), then produced a token of the same word as if they were responding to the child whose speech they had just rated. Result The duration of adults' fricatives varied as a function of their perception of the accuracy of children's speech: longer fricatives were produced following productions that they rated as inaccurate. This tendency to modify duration in response to perceived inaccurate tokens was mediated by measures of self-reported experience interacting with children. However, speakers did not increase the spectral distinctiveness of their fricatives following the perception of inaccurate tokens. Conclusion These results suggest that adults modify temporal features of their speech in response to perceiving children's inaccurate productions. These longer fricatives are potentially both enhanced input to children, and an error-corrective signal.},
  file = {/Users/megcychosz/Zotero/storage/DNIZ8IRU/Julien and Munson - 2012 - Modifying Speech to Children based on their Percei.pdf},
  journal = {Journal of speech, language, and hearing research : JSLHR},
  number = {6},
  pmcid = {PMC3929121},
  pmid = {22744140}
}

@article{jungRelationshipOnsetCanonical2020,
  title = {The {{Relationship Between}} the {{Onset}} of {{Canonical Syllables}} and {{Speech Perception Skills}} in {{Children With Cochlear Implants}}},
  author = {Jung, Jongmin and Houston, Derek},
  year = {2020},
  month = feb,
  volume = {63},
  pages = {393--404},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2019_JSLHR-19-00158},
  file = {/Users/megcychosz/Zotero/storage/BD5QNTQ6/Jung and Houston - 2020 - The Relationship Between the Onset of Canonical Sy.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {2}
}

@article{jusczykHowEnglishLearningInfants2002,
  title = {How {{English}}-{{Learning Infants Respond}} to {{Markedness}} and {{Faithfulness Constraints}}},
  author = {Jusczyk, Peter W. and Smolensky, Paul and Allocco, Theresa},
  year = {2002},
  month = jan,
  volume = {10},
  pages = {31--73},
  issn = {1048-9223, 1532-7817},
  doi = {10.1207/S15327817LA1001_3},
  file = {/Users/megcychosz/Zotero/storage/SNKT8WH4/Jusczyk et al. - 2002 - How English-Learning Infants Respond to Markedness.pdf},
  journal = {Language Acquisition},
  language = {en},
  number = {1}
}

@article{kalashnikovaDevelopmentFastmappingNovel2018,
  title = {The Development of Fast-Mapping and Novel Word Retention Strategies in Monolingual and Bilingual Infants},
  author = {Kalashnikova, Marina and Escudero, Paola and Kidd, Evan},
  year = {2018},
  month = nov,
  volume = {21},
  pages = {e12674},
  issn = {1363755X},
  doi = {10.1111/desc.12674},
  abstract = {The mutual exclusivity (ME) assumption is proposed to facilitate early word learning by guiding infants to map novel words to novel referents. This study assessed the emergence and use of ME to both disambiguate and retain the meanings of novel words across development in 18-\-month-o\-ld monolingual and bilingual children (Experiment 1; N = 58), and in a sub-g\- roup of these children again at 24 months of age (Experiment 2: N = 32). Both monolinguals and bilinguals employed ME to select the referent of a novel label to a similar extent at 18 and 24 months. At 18 months, there were also no differences in novel word retention between the two language-\- background groups. However, at 24 months, only monolinguals showed the ability to retain these label\textendash object mappings. These findings indicate that the development of the ME assumption as a reliable word-l\-earning strategy is shaped by children's individual language exposure and experience with language use.},
  file = {/Users/megcychosz/Zotero/storage/75UL87TP/Kalashnikova et al. - 2018 - The development of fast-mapping and novel word ret.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {6}
}

@article{kalashnikovaInfantdirectedSpeechSeven2018,
  title = {Infant-Directed Speech from Seven to Nineteen Months Has Similar Acoustic Properties but Different Functions},
  author = {Kalashnikova, Marina and Burnham, Denis},
  year = {2018},
  month = sep,
  volume = {45},
  pages = {1035--1053},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000917000629},
  abstract = {This longitudinal study assessed three acoustic components of maternal infant-directed speech (IDS) \textendash{} pitch, affect, and vowel hyperarticulation \textendash{} in relation to infants' age and their expressive vocabulary size. These three individual components were measured in IDS addressed to infants at 7, 9, 11, 15, and 19 months (N = 18). All three components were exaggerated at all ages in mothers' IDS compared to their adult-directed speech. Importantly, the only significant predictor of infants' expressive vocabulary size at 15 and 19 months was vowel hyperarticulation, but only at 9 months and beyond, not at 7 months, and not pitch or affect at any age. These results set apart vowel hyperarticulation in IDS to infants as the critical IDS component for vocabulary development. Thus IDS, specifically the degree of vowel hyperarticulation therein, is a vehicle by which parents can provide the most optimal speech quality for their infants' linguistic and communicative development.},
  file = {/Users/megcychosz/Zotero/storage/7CFKGLWJ/Kalashnikova and Burnham - 2018 - Infant-directed speech from seven to nineteen mont.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {5}
}

@article{kalashnikovaOriginsBabytalkSmiling2017,
  title = {The Origins of Babytalk: Smiling, Teaching or Social Convergence?},
  shorttitle = {The Origins of Babytalk},
  author = {Kalashnikova, Marina and Carignan, Christopher and Burnham, Denis},
  year = {2017},
  month = aug,
  volume = {4},
  pages = {170306},
  issn = {2054-5703},
  doi = {10.1098/rsos.170306},
  abstract = {When addressing their young infants, parents systematically modify their speech. Such infant-directed speech (IDS) contains exaggerated vowel formants, which have been proposed to foster language development via articulation of more distinct speech sounds. Here, this assumption is rigorously tested using both acoustic               and               , for the first time, fine-grained articulatory measures. Mothers were recorded speaking to their infant and to another adult, and measures were taken of their acoustic vowel space, their tongue and lip movements and the length of their vocal tract. Results showed that infant- but not adult-directed speech contains acoustically exaggerated vowels, and these are not the product of adjustments to tongue or to lip movements. Rather, they are the product of a shortened vocal tract due to a raised larynx, which can be ascribed to speakers' unconscious effort to appear smaller and more non-threatening to the young infant. This adjustment in IDS may be a vestige of early mother\textendash infant interactions, which had as its primary purpose the transmission of non-aggressiveness and/or a primitive manifestation of pre-linguistic vocal social convergence of the mother to her infant. With the advent of human language, this vestige then acquired a secondary purpose\textemdash facilitating language acquisition via the serendipitously exaggerated vowels.},
  file = {/Users/megcychosz/Zotero/storage/G6AXKXK5/Kalashnikova et al. - 2017 - The origins of babytalk smiling, teaching or soci.pdf},
  journal = {Royal Society Open Science},
  language = {en},
  number = {8}
}

@article{kapnoulaEvaluatingSourcesFunctions2017,
  title = {Evaluating the Sources and Functions of Gradiency in Phoneme Categorization: {{An}} Individual Differences Approach.},
  shorttitle = {Evaluating the Sources and Functions of Gradiency in Phoneme Categorization},
  author = {Kapnoula, Efthymia C. and Winn, Matthew B. and Kong, Eun Jong and Edwards, Jan and McMurray, Bob},
  year = {2017},
  month = sep,
  volume = {43},
  pages = {1594--1611},
  issn = {1939-1277, 0096-1523},
  doi = {10.1037/xhp0000410},
  abstract = {During spoken language comprehension listeners transform continuous acoustic cues into categories (e.g. /b/ and /p/). While longstanding research suggests that phonetic categories are activated in a gradient way, there are also clear individual differences in that more gradient categorization has been linked to various communication impairments like dyslexia and specific language impairments (Joanisse, Manis, Keating, \& Seidenberg, 2000; L\'opez-Zamora, Luque, \'Alvarez, \& Cobos, 2012; Serniclaes, Van Heghe, Mousty, Carr\'e, \& Sprenger-Charolles, 2004; Werker \& Tees, 1987). Crucially, most studies have used two-alternative forced choice (2AFC) tasks to measure the sharpness of between-category boundaries. Here we propose an alternative paradigm that allows us to measure categorization gradiency in a more direct way. Furthermore, we follow an individual differences approach to: (a) link this measure of gradiency to multiple cue integration, (b) explore its relationship to a set of other cognitive processes, and (c) evaluate its role in individuals' ability to perceive speech in noise. Our results provide validation for this new method of assessing phoneme categorization gradiency and offer preliminary insights into how different aspects of speech perception may be linked to each other and to more general cognitive processes.},
  file = {/Users/megcychosz/Zotero/storage/UN9REIXV/Kapnoula et al. - 2017 - Evaluating the sources and functions of gradiency .pdf},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  language = {en},
  number = {9}
}

@article{karasikTiesThatBind2018,
  title = {The Ties That Bind: {{Cradling}} in {{Tajikistan}}},
  author = {Karasik, L. B. and {Tamis-LeMonda}, C. S. and Ossmy, O. and Adolph, K. E.},
  year = {2018},
  volume = {13},
  pages = {e0204428},
  journal = {PLoS ONE},
  number = {10}
}

@article{kartushinaEffectPhoneticProduction2015,
  title = {The Effect of Phonetic Production Training with Visual Feedback on the Perception and Production of Foreign Speech Sounds},
  author = {Kartushina, Natalia and {Hervais-Adelman}, Alexis and Frauenfelder, Ulrich Hans and Golestani, Narly},
  year = {2015},
  month = aug,
  volume = {138},
  pages = {817--832},
  issn = {0001-4966},
  doi = {10.1121/1.4926561},
  file = {/Users/megcychosz/Zotero/storage/2AUKJGIC/Kartushina et al. - 2015 - The effect of phonetic production training with vi.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@article{kartushinaFrontiersEffectsL22014,
  title = {Frontiers | {{On}} the Effects of {{L2}} Perception and of Individual Differences in {{L1}} Production on {{L2}} Pronunciation | {{Psychology}}},
  author = {Kartushina, N. and Frauenfelder, U.H.},
  year = {2014},
  volume = {5},
  pages = {1--17},
  file = {/Users/megcychosz/Zotero/storage/NDPGYUXX/full.html},
  journal = {Frontiers in Psychology},
  number = {1246}
}

@article{katseffPartialCompensationAltered2012,
  title = {Partial {{Compensation}} for {{Altered Auditory Feedback}}: {{A Tradeoff}} with {{Somatosensory Feedback}}?},
  shorttitle = {Partial {{Compensation}} for {{Altered Auditory Feedback}}},
  author = {Katseff, Shira and Houde, John and Johnson, Keith},
  year = {2012},
  month = jun,
  volume = {55},
  pages = {295--308},
  issn = {0023-8309, 1756-6053},
  doi = {10.1177/0023830911417802},
  abstract = {Talkers are known to compensate only partially for experimentally-induced changes to their auditory feedback. In a typical experiment, talkers might hear their F1 feedback shifted higher (so that /e/ sounds like /\ae/, for example), and compensate by lowering F1 in their subsequent speech by about a quarter of that distance. Here, we sought to characterize and understand partial compensation by examining how talkers respond to each step on a staircase of increasing shifts in auditory feedback.},
  file = {/Users/megcychosz/Zotero/storage/S3X2CEVJ/Katseff et al. - 2012 - Partial Compensation for Altered Auditory Feedback.pdf},
  journal = {Language and Speech},
  language = {en},
  number = {2}
}

@article{katzAnticipatoryCoarticulationSpeech1991,
  title = {Anticipatory Coarticulation in the Speech of Adults and Young Children: {{Acoustic}}, Perceptual, and Video Data},
  author = {Katz, William F. and Kripke, Clarissa and Tallal, Paula},
  year = {1991},
  month = dec,
  volume = {34},
  pages = {1222--1232},
  file = {/Users/megcychosz/Zotero/storage/PA2QYB8K/Katz et al. 1991.pdf},
  journal = {Journal of Speech Language and Hearing Research}
}

@article{kaushanskayaDoesExposureCode2019,
  title = {Does {{Exposure}} to {{Code}}-{{Switching Influence Language Performance}} in {{Bilingual Children}}?},
  author = {Kaushanskaya, Margarita and Crespo, Kimberly},
  year = {2019},
  month = may,
  volume = {90},
  pages = {708--718},
  issn = {0009-3920, 1467-8624},
  doi = {10.1111/cdev.13235},
  file = {/Users/megcychosz/Zotero/storage/6J2GDZ7T/Kaushanskaya and Crespo - 2019 - Does Exposure to Code‐Switching Influence Language.pdf},
  journal = {Child Development},
  language = {en},
  number = {3}
}

@article{kavitskayaInvestigatingEffectsSyllable2011,
  title = {Investigating the Effects of Syllable Complexity in {{Russian}}-Speaking Children with {{SLI}}},
  author = {Kavitskaya, Darya and Babyonyshev, Maria and Walls, Theodore and Grigorenko, Elena},
  year = {2011},
  month = nov,
  volume = {38},
  pages = {979--998},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000910000413},
  abstract = {This study examined the effect of number of syllables and syllable structure on repetition of pseudo-words by Russian-speaking children with Specific Language Impairment (SLI) and typically developing (TD) children. One hundred and forty-four pseudo-words, varying in length and syllable complexity, were presented to two groups of children : 15 children with SLI, age range 4; 0 to 8; 8, and 15 TD children matched in age to the SLI group. The number of errors in the repetition of pseudowords was analyzed in terms of the number of syllables and syllable complexity. The results demonstrated that children with SLI have deficits in working memory capacity. In addition to the pseudo-word length, the repetition performance was affected by syllable structure complexity.},
  file = {/Users/megcychosz/Zotero/storage/TZVVIQPQ/Kavitskaya et al. - 2011 - Investigating the effects of syllable complexity i.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {5}
}

@article{kehoeBilingualPhonologicalAcquisition2019,
  title = {Bilingual Phonological Acquisition: The Influence of Language-Internal, Language-External, and Lexical Factors},
  shorttitle = {Bilingual Phonological Acquisition},
  author = {Kehoe, Margaret and Havy, M{\'e}lanie},
  year = {2019},
  month = mar,
  volume = {46},
  pages = {292--333},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000918000478},
  abstract = {This study examines the influence of language-internal (frequency and complexity of linguistic properties), language-external (percent French input, socioeconomic status (SES), and gender), and lexical factors (size of total and French vocabulary) on the phonological production abilities of monolingual and bilingual French-speaking children, aged 2;6. Children participated in an object and picture naming task in which they produced words selected to test different phonological properties. The bilinguals' first languages were coded in terms of the frequency and complexity of these phonological properties. Results indicated that bilinguals who spoke languages characterized by high frequency/complexity of codas and clusters had superior results in their coda and cluster accuracy in comparison to monolinguals. Bilinguals also had better coda and cluster accuracy scores than monolinguals. These findings provide evidence for cross-linguistic interaction in combination with a `general bilingual effect'. In addition, percent French exposure, SES, total vocabulary, and gender influenced phonological production.},
  file = {/Users/megcychosz/Zotero/storage/ENBS5JK2/Kehoe and Havy - 2019 - Bilingual phonological acquisition the influence .pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {2}
}

@article{kellyAcquisitionPolysyntheticLanguages2014,
  title = {The {{Acquisition}} of {{Polysynthetic Languages}}: {{The Acquisition}} of {{Polysynthetic Languages}}},
  shorttitle = {The {{Acquisition}} of {{Polysynthetic Languages}}},
  author = {Kelly, Barbara and Wigglesworth, Gillian and Nordlinger, Rachel and Blythe, Joseph},
  year = {2014},
  month = feb,
  volume = {8},
  pages = {51--64},
  issn = {1749818X},
  doi = {10.1111/lnc3.12062},
  abstract = {One of the major challenges in acquiring a language is being able to use morphology as an adult would, and thus, a considerable amount of acquisition research has focused on morphological production and comprehension. Most of this research, however, has focused on the acquisition of morphology in isolating languages, or languages (such as English) with limited inflectional morphology. The nature of the learning task is different, and potentially more challenging, when the child is learning a polysynthetic language \textendash{} a language in which words are highly morphologically complex, expressing in a single word what in English takes a multi-word clause. To date, there has been no cross-linguistic survey of how children approach this puzzle and learn polysynthetic languages. This paper aims to provide such a survey, including a discussion of some of the general findings in the literature regarding the acquisition of polysynthetic systems.},
  file = {/Users/megcychosz/Zotero/storage/KWG9TBL7/Kelly et al. - 2014 - The Acquisition of Polysynthetic Languages The Ac.pdf},
  journal = {Language and Linguistics Compass},
  language = {en},
  number = {2}
}

@article{kempsProsodicCuesMorphological2005,
  title = {Prosodic Cues for Morphological Complexity in {{Dutch}} and {{English}}},
  author = {Kemps, Rach{\`e}l J. J. K. and Wurm, Lee H. and Ernestus, Mirjam and Schreuder, Robert and Baayen, Harald},
  year = {2005},
  month = feb,
  volume = {20},
  pages = {43--73},
  issn = {0169-0965, 1464-0732},
  doi = {10.1080/01690960444000223},
  file = {/Users/megcychosz/Zotero/storage/VGYIM66B/Kemps et al. - 2005 - Prosodic cues for morphological complexity in Dutc.pdf},
  journal = {Language and Cognitive Processes},
  language = {en},
  number = {1-2}
}

@article{kempsProsodicCuesMorphological2005a,
  title = {Prosodic Cues for Morphological Complexity: {{The}} Case of {{Dutch}} Plural Nouns},
  shorttitle = {Prosodic Cues for Morphological Complexity},
  author = {Kemps, Rach{\`e}l J. J. K. and Ernestus, Mirjam and Schreuder, Robert and Harald Baayen, R.},
  year = {2005},
  month = apr,
  volume = {33},
  pages = {430--446},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03193061},
  file = {/Users/megcychosz/Zotero/storage/FL9V6ERL/Kemps et al. - 2005 - Prosodic cues for morphological complexity The ca.pdf},
  journal = {Memory \& Cognition},
  language = {en},
  number = {3}
}

@article{kentAnatomicalNeuromuscularMaturation1976,
  title = {Anatomical and Neuromuscular Maturation of the Speech Mechanism: {{Evidence}} from Acoustic Studies.},
  author = {Kent, R.D.},
  year = {1976},
  volume = {19},
  pages = {421--447},
  journal = {Journal of Speech Language and Hearing Research}
}

@article{kentAnatomicalNeuromuscularMaturation1976a,
  title = {Anatomical and {{Neuromuscular Maturation}} of the {{Speech Mechanism}}: {{Evidence}} from {{Acoustic Studies}}},
  shorttitle = {Anatomical and {{Neuromuscular Maturation}} of the {{Speech Mechanism}}},
  author = {Kent, R.D.},
  year = {1976},
  month = sep,
  volume = {19},
  pages = {421--447},
  issn = {0022-4685},
  doi = {10.1044/jshr.1903.421},
  abstract = {This paper surveys acoustic studies of speech development and discusses the data with respect to the anatomical and neuromuscular maturation of the speech mechanism. The acoustic data on various aspects of speech production indicate that the accuracy of motor control improves with age until adult-like performance is achieved at about 11 or 12 years, somewhat after the age at which speech sound acquisition usually is judged to be complete. Other topics of discussion are (1) problems in the spectrographic analysis of children's speech, (2) formant scale factors that relate children's and adults' data, and (3) identification and diagnosis of developmental disorders through acoustic analyses of speech sounds.},
  file = {/Users/megcychosz/Zotero/storage/7LXPSQKM/1.4998590.pdf;/Users/megcychosz/Zotero/storage/D7THH8XC/Kent - 1976 - Anatomical and Neuromuscular Maturation of the Spe.pdf},
  journal = {Journal of Speech and Hearing Research},
  language = {en},
  number = {3}
}

@article{kentDevelopmentCraniofacialorallaryngealAnatomy1995,
  title = {Development of the Craniofacial-Oral-Laryngeal Anatomy: {{A}} Review},
  author = {Kent, R.D. and Vorperian, Houri K},
  year = {1995},
  volume = {3},
  pages = {145--190},
  file = {/Users/megcychosz/Zotero/storage/5I5TX7LR/zengine.pdf},
  journal = {Journal of Medical Speech-Language Pathology},
  number = {3}
}

@incollection{kentSegmentalOrganizationSpeech1983,
  title = {The {{Segmental Organization}} of {{Speech}}},
  booktitle = {The {{Production}} of {{Speech}}},
  author = {Kent, R.D.},
  editor = {MacNeilage, Peter F.},
  year = {1983},
  pages = {57--89},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4613-8202-7_4},
  file = {/Users/megcychosz/Zotero/storage/CQAE6UWK/Kent - 1983 - The Segmental Organization of Speech.pdf},
  isbn = {978-1-4613-8204-1 978-1-4613-8202-7},
  language = {en}
}

@article{kentStaticMeasurementsVowel2018,
  title = {Static Measurements of Vowel Formant Frequencies and Bandwidths: {{A}} Review},
  shorttitle = {Static Measurements of Vowel Formant Frequencies and Bandwidths},
  author = {Kent, Raymond D. and Vorperian, Houri K.},
  year = {2018},
  month = jul,
  volume = {74},
  pages = {74--97},
  issn = {00219924},
  doi = {10.1016/j.jcomdis.2018.05.004},
  abstract = {Purpose: Data on vowel formants have been derived primarily from static measures representing an assumed steady state. This review summarizes data on formant frequencies and bandwidths for American English and also addresses (a) sources of variability (focusing on speech sample and time sampling point), and (b) methods of data reduction such as vowel area and dispersion. Method: Searches were conducted with CINAHL, Google Scholar, MEDLINE/PubMed, SCOPUS, and other online sources including legacy articles and references. The primary search items were vowels, vowel space area, vowel dispersion, formants, formant frequency, and formant bandwidth. Results: Data on formant frequencies and bandwidths are available for both sexes over the lifespan, but considerable variability in results across studies affects even features of the basic vowel quadrilateral. Origins of variability likely include differences in speech sample and time sampling point. The data reveal the emergence of sex differences by 4 years of age, maturational reductions in formant bandwidth, and decreased formant frequencies with advancing age in some persons. It appears that a combination of methods of data reduction provide for optimal data interpretation. Conclusion: The lifespan database on vowel formants shows considerable variability within specific age-sex groups, pointing to the need for standardized procedures.},
  file = {/Users/megcychosz/Zotero/storage/HX36PWRG/Kent and Vorperian - 2018 - Static measurements of vowel formant frequencies a.pdf},
  journal = {Journal of Communication Disorders},
  language = {en}
}

@article{kentWhatAcousticStudies2020,
  title = {What {{Acoustic Studies Tell Us About Vowels}} in {{Developing}} and {{Disordered Speech}}},
  author = {Kent, R.D. and Rountrey, Carrie},
  year = {2020},
  file = {/Users/megcychosz/Zotero/storage/KT5PLVKQ/Kent and Rountrey - 2020 - What Acoustic Studies Tell Us About Vowels in Deve.pdf},
  journal = {American Journal of Speech-Language Pathology}
}

@article{keren-portnoyRoleVocalPractice2010,
  title = {The {{Role}} of {{Vocal Practice}} in {{Constructing Phonological Working Memory}}},
  author = {{Keren-Portnoy}, Tamar and Vihman, Marilyn M. and DePaolis, Rory A. and Whitaker, Chris J. and Williams, Nicola M.},
  year = {2010},
  month = oct,
  volume = {53},
  pages = {1280},
  issn = {1092-4388},
  doi = {10.1044/1092-4388(2009/09-0003)},
  abstract = {Purpose: This study looks for effects of vocal practice on phonological working memory. Method: We used a longitudinal design, combining both naturalistic observations and a nonword repetition test. Fifteen 26-month-olds (twelve of whom were followed from age eleven months) were administered a nonword test including real words, ``standard'' nonwords (identical for all children), and nonwords based on individual children's production inventory (IN and OUT words). Results: A strong relationship was found between (i) length of experience with consonant production and (ii) nonword repetition and between (i) differential experience with specific consonants through production and (ii) performance on the IN vs. OUT words. Conclusions: Performance depended on familiarity with words or their subunits, and was strongest for real words, weaker for IN words, and weakest for OUT words. Our results demonstrate the important role of speech production in the construction of phonological working memory. [145 words]},
  file = {/Users/megcychosz/Zotero/storage/JHC2UD6U/Keren-Portnoy et al. - 2010 - The Role of Vocal Practice in Constructing Phonolo.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {5}
}

@article{kernInteractionPhoneticPhonological2018,
  title = {The Interaction of Phonetic/Phonological Development and Input Characteristics in Early Lexical Development: Longitudinal and Crosslinguistic Perspectives},
  shorttitle = {The Interaction of Phonetic/Phonological Development and Input Characteristics in Early Lexical Development},
  author = {Kern, Sophie},
  year = {2018},
  month = dec,
  volume = {63},
  pages = {481--492},
  issn = {0008-4131, 1710-1115},
  doi = {10.1017/cnj.2018.21},
  file = {/Users/megcychosz/Zotero/storage/EJC7359L/Kern - 2018 - The interaction of phoneticphonological developme.pdf},
  journal = {Canadian Journal of Linguistics/Revue canadienne de linguistique},
  language = {en},
  number = {4}
}

@incollection{kernInvarianceVariationFrequency2018,
  title = {Invariance in Variation: {{Frequency}} and Neighbourhood Density as Predictors of Vocabulary Size},
  booktitle = {Sources of Variation in First Language Acquisition: Languages, Contexts, and Learners},
  author = {Kern, Sophie and {dos Santos}, Christophe},
  editor = {Hickmann, Maya and Veneziano, Edy and Jisa, Harriet},
  year = {2018},
  pages = {183--200},
  publisher = {{John Benjamins Publishing Company}},
  series = {Trends in {{Language Acquisition Research}}}
}

@article{kerswillChildrenAdolescentsLanguage1996,
  title = {Children, Adolescents, and Language Change},
  author = {Kerswill, Paul},
  year = {1996},
  month = jul,
  volume = {8},
  pages = {177--202},
  issn = {0954-3945, 1469-8021},
  doi = {10.1017/S0954394500001137},
  abstract = {The article models the spread of linguistic change by taking precise account of the ages of the acquirers and transmitters of change. Several studies, some orig\- inal, are reviewed in order to address the following questions: ``What types of linguistic feature can an individual acquire at different ages?'' ``How much influence do people of different ages exert on the speech of other individuals?'' The article is organized around three key interlocutor combinations: parentinfant/young child, peer group-preadolescent, and older adolescent/adultadolescent. The studies suggest that borrowings are the easiest to acquire, while lexically unpredictable phonological changes are the most difficult. In between are Neogrammarian changes and morphologically conditioned features. The age of the speaker is critical; only the youngest children acquire the ``hardest'' fea\- tures. However, adolescents may be the most influential transmitters of change. A difficulty hierarchy for the acquisition of second dialect features is then pre\- sented; it is suggested that this predicts the nature of linguistic change found under different sociolinguistic conditions. The approach presented here allows for a more detailed understanding of the spread of linguistic change.},
  file = {/Users/megcychosz/Zotero/storage/ZG6E8T7U/Kerswill - 1996 - Children, adolescents, and language change.pdf},
  journal = {Language Variation and Change},
  language = {en},
  number = {2}
}

@article{kerswillCreatingNewTown2000,
  title = {Creating a {{New Town Koine}}: {{Children}} and {{Language Change}} in {{Milton Keynes}}},
  shorttitle = {Creating a {{New Town Koine}}},
  author = {Kerswill, Paul and Williams, Ann},
  year = {2000},
  volume = {29},
  pages = {65--115},
  publisher = {{Cambridge University Press}},
  issn = {0047-4045},
  abstract = {Koineization -- the development of a new, mixed variety following dialect contact -- has well-documented outcomes. However, there have been few studies of the phenomenon actually in progress. This article describes the development of a new variety in the English New Town of Milton Keynes, designated in 1967. The article is structured around eight "principles" that relate the process of koineization to its outcomes. Recordings were made of 48 Milton Keynes-born children in three age groups (4, 8, and 12), the principal caregiver of each child, and several elderly locally born residents. Quantitative analysis of ten phonetic variables suggests that substantial but not complete focusing occurs in the child generation. The lack of linguistic continuity in the New Town is demonstrated, and the time scale of koineization there is discussed. Finally, it is shown that demography and the social-network characteristics of individuals are crucial to the outcomes of koineization.},
  file = {/Users/megcychosz/Zotero/storage/YPNP5Q37/Kerswill and Williams - 2000 - Creating a New Town Koine Children and Language C.pdf},
  journal = {Language in Society},
  number = {1}
}

@article{khattabACQUISITIONGEMINATIONLEBANESEARABIC,
  title = {{{THE ACQUISITION OF GEMINATION IN LEBANESE}}-{{ARABIC CHILDREN}}},
  author = {Khattab, Ghada and {Al-Tamimi}, Jalal},
  pages = {6},
  abstract = {This is the first study on the acquisition of gemination in Arabic, a phonological aspect that is prominent in the adult phonology yet complex in terms of its implementation and interaction with the grammar. The study reports on the longitudinal development of five Lebanese children in the second year of life and enables the authors the trace the transition from phonetic to phonological acquisition in the child.},
  file = {/Users/megcychosz/Zotero/storage/EBFAF3U7/Khattab and Al-Tamimi - THE ACQUISITION OF GEMINATION IN LEBANESE-ARABIC C.pdf},
  language = {en}
}

@article{khattabAgeInputLanguage2003,
  title = {Age, {{Input}}, and {{Language Mode Factors}} in the {{Acquisition}} of {{VOT}} by {{English}}-{{Arabic Bilingual Children}}},
  author = {Khattab, Ghada},
  year = {2003},
  pages = {4},
  abstract = {This paper investigates word-initial Voice Onset Time (VOT) patterns of three Lebanese-English bilinguals aged five, seven and ten and living in Yorkshire, England. The aim is to examine the extent to which children exposed to two languages establish phonetically distinct contrasts for either language. Results show that VOT patterns for each bilingual child differ across the two languages. But while the contrast in English resembles a monolingual-like model, that for Arabic exhibits persisting developmental features that are intricately related to age, complexity, and input. Furthermore, English words produced during code-switching in the Arabic sessions exhibit different VOT patterns from those produced during the English sessions. Such results highlight the importance of taking the language mode into account when investigating language differentiation.},
  file = {/Users/megcychosz/Zotero/storage/GZA5TDVQ/Khattab - 2003 - Age, Input, and Language Mode Factors in the Acqui.pdf},
  language = {en}
}

@article{khattabPhoneticConvergenceDivergence2013,
  title = {Phonetic Convergence and Divergence Strategies in {{English}}-{{Arabic}} Bilingual Children},
  author = {Khattab, Ghada},
  year = {2013},
  month = jan,
  volume = {51},
  issn = {1613-396X, 0024-3949},
  doi = {10.1515/ling-2013-0017},
  abstract = {This paper examines the role that multiple models of English play in the daily interactions of English-Arabic bilingual children growing up in the UK and how these models are harnessed for communicative purposes. Bilingual children are often regularly exposed to standard, nonstandard, and non-native varieties of either of their languages. These varieties constitute the source of phonological knowledge for these children and influence their sociolinguistic development (Khattab 2009). The bilinguals' sociolinguistic competence not only concerns their ability to switch between languages, but also to switch between native and non-native varieties for communicative purposes. To illustrate this behavior we report on convergence and divergence patterns by three English-Arabic bilingual children aged 5, 7, and 10, growing up in Yorkshire, England. The aim is to explore the role of social, contextual, and interactional factors in shaping the bilinguals' English accent and their developing sociophonetic competence. Semi-structured interactions between the children and their mothers are analyzed for language use and within that, for specific phonetic aspects of the children's English accent in English-only and in codeswitched utterances.},
  file = {/Users/megcychosz/Zotero/storage/38KU8JS6/Khattab - 2013 - Phonetic convergence and divergence strategies in .pdf},
  journal = {Linguistics},
  language = {en},
  number = {2}
}

@article{kiddArticulatoryrateContextEffects1989,
  title = {Articulatory-Rate Context Effects in Phoneme Indentification},
  author = {Kidd, Gary},
  year = {1989},
  volume = {15},
  pages = {736--748},
  file = {/Users/megcychosz/Zotero/storage/5TALCJTJ/Kidd - 1989 - Articulatory-rate context effects in phoneme inden.pdf},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  number = {4}
}

@article{kirbyMixedeffectsDesignAnalysis2018,
  title = {Mixed-Effects Design Analysis for Experimental Phonetics},
  author = {Kirby, James and Sonderegger, Morgan},
  year = {2018},
  pages = {37},
  abstract = {It is common practice in the statistical analysis of phonetic data to draw conclusions on the basis of statistical significance. While p-values reflect the probability of incorrectly concluding a null effect is real, they do not provide information about other types of error that are also important for interpreting statistical results. In this paper, we focus on three measures related to these errors. The first, power, reflects the likelihood of detecting an effect that in fact exists. The second and third, Type M and Type S errors, measure the extent to which estimates of the magnitude and direction of an effect are inaccurate. We then provide an example of design analysis (Gelman \& Carlin, 2014), using data from an experimental study on German incomplete neutralization, to illustrate how power, magnitude, and sign errors vary with sample and effect size. This case study shows how the informativity of research findings can vary substantially in ways that are not always, or even usually, apparent on the basis of a p-value alone. We conclude by repeating three recommendations for good statistical practice in phonetics from best practices widely recommended for the social and behavioral sciences: report all results; design studies which will produce high-precision estimates; and conduct direct replications of previous findings.},
  file = {/Users/megcychosz/Zotero/storage/A3PP3JAV/Mixed-effects design analysis for experimental pho.pdf},
  language = {en}
}

@article{kirkAccountingVariability2YearOlds2006,
  title = {Accounting for {{Variability}} in 2-{{Year}}-{{Olds}}' {{Production}} of {{Coda Consonants}}},
  author = {Kirk, Cecilia and Demuth, Katherine},
  year = {2006},
  month = apr,
  volume = {2},
  pages = {97--118},
  issn = {1547-5441, 1547-3341},
  doi = {10.1207/s15473341lld0202_2},
  file = {/Users/megcychosz/Zotero/storage/JKLVDYGD/Kirk and Demuth - 2006 - Accounting for Variability in 2-Year-Olds' Product.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {2}
}

@article{kitamuraAgeSpecificPreferencesInfantDirected2009,
  title = {Age-{{Specific Preferences}} for {{Infant}}-{{Directed Affective Intent}}},
  author = {Kitamura, Christine and Lam, Christa},
  year = {2009},
  volume = {14},
  pages = {77--100},
  issn = {1532-7078},
  doi = {10.1080/15250000802569777},
  abstract = {This study examined the developmental course of infants' attentional preferences for 3 types of infant-directed affective intent, which have been shown to be commonly used at particular ages in the first year of life. Specifically, Kitamura and Burnham (2003) found mothers' tone of voice in infant-directed speech is most comforting between birth and 3 months, most approving at 6 months, and most directive at 9 months. Thus, the aim of this study was to assess whether there is a relation between the type of affective intent used by mothers at each age point, and infants' affective intent preferences. Each infant group, 3-, 6-, and 9-month-olds, was played the 3 types of affective intent alternating across a single test session. When analyzed across age, the interactions revealed the predicted developmental trajectory; that is, infant preferences transformed between 3 and 6 months from comforting to approving, and between 6 and 9 months, from approving to directive. However, when analyzed separately by age, it was shown that 3-month-olds preferred comforting to other types; 6-month-olds preferred approving to directive, but listened equally to approving and comforting; and 9-month-olds showed no preference for any type of affective intent. Because it was possible that 9-month-olds were more focused on phonetic and phonotactic information, a new group of 9-month-olds was tested with intonation-only versions of the 3 affective intent types. Under these conditions, they were found to prefer directive to comforting, but not directive to approving types. The results of this study have implications for what infants pay attention to in their social and linguistic environment over the course of the first year.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1080/15250000802569777},
  file = {/Users/megcychosz/Zotero/storage/DFP9AQ77/Kitamura and Lam - 2009 - Age-Specific Preferences for Infant-Directed Affec.pdf;/Users/megcychosz/Zotero/storage/EHFGZQE6/15250000802569777.html},
  journal = {Infancy},
  language = {en},
  number = {1}
}

@article{kitamuraPitchCommunicativeIntent2003,
  title = {Pitch and {{Communicative Intent}} in {{Mother}}'s {{Speech}}: {{Adjustments}} for {{Age}} and {{Sex}} in the {{First Year}}},
  shorttitle = {Pitch and {{Communicative Intent}} in {{Mother}}'s {{Speech}}},
  author = {Kitamura, Christine and Burnham, Denis},
  year = {2003},
  volume = {4},
  pages = {85--110},
  issn = {1532-7078},
  doi = {10.1207/S15327078IN0401_5},
  abstract = {This study investigated pitch and communicative intent in mothers' infant-directed speech spoken to their infants at birth, 3, 6, 9, and 12 months. Audio recordings of mothers (6 with female, and 6 with male infants) talking to another adult and to their infant at 5 ages were low-pass filtered and rated by 60 adults on 5 scales (Positive or Negative Affect, Express Affection, Encourage Attention, Comfort or Soothe, and Direct Behavior). Mean fundamental frequency (F0) and pitch range of utterances were also measured. Utterances associated with positive affect tend to peak at 6 and 12 months, whereas more directive utterances peaked at 9 months. Mean F0 followed the age trend for affective utterances, and pitch range followed the trend for directive utterances. The results suggest mother speech patterns reflect, complement, and perhaps facilitate infant development.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1207/S15327078IN0401\_5},
  file = {/Users/megcychosz/Zotero/storage/RUQCYVFN/Kitamura and Burnham - 2003 - Pitch and Communicative Intent in Mother's Speech.pdf;/Users/megcychosz/Zotero/storage/HEBS27PG/S15327078IN0401_5.html},
  journal = {Infancy},
  language = {en},
  number = {1}
}

@article{kitamuraUniversalitySpecificityInfantdirected2001,
  title = {Universality and Specificity in Infant-Directed Speech: {{Pitch}} Modifications as a Function of Infant Age and Sex in a Tonal and Non-Tonal Language},
  shorttitle = {Universality and Specificity in Infant-Directed Speech},
  author = {Kitamura, C. and Thanavishuth, C. and Burnham, D. and Luksaneeyanawin, S.},
  year = {2001},
  month = apr,
  volume = {24},
  pages = {372--392},
  issn = {01636383},
  doi = {10.1016/S0163-6383(02)00086-3},
  abstract = {The aim of this study was to investigate the prosodic characteristics of infant-directed speech (IDS) to boys and girls in a tonal (Thai) and non-tonal (Australian English) language. Speech was collected from mothers speaking to infants at birth, and 3, 6, 9, and 12 months, and also to another adult. Mean-F0, pitch range, and utterance slope-F0 were extracted, and the integrity of the tonal information in Thai investigated. The age trends across the two languages differed for each of these measures but Australian English IDS was generally more exaggerated than Thai IDS. With respect to sex differences, Australian English mothers used higher mean-F0, pitch range, and more rising utterances for girls than boys, but Thai mothers used more subdued mean-F0 and more falling utterances for girls than boys. Despite variations in pitch modifications by Thai and Australian English mothers, overall IDS is more exaggerated than adult-directed speech (ADS) in both languages. Furthermore, tonal information in Thai was only slightly less identifiable in Thai IDS than Thai ADS. The universal features and language-specific differences in IDS are discussed in terms of facilitating infant socialization at younger ages, and language acquisition later in infancy. \textcopyright{} 2002 Elsevier Science Inc. All rights reserved.},
  file = {/Users/megcychosz/Zotero/storage/Y2R89DXY/Kitamura et al. - 2001 - Universality and specificity in infant-directed sp.pdf},
  journal = {Infant Behavior and Development},
  language = {en},
  number = {4}
}

@article{kleinAcquisitionMedialAllophones2002,
  title = {The Acquisition of Medial /t, d/ Allophones in Bisyllabic Contexts},
  author = {Klein, Harriet B. and Altman, Elaine K.},
  year = {2002},
  month = jan,
  volume = {16},
  pages = {215--232},
  issn = {0269-9206, 1464-5076},
  doi = {10.1080/02699200110112592},
  abstract = {The acquisition of medial /t, d/ allophones was examined in four children between 2 and 5 years of age, over a period of 38 months. Children labelled pictures designed to elicit a sample of these allophones in iambic ([t]) and trochaic (\textasciimacron ap, nasal and lateral release) contexts. Productions were analysed with reference to attainment of target allophones and use of non-target segmental (e.g., [d ] or [t] in place of \textasciimacron ap) and syllabic variants (e.g., unstressed syllable deletion). All children produced the target [t] allophone in iambic context. Across children, between 10 and 15 variants occurred in trochaic contexts. Nasal and lateral release allophones were never attained. Flap attainment was variable, with signi\textregistered cant di\OE erences across children and across phonetic contexts. Results suggest a hierarchy of /t, d/ allophone production with reference to prosodic and phonetic contexts. Discussion includes implications of these \textregistered ndings for clinical intervention.},
  file = {/Users/megcychosz/Zotero/storage/YYWVPSP9/The acquisition of medial t, d allophones in bis.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {3}
}

@incollection{kleinRelationshipInfantCaretaker1977,
  title = {Relationship of Infant/Caretaker Interaction, Social Class and Nutritional Status to Developmental Test Performance among {{Guatemalan}} Infants.},
  booktitle = {Culture and Infancy: {{Variations}} in the Human Experience},
  author = {Klein, R.E and Lasky, R. E. and Yarbrough, C. and Habicht, J. and Sellers, M. J.},
  editor = {Leiderman, P.H.},
  year = {1977},
  pages = {385--403}
}

@phdthesis{kleinschmidtPerceptionVariableStructured2016,
  title = {Perception in a Variable but Structured World: {{The}} Case of Speech Perception},
  shorttitle = {Perception in a {{Variable}} but {{Structured World}}},
  author = {Kleinschmidt, Dave F},
  year = {2016},
  address = {{Rochester, NY}},
  doi = {10.31237/osf.io/zwves},
  abstract = {Perceptual systems have to make sense out of a world that is not only noisy  and ambiguous, but that also varies from situation to situation. Human speech  perception is a perceptual domain where this problem has long been  acknowledged: individual talkers vary substantially in how they produce  linguistic units using acoustic cues.  Yet, how the speech system solves this  problem of talker variability remains poorly understood. This thesis presents  a computational framework---the ideal adapter---for understanding this  problem and how the speech perception system solves it. The basic insight of  this framework is that variability in speech is not arbitrary but rather  structured: talkers are reasonably consistent in the way they produce  cues, and individual talkers tend to cluster into groups by gender,  regional background, etc.  This structure means that listeners can use their  previous experience with other talkers to guide perception of unfamiliar  talkers, as well as familiar talkers that they encounter again. This framework  unifies a large and messy literature on how listeners cope with talker  variability, leads to quantitative models that provide good fits to human  behavior in a variety of situations, and makes specific, testable predictions  that open up new frontiers in understanding speech perception. This framework  also applies to perception in general, and highlights how speech perception  can serve as a model organism for understanding how perceptual systems cope  with a variable but structured world.},
  file = {/Users/megcychosz/Zotero/storage/Q7VEAQQ8/Kleinschmidt - 2017 - Perception in a Variable but Structured World The.pdf},
  language = {en},
  school = {University of Rochester},
  type = {Unpublished Doctoral Dissertation}
}

@article{kleinschmidtRobustSpeechPerception2015,
  title = {Robust Speech Perception: {{Recognize}} the Familiar, Generalize to the Similar, and Adapt to the Novel},
  shorttitle = {Robust Speech Perception},
  author = {Kleinschmidt, Dave F. and Jaeger, T. Florian},
  year = {2015},
  month = apr,
  volume = {122},
  pages = {148--203},
  issn = {0033-295X},
  doi = {10.1037/a0038695},
  abstract = {Successful speech perception requires that listeners map the acoustic signal to linguistic categories. These mappings are not only probabilistic, but change depending on the situation. For example, one talker's /p/ might be physically indistinguishable from another talker's /b/ (cf. lack of invariance). We characterize the computational problem posed by such a subjectively non-stationary world and propose that the speech perception system overcomes this challenge by (1) recognizing previously encountered situations, (2) generalizing to other situations based on previous similar experience, and (3) adapting to novel situations. We formalize this proposal in the ideal adapter framework: (1) to (3) can be understood as inference under uncertainty about the appropriate generative model for the current talker, thereby facilitating robust speech perception despite the lack of invariance. We focus on two critical aspects of the ideal adapter. First, in situations that clearly deviate from previous experience, listeners need to adapt. We develop a distributional (belief-updating) learning model of incremental adaptation. The model provides a good fit against known and novel phonetic adaptation data, including perceptual recalibration and selective adaptation. Second, robust speech recognition requires listeners learn to represent the structured component of cross-situation variability in the speech signal. We discuss how these two aspects of the ideal adapter provide a unifying explanation for adaptation, talker-specificity, and generalization across talkers and groups of talkers (e.g., accents and dialects). The ideal adapter provides a guiding framework for future investigations into speech perception and adaptation, and more broadly language comprehension.},
  file = {/Users/megcychosz/Zotero/storage/S6JQZABR/Kleinschmidt and Jaeger - 2015 - Robust speech perception Recognize the familiar, .pdf},
  journal = {Psychological review},
  number = {2},
  pmcid = {PMC4744792},
  pmid = {25844873}
}

@article{kocdorEffectInterdeviceInterval2016,
  title = {The Effect of Interdevice Interval on Speech Perception Performance among Bilateral, Pediatric Cochlear Implant Recipients: {{Effect}} of {{Interdevice Interval}} on {{Speech}}},
  shorttitle = {The Effect of Interdevice Interval on Speech Perception Performance among Bilateral, Pediatric Cochlear Implant Recipients},
  author = {Kocdor, Pelin and Iseli, Claire E. and Teagle, Holly F. and Woodard, Jennifer and Park, Lisa and Zdanski, Carlton J. and Brown, Kevin D. and Adunka, Oliver F. and Buchman, Craig A.},
  year = {2016},
  month = oct,
  volume = {126},
  pages = {2389--2394},
  issn = {0023852X},
  doi = {10.1002/lary.26012},
  abstract = {Objectives/Hypothesis: To determine if prolongation of the interdevice interval in children receiving bilateral cochlear implants adversely affects speech perception outcomes. Study Design: Retrospective chart review. Methods: Retrospective review of our pediatric cochlear implant database was performed. Children who had undergone revision surgery or had less than 12 months listening experience with either the first or second implant were excluded. The interdevice interval, best Phonetically Balanced Kindergarten word lists (PBK) score from each ear, and demographic data about each patient were collected. A ratio of PBK was generated (PBK second side/PBK first side) to minimize potential confounding from other individual patient factors that affect speech outcomes. Results: Two hundred forty children met the study criteria. Mean age at first cochlear implantation (CI) was 3.2 years (0.6\textendash 17.9), and the second was 6.6 years (0.8\textendash 22.4). Mean best PBK score from the first CI side was 83.8\% (0\textendash 100), and the second was 67.5\% (0\textendash 100) (P {$<$} .001). When the PBK ratio was plotted against interdevice interval, R2 was 0.47 (P {$<$} .001). When analyzed for hearing stability, those with a progressive loss history demonstrated less influence of prolonged interdevice interval on performance. Multivariate analysis did not identify other factors influencing the ratio. A line of best fit for those with stable hearing loss suggested best outcomes were with an interdevice interval less than 3 to 4 years. Beyond 7 to 8 years, very few achieved useful speech recognition from the second CI. Conclusions: Where possible, the second implant should be received within 3 to 4 years of the first to maximize outcome in those with stable, severe to profound sensorineural hearing loss.},
  file = {/Users/megcychosz/Zotero/storage/PLLZP3C6/Kocdor et al. - 2016 - The effect of interdevice interval on speech perce.pdf},
  journal = {The Laryngoscope},
  language = {en},
  number = {10}
}

@inproceedings{koenigTypeUnderspecificationOnline1995,
  title = {Type {{Underspecification}} and {{On}}-Line {{Type Construction}} in the {{Lexicon}}},
  booktitle = {Proceedings of the 13th {{West Coast Conference}} on {{Formal Linguistics}}},
  author = {Koenig, Jean-Pierre and Jurafsky, Daniel},
  editor = {Aranovich, Raul and Byrne, William and Preuss, Susanne and Senturia, Martha},
  year = {1995},
  pages = {270--285},
  publisher = {{CSLI Publications}},
  address = {{Stanford, CA}},
  file = {/Users/megcychosz/Zotero/storage/KFAXRAGR/Koenig and Jurafsky - Type Underspeciﬁcation and On-line Type Constructi.pdf},
  language = {en}
}

@article{koesterComparisonVocalPatterns1998,
  title = {A {{Comparison}} of the {{Vocal Patterns}} of {{Deaf}} and {{Hearing Mother}}-{{Infant Dyads}} during {{Face}}-to-{{Face Interactions}}},
  author = {Koester, L. S. and Brooks, L. R. and Karkowski, A. M.},
  year = {1998},
  month = oct,
  volume = {3},
  pages = {290--301},
  issn = {1081-4159, 1465-7325},
  doi = {10.1093/oxfordjournals.deafed.a014357},
  file = {/Users/megcychosz/Zotero/storage/8UITQ63G/Koester et al. - 1998 - A Comparison of the Vocal Patterns of Deaf and Hea.pdf},
  journal = {Journal of Deaf Studies and Deaf Education},
  language = {en},
  number = {4}
}

@article{kolinskyImpactAlphabeticLiteracy2021,
  title = {The Impact of Alphabetic Literacy on the Perception of Speech Sounds},
  author = {Kolinsky, R{\'e}gine and Navas, Ana Luiza and {Vidigal de Paula}, Fraulein and {Ribeiro de Brito}, Nathalia and {de Medeiros Botecchia}, Larissa and Bouton, Sophie and Serniclaes, Willy},
  year = {2021},
  month = mar,
  pages = {104687},
  issn = {00100277},
  doi = {10.1016/j.cognition.2021.104687},
  abstract = {The aim of the present study was to evaluate the impact of literacy on phoneme perception. It built on previous research by using more controlled stimuli than in former studies and by independently examining the impacts of literacy and age on phoneme perception. Participants were adult and children beginning readers, and skilled adult readers. They were presented with identification and discrimination tasks, using a voicing continuum. In addition to examining their categorical perception of speech sounds and the precision of phonemic categories, participants' literacy level was carefully evaluated. The results confirmed that neither age nor literacy modulated categorical perception. However, level of literacy did have a significant impact on the precision of phonemic categories, which was independent from the influence of age.},
  file = {/Users/megcychosz/Zotero/storage/3X2DBLAV/Kolinsky et al. - 2021 - The impact of alphabetic literacy on the perceptio.pdf},
  journal = {Cognition},
  language = {en}
}

@article{kondaurovaVocalImitationMothers2020,
  title = {Vocal Imitation between Mothers and Their Children with Cochlear Implants},
  author = {Kondaurova, Maria V. and Fagan, Mary K. and Zheng, Qi},
  year = {2020},
  month = aug,
  pages = {infa.12363},
  issn = {1525-0008, 1532-7078},
  doi = {10.1111/infa.12363},
  abstract = {To better explain variation in language acquisition in children with hearing loss, this study examined vocal (e.g., vocalization) and lexical (e.g., word) imitation in spontaneous interactions between mothers and children with 12 months of hearing experience using their cochlear implants (n = 12; mean age 27.9 months). Hearing children in two control groups were matched to children with cochlear implants, either by child chronological age (n = 12; mean age = 27.4 months) or by child hearing experience (n = 12; mean age 12 months). All three groups of mother\textendash child dyads were audio-recorded playing together. Mothers and children in all groups imitated their partners' vocalization and word utterances; however, the cochlear implant and hearing experience-matched groups produced fewer word imitations than the age-matched group. The frequency of preceding child vocalization or word production predicted maternal imitation type (vocalization or word); however, frequency of maternal vocalization predicted child vocalization imitation only. The results showed that child hearing experience affected imitation in both communication partners.},
  file = {/Users/megcychosz/Zotero/storage/E3UQU72X/Kondaurova et al. - 2020 - Vocal imitation between mothers and their children.pdf},
  journal = {Infancy},
  language = {en}
}

@article{kondaurovaVocalTurnTakingMothers2020,
  title = {Vocal {{Turn}}-{{Taking Between Mothers}} and {{Their Children With Cochlear Implants}}:},
  shorttitle = {Vocal {{Turn}}-{{Taking Between Mothers}} and {{Their Children With Cochlear Implants}}},
  author = {Kondaurova, Maria V. and Smith, Nicholas A. and Zheng, Qi and Reed, Jessa and Fagan, Mary K.},
  year = {2020},
  volume = {41},
  pages = {362--373},
  issn = {0196-0202},
  doi = {10.1097/AUD.0000000000000769},
  abstract = {Objectives: The primary objective of the study was to examine the occurrence and temporal structure of vocal turn-taking during spontaneous interactions between mothers and their children with cochlear implants (CI) over the first year after cochlear implantation as compared with interactions between mothers and children with normal hearing (NH). Design: Mothers' unstructured play sessions with children with CI (n = 12) were recorded at 2 time points, 3 months (mean age 18.3 months) and 9 months (mean age 27.5 months) post-CI. A separate control group of mothers with age-matched hearing children (n = 12) was recorded at the same 2 time points. Five types of events were coded: mother and child vocalizations, vocalizations including speech overlap, and between- and within-speaker pauses. We analyzed the proportion of child and mother vocalizations involved in turn-taking, the temporal structure of turn-taking, and the temporal reciprocity of turn-taking using proportions of simultaneous speech and the duration of betweenand within-speaker pauses. Results: The CI group produced a significantly smaller proportion of vocalizations in turn-taking than the NH group at the first session; however, CI children's proportion of vocalizations in turn-taking increased over time. There was a significantly larger proportion of simultaneous speech in the CI compared with the NH group at the first session. The CI group produced longer between-speaker pauses as compared with those in the NH group at the first session with mothers decreasing the duration of between-speaker pauses over time. NH infants and mothers in both groups produced longer within- than between-speaker pauses but CI infants demonstrated the opposite pattern. In addition, the duration of mothers' between-speaker pauses (CI and NH) was predicted by the duration of the infants' between-speaker pauses. Conclusions: Vocal turn-taking and timing in both members of the dyad, the mother and infant, were sensitive to the experiential effects of child hearing loss and remediation with CI. Child hearing status affected dyadspecific coordination in the timing of responses between mothers and their children.},
  file = {/Users/megcychosz/Zotero/storage/5VBE2BNE/Kondaurova et al. - 2020 - Vocal Turn-Taking Between Mothers and Their Childr.pdf},
  journal = {Ear and Hearing},
  language = {en},
  number = {2}
}

@incollection{konnerInfancyKalahariDesert1977,
  title = {Infancy among the {{Kalahari}} Desert {{San}}},
  booktitle = {Culture and Infancy: {{Variations}} in the Human Experience},
  author = {Konner, M.},
  editor = {Leiderman, P.H.},
  year = {1977},
  pages = {287--328}
}

@article{koNonlinearDevelopmentSpeaking2012,
  title = {Nonlinear Development of Speaking Rate in Child-Directed Speech},
  author = {Ko, Eon-Suk},
  year = {2012},
  month = jun,
  volume = {122},
  pages = {841--857},
  issn = {00243841},
  doi = {10.1016/j.lingua.2012.02.005},
  abstract = {This study investigates the role of child-directed speech (CDS) in language acquisition by re-evaluating the old claim that mothers adapt their speech over the course of child language development. The specific hypothesis tested is that there may be quantal changes in certain properties of CDS such as speaking rate around the time children reach major linguistic milestones. The developmental path of CDS speaking rate was analyzed in 25 mother\textendash child pairs from longitudinal corpora in CHILDES database (MacWhinney, 2000). A parallel analysis was also made on the development of speaking rate in the child as well as the mean length of utterance (MLU) in mother and child. The total number of utterances analyzed approximates one million. The findings reveal that CDS speaking rate changes nonlinearly with a shift occurring early in the multiword stage. There is also some indication that another breakpoint might be present around the onset of child speech production. A parallel pattern of nonlinearity is also observed in the speaking rate of the child and the MLU of both mother and child. The results support the notion that CDS is adapted to the changing needs of the language-learning child, which could reflect its facilitative role in child language acquisition.},
  file = {/Users/megcychosz/Zotero/storage/D7HPEWE3/Ko - 2012 - Nonlinear development of speaking rate in child-di.pdf},
  journal = {Lingua},
  language = {en},
  number = {8}
}

@article{koopmans-vanbeinumBabblingLackAuditory2001,
  title = {Babbling and the Lack of Auditory Speech Perception: A Matter of Coordination?},
  shorttitle = {Babbling and the Lack of Auditory Speech Perception},
  author = {{Koopmans-van Beinum}, Florien J. and Clement, Chris J. and Dikkenberg-Pot, Ineke Van Den},
  year = {2001},
  volume = {4},
  pages = {61--70},
  issn = {1467-7687},
  doi = {10.1111/1467-7687.00149},
  abstract = {This paper concentrates on the question whether and where the lack of auditory perception can be traced in the early sound productions of deaf infants. A sensorimotor description system based on movements in the phonatory and articulatory speech production systems was developed to classify early infant vocalizations. Canonical babbling is a strong cue in the normal speech developmental process. Therefore the main question in this work was why deaf infants do not start to babble in their first year of life like normally hearing children do. Detailed analyses of early vocalizations of deaf and hearing infants revealed that auditory feedback is needed to lead to coordination of movements of the phonatory and the articulatory system, and that this coordination capacity is a prerequisite for the development of normal speech production.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-7687.00149},
  file = {/Users/megcychosz/Zotero/storage/DQ3W78EK/Beinum et al. - 2001 - Babbling and the lack of auditory speech perceptio.pdf;/Users/megcychosz/Zotero/storage/VTRS8UB8/1467-7687.html},
  journal = {Developmental Science},
  language = {en},
  number = {1}
}

@book{koopmans-vanbeinumVowelContrastReduction1980,
  title = {Vowel Contrast Reduction, an Acoustic and Perceptual Study of {{Dutch}} Vowels in Various Speech Conditions},
  author = {{Koopmans-Van Beinum}, F. J.},
  year = {1980},
  publisher = {{University of Amsterdam, Academische Per B.V.}},
  address = {{Amsterdam}},
  series = {{{PhD Dissertation}}}
}

@article{krauseAcousticPropertiesNaturally2004,
  title = {Acoustic Properties of Naturally Produced Clear Speech at Normal Speaking Rates},
  author = {Krause, Jean C. and Braida, Louis D.},
  year = {2004},
  month = jan,
  volume = {115},
  pages = {362--378},
  issn = {0001-4966},
  doi = {10.1121/1.1635842},
  file = {/Users/megcychosz/Zotero/storage/RINMUPJ8/Krause and Braida - 2004 - Acoustic properties of naturally produced clear sp.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{kristensenFemaleCaregiversTalk2020,
  title = {Female Caregivers Talk More to 18-56-Months-Old Children with and without Hearing Impairment than Male Caregivers Measured with {{LENA}}\texttrademark{} \textendash{} {{A}} Cross-Sectional Pilot Study},
  author = {Kristensen, Nina Melsom and Sundby, Catharina Fallet and Hauge, Mai Nayeli and L{\"o}fkvist, Ulrika},
  year = {2020},
  month = mar,
  volume = {130},
  pages = {109809},
  issn = {01655876},
  doi = {10.1016/j.ijporl.2019.109809},
  abstract = {The objective of the current study was to investigate possible differences in word count use per day (number of adult words) by caregivers of different gender, in a sample of Norwegian children (N = 17) with hearing impairment (HI) (n = 8) and normal hearing (NH) (n = 9), aged 18\textendash 56 months. The current study had a crosssectional, descriptive study design. One all-day recording with the LENA technology was conducted to measure adult word use in the home environment (Md length: 12.46 h, 9.13\textendash 16 h). Female caregivers used a significantly higher amount of words than male caregivers close to the children, regardless of their hearing status, HI: p = .01, NH: p = .01. All children were exposed to a higher number of adult words from female caregivers. There is a need to conduct more and further research about possible caregiver differences, and investigate not only the quantity of word use, but also the qualitative interaction patterns between caregivers of different gender and young children with HI, and in relation to early intervention actions.},
  file = {/Users/megcychosz/Zotero/storage/Q8UEHU8D/Kristensen et al. - 2020 - Female caregivers talk more to 18-56-months-old ch.pdf},
  journal = {International Journal of Pediatric Otorhinolaryngology},
  language = {en}
}

@article{kuhlCrossLanguageAnalysisPhonetic1997,
  title = {Cross-{{Language Analysis}} of {{Phonetic Units}} in {{Language Addressed}} to {{Infants}}},
  author = {Kuhl, P. K. and Andruski, J. E. and Chistovich, I.A. and Chistovich, L.A. and Kozhevnikova, E.V. and Ryskina, V. L. and Stolyarova, E.I. and Sundberg, U. and Lacerda, F.},
  year = {1997},
  volume = {277},
  pages = {684--686},
  issn = {00368075, 10959203},
  doi = {10.1126/science.277.5326.684},
  file = {/Users/megcychosz/Zotero/storage/T8F9XRKM/Kuhl - 1997 - Cross-Language Analysis of Phonetic Units in Langu.pdf},
  journal = {Science},
  language = {en},
  number = {5326}
}

@article{kuhlForeignlanguageExperienceInfancy2003,
  title = {Foreign-Language Experience in Infancy: {{Effects}} of Short-Term Exposure and Social Interaction on Phonetic Learning},
  shorttitle = {Foreign-Language Experience in Infancy},
  author = {Kuhl, P. K. and Tsao, F.-M. and Liu, H.-M.},
  year = {2003},
  month = jul,
  volume = {100},
  pages = {9096--9101},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1532872100},
  file = {/Users/megcychosz/Zotero/storage/K8TL6Y4C/Kuhl et al. - 2003 - Foreign-language experience in infancy Effects of.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {15}
}

@article{kuhlHumanAdultsHuman1991,
  title = {Human Adults and Human Infants Show a ``Perceptual Magnet Effect'' for the Prototypes of Speech Categories, Monkeys Do Not},
  author = {Kuhl, Patricia K.},
  year = {1991},
  month = mar,
  volume = {50},
  pages = {93--107},
  issn = {0031-5117, 1532-5962},
  doi = {10.3758/BF03212211},
  file = {/Users/megcychosz/Zotero/storage/QWFU6R9X/Kuhl - 1991 - Human adults and human infants show a “perceptual .pdf},
  journal = {Perception \& Psychophysics},
  language = {en},
  number = {2}
}

@article{kuhlLinguisticExperienceAlters1992,
  title = {Linguistic Experience Alters Phonetic Perception in Infants by 6 Months of Age},
  author = {Kuhl, P. and Williams, K. and Lacerda, F and Stevens, K. and Lindblom, B},
  year = {1992},
  month = jan,
  volume = {255},
  pages = {606--608},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1736364},
  file = {/Users/megcychosz/Zotero/storage/94F8KVTT/Kuhl et al. - 1992 - Linguistic experience alters phonetic perception i.pdf},
  journal = {Science},
  language = {en},
  number = {5044}
}

@article{kuhlLinguisticExperienceAlters1992a,
  title = {Linguistic Experience Alters Phonetic Perception in Infants by 6 Months of Age},
  author = {Kuhl, P. and Williams, K. and Lacerda, F and Stevens, K. and Lindblom, B},
  year = {1992},
  month = jan,
  volume = {255},
  pages = {606--608},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1736364},
  file = {/Users/megcychosz/Zotero/storage/2E6RESMJ/Kuhl et al. - 1992 - Linguistic experience alters phonetic perception i.pdf},
  journal = {Science},
  language = {en},
  number = {5044}
}

@article{kuhlPhoneticLearningPathway2008,
  title = {Phonetic Learning as a Pathway to Language: New Data and Native Language Magnet Theory Expanded ({{NLM}}-e)},
  shorttitle = {Phonetic Learning as a Pathway to Language},
  author = {Kuhl, Patricia K and Conboy, Barbara T and {Coffey-Corina}, Sharon and Padden, Denise and {Rivera-Gaxiola}, Maritza and Nelson, Tobey},
  year = {2008},
  month = mar,
  volume = {363},
  pages = {979--1000},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2007.2154},
  file = {/Users/megcychosz/Zotero/storage/ZUW57T5Z/Kuhl et al. - 2008 - Phonetic learning as a pathway to language new da.pdf},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  language = {en},
  number = {1493}
}

@article{kunterMorphologicalEmbeddingPhonetic,
  title = {Morphological Embedding and Phonetic Reduction: The Case of Triconstituent Compounds},
  author = {Kunter, Gero and Plag, Ingo},
  volume = {26},
  pages = {201--227},
  abstract = {In this paper we propose that the internal bracketing of a word with more than two morphemes is reflected in the phonetic implementation. We hypothesize that embedded forms show more phonetic reduction than forms at higher structural levels (`Embedded Reduction Hypothesis'). This paper tests the prediction of the Embedded Reduction Hypothesis with triconstituent compounds. The analysis of the durational properties of almost 500 compound tokens shows that there is a lengthening effect on the non-embedded constituent, and a shortening effect on the adjacent embedded constituent. Yet, this predicted effect of embedding interacts with other lexical factors, above all the bigram frequency of the embedded compound. At a theoretical level, these effects mean that the durational properties of the cross-boundary constituents are indicative of the hierarchical structure and of the strength of the internal boundary of triconstituent compounds. Hence, morphological structure is reflected in the speech signal.},
  file = {/Users/megcychosz/Zotero/storage/946YBQTK/Kunter - Morphological embedding and phonetic reduction th.pdf},
  journal = {Morphology},
  language = {en}
}

@article{kuznetsovaLmerTestPackageTests2017,
  title = {{{lmerTest Package}}: {{Tests}} in Linear Mixed-Effects Models},
  author = {Kuznetsova, A. and Brockhoff, P.B. and Christensen, R.H.B.},
  year = {2017},
  volume = {82},
  pages = {1--26},
  journal = {Journal of Statistical Software},
  number = {13}
}

@article{lahiriMentalRepresentationLexical1991,
  title = {The Mental Representation of Lexical Form: {{A}} Phonological Approach to the Recognition Lexicon},
  author = {Lahiri, Aditi and {Marslen-Wilson}, William},
  year = {1991},
  volume = {38},
  pages = {245--294},
  abstract = {we propose G psycholinguistic model of lexical processing which incorporates both process and representation. The view of lexical access and selection that we advocate claims that these processes are conducted with respect to abstract underspecified phor?ological representations of lexical form. The abstract form of a given item in the recognition lexicon is an integrated segmental-featural representation, where all predictable and non-distinctive information is withheld. This means that listeners do not have available to them, as they process the speech input, a representation of the srlrface phonetic realisation of a given word-form. What determines performance is the abstract, underspecified representation with respect to which this surface string is being interpreted.},
  file = {/Users/megcychosz/Zotero/storage/8BDK2K4W/Marslen-Wilson - sentation of lexicalIform to the recognition lexi.pdf},
  journal = {Cognition},
  language = {en}
}

@article{laingBabbleWordsInfants2020,
  title = {From Babble to Words: {{Infants}}' Early Productions Match Words and Objects in Their Environment},
  author = {Laing, Catherine E and Bergelson, Elika},
  year = {2020},
  volume = {122},
  pages = {e101308},
  file = {/Users/megcychosz/Zotero/storage/K58DQ4JF/Laing and Bergelson - 2020 - From babble to words Infants’ early productions m.pdf},
  journal = {Cognitive Psychology}
}

@article{laingPhonologicalMotivationAcquisition,
  title = {Phonological {{Motivation}} for the {{Acquisition}} of {{Onomatopoeia}}: {{An Analysis}} of {{Early Words}}},
  author = {Laing, Catherine E},
  pages = {22},
  abstract = {Onomatopoeia are disproportionately high in number in infants' early words compared to adult language. Studies of infant language perception have proposed an iconic advantage for onomatopoeia, which may make them easier for infants to learn. This study analyses infants' early word production to show a phonological motivation for onomatopoeia in early acquisition. Crosslinguistic evidence from 16 infants demonstrates how these forms fit within a phonologically-systematic developing lexicon. We observe a predominance of consonant harmony and open CV syllables in infants' early words\textemdash structures that are typical of onomatopoeia across languages. Infants' acquisition of onomatopoeia is shown to be driven by a preference for structures that are easy to plan and produce. These data present an original perspective on onomatopoeia in early development, highlighting the role of production in language acquisition in general, and onomatopoeic words in particular.},
  file = {/Users/megcychosz/Zotero/storage/RI6EC8VT/Laing - Phonological Motivation for the Acquisition of Ono.pdf},
  language = {en}
}

@article{lammertShortTimeEstimationVocal2015,
  title = {On {{Short}}-{{Time Estimation}} of {{Vocal Tract Length}} from {{Formant Frequencies}}},
  author = {Lammert, Adam C. and Narayanan, Shrikanth S.},
  editor = {Larson, Charles R},
  year = {2015},
  month = jul,
  volume = {10},
  pages = {e0132193},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0132193},
  abstract = {Vocal tract length is highly variable across speakers and determines many aspects of the acoustic speech signal, making it an essential parameter to consider for explaining behavioral variability. A method for accurate estimation of vocal tract length from formant frequencies would afford normalization of interspeaker variability and facilitate acoustic comparisons across speakers. A framework for considering estimation methods is developed from the basic principles of vocal tract acoustics, and an estimation method is proposed that follows naturally from this framework. The proposed method is evaluated using acoustic characteristics of simulated vocal tracts ranging from 14 to 19 cm in length, as well as real-time magnetic resonance imaging data with synchronous audio from five speakers whose vocal tracts range from 14.5 to 18.0 cm in length. Evaluations show improvements in accuracy over previously proposed methods, with 0.631 and 1.277 cm root mean square error on simulated and human speech data, respectively. Empirical results show that the effectiveness of the proposed method is based on emphasizing higher formant frequencies, which seem less affected by speech articulation. Theoretical predictions of formant sensitivity reinforce this empirical finding. Moreover, theoretical insights are explained regarding the reason for differences in formant sensitivity.},
  file = {/Users/megcychosz/Zotero/storage/N534M5XV/Lammert and Narayanan - 2015 - On Short-Time Estimation of Vocal Tract Length fro.PDF},
  journal = {PLOS ONE},
  language = {en},
  number = {7}
}

@article{lancasterRemoteHearingScreenings2008,
  title = {Remote {{Hearing Screenings}} via {{Telehealth}} in a {{Rural Elementary School}}},
  author = {Lancaster, Paul and Krumm, Mark and Ribera, John and Klich, Richard},
  year = {2008},
  month = dec,
  volume = {17},
  pages = {114--122},
  issn = {1059-0889, 1558-9137},
  doi = {10.1044/1059-0889(2008/07-0008)},
  abstract = {Purpose: Telehealth (telepractice) is the provision of health care services using telecommunications. Telehealth technology typically has been employed to increase the level of health care access for consumers living in rural communities. In this way, audiologists can use telehealth to provide services in the rural school systems. This is important because school hearing screening programs are the foundation of educational audiology programs. Therefore, the goal of this study was to determine the feasibility of providing hearing screening services by telehealth technology to school-age children. Method: Hearing screening services\textemdash including otoscopy, pure-tone, and immittance audiometry\textemdash were conducted on 32 children in 3rd grade attending an elementary school in rural Utah. Each child received 1 screening on-site and another through telehealth procedures. Results: Immittance and otoscopy results were identical for on-site and telehealth screening protocols. Five children responded differently to pure-tone stimuli presented by the telehealth protocol than by the on-site protocol. However, no statistically significant difference was found for pure-tone screening results obtained by telehealth or on-site screening procedures (binomial test, p = .37). Likewise, overall screening results obtained by traditional and telehealth procedures were not statistically significant (binomial test, p = .37). Conclusion: The results of this study suggest that school hearing screenings may be provided using telehealth technology. This study did find that 5 students performed differently to puretone screenings administered by the telehealth protocol in contrast to on-site hearing screening services. Further research is necessary to identify factors leading to false responses to pure-tone hearing screening when telehealth technology is used. In addition, telehealth hearing screening protocols should be conducted with participants of different age groups and experiencing a wide range of hearing loss to further clarify the value of telehealth technology.},
  file = {/Users/megcychosz/Zotero/storage/499DMYSB/Lancaster et al. - 2008 - Remote Hearing Screenings via Telehealth in a Rura.pdf},
  journal = {American Journal of Audiology},
  language = {en},
  number = {2}
}

@book{langSpanishWordFormation2013,
  title = {Spanish {{Word Formation}}},
  author = {Lang, M. F.},
  year = {2013},
  month = oct,
  publisher = {{Routledge}},
  abstract = {First published in 1990. Routledge is an imprint of Taylor \& Francis, an informa company.},
  googlebooks = {SR\_YAQAAQBAJ},
  isbn = {978-1-135-08076-1},
  keywords = {Language Arts \& Disciplines / General,Language Arts \& Disciplines / Linguistics / General},
  language = {en}
}

@techreport{lavechinReverseengineeringLanguageAcquisition2021,
  title = {Reverse-Engineering Language Acquisition with Child-Centered Long-Form Recordings},
  author = {Lavechin, Marvin and {de Seyssel}, Maureen and Gautheron, Lucas and Dupoux, Emmanuel and Cristia, Alejandrina},
  year = {2021},
  month = mar,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/pt9xq},
  abstract = {Language use in everyday life can be studied using light-weight, wearable recorders that collect long-form recordings, i.e. audio (including speech) over whole days. We first place this technique into the broader context of the current ways of studying both the input being received by children as well as children's own language production, laying out the main advantages and drawbacks of long-form recordings. We then go on to argue that a unique advantage of long-form recordings is that they can fuel realistic models of early language acquisition that use speech for representing children's input and/or for establishing production benchmarks. To enable the field to make the most of this unique empirical and conceptual contribution, we outline what this reverse-engineering approach from long-form recordings entails, why it is useful, and how to evaluate success.},
  file = {/Users/megcychosz/Zotero/storage/IZBTDZZG/Lavechin et al. - 2021 - Reverse-engineering language acquisition with chil.pdf},
  language = {en},
  type = {Preprint}
}

@article{lawEffectsVocabularySize2015,
  title = {Effects of {{Vocabulary Size}} on {{Online Lexical Processing}} by {{Preschoolers}}},
  author = {Law, Franzo and Edwards, Jan R.},
  year = {2015},
  month = oct,
  volume = {11},
  pages = {331--355},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2014.961066},
  file = {/Users/megcychosz/Zotero/storage/62FNT88B/Law and Edwards - 2015 - Effects of Vocabulary Size on Online Lexical Proce.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {4}
}

@article{lawEffectsVocabularySize2015a,
  title = {Effects of {{Vocabulary Size}} on {{Online Lexical Processing}} by {{Preschoolers}}},
  author = {Law, Franzo and Edwards, Jan R.},
  year = {2015},
  month = oct,
  volume = {11},
  pages = {331--355},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2014.961066},
  file = {/Users/megcychosz/Zotero/storage/DTGA5HTE/Law and Edwards - 2015 - Effects of Vocabulary Size on Online Lexical Proce.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {4}
}

@article{lawVocabularySizeAuditory2017,
  title = {Vocabulary Size and Auditory Word Recognition in Preschool Children},
  author = {Law, Franzo and Mahr, Tristan and Schneeberg, Alissa and Edwards, Jan},
  year = {2017},
  month = jan,
  volume = {38},
  pages = {89--125},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716416000126},
  abstract = {Recognizing familiar words quickly and accurately facilitates learning new words, as well as other aspects of language acquisition. This study used the visual world paradigm with semantic and phonological competitors to study lexical processing efficiency in 2\textendash 5 year-old children. Experiment 1 found this paradigm was sensitive to vocabulary-size differences. Experiment 2 included a more diverse group of children who were tested in their native dialect (either African American English or Mainstream American English). No effect of stimulus dialect was observed,. Results showed that vocabulary size was a better predictor of eye gaze patterns than maternal education, but that maternal education level had a moderating effect; as maternal education level increased, vocabulary size was less predictive of lexical processing efficiency.},
  file = {/Users/megcychosz/Zotero/storage/MQ6ZLASF/Law et al. - 2017 - Vocabulary size and auditory word recognition in p.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {1}
}

@article{lee-kimMorphologicalEffectsDarkness2013,
  title = {Morphological Effects on the Darkness of {{English}} Intervocalic /l/},
  author = {{Lee-Kim}, Sang-Im and Davidson, Lisa and Hwang, Sangjin},
  year = {2013},
  month = jan,
  volume = {4},
  pages = {475--511},
  issn = {1868-6354, 1868-6346},
  doi = {10.1515/lp-2013-0015},
  file = {/Users/megcychosz/Zotero/storage/B2BNMZD8/lee-kim et al. 2013  notes (1).rtf;/Users/megcychosz/Zotero/storage/V6AUC5JR/Lee-Kim et al. - 2013 - Morphological effects on the darkness of English i.pdf},
  journal = {Laboratory Phonology},
  language = {en},
  number = {2}
}

@article{leeAcousticsChildrenSpeech1999,
  title = {Acoustics of Children's Speech: {{Developmental}} Changes of Temporal and Spectral Parameters},
  shorttitle = {Acoustics of Children's Speech},
  author = {Lee, Sungbok and Potamianos, Alexandros and Narayanan, Shrikanth},
  year = {1999},
  month = mar,
  volume = {105},
  pages = {1455--1468},
  issn = {0001-4966},
  doi = {10.1121/1.426686},
  file = {/Users/megcychosz/Zotero/storage/4RZLKGD4/Lee et al methods notes.rtf;/Users/megcychosz/Zotero/storage/995GNZL3/Lee et al. - 1999 - Acoustics of children’s speech Developmental chan.pdf;/Users/megcychosz/Zotero/storage/CKBNMN7Y/infa.12019.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {3}
}

@article{leeBabblingDevelopmentSeen2018,
  title = {Babbling Development as Seen in Canonical Babbling Ratios: {{A}} Naturalistic Evaluation of All-Day Recordings},
  shorttitle = {Babbling Development as Seen in Canonical Babbling Ratios},
  author = {Lee, Chia-Cheng and Jhang, Yuna and Relyea, George and Chen, Li-mei and Oller, D. Kimbrough},
  year = {2018},
  month = feb,
  volume = {50},
  pages = {140--153},
  issn = {01636383},
  doi = {10.1016/j.infbeh.2017.12.002},
  abstract = {Canonical babbling (CB) is critical in forming foundations for speech. Research has shown that the emergence of CB precedes first words, predicts language outcomes, and is delayed in infants with several communicative disorders. We seek a naturalistic portrayal of CB development, using all-day home recordings to evaluate the influences of age, language, and social circumstances on infant CB production. Thus we address the nature of very early language foundations and how they can be modulated. This is the first study to evaluate possible interactions of language and social circumstance in the development of babbling. We examined the effects of age (6 and 11 months), language/culture (English and Chinese), and social circumstances (during infant-directed speech [IDS], during infant overhearing of adult-directed speech [ADS], or when infants were alone) on canonical babbling ratios (CBR=canonical syllables/total syllables). The results showed a three-way interaction of infant age by infant language/culture by social circumstance. The complexity of the results forces us to recognize that a variety of factors can interact in the development of foundations for language, and that both the infant vocal response to the language/ culture environment and the language/culture environment of the infant may change across age.},
  file = {/Users/megcychosz/Zotero/storage/7HH9VHN7/Lee et al. - 2018 - Babbling development as seen in canonical babbling.pdf;/Users/megcychosz/Zotero/storage/9Z4YCPVL/Lee et al. 2018.rtf},
  journal = {Infant Behavior and Development},
  language = {en}
}

@article{leeEmergencePhoneticCategories2017,
  title = {The Emergence of Phonetic Categories in {{Korean}}\textendash{{English}} Bilingual Children},
  author = {Lee, Sue Ann S. and Iverson, Gregory K.},
  year = {2017},
  month = nov,
  volume = {44},
  pages = {1485--1515},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000916000659},
  abstract = {The present study examined the speech production of three-year-old Korean\textendash English bilingual (KEB) children. English and Korean stops, as well as front vowels in both languages, were compared acoustically among the KEB children, then also measured against those of their age-equivalent monolingual counterparts. Evidence of distinctive phonetic categorization in bilingual children was more salient in vowels than in stops. Vowels and stops produced by the bilingual children were not significantly different from those of their monolingual counterparts. The findings suggest that, similar to other language domains, two linguistic systems are apparent in the phonetic production component of three-year-old KEB children, but that phonetic distinctiveness in production may not emerge holistically in an across-the-board fashion, appearing earlier in vowels than stops. Thus, the phonetic production systems of the two languages may develop with only limited interaction in simultaneous KEB children exposed to two languages at an early age.},
  file = {/Users/megcychosz/Zotero/storage/PT4RFSRQ/Lee and Iverson - 2017 - The emergence of phonetic categories in Korean–Eng.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {6}
}

@article{leeRecordingTechnologiesInterview2004,
  title = {Recording {{Technologies}} and the {{Interview}} in {{Sociology}}, 1920\textendash 2000},
  author = {Lee, Raymond M.},
  year = {2004},
  month = dec,
  volume = {38},
  pages = {869--889},
  issn = {0038-0385, 1469-8684},
  doi = {10.1177/0038038504047177},
  abstract = {Little is known about the changing techniques and technologies for the recording of unstructured interviews.This article traces the evolution of devices for recording what is said in unstructured interviews, and looks at the impact of technological change on the interview process.},
  file = {/Users/megcychosz/Zotero/storage/UZA7SSX4/Lee - 2004 - Recording Technologies and the Interview in Sociol.pdf},
  journal = {Sociology},
  language = {en},
  number = {5}
}

@article{leeSubtletyAmbientLanguageEffects2017a,
  title = {Subtlety of {{Ambient}}-{{Language Effects}} in {{Babbling}}: {{A Study}} of {{English}}- and {{Chinese}}-{{Learning Infants}} at 8, 10, and 12 {{Months}}},
  shorttitle = {Subtlety of {{Ambient}}-{{Language Effects}} in {{Babbling}}},
  author = {Lee, Chia-Cheng and Jhang, Yuna and Chen, Li-mei and Relyea, George and Oller, D. Kimbrough},
  year = {2017},
  month = jan,
  volume = {13},
  pages = {100--126},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2016.1180983},
  abstract = {Prior research on ambient-language effects in babbling has often suggested infants produce language-specific phonological features within the first year. These results have been questioned in research failing to find such effects and challenging the positive findings on methodological grounds. We studied English- and Chinese-learning infants at 8, 10, and 12 months and found listeners could not detect ambient-language effects in the vast majority of infant utterances, but only in items deemed to be words or to contain canonical syllables that may have made them sound like words with language-specific shapes. Thus, the present research suggests the earliest ambient-language effects may be found in emerging lexical items or in utterances influenced by language-specific features of lexical items. Even the ambient-language effects for infant canonical syllables and words were very small compared with ambient-language effects for meaningless but phonotactically well-formed syllable sequences spoken by adult native speakers of English and Chinese.},
  file = {/Users/megcychosz/Zotero/storage/3N2GF4HZ/Lee et al. - 2017 - Subtlety of Ambient-Language Effects in Babbling .pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {1}
}

@article{leeVowelPlaceDetection2008,
  title = {Vowel Place Detection for a Knowledge-based Speech Recognition System},
  author = {Lee, Sukmyung and Choi, Jeung-Yoon},
  year = {2008},
  month = may,
  volume = {123},
  pages = {3330--3330},
  issn = {0001-4966},
  doi = {10.1121/1.2933844},
  file = {/Users/megcychosz/Zotero/storage/9DFLXFTG/Lee and Choi - 2008 - Vowel place detection for a knowledge‐based speech.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@inproceedings{lefrancACLEWDiViMeEasytouse2018,
  title = {The {{ACLEW DiViMe}}: {{An Easy}}-to-Use {{Diarization Tool}}},
  shorttitle = {The {{ACLEW DiViMe}}},
  booktitle = {Interspeech 2018},
  author = {Le Franc, Adrien and Riebling, Eric and Karadayi, Julien and Wang, Yun and Scaff, Camila and Metze, Florian and Cristia, Alejandrina},
  year = {2018},
  month = sep,
  pages = {1383--1387},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2018-2324},
  abstract = {We present ``DiViMe'', an open-source virtual machine aimed at packaging speech technology for real-life data, and developed in the context of the ``Analyzing Children's Language Environments across the World'' Project. This first release focuses on Speech Activity Detection, Speaker Diarization, and their evaluation. The present paper introduces the set of included tools and the current workflow, which is focused on making minimal assumptions regarding users' technical skills. Additionally, we show how the current DiViMe tools fare against three sets of challenging data. In a first experiment, we look at performance with samples extracted from daylong recordings gathered using the LENATM system from English-learning children. We find that the performance of the tools currently in DiViMe is not far from that achieved by the LENATM proprietary software. In a second experiment, we generalize to other samples of child-centered daylong files, gathered with non-LENATM hardware from non-English-learning children, showing that performance does not degrade in this condition. Finally, we report on performance in the DiHARD 2018 Challenge Test Data. Originally conceived in the ``Speech Recognition Virtual Kitchen'', DiViMe is a promising platform for packaging speech technology tools for widespread re-use, with potential impact on both fundamental and applied speech and language research.},
  file = {/Users/megcychosz/Zotero/storage/X6AFFCGQ/Le Franc et al. - 2018 - The ACLEW DiViMe An Easy-to-use Diarization Tool.pdf},
  language = {en}
}

@article{lehetCircumspectionUsingAutomated2020,
  title = {Circumspection in Using Automated Measures: {{Talker}} Gender and Addressee Affect Error Rates for Adult Speech Detection in the {{Language ENvironment Analysis}} ({{LENA}}) System.},
  author = {Lehet, M. and Arjmandi, M. K. and Dilley, L. and Houston, D.},
  year = {2020},
  file = {/Users/megcychosz/Zotero/storage/L8ZVE54U/Lehet2020_Article_CircumspectionInUsingAutomated.pdf;/Users/megcychosz/Zotero/storage/U8JNNT3H/LENA Accuracy JSLHR resubmitted.pdf},
  journal = {Behavior Research Methods}
}

@article{lehistePerceptionCoarticulationEffects1972,
  title = {On the Perception of Coarticulation Effects in {{English VCV}} Syllables},
  author = {Lehiste, I. and Shockey, L.},
  year = {1972},
  volume = {15},
  pages = {500--506},
  file = {/Users/megcychosz/Zotero/storage/8XK4YP76/WPL_12_June_1972_78.pdf},
  journal = {Journal of Speech and Hearing Research},
  number = {3}
}

@article{lehisteTimingUtterancesLinguistic1972,
  title = {The {{Timing}} of {{Utterances}} and {{Linguistic Boundaries}}},
  author = {Lehiste, Ilse},
  year = {1972},
  month = jun,
  volume = {51},
  pages = {2018--2024},
  issn = {0001-4966},
  doi = {10.1121/1.1913062},
  file = {/Users/megcychosz/Zotero/storage/C7V6UGWV/Lehiste - 1972 - The Timing of Utterances and Linguistic Boundaries.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {6B}
}

@book{lenthEmmeansEstimatedMarginal2021,
  title = {Emmeans: {{Estimated Marginal Means}}, Aka {{Least}}-{{Squares Means}}},
  author = {Lenth, Russell V.},
  year = {2021},
  edition = {R package version 1.6.1}
}

@techreport{leungParentsFinetuneTheir2020,
  title = {Parents Fine-Tune Their Speech to Children's Vocabulary Knowledge},
  author = {Leung, Ashley and Tunkel, Alex and Yurovsky, Daniel},
  year = {2020},
  month = apr,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/prz8g},
  abstract = {Young children learn language at an incredible rate. While children come prepared with powerful statistical learning mechanisms, the statistics they encounter are also prepared for them: Children learn from caregivers motivated to communicate with them. How precisely do parents tune their speech to their children's individual language knowledge? To answer this question, we asked parent-child pairs (n=41) to play a reference game in which the parent's goal was to guide their child to select a target animal from a set of three. Parents fine-tuned their referring expressions to their children's knowledge at the lexical level, producing more informative references for animals they thought their children did not know. Further, parents learned about their children's knowledge over the course of the game, and tuned their referring expressions accordingly. Child-directed speech may thus support children's learning not because it is uniformly simplified, but because it is tuned to individual children's language development.},
  file = {/Users/megcychosz/Zotero/storage/465UHEID/Leung et al. - 2020 - Parents fine-tune their speech to children’s vocab.pdf},
  language = {en},
  type = {Preprint}
}

@article{libermanMotorTheorySpeech1985,
  title = {The Motor Theory of Speech Perception Revised},
  author = {Liberman, Alvin M. and Mattingly, Ignatius G.},
  year = {1985},
  month = oct,
  volume = {21},
  pages = {1--36},
  issn = {00100277},
  doi = {10.1016/0010-0277(85)90021-6},
  abstract = {A motor theory of speech perception, initially proposed to account for results of early experiments with synthetic speech, is now extensively revised to accommodate recent findings, and to relate the assumptions of the theory to those that might be made about other perceptual modes. According to the revised theory, phonetic information is perceived in a biologically distinct system, a `module' specialized to detect the intended gestures of the speaker that are the basis for phonetic categories. Built into the structure of this module is the unique but lawful relationship between the gestures and the acoustic patterns in which they are variously overlapped. In consequence, the module causes perception of phonetic structure without translation from preliminary auditory impressions. Thus, it is comparable to such other modules as the one that enables an animal to localize sound. Peculiar to the phonetic module are the relation between perception and production it incorporates and the fact that it must compete with other modules for the same stimulus variations.},
  file = {/Users/megcychosz/Zotero/storage/KLDFMJG4/Liberman and Mattingly - 1985 - The motor theory of speech perception revised.pdf},
  journal = {Cognition},
  language = {en},
  number = {1}
}

@article{libermanPerceptionSpeechCode1967,
  title = {Perception of the Speech Code},
  author = {Liberman, Alvin M. and Cooper, F. S. and Shankweiler, D.P. and {Studdert-Kennedy}, M.},
  year = {1967},
  volume = {74},
  pages = {431--461},
  file = {/Users/megcychosz/Zotero/storage/JJE8VJ7C/liberman.etal.1967.pdf},
  journal = {Psychological Review},
  number = {6}
}

@phdthesis{liceraldeConsequencesPowerTransformation2018,
  title = {Consequences of Power Transformation in Linear Mixed-Effects Models of Chronometric Data},
  author = {Liceralde, V. R. T},
  year = {2018},
  address = {{Chapel Hill, NC}},
  school = {University of North Carolina, Chapel Hill}
}

@article{liceraldeConsequencesUsingPowerunderreview,
  title = {Consequences of Using Power Transformations as a Statistical Solution in Linear Mixed-Effects Models of Chronometric Data},
  author = {Liceralde, V. R. T and Gordon, P. C.},
  year = {under review}
}

@article{liContrastCovertContrast2009,
  title = {Contrast and Covert Contrast: {{The}} Phonetic Development of Voiceless Sibilant Fricatives in {{English}} and {{Japanese}} Toddlers},
  shorttitle = {Contrast and Covert Contrast},
  author = {Li, Fangfang and Edwards, Jan and Beckman, Mary E.},
  year = {2009},
  month = jan,
  volume = {37},
  pages = {111--124},
  issn = {00954470},
  doi = {10.1016/j.wocn.2008.10.001},
  abstract = {This paper examines the acoustic characteristics of voiceless sibilant fricatives in English-and Japanese-speaking adults and the acquisition of contrasts involving these sounds in 2- and 3-yearold children. Both English and Japanese have a two-way contrast between an alveolar fricative (/s/), and a postalveolar fricative (/{$\int$}/ in English and /ɕ/ in Japanese). Acoustic analysis of the adult productions revealed cross-linguistic differences in what acoustic parameters were used to differentiate the two fricatives in the two languages and in how well the two fricatives were differentiated by the acoustic parameters that were investigated. For the children's data, the transcription results showed that English-speaking children generally produced the alveolar fricative more accurately than the postalveolar one, whereas the opposite was true for Japanese-speaking children. In addition, acoustic analysis revealed the presence of covert contrast in the productions of some English-speaking and some Japanese-speaking children. The different development patterns are discussed in terms of the differences in the fine phonetic detail of the contrast in the two languages.},
  file = {/Users/megcychosz/Zotero/storage/BSFL5UZB/Li et al. - 2009 - Contrast and covert contrast The phonetic develop.pdf;/Users/megcychosz/Zotero/storage/Y5FRFMB2/nihms-160932.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {1}
}

@article{lidzHowNatureMeets2015,
  title = {How {{Nature Meets Nurture}}: {{Universal Grammar}} and {{Statistical Learning}}},
  shorttitle = {How {{Nature Meets Nurture}}},
  author = {Lidz, Jeffrey and Gagliardi, Annie},
  year = {2015},
  month = jan,
  volume = {1},
  pages = {333--353},
  issn = {2333-9683, 2333-9691},
  doi = {10.1146/annurev-linguist-030514-125236},
  abstract = {Evidence of children's sensitivity to statistical features of their input in language acquisition is often used to argue against learning mechanisms driven by innate knowledge. At the same time, evidence of children acquiring knowledge that is richer than the input supports arguments in favor of such mechanisms. This tension can be resolved by separating the inferential and deductive components of the language learning mechanism. Universal Grammar provides representations that support deductions about sentences that fall outside of experience. In addition, these representations define the evidence that learners use to infer a particular grammar. The input is compared with the expected evidence to drive statistical inference. In support of this model, we review evidence of (a) children's sensitivity to the environment, (b) mismatches between input and intake, (c) the need for learning mechanisms beyond innate representations, and (d) the deductive consequences of children's acquired syntactic representations.},
  file = {/Users/megcychosz/Zotero/storage/YDS69BZL/Lidz and Gagliardi - 2015 - How Nature Meets Nurture Universal Grammar and St.pdf},
  journal = {Annual Review of Linguistics},
  language = {en},
  number = {1}
}

@article{liebermanSpeechNeanderthalMan1972,
  title = {On the Speech of Neanderthal Man},
  author = {Lieberman, Philip and Crelin, Edmund S.},
  year = {1972},
  volume = {2},
  pages = {203--222},
  doi = {10.1515/9783110819434},
  file = {/Users/megcychosz/Zotero/storage/UI7ACAQX/Liebermann - 1972 - The Speech of Primates.pdf},
  journal = {Linguistic Inquiry},
  language = {en},
  number = {2}
}

@incollection{lievenCrosslinguisticCrossculturalAspects1994,
  title = {Crosslinguistic and Crosscultural Aspects of Language Addressed to Children},
  booktitle = {Input and Interation in Language Acquisition},
  author = {Lieven, Elena V. M.},
  editor = {Gallaway, C. and Richards, B. J.},
  year = {1994},
  pages = {56--73},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}}
}

@article{lievenLexicallybasedLearningEarly1997,
  title = {Lexically-Based Learning and Early Grammatical Development},
  author = {Lieven, Elena V. M. and Pine, Julian M. and Baldwin, Gillian},
  year = {1997},
  month = feb,
  volume = {24},
  pages = {187--219},
  issn = {03050009},
  doi = {10.1017/S0305000996002930},
  file = {/Users/megcychosz/Zotero/storage/5JERSQ9Z/Lieven et al. - 1997 - Lexically-based learning and early grammatical dev.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {1}
}

@article{liLanguageSpecificDevelopmentalDifferences2012,
  title = {Language-{{Specific Developmental Differences}} in {{Speech Production}}: {{A Cross}}-{{Language Acoustic Study}}},
  shorttitle = {Language-{{Specific Developmental Differences}} in {{Speech Production}}},
  author = {Li, Fangfang},
  year = {2012},
  volume = {83},
  pages = {1303--1315},
  issn = {1467-8624},
  doi = {10.1111/j.1467-8624.2012.01773.x},
  abstract = {Speech productions of 40 English- and 40 Japanese-speaking children (aged 2\textendash 5) were examined and compared with the speech produced by 20 adult speakers (10 speakers per language). Participants were recorded while repeating words that began with ``s'' and ``sh'' sounds. Clear language-specific patterns in adults' speech were found, with English speakers differentiating ``s'' and ``sh'' in 1 acoustic dimension (i.e., spectral mean) and Japanese speakers differentiating the 2 categories in 3 acoustic dimensions (i.e., spectral mean, standard deviation, and onset F2 frequency). For both language groups, children's speech exhibited a gradual change from an early undifferentiated form to later differentiated categories. The separation processes, however, only occur in those acoustic dimensions used by adults in the corresponding languages.},
  annotation = {\_eprint: https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8624.2012.01773.x},
  file = {/Users/megcychosz/Zotero/storage/R5UQV9AR/Li - 2012 - Language-Specific Developmental Differences in Spe.pdf;/Users/megcychosz/Zotero/storage/52T6SBHK/j.1467-8624.2012.01773.html},
  journal = {Child Development},
  language = {en},
  number = {4}
}

@incollection{lindblomExplainingPhoneticVariation1990,
  title = {Explaining {{Phonetic Variation}}: {{A Sketch}} of the {{H}}\&{{H Theory}}},
  shorttitle = {Explaining {{Phonetic Variation}}},
  booktitle = {Speech {{Production}} and {{Speech Modelling}}},
  author = {Lindblom, B.},
  editor = {Hardcastle, William J. and Marchal, Alain},
  year = {1990},
  pages = {403--439},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  doi = {10.1007/978-94-009-2037-8_16},
  abstract = {The H\&H theory is developed from evidence showing that speaking and listening are shaped by biologically general processes. Speech production is adaptive. Speakers can, and typically do, tune their performance according to communicative and situational demands, controlling the interplay between production-oriented factors on the one hand, and output-oriented constraints on the other. For the ideal speaker, H\&H claims that such adaptations reflect his tacit awareness of the listener's access to sources of information independent of the signal and his judgement of the short-term demands for explicit signal information. Hence speakers are expected to vary their output along a continuum of hyper- and hypospeech. The theory suggests that the lack of invariance that speech signals commonly exhibit (Perkell and Klatt 1986) is a direct consequence of this adaptive organization (cf MacNeilage 1970). Accordingly, in the H\&H program the quest for phonetic invariance is replaced by another research task: Explicating the notion of sufficient discriminability and defining the class of speech signals that meet that criterion.},
  file = {/Users/megcychosz/Zotero/storage/6FFYTHTA/Lindblom - 1990 - Explaining Phonetic Variation A Sketch of the H&H.pdf},
  isbn = {978-94-010-7414-8 978-94-009-2037-8},
  language = {en}
}

@incollection{lindblomPhonologicalUnitsAdaptive1992,
  title = {Phonological Units as Adaptive Emergents of Lexical Development},
  booktitle = {Phonological Development: {{MOdels}}, Researhc, Implications},
  author = {Lindblom, B},
  editor = {Ferguson, C.A. and Menn, Lise and {Stoel-Gammon}, Carol},
  year = {1992},
  pages = {131--163},
  publisher = {{York}},
  address = {{Timonium, MD}}
}

@article{lindblomSpectroraphicStudyVowel1963,
  title = {Spectroraphic {{Study}} of {{Vowel Reduction}}},
  author = {Lindblom, B},
  year = {1963},
  volume = {35},
  pages = {1773--1781},
  file = {/Users/megcychosz/Zotero/storage/TDV57FN6/Lindblom - Spectroraphic Study of Vowel Reduction.pdf},
  journal = {Journal of the Acoustical Society of America},
  language = {en},
  number = {11}
}

@article{linzenWhatCanLinguistics2019,
  title = {What Can Linguistics and Deep Learning Contribute to Each Other? {{Response}} to {{Pater}}},
  shorttitle = {What Can Linguistics and Deep Learning Contribute to Each Other?},
  author = {Linzen, Tal},
  year = {2019},
  issn = {1535-0665},
  doi = {10.1353/lan.2019.0001},
  file = {/Users/megcychosz/Zotero/storage/F3RAXTSE/Linzen - 2019 - What can linguistics and deep learning contribute .pdf},
  journal = {Language},
  language = {en}
}

@book{lipskiEspanolAmericaLinguistica1996,
  title = {{El Espanol de America (Linguistica) (Linguistica / Linguistics) (Spanish Edition)}},
  author = {Lipski, John M. and Recuero, Silvia Iglesias},
  year = {1996},
  publisher = {{C\'atedra}},
  abstract = {En este libro se describe la inmensa riqueza de la variedad de " lenguas espa\~nolas " que se hablan desde la frontera de EE.UU.-Canad\'a hasta la Ant\'artida. En la primera parte presenta un an\'alisis ling\"u\'istico del espa\~nol de Am\'erica y lo sit\'ua en un extenso contexto. El autor examina la fonolog\'ia y morfolog\'ia de la lengua, su sintaxis, la variaci\'on l\'exica y la diferenciaci\'on social, sus contactos pasados y presentes con otras lenguas y explora los factores sociohist\'oricos que han afectado a los dialectos americanos. Proporciona detalles acerca de las influencias africanas y nativo-americanas de lengua y poblaci\'on y las contribuciones del espa\~nol peninsular. En la segunda parte da un detallado informe del espa\~nol de Am\'erica en cada pa\'is, con sus claves hist\'oricas, detalles de pronunciaci\'on, morfosintaxis y l\'exico.},
  file = {/Users/megcychosz/Zotero/storage/FN5HPGDX/Lipski and Recuero - 1996 - El Espanol de America (Linguistica) (Linguistica .pdf},
  googlebooks = {sqa8rnrSBkkC},
  isbn = {978-84-376-1423-6},
  keywords = {Foreign Language Study / Spanish,Language Arts \& Disciplines / General,Language Arts \& Disciplines / Linguistics / General,Language Arts \& Disciplines / Linguistics / Sociolinguistics,Literary Criticism / European / Spanish \& Portuguese},
  language = {es}
}

@article{liuAcousticAnalysisLexical2007,
  title = {Acoustic Analysis of Lexical Tone in {{Mandarin}} Infant-Directed Speech.},
  author = {Liu, Huei-Mei and Tsao, Feng-Ming and Kuhl, Patricia K.},
  year = {2007},
  volume = {43},
  pages = {912--917},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/0012-1649.43.4.912},
  file = {/Users/megcychosz/Zotero/storage/YMK3PK3J/Liu et al. - 2007 - Acoustic analysis of lexical tone in Mandarin infa.pdf},
  journal = {Developmental Psychology},
  language = {en},
  number = {4}
}

@article{liuAgerelatedChangesAcoustic2009,
  title = {Age-Related {{Changes}} in {{Acoustic Modifications}} of {{Mandarin Maternal Speech}} to {{Preverbal Infants}} and {{Five}}-{{Year}}-{{Old Children}}: {{A Longitudinal Study}}},
  shorttitle = {Age-Related {{Changes}} in {{Acoustic Modifications}} of {{Mandarin Maternal Speech}} to {{Preverbal Infants}} and {{Five}}-{{Year}}-{{Old Children}}},
  author = {Liu, Huei-Mei and Tsao, Feng-Ming and Kuhl, Patricia K.},
  year = {2009},
  month = sep,
  volume = {36},
  pages = {909},
  issn = {0305-0009},
  doi = {10.1017/S030500090800929X},
  abstract = {Acoustic-phonetic exaggeration of infant-directed speech (IDS) is well documented, but few studies address whether these features are modified with a child's age. Mandarin-speaking mothers were recorded while addressing an adult and their child at two ages (7-12 months and 5 years) to examine the acoustic-phonetic differences between IDS and child\textendash directed speech (CDS). CDS exhibits an exaggeration pattern resembling that of IDS\textemdash expanded vowel space, longer vowels, higher pitch, and greater lexical tone differences\textemdash when compared to ADS. Longitudinal analysis demonstrated that the extent of acoustic exaggeration is significantly smaller in CDS than in IDS. Age-related changes in maternal speech provide some support for the hypothesis that mothers adjust their speech directed toward children as a function of the child's language ability.},
  file = {/Users/megcychosz/Zotero/storage/45T56Q3S/Liu et al. - 2009 - Age-related Changes in Acoustic Modifications of M.pdf},
  journal = {Journal of child language},
  number = {4},
  pmcid = {PMC2818882},
  pmid = {19232142}
}

@article{liuAgerelatedChangesAcoustic2009a,
  title = {Age-Related {{Changes}} in {{Acoustic Modifications}} of {{Mandarin Maternal Speech}} to {{Preverbal Infants}} and {{Five}}-{{Year}}-{{Old Children}}: {{A Longitudinal Study}}},
  shorttitle = {Age-Related {{Changes}} in {{Acoustic Modifications}} of {{Mandarin Maternal Speech}} to {{Preverbal Infants}} and {{Five}}-{{Year}}-{{Old Children}}},
  author = {Liu, Huei-Mei and Tsao, Feng-Ming and Kuhl, Patricia K.},
  year = {2009},
  month = sep,
  volume = {36},
  pages = {909},
  issn = {0305-0009},
  doi = {10.1017/S030500090800929X},
  abstract = {Acoustic-phonetic exaggeration of infant-directed speech (IDS) is well documented, but few studies address whether these features are modified with a child's age. Mandarin-speaking mothers were recorded while addressing an adult and their child at two ages (7-12 months and 5 years) to examine the acoustic-phonetic differences between IDS and child\textendash directed speech (CDS). CDS exhibits an exaggeration pattern resembling that of IDS\textemdash expanded vowel space, longer vowels, higher pitch, and greater lexical tone differences\textemdash when compared to ADS. Longitudinal analysis demonstrated that the extent of acoustic exaggeration is significantly smaller in CDS than in IDS. Age-related changes in maternal speech provide some support for the hypothesis that mothers adjust their speech directed toward children as a function of the child's language ability.},
  file = {/Users/megcychosz/Zotero/storage/E7AF3L2S/Liu et al. - 2009 - Age-related Changes in Acoustic Modifications of M.pdf},
  journal = {Journal of child language},
  number = {4},
  pmcid = {PMC2818882},
  pmid = {19232142}
}

@article{liuAssociationMothersSpeech2003,
  title = {An Association between Mothers' Speech Clarity and Infants' Speech Discrimination Skills},
  author = {Liu, Huei-Mei and Kuhl, Patricia K. and Tsao, Feng-Ming},
  year = {2003},
  volume = {6},
  pages = {F1-F10},
  issn = {1467-7687},
  doi = {10.1111/1467-7687.00275},
  abstract = {The quality of speech directed towards infants may play an important role in infants' language development. However, few studies have examined the link between the two. We examined the correlation between maternal speech clarity and infant speech perception performance in two groups of Mandarin-speaking mother\textendash infant pairs. Maternal speech clarity was assessed using the degree of expansion of the vowel space, a measure previously shown to reflect the intelligibility of words and sentences. Speech discrimination in the infants (6\textendash 8 and 10\textendash 12-month-olds) was measured using a head-turn task. The results show that mothers' vowel space area is significantly correlated with infants' speech discrimination performance. Socioeconomic data from both parents show that the result cannot be attributed to parental socioeconomic factors. This study is correlational and therefore a causal relationship cannot be firmly established. However, the results are consistent with the view that maternal speech clarity directly affects infants' early language learning.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-7687.00275},
  file = {/Users/megcychosz/Zotero/storage/WUCBLGIA/Liu et al. - 2003 - An association between mothers’ speech clarity and.pdf;/Users/megcychosz/Zotero/storage/3MRKLE6U/1467-7687.html},
  journal = {Developmental Science},
  language = {en},
  number = {3}
}

@article{liuLexicalAcousticFeatures2014,
  title = {Lexical and {{Acoustic Features}} of {{Maternal Utterances Addressing Preverbal Infants}} in {{Picture Book Reading Link}} to 5-{{Year}}-{{Old Children}}'s {{Language Development}}},
  author = {Liu, Huei-Mei},
  year = {2014},
  month = nov,
  volume = {25},
  pages = {1103--1117},
  issn = {1040-9289, 1556-6935},
  doi = {10.1080/10409289.2014.899887},
  file = {/Users/megcychosz/Zotero/storage/9CCW74ER/Liu - 2014 - Lexical and Acoustic Features of Maternal Utteranc.pdf},
  journal = {Early Education and Development},
  language = {en},
  number = {8}
}

@article{livelyEffectsCognitiveWorkload1993,
  title = {Effects of Cognitive Workload on Speech Production: {{Acoustic}} Analyses and Perceptual Consequences},
  author = {Lively, Scott E and Pisoni, David B and Summers, W Van and Bernacki, Robert H},
  year = {1993},
  volume = {93},
  pages = {2962--2973},
  abstract = {The present investigation examined the effects of cognitive workload on speech production. Workload was manipulated by having talkers perform a compensatory visual tracking task while speaking test sentences of the form ``Say hVd again.'' Acoustic measurements were made to compare utterances produced under workload with the same utterances produced in a control condition. In the workload condition, some talkers produced utterances with increased amplitude and amplitude variability, decreased spectral tilt and F0 variability and increased speaking rate. No changes in F1, F2, or F3 were observed across conditions for any of the talkers. These findings indicate both laryngeal and sublaryngeal adjustments in articulation, as well as modifications in the absolute timing of articulatory gestures. The results of a perceptual identification experiment paralleled the acoustic measurements. Small but significant advantages in intelligibility were observed for utterances produced under workload for talkers who showed robust changes in speech production. Changes in amplitude and amplitude variability for utterances produced under workload appeared to be the major factor controlling intelligibility. The results of the present investigation support the assumptions of Lindblom's [''Explaining phonetic variation: A sketch of the H\&theory,'' in Speech Production and Speech Modeling (Klewer Academic, The Netherlands, 1990)] H\&H model: Talkers adapt their speech to suit the demands of the environment and these modifications are designed to maximize intelligibility.},
  file = {/Users/megcychosz/Zotero/storage/62BBFT73/Lively et al. - 2012 - Effects of cognitive workload on speech production.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{lobanovClassificationRussianVowels1971,
  title = {Classification of {{Russian Vowels Spoken}} by {{Different Speakers}}},
  author = {Lobanov, B. M.},
  year = {1971},
  month = feb,
  volume = {49},
  pages = {606--608},
  issn = {0001-4966},
  doi = {10.1121/1.1912396},
  file = {/Users/megcychosz/Zotero/storage/UIURBB48/Lobanov - 1971 - Classification of Russian Vowels Spoken by Differe.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {2B}
}

@incollection{loizouSpeechProcessingVocoderCentric2006,
  title = {Speech {{Processing}} in {{Vocoder}}-{{Centric Cochlear Implants}}},
  booktitle = {Advances in {{Oto}}-{{Rhino}}-{{Laryngology}}},
  author = {Loizou, Philipos C.},
  editor = {M{\o}ller, A.R.},
  year = {2006},
  volume = {64},
  pages = {109--143},
  publisher = {{Karger}},
  address = {{Basel}},
  doi = {10.1159/000094648},
  abstract = {The principles of most recent cochlear implant processor are similar to that of the channel vocoder, originally used for transmitting speech over telephone lines with much less bandwidth than that required for transmitting the unprocessed speech signal. An overview of the various vocoder-centric processing strategies proposed for cochlear implants since the late 1990s is provided including the strategies used in different commercially available implant processors. Special emphasis is placed on reviewing the strategies designed to enhance pitch information for potentially better music perception. The various noise suppression strategies proposed over the years based on multi-microphone and single-microphone inputs are also described.},
  file = {/Users/megcychosz/Zotero/storage/EWJVMLXE/Loizou - 2006 - Speech Processing in Vocoder-Centric Cochlear Impl.pdf},
  isbn = {978-3-8055-8157-8 978-3-318-01380-1},
  language = {en}
}

@techreport{longSocialEndogenousInfant2019,
  title = {Social and Endogenous Infant Vocalizations},
  author = {Long, Helen and Bowman, Dale and Yoo, Hyunjoo and {Burkhardt-Reed}, Megan and Bene, Edina and Oller, D. Kimbrough},
  year = {2019},
  month = oct,
  institution = {{Developmental Biology}},
  doi = {10.1101/821371},
  abstract = {Research on infant vocal development has provided notable insights into vocal interaction with caregivers, elucidating growth in foundations for language through parental elicitation and reaction to vocalizations. A role for infant vocalizations produced endogenously, potentially providing raw material for interaction and a basis for growth in the vocal capacity itself, has received less attention. We report that in laboratory recordings of infants and their parents, the bulk of infant speech-like vocalizations, or "protophones", were directed toward no one and instead appeared to be generated endogenously, mostly in exploration of vocal abilities. The tendency to predominantly produce protophones without directing them to others occurred both during periods when parents were instructed to interact with their infants and during periods when parents were occupied with an interviewer, with the infants in the room. The results emphasize the infant as an agent in vocal learning, even when not interacting socially and suggest an enhanced perspective on foundations for vocal language.},
  file = {/Users/megcychosz/Zotero/storage/2WQ4YIYN/Long et al. - 2019 - Social and endogenous infant vocalizations.pdf},
  language = {en},
  type = {Preprint}
}

@article{lopezAdultResponsesInfant2020,
  title = {Adult Responses to Infant Prelinguistic Vocalizations Are Associated with Infant Vocabulary: {{A}} Home Observation Study},
  shorttitle = {Adult Responses to Infant Prelinguistic Vocalizations Are Associated with Infant Vocabulary},
  author = {Lopez, Lukas D. and Walle, Eric A. and Pretzer, Gina M. and Warlaumont, Anne S.},
  editor = {Nomikou, Iris},
  year = {2020},
  month = nov,
  volume = {15},
  pages = {e0242232},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0242232},
  abstract = {This study used LENA recording devices to capture infants' home language environments and examine how qualitative differences in adult responding to infant vocalizations related to infant vocabulary. Infant-directed speech and infant vocalizations were coded in samples taken from daylong home audio recordings of 13-month-old infants. Infant speech-related vocalizations were identified and coded as either canonical or non-canonical. Infant-directed adult speech was identified and classified into different pragmatic types. Multiple regressions examined the relation between adult responsiveness, imitating, recasting, and expanding and infant canonical and non-canonical vocalizations with caregiver-reported infant receptive and productive vocabulary. An interaction between adult like-sound responding (i.e., the total number of imitations, recasts, and expansions) and infant canonical vocalizations indicated that infants who produced more canonical vocalizations and received more adult like-sound responses had higher productive vocabularies. When sequences were analyzed, infant canonical vocalizations that preceded and followed adult recasts and expansions were positively associated with infant productive vocabulary. These findings provide insights into how infant-adult vocal exchanges are related to early vocabulary development.},
  file = {/Users/megcychosz/Zotero/storage/SWZVA9EJ/Lopez et al. - 2020 - Adult responses to infant prelinguistic vocalizati.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {11}
}

@article{loreTalkReadSing2018,
  title = {Talk, {{Read}}, {{Sing}}: {{Early Language Exposure As}} an {{Overlooked Social Determinant}} of {{Health}}},
  shorttitle = {Talk, {{Read}}, {{Sing}}},
  author = {LoRe, Danielle and Ladner, Peter and Suskind, Dana},
  year = {2018},
  month = sep,
  volume = {142},
  pages = {e20182007},
  issn = {0031-4005, 1098-4275},
  doi = {10.1542/peds.2018-2007},
  file = {/Users/megcychosz/Zotero/storage/7ZJ4A24F/LoRe et al. - 2018 - Talk, Read, Sing Early Language Exposure As an Ov.pdf},
  journal = {Pediatrics},
  language = {en},
  number = {3}
}

@article{lorgeEstimatingSizeVocabularies1963,
  title = {Estimating the {{Size}} of {{Vocabularies}} of {{Children}} and {{Adults}}: {{An Analysis}} of {{Methodological Issues}}},
  shorttitle = {Estimating the {{Size}} of {{Vocabularies}} of {{Children}} and {{Adults}}},
  author = {Lorge, Irving and Chall, Jeanne},
  year = {1963},
  month = dec,
  volume = {32},
  pages = {147--157},
  issn = {0022-0973, 1940-0683},
  doi = {10.1080/00220973.1963.11010819},
  file = {/Users/megcychosz/Zotero/storage/BMJAFECG/Lorge and Chall - 1963 - Estimating the Size of Vocabularies of Children an.pdf},
  journal = {The Journal of Experimental Education},
  language = {en},
  number = {2}
}

@book{losiewiczEffectFrequencyLinguistic,
  title = {The Effect of Frequency on Linguistic Morphology},
  author = {Losiewicz, Beth L.},
  publisher = {{University of Texas, Austin}},
  address = {{Austin, Texas}},
  series = {Unpublished Doctoral Dissertation}
}

@article{losiewiczWordFrequencyEffects1995,
  title = {Word Frequency Effects on the Acoustic Duration of Morphemes},
  author = {Losiewicz, Beth L.},
  year = {1995},
  volume = {97},
  pages = {3243--3243},
  issn = {0001-4966},
  doi = {10.1121/1.411745},
  file = {/Users/megcychosz/Zotero/storage/5Y9LRYJA/Losiewicz - 1995 - Word frequency effects on the acoustic duration of.pdf},
  journal = {Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{loTransformNotTransform2015,
  title = {To Transform or Not to Transform: Using Generalized Linear Mixed Models to Analyse Reaction Time Data},
  shorttitle = {To Transform or Not to Transform},
  author = {Lo, Steson and Andrews, Sally},
  year = {2015},
  month = aug,
  volume = {6},
  pages = {1--16},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2015.01171},
  abstract = {Linear mixed-effect models (LMMs) are being increasingly widely used in psychology to analyse multi-level research designs. This feature allows LMMs to address some of the problems identified by Speelman and McGann (2013) about the use of mean data, because they do not average across individual responses. However, recent guidelines for using LMM to analyse skewed reaction time (RT) data collected in many cognitive psychological studies recommend the application of non-linear transformations to satisfy assumptions of normality. Uncritical adoption of this recommendation has important theoretical implications which can yield misleading conclusions. For example, Balota et al. (2013) showed that analyses of raw RT produced additive effects of word frequency and stimulus quality on word identification, which conflicted with the interactive effects observed in analyses of transformed RT. Generalized linear mixed-effect models (GLMM) provide a solution to this problem by satisfying normality assumptions without the need for transformation. This allows differences between individuals to be properly assessed, using the metric most appropriate to the researcher's theoretical context. We outline the major theoretical decisions involved in specifying a GLMM, and illustrate them by reanalysing Balota et al.'s datasets. We then consider the broader benefits of using GLMM to investigate individual differences.},
  file = {/Users/megcychosz/Zotero/storage/9CY6DQAC/Lo and Andrews - 2015 - To transform or not to transform using generalize.pdf},
  journal = {Frontiers in Psychology},
  language = {en},
  number = {1171}
}

@article{lovcevicAcousticFeaturesInfantDirected,
  title = {Acoustic {{Features}} of {{Infant}}-{{Directed Speech}} to {{Infants}} with {{Hearing Loss}}},
  author = {Lovcevic, Irena},
  file = {/Users/megcychosz/Zotero/storage/893YH228/Preprint_Lovcevic, Kalashnikova, & Burnham, 2020.pdf}
}

@article{luceRecognizingSpokenWords1998,
  title = {Recognizing {{Spoken Words}}: {{The Neighborhood Activation Model}}},
  shorttitle = {Recognizing {{Spoken Words}}},
  author = {Luce, Paul A. and Pisoni, David B.},
  year = {1998},
  month = feb,
  volume = {19},
  pages = {1--36},
  issn = {0196-0202},
  abstract = {Objective A fundamental problem in the study of human spoken word recognition concerns the structural relations among the sound patterns of words in memory and the effects these relations have on spoken word recognition. In the present investigation, computational and experimental methods were employed to address a number of fundamental issues related to the representation and structural organization of spoken words in the mental lexicon and to lay the groundwork for a model of spoken word recognition. Design Using a computerized lexicon consisting of transcriptions of 20,000 words, similarity neighborhoods for each of the transcriptions were computed. Among the variables of interest in the computation of the similarity neighborhoods were: 1) the number of words occurring in a neighborhood, 2) the degree of phonetic similarity among the words, and 3) the frequencies of occurrence of the words in the language. The effects of these variables on auditory word recognition were examined in a series of behavioral experiments employing three experimental paradigms: perceptual identification of words in noise, auditory lexical decision, and auditory word naming. Results The results of each of these experiments demonstrated that the number and nature of words in a similarity neighborhood affect the speed and accuracy of word recognition. A neighborhood probability rule was developed that adequately predicted identification performance. This rule, based on  choice rule, combines stimulus word intelligibility, neighborhood confusability, and frequency into a single expression. Based on this rule, a model of auditory word recognition, the neighborhood activation model, was proposed. This model describes the effects of similarity neighborhood structure on the process of discriminating among the acoustic-phonetic representations of words in memory. The results of these experiments have important implications for current conceptions of auditory word recognition in normal and hearing impaired populations of children and adults.},
  file = {/Users/megcychosz/Zotero/storage/J8I8U4HV/Luce and Pisoni - 1998 - Recognizing Spoken Words The Neighborhood Activat.pdf},
  journal = {Ear and hearing},
  number = {1},
  pmcid = {PMC3467695},
  pmid = {9504270}
}

@article{lundRelationVocabularyKnowledge2020,
  title = {The {{Relation Between Vocabulary Knowledge}} and {{Phonological Awareness}} in {{Children With Cochlear Implants}}},
  author = {Lund, Emily},
  year = {2020},
  month = jul,
  volume = {63},
  pages = {2386--2402},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2020_JSLHR-19-00259},
  abstract = {Purpose               The purpose of this study was to evaluate the relation between lexical knowledge and phonological awareness performance of children with cochlear implants.                                         Method               Thirty children with cochlear implants (aged 5\textendash 7 years), 30 children with normal hearing matched for age, and 30 children with normal hearing matched for vocabulary size participated in the study. Children completed a vocabulary knowledge measure and three phonological awareness tasks with words that had high and low neighborhood density.                                         Results               Children with cochlear implants performed more poorly than their age-matched peers and similarly to their vocabulary-matched peers on phonological awareness tasks. When performance was analyzed according to the neighborhood density of the target word, children with cochlear implants and age-matched children performed better with high-density words. Across all groups, vocabulary size correlated significantly with phonological awareness performance.                                         Conclusion               Children with cochlear implants demonstrate delays in both vocabulary knowledge and phonological awareness performance, but children with cochlear implants appear to take advantage of lexical information similarly to their age-matched peers.},
  file = {/Users/megcychosz/Zotero/storage/39AJ3LG9/Lund - 2020 - The Relation Between Vocabulary Knowledge and Phon.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {7}
}

@article{luoCommunityBasedCaregiverImplementedEarly2019,
  title = {Community-{{Based}}, {{Caregiver}}-{{Implemented Early Language Intervention}} in {{High}}-{{Risk Families}}: {{Lessons Learned}}},
  shorttitle = {Community-{{Based}}, {{Caregiver}}-{{Implemented Early Language Intervention}} in {{High}}-{{Risk Families}}},
  author = {Luo, Rufan and Alper, Rebecca M. and {Hirsh-Pasek}, Kathy and Mogul, Marjie and Chen, Yu and Masek, Lillian R. and Paterson, Sarah and Pace, Amy and Adamson, Lauren B. and Bakeman, Roger and Golinkoff, Roberta M. and Owen, Margaret T.},
  year = {2019},
  volume = {13},
  pages = {283--291},
  issn = {1557-055X},
  doi = {10.1353/cpr.2019.0056},
  abstract = {Background: High-quality, early caregiver-child interaction facilitates language, cognitive, and health outcomes. Children in low socioeconomic status households experience less frequent and lower-quality language interactions on average than their middle to high socioeconomic status peers. Early caregiver-implemented intervention may help to improve outcomes for these children.},
  file = {/Users/megcychosz/Zotero/storage/DA9VR96I/Luo et al. - 2019 - Community-Based, Caregiver-Implemented Early Langu.pdf},
  journal = {Progress in Community Health Partnerships: Research, Education, and Action},
  language = {en},
  number = {3}
}

@article{lupyanLanguageStructurePartly2010,
  title = {Language Structure Is Partly Determined by Social Structure},
  author = {Lupyan, G. and Dale, R.},
  year = {2010},
  volume = {5},
  pages = {e8559},
  journal = {PLoS ONE}
}

@book{macdonald105Publications0422002,
  title = {105 {{Publications}} 6,042 {{Citations See Profile}}},
  author = {Macdonald, Maryellen Coles and Christiansen, Morten H. and Macdonald, Maryellen C. and Christiansen, Morten H.},
  year = {2002},
  abstract = {All in-text	references	underlined	in	blue	are	linked	to	publications	on	ResearchGate, letting you	access	and	read	them	immediately.}
}

@article{macdonaldReassessingWorkingMemory2002,
  title = {Reassessing Working Memory: {{Comment}} on {{Just}} and {{Carpenter}} (1992) and {{Waters}} and {{Caplan}} (1996).},
  shorttitle = {Reassessing Working Memory},
  author = {MacDonald, Maryellen C. and Christiansen, Morten H.},
  year = {2002},
  volume = {109},
  pages = {35--54},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/0033-295X.109.1.35},
  file = {/Users/megcychosz/Zotero/storage/IZDI7LFU/MacDonald and Christiansen - 2002 - Reassessing working memory Comment on Just and Ca.pdf},
  journal = {Psychological Review},
  language = {en},
  number = {1}
}

@article{mackayMetamorphosisCriticalInterval1968,
  title = {Metamorphosis of a {{Critical Interval}}: {{Age}}-{{Linked Changes}} in the {{Delay}} in {{Auditory Feedback}} That {{Produces Maximal Disruption}} of {{Speech}}},
  shorttitle = {Metamorphosis of a {{Critical Interval}}},
  author = {MacKay, Donald G.},
  year = {1968},
  month = apr,
  volume = {43},
  pages = {811--821},
  issn = {0001-4966},
  doi = {10.1121/1.1910900},
  file = {/Users/megcychosz/Zotero/storage/ZZU5RRSJ/MacKay - 1968 - Metamorphosis of a Critical Interval Age‐Linked C.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@incollection{macneilageMotorExplanationsBabbling1993,
  title = {Motor Explanations of Babbling and Early Speech Patterns.},
  booktitle = {Developmental Neurocognition : {{Speech}} and Face Processing in the First Year of Life},
  author = {MacNeilage, Peter F. and Davis, Barbara L.},
  editor = {{de Boysson-Bardies}, B. and {de Schoenen}, S. and Jusczyk, Peter W. and MacNeilage, P. F. and Morton, J.},
  year = {1993},
  pages = {341--352},
  publisher = {{Springer}},
  address = {{Kluewer; Dordrecht}}
}

@article{macneilageOriginInternalStructure2000,
  title = {On the {{Origin}} of {{Internal Structure}} of {{Word Forms}}},
  author = {MacNeilage, P. F. and Davis, B.},
  year = {2000},
  month = apr,
  volume = {288},
  pages = {527--531},
  issn = {00368075, 10959203},
  doi = {10.1126/science.288.5465.527},
  file = {/Users/megcychosz/Zotero/storage/95MCLUG4/MacNeilage - 2000 - On the Origin of Internal Structure of Word Forms.pdf},
  journal = {Science},
  language = {en},
  number = {5465}
}

@book{macwhinneyCHILDESProjectTools2000,
  title = {The {{CHILDES Project}}: {{Tools}} for {{Analyzing Talk}}},
  author = {MacWhinney, B.},
  year = {2000},
  edition = {3rd Edition},
  publisher = {{Lawrence Erlbaum Associates}},
  address = {{Mahwah, NJ}}
}

@article{mahrAnticipatoryCoarticulationFacilitates2015,
  title = {Anticipatory Coarticulation Facilitates Word Recognition in Toddlers},
  author = {Mahr, Tristan and McMillan, Brianna T.M. and Saffran, Jenny R. and Ellis Weismer, Susan and Edwards, Jan},
  year = {2015},
  month = sep,
  volume = {142},
  pages = {345--350},
  issn = {00100277},
  doi = {10.1016/j.cognition.2015.05.009},
  abstract = {Children learn from their environments and their caregivers. To capitalize on learning opportunities, young children have to recognize familiar words efficiently by integrating contextual cues across word boundaries. Previous research has shown that adults can use phonetic cues from anticipatory coarticulation during word recognition. We asked whether 18\textendash 24 montholds (n = 29) used coarticulatory cues on the word ``the'' when recognizing the following noun. We performed a looking-while-listening eyetracking experiment to examine word recognition in neutral versus facilitating coarticulatory conditions. Participants looked to the target image significantly sooner when the determiner contained facilitating coarticulatory cues. These results provide the first evidence that novice word-learners can take advantage of anticipatory subphonemic cues during word recognition.},
  file = {/Users/megcychosz/Zotero/storage/HYY6LBY3/Mahr et al. - 2015 - Anticipatory coarticulation facilitates word recog.pdf},
  journal = {Cognition},
  language = {en}
}

@inproceedings{mahrLexicalProcessingChildren2017,
  title = {Lexical Processing of Children with Cochlear Implants.},
  booktitle = {42nd {{Annual Boston University Conference}} on {{Language Development}}},
  author = {Mahr, Tristan and Edwards, Jan},
  year = {2017},
  address = {{Boston, MA}}
}

@article{mahrUsingLanguageInput2018,
  title = {Using Language Input and Lexical Processing to Predict Vocabulary Size},
  author = {Mahr, Tristan and Edwards, Jan},
  year = {2018},
  month = nov,
  volume = {21},
  pages = {1--14},
  issn = {1363755X},
  doi = {10.1111/desc.12685},
  abstract = {Children learn words by listening to caregivers, and the quantity and quality of early language input predict later language development. Recent research suggests that word recognition efficiency may influence the relationship between input and vocabulary growth. We asked whether language input and lexical processing at 28\textendash 39 months predicted vocabulary size one year later in 109 preschoolers. Input was measured using adult word counts from LENA recordings. We used the visual world paradigm and measured lexical processing as the rate of change in proportion of looks to target. Regression analysis showed that lexical processing did not constrain the effect of input on vocabulary size. We also found that input and processing were more reliable predictors of receptive than expressive vocabulary growth.},
  file = {/Users/megcychosz/Zotero/storage/6E4P4NUG/Mahr and Edwards - 2018 - Using language input and lexical processing to pre.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {6}
}

@article{majoranoRelationshipInfantsProduction2014,
  title = {The {{Relationship Between Infants}}' {{Production Experience}} and {{Their Processing}} of {{Speech}}},
  author = {Majorano, Marinella and Vihman, Marilyn M. and DePaolis, Rory A.},
  year = {2014},
  month = apr,
  volume = {10},
  pages = {179--204},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2013.829740},
  file = {/Users/megcychosz/Zotero/storage/LFFCFDNF/Majorano et al. - 2014 - The Relationship Between Infants’ Production Exper.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {2}
}

@article{mallikarjunCocktailPartyEffect2019,
  title = {The Cocktail Party Effect in the Domestic Dog ({{Canis}} Familiaris)},
  author = {Mallikarjun, Amritha and Shroads, Emily and Newman, Rochelle S.},
  year = {2019},
  month = may,
  volume = {22},
  pages = {423--432},
  issn = {1435-9448, 1435-9456},
  doi = {10.1007/s10071-019-01255-4},
  abstract = {Like humans, canine companions often find themselves in noisy environments, and are expected to respond to human speech despite potential distractors. Such environments pose particular problems for young children, who have limited linguistic knowledge. Here, we examined whether dogs show similar difficulties. We found that dogs prefer their name to a stressmatched foil in quiet conditions, despite hearing it spoken by a novel talker. They continued to prefer their name in the presence of multitalker human speech babble at signal-to-noise levels as low as 0 dB, when their name was the same intensity as the foil. This surpasses the performance of 1-year-old infants, who fail to prefer their name to a foil at 0 dB (Newman in Dev Psychol 41(2):352\textendash 362, 2005). Overall, we find better performance at name recognition in dogs that were trained to do tasks for humans, like service dogs, search-and-rescue dogs, and explosives detection dogs. These dogs were of several different breeds, and their tasks were widely different from one another. This suggests that their superior performance may be due to generally more training and better attention. In summary, these results demonstrate that dogs can recognize their name even in relatively difficult levels of multitalker babble, and that dogs who work with humans are especially adept at name recognition in comparison with companion dogs. Future studies will explore the effect of different types of background noise on word recognition in dogs.},
  file = {/Users/megcychosz/Zotero/storage/4FGTQBMG/Mallikarjun et al. - 2019 - The cocktail party effect in the domestic dog (Can.pdf},
  journal = {Animal Cognition},
  language = {en},
  number = {3}
}

@article{mankerPerceptualFilteringPredictable2020,
  title = {The Perceptual Filtering of Predictable Coarticulation in Exemplar Memory},
  author = {Manker, Jonathan},
  year = {2020},
  month = nov,
  volume = {11},
  issn = {1868-6354, 1868-6354},
  doi = {10.5334/labphon.240},
  file = {/Users/megcychosz/Zotero/storage/MX7J8P77/Manker - 2020 - The perceptual filtering of predictable coarticula.pdf},
  journal = {Laboratory Phonology: Journal of the Association for Laboratory Phonology},
  language = {en},
  number = {1}
}

@article{mannInfluencePrecedingLiquid1980,
  title = {Influence of Preceding Liquid on Stop-Consonant Perception},
  author = {Mann, Virginia A},
  year = {1980},
  volume = {28},
  pages = {407--412},
  file = {/Users/megcychosz/Zotero/storage/AHY9B9FA/Mann - Influence of preceding liquid on stop-consonant pe.pdf},
  journal = {Perception \& Psychophysics},
  language = {en},
  number = {5}
}

@article{mannInfluenceVocalicContext1980,
  title = {Influence of Vocalic Context on Perception of the [Sh]-[s] Distinction},
  author = {Mann, V. and Repp, B.},
  year = {1980},
  volume = {28},
  pages = {213--228},
  abstract = {Three experiments investigated the conditions under which fricative perception is influenced by following vocalic context. In Experiment 1, a reaction-time task, listeners showed no such influences, suggesting that they reached decisions about the fricative category before processing the vocalic context. In Experiment 2, a fixed-standard AX discrimination task employing synthetic fricative noises from a [5]-[s] continuum, listeners successfully discriminated fricative noises in isolation but shifted to a phonetic (categorical) mode of perception when vocalic context was added. Their response patterns changed systematically wi th the nature. of the context. In Experiment 3, the subjects listened first to pairs of isolated noises immediately followed by the same noises in context. When, subsequently, only noises in context were presented for discrimination, most of the subjects performed noncategorically and were no longer influenced by different vocalic contexts. These experiments demonstrate the availability of different perceptual strategies in listening to speech.},
  file = {/Users/megcychosz/Zotero/storage/QLU4WX52/Repp - INFLUENCE OF VOCALIC CONTEXT ON PERCEPTION OF THE .pdf},
  journal = {Perception \& Psychophysics},
  language = {en}
}

@article{manningAlexaCanYou2019,
  title = {Alexa: {{Can You Keep}} a {{Secret}}?  {{The Third}}-{{Party Doctrine}} in the {{Age}} of the {{Smart Home}}},
  author = {Manning, Grace},
  year = 2019,
  volume = {56},
  pages = {7},
  file = {/Users/megcychosz/Zotero/storage/YZPXK9F7/Manning - Alexa Can You Keep a Secret  The Third-Party Doc.pdf},
  journal = {American Criminal Law Review},
  language = {en},
  number = {0}
}

@article{manuelRoleContrastLimiting1990,
  title = {The Role of Contrast in Limiting Vowel-to-Vowel Coarticulation in Different Languages},
  author = {Manuel, S.},
  year = {1990},
  volume = {SR-103/104},
  pages = {1--20},
  file = {/Users/megcychosz/Zotero/storage/2VPBULXV/Manuel 1990.pdf},
  journal = {Haskins Laboratories Status Report on Speech Research}
}

@article{manuelUniversalLanguageParticular1984,
  title = {Universal and Language Particular Aspects of Vowel-to-Vowel Coarticulation},
  author = {Manuel, Sharon and Krakow, R.},
  year = {1984},
  volume = {SR-77/78},
  pages = {69--78},
  file = {/Users/megcychosz/Zotero/storage/T9VIV8L2/Universal and language particular aspects of vowel.pdf},
  journal = {Haskins Laboratories Status Report on Speech Research}
}

@article{marchmanAccuracyLanguageEnvironment2020,
  title = {Accuracy of the {{Language Environment Analyses}} ({{LENA}} {{{\textsuperscript{TM}}}} ) System for Estimating Child and Adult Speech in Laboratory Settings},
  author = {Marchman, Virginia A. and Weisleder, Adriana and Hurtado, Nereyda and Fernald, Anne},
  year = {2020},
  month = jul,
  pages = {1--16},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000920000380},
  abstract = {Laboratory observations are a mainstay of language development research, but transcription is costly. We test whether speech recognition technology originally designed for day-long contexts can be usefully applied to this use-case. We compared automated adult word and child vocalization counts from Language Environment Analysis (LENATM) to those of transcribers in 20-minute play sessions with Spanishspeaking dyads (n = 104) at 1;7 and 2;2. For adult words, results indicated moderate associations but large absolute differences. Associations for child vocalizations were weaker with larger absolute discrepancies. LENA has moderate potential to ease the burden of transcription in some research and clinical applications.},
  file = {/Users/megcychosz/Zotero/storage/BMWE7PJH/Marchman et al. - 2020 - Accuracy of the Language Environment Analyses (LEN.pdf},
  journal = {Journal of Child Language},
  language = {en}
}

@article{marchmanCaregiverTalkYoung2017,
  title = {Caregiver Talk to Young {{Spanish}}-{{English}} Bilinguals: Comparing Direct Observation and Parent-Report Measures of Dual-Language Exposure},
  shorttitle = {Caregiver Talk to Young {{Spanish}}-{{English}} Bilinguals},
  author = {Marchman, Virginia A. and Mart{\'i}nez, Luc{\'i}a Z. and Hurtado, Nereyda and Gr{\"u}ter, Theres and Fernald, Anne},
  year = {2017},
  month = jan,
  volume = {20},
  pages = {e12425},
  issn = {1363755X},
  doi = {10.1111/desc.12425},
  abstract = {In research on language development by bilingual children, the early language environment is commonly characterized in terms of the relative amount of exposure a child gets to each language based on parent report. Little is known about how absolute measures of child-directed speech in two languages relate to language growth. In this study of 3-year-old Spanish-English bilinguals (n = 18), traditional parent-report estimates of exposure were compared to measures of the number of Spanish and English words children heard during naturalistic audio recordings. While the two estimates were moderately correlated, observed numbers of child-directed words were more consistently predictive of children's processing speed and standardized test performance, even when controlling for reported proportion of exposure. These findings highlight the importance of caregiver engagement in bilingual children's language outcomes in both of the languages they are learning.},
  file = {/Users/megcychosz/Zotero/storage/GWJGD433/Marchman et al. - 2017 - Caregiver talk to young Spanish-English bilinguals.pdf;/Users/megcychosz/Zotero/storage/JFRCAHRH/Marchman et al. - 2017 - Caregiver talk to young Spanish-English bilinguals.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {1}
}

@article{marchmanChildrenProductivityEnglish1997,
  title = {Children's {{Productivity}} in the {{English Past Tense}}: {{The Role}} of {{Frequency}}, {{Phonology}}, and {{Neighborhood Structure}}},
  shorttitle = {Children's {{Productivity}} in the {{English Past Tense}}},
  author = {Marchman, Virginia A.},
  year = {1997},
  month = jul,
  volume = {21},
  pages = {283--304},
  issn = {03640213},
  doi = {10.1207/s15516709cog2103_2},
  file = {/Users/megcychosz/Zotero/storage/KCNDPI6S/Marchman - 1997 - Children's Productivity in the English Past Tense.pdf},
  journal = {Cognitive Science},
  language = {en},
  number = {3}
}

@article{marchmanConcurrentValidityCaregiver2002,
  title = {Concurrent {{Validity}} of {{Caregiver}}/{{Parent Report Measures}} of {{Language}} for {{Children Who Are Learning Both English}} and {{Spanish}}},
  author = {Marchman, Virginia and {Martinez-Sussmann}, Carmen},
  year = {2002},
  month = oct,
  volume = {45},
  pages = {983--97},
  doi = {10.1044/1092-4388(2002/080)},
  abstract = {The validity of two analogous caregiver/parent report measures of early language development in young children who are learning both English and Spanish is examined. Caregiver/parent report indices of vocabulary production and grammar were obtained for 26 children using the MacArthur Communicative Development Inventory: Words \& Sentences (CDI; Fenson et al., 1994) and the Inventario del Desarrollo de Habilidades Comunicativas: Palabras y Enunciados (IDHC; Jackson-Maldonado, Bates, \& Thal, 1992). Scores were significantly correlated with analogous laboratory measures in both English and Spanish, including a real-object naming task and spontaneous language use during free-play. The findings offer evidence that the CDI and IDHC provide valid assessments of early language milestones in young English- and Spanish-speaking children. Factors that may influence the validity of these tools for use with this population are also discussed.},
  journal = {Journal of Speech Language and Hearing Research}
}

@book{marcusAlgebraicMindIntegrating2018,
  title = {The Algebraic Mind: {{Integrating}} Connectionism and Cognitive Science},
  author = {Marcus, Gary},
  year = {2018},
  publisher = {{MIT Press}},
  address = {{Massachusetts Institute of Technology}}
}

@article{marklundAmountSpeechExposure2019,
  title = {Amount of Speech Exposure Predicts Vowel Perception in Four- to Eight-Month-Olds},
  author = {Marklund, Ellen and Schwarz, Iris-Corinna and Lacerda, Francisco},
  year = {2019},
  month = apr,
  volume = {36},
  pages = {100622},
  issn = {18789293},
  doi = {10.1016/j.dcn.2019.100622},
  abstract = {During the first year of life, infants shift their focus in speech perception from acoustic to linguistic information. This perceptual reorganization is related to exposure, and a direct relation has previously been demonstrated between amount of daily language exposure and mismatch response (MMR) amplitude to a native consonant contrast at around one year of age. The present study investigates the same relation between amount of speech exposure and MMR amplitude to a native vowel contrast at four to eight months of age. Importantly, the present study uses spectrally rotated speech in an effort to take general neural maturation into account. The amplitude of the part of the MMR that is tied specifically to speech processing correlates with amount of daily speech exposure, as estimated using the LENA system.},
  file = {/Users/megcychosz/Zotero/storage/3IYXAVK3/Marklund et al. - 2019 - Amount of speech exposure predicts vowel perceptio.pdf},
  journal = {Developmental Cognitive Neuroscience},
  language = {en}
}

@article{markmanConstraintsChildrenPlaceonWordMeanings,
  title = {{{ConstraintsChildrenPlaceon WordMeanings}}},
  author = {Markman, Ellen M},
  pages = {21},
  file = {/Users/megcychosz/Zotero/storage/BXD7KGMI/Markman - ConstraintsChildrenPlaceon WordMeanings.PDF},
  language = {en}
}

@article{martinetFunctionStructureSound1952,
  title = {Function, {{Structure}}, and {{Sound Change}}},
  author = {Martinet, Andr{\'e}},
  year = {1952},
  month = apr,
  volume = {8},
  pages = {1--32},
  issn = {0043-7956, 2373-5112},
  doi = {10.1080/00437956.1952.11659416},
  file = {/Users/megcychosz/Zotero/storage/BZJNY6RA/Martinet - 1952 - Function, Structure, and Sound Change.pdf},
  journal = {\emph{WORD}},
  language = {en},
  number = {1}
}

@article{martinLearningPhonemesProtoLexicon2013,
  title = {Learning {{Phonemes With}} a {{Proto}}-{{Lexicon}}},
  author = {Martin, Andrew and Peperkamp, Sharon and Dupoux, Emmanuel},
  year = {2013},
  month = jan,
  volume = {37},
  pages = {103--124},
  issn = {03640213},
  doi = {10.1111/j.1551-6709.2012.01267.x},
  abstract = {Before the end of the first year of life, infants begin to lose the ability to perceive distinctions between sounds that are not phonemic in their native language. It is typically assumed that this developmental change reflects the construction of language-specific phoneme categories, but how these categories are learned largely remains a mystery. Peperkamp, Le Calvez, Nadal, and Dupoux (2006) present an algorithm that can discover phonemes using the distributions of allophones as well as the phonetic properties of the allophones and their contexts. We show that a third type of information source, the occurrence of pairs of minimally differing word forms in speech heard by the infant, is also useful for learning phonemic categories and is in fact more reliable than purely distributional information in data containing a large number of allophones. In our model, learners build an approximation of the lexicon consisting of the high-frequency n-grams present in their speech input, allowing them to take advantage of top-down lexical information without needing to learn words. This may explain how infants have already begun to exhibit sensitivity to phonemic categories before they have a large receptive lexicon.},
  file = {/Users/megcychosz/Zotero/storage/LDMFXYHH/Martin et al. - 2013 - Learning Phonemes With a Proto-Lexicon.pdf},
  journal = {Cognitive Science},
  language = {en},
  number = {1}
}

@article{martinMothersSpeakLess2015,
  title = {Mothers {{Speak Less Clearly}} to {{Infants Than}} to {{Adults}}: {{A Comprehensive Test}} of the {{Hyperarticulation Hypothesis}}},
  shorttitle = {Mothers {{Speak Less Clearly}} to {{Infants Than}} to {{Adults}}},
  author = {Martin, Andrew and Schatz, Thomas and Versteegh, Maarten and Miyazawa, Kouki and Mazuka, Reiko and Dupoux, Emmanuel and Cristia, Alejandrina},
  year = {2015},
  month = mar,
  volume = {26},
  pages = {341--347},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797614562453},
  abstract = {Infants learn language at an incredible speed, and one of the first steps in this voyage is learning the basic sound units of their native languages. It is widely thought that caregivers facilitate this task by hyperarticulating when speaking to their infants. Using state-of-the-art speech technology, we addressed this key theoretical question: Are sound categories clearer in infant-directed speech than in adult-directed speech? A comprehensive examination of sound contrasts in a large corpus of recorded, spontaneous Japanese speech demonstrates that there is a small but significant tendency for contrasts in infant-directed speech to be less clear than those in adult-directed speech. This finding runs contrary to the idea that caregivers actively enhance phonetic categories in infant-directed speech. These results suggest that to be plausible, theories of infants' language acquisition must posit an ability to learn from noisy data.},
  file = {/Users/megcychosz/Zotero/storage/U3JS9J9M/Martin et al. - 2015 - Mothers Speak Less Clearly to Infants Than to Adul.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {3}
}

@inproceedings{martlandEstimatingChildAdolescent1996,
  title = {Estimating Child and Adolescent Formant Frequency Values from Adult Data},
  booktitle = {Proceeding of {{Fourth International Conference}} on {{Spoken Language Processing}}. {{ICSLP}} '96},
  author = {Martland, P. and Whiteside, S.P. and Beet, S.W. and {Baghai-Ravary}, L.},
  year = {1996},
  volume = {2},
  pages = {626--629},
  publisher = {{IEEE}},
  address = {{Philadelphia, PA, USA}},
  doi = {10.1109/ICSLP.1996.607439},
  file = {/Users/megcychosz/Zotero/storage/UQCK8IZD/Martland et al. - 1996 - Estimating child and adolescent formant frequency .pdf},
  isbn = {978-0-7803-3555-4},
  language = {en}
}

@article{maslowskiHowTrackingHabitual2019,
  title = {How the Tracking of Habitual Rate Influences Speech Perception.},
  author = {Maslowski, Merel and Meyer, Antje S. and Bosker, Hans Rutger},
  year = {2019},
  month = jan,
  volume = {45},
  pages = {128--138},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000579},
  abstract = {Listeners are known to track statistical regularities in speech. Yet, which temporal cues are encoded is unclear. This study tested effects of talker-specific habitual speech rate and talker-independent average speech rate (heard over a longer period of time) on the perception of the temporal Dutch vowel contrast /ɑ/\textendash/a:/. First, Experiment 1 replicated that slow local (surrounding) speech contexts induce fewer long /a:/ responses than faster contexts. Experiment 2 tested effects of long-term habitual speech rate. A high-rate group listened to ambiguous vowels embedded in ``neutral'' speech from Talker A, intermixed with fast speech from Talker B. A low-rate group listened to the same neutral speech from Talker A, and/but to Talker B speaking at a slow rate. Between-groups comparison of the neutral trials showed that the high-rate group demonstrated a lower proportion of /a:/ responses, indicating that Talker A's habitual speech rate sounded slower when B was faster. In Experiment 3, both talkers produced speech at both rates, removing the different habitual speech rates of Talkers A and B, while maintaining the average rates differing between groups. In Experiment 3, no global rate effect was observed. Taken together, the present experiments show that a talker's habitual rate is encoded relative to the habitual rate of another talker, carrying implications for episodic and constraint-based models of speech perception.},
  file = {/Users/megcychosz/Zotero/storage/27D56LDQ/Maslowski et al. - 2019 - How the tracking of habitual rate influences speec.pdf},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  language = {en},
  number = {1}
}

@article{mastinInfantEngagementEarly2016,
  title = {Infant Engagement and Early Vocabulary Development: A Naturalistic Observation Study of {{Mozambican}} Infants from 1;1 to 2;1},
  shorttitle = {Infant Engagement and Early Vocabulary Development},
  author = {Mastin, J. Douglas and Vogt, Paul},
  year = {2016},
  month = mar,
  volume = {43},
  pages = {235--264},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000915000148},
  abstract = {This study analyzes how others engage rural and urban Mozambican infants during naturalistic observations, and how the proportion of time spent in different engagements relates to infants' language development over the second year of life. Using an extended version of Bakeman and Adamson's (1984) categorization of infant engagement, we investigated to what extent a detailed analysis of infant engagement can contribute to our understanding of vocabulary development in natural settings. In addition, we explored how the different infant engagements relate to vocabulary size, and how these differ between both communities. Results show that rural infants spend significantly more time in forms of solitary engagement, whereas urban infants spend more time in forms of triadic joint engagement. In regard to correlations with reported productive vocabulary, we find that dyadic Persons engagement (i.e. interactions not about concrete objects) has positive correlations with vocabulary measures in both rural and urban communities. In addition, we find that triadic Coordinated Joint Attention has a positive relationship with vocabulary in the urban community, but a contrasting negative correlation with vocabulary in the rural community. These similarities and differences are explained based upon the parenting beliefs and socialization practices of different prototypical learning environments. Overall, this study concludes that the extended categorization provides a valuable contribution to the analysis of infant engagement and their relation to language acquisition, especially for analyzing naturalistic observations as compared to semi-structured studies. Moreover, with respect to vocabulary development, Mozambican infants appear to benefit strongest from dyadic Persons engagement, while they do not necessarily benefit from joint attention, as tends to be the case for children from industrial, developed communities.},
  file = {/Users/megcychosz/Zotero/storage/XDDYNBAX/Mastin and Vogt - 2016 - Infant engagement and early vocabulary development.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {02}
}

@article{mathotOpenSesameOpensourceGraphical2012,
  title = {{{OpenSesame}}: {{An}} Open-Source, Graphical Experiment Builder for the Social Sciences},
  author = {Math{\^o}t, S. and Schreij, D. and Theeuwes, J.},
  year = {2012},
  volume = {44},
  pages = {314--324},
  journal = {Behavior Research Methods},
  number = {2}
}

@article{matthewsErrorsOmissionEnglishSpeaking2006,
  title = {Errors of {{Omission}} in {{English}}-{{Speaking Children}}'s {{Production}} of {{Plurals}} and the {{Past Tense}}: {{The Effects}} of {{Frequency}}, {{Phonology}}, and {{Competition}}},
  shorttitle = {Errors of {{Omission}} in {{English}}-{{Speaking Children}}'s {{Production}} of {{Plurals}} and the {{Past Tense}}},
  author = {Matthews, Danielle E. and Theakston, Anna L.},
  year = {2006},
  month = nov,
  volume = {30},
  pages = {1027--1052},
  issn = {03640213},
  doi = {10.1207/s15516709cog0000_66},
  abstract = {How do English-speaking children inflect nouns for plurality and verbs for the past tense? We assess theoretical answers to this question by considering errors of omission, which occur when children produce a stem in place of its inflected counterpart (e.g., saying ``dress'' to refer to 5 dresses). A total of 307 children (aged 3;11\textendash 9;9) participated in 3 inflection studies. In Study 1, we show that errors of omission occur until the age of 7 and are more likely with both sibilant regular nouns (e.g., dress) and irregular nouns (e.g., man) than regular nouns (e.g., dog). Sibilant nouns are more likely to be inflected if they are high frequency. In Studies 2 and 3, we show that similar effects apply to the inflection of verbs and that there is an advantage for ``regular-like'' irregulars whose inflected form, but not stem form, ends in d/t. The results imply that (a) stems and inflected forms compete for production and (b) children generalize both product-oriented and source-oriented schemas when learning about inflectional morphology.},
  file = {/Users/megcychosz/Zotero/storage/FXAPQ6HP/Matthews and Theakston - 2006 - Errors of Omission in English-Speaking Children's .pdf},
  journal = {Cognitive Science},
  language = {en},
  number = {6}
}

@misc{matthiesenwickertlehrers.c.LAWSRECORDINGCONVERSATIONS,
  title = {{{LAWS ON RECORDING CONVERSATIONS IN ALL}} 50 {{STATES}}},
  author = {Matthiesen, Wickert, \& Lehrer, S.C.}
}

@article{matthiesVariationAnticipatoryCoarticulation2001,
  title = {Variation in {{Anticipatory Coarticulation With Changes}} in {{Clarity}} and {{Rate}}},
  author = {Matthies, Melanie and Perrier, Pascal and Perkell, Joseph and Zandipour, Majid},
  year = {2001},
  volume = {44},
  pages = {340--353},
  journal = {Journal of Speech Language and Hearing Research},
  number = {2}
}

@article{matthiesVariationAnticipatoryCoarticulation2001a,
  title = {Variation in {{Anticipatory Coarticulation With Changes}} in {{Clarity}} and {{Rate}}},
  author = {Matthies, Melanie and Perrier, Pascal and Perkell, Joseph S. and Zandipour, Majid},
  year = {2001},
  month = apr,
  volume = {44},
  pages = {340--353},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2001/028)},
  abstract = {Massachusetts Institute of Technology Cambridge This study tests the hypothesis that the relative timing, or coarticulation, of articulatory movements at VC and CV boundaries is influenced by both the listener's requirement for clarity and the speaker's strategy to economize effort. Movement and acoustic data were collected from 7 subjects who spoke in three conditions: normal, clear, and fast. It was predicted that fast speech would show more coarticulation and clear speech would show less coarticulation than normal speech. The speech materials were designed to investigate coarticulation in the movements of the upper lip and tongue. They consisted of repetitions of [iCnu] utterances embedded in carrier phrases, where the number of consonants, n, ranged from 1 to 3. Analyses focused on kinematic measures and the amount of coarticulation (overlap) of the /i-u/ transition movement with the acoustic interval of the /i/. The consonant-string duration was longest in the clear speaking condition and shortest in the fast condition. Compared to the normal condition, peak velocities were higher in the fast and clear speaking conditions, indicating increased effort. The influences of speaking condition on coarticulation and on the formants of the /i/ were small. Thus, even though there was evidence of increased effort in the clear and fast conditions, the hypothesized effects of a trade-off between clarity and economy of effort were minimally evident in formant values for /i/ and measures of coarticulation.},
  file = {/Users/megcychosz/Zotero/storage/FR6PVQ6H/Matthies et al. - 2001 - Variation in Anticipatory Coarticulation With Chan.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {2}
}

@article{mattysIntegrationMultipleSpeech2005,
  title = {Integration of Multiple Speech Segmentation Cues: {{A}} Hierarchical Framework},
  shorttitle = {Integration of Multiple Speech Segmentation Cues},
  author = {Mattys, Sven L. and White, Laurence and Melhorn, James F.},
  year = {2005},
  volume = {134},
  pages = {477--500},
  abstract = {A central question in psycholinguistic research is how listeners isolate words from connected speech despite the paucity of clear word-boundary cues in the signal. A large body of empirical evidence indicates that word segmentation is promoted by both lexical (knowledge-derived) and sublexical (signal-derived) cues. However, an account of how these cues operate in combination or in conflict is lacking. The present study fills this gap by assessing speech segmentation when cues are systematically pitted against each other. The results demonstrate that listeners do not assign the same power to all segmentation cues; rather, cues are hierarchically integrated, with descending weights allocated to lexical, segmental, and prosodic cues. Lower level cues drive segmentation when the interpretive conditions are altered by a lack of contextual and lexical information or by white noise. Taken together, the results call for an integrated, hierarchical, and signal-contingent approach to speech segmentation.},
  file = {/Users/megcychosz/Zotero/storage/T678C6ID/Mattys et al. - 2005 - Integration of multiple speech segmentation cues .pdf;/Users/megcychosz/Zotero/storage/4UA2FMNI/summary.html},
  journal = {Journal of Experimental Psychology: General},
  number = {4}
}

@article{maWordLearningInfant2011,
  title = {Word {{Learning}} in {{Infant}}- and {{Adult}}-{{Directed Speech}}},
  author = {Ma, Weiyi and Golinkoff, Roberta Michnick and Houston, Derek M. and {Hirsh-Pasek}, Kathy},
  year = {2011},
  month = jul,
  volume = {7},
  pages = {185--201},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2011.579839},
  file = {/Users/megcychosz/Zotero/storage/A2LTIPIA/Ma et al. - 2011 - Word Learning in Infant- and Adult-Directed Speech.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {3}
}

@article{mayeInfantSensitivityDistributional2002,
  title = {Infant Sensitivity to Distributional Information Can Affect Phonetic Discrimination},
  author = {Maye, Jessica and Werker, Janet F and Gerken, LouAnn},
  year = {2002},
  month = jan,
  volume = {82},
  pages = {B101-B111},
  issn = {00100277},
  doi = {10.1016/S0010-0277(01)00157-3},
  abstract = {For nearly two decades it has been known that infants' perception of speech sounds is affected by native language input during the first year of life. However, definitive evidence of a mechanism to explain these developmental changes in speech perception has remained elusive. The present study provides the first evidence for such a mechanism, showing that the statistical distribution of phonetic variation in the speech signal influences whether 6- and 8-month-old infants discriminate a pair of speech sounds. We familiarized infants with speech sounds from a phonetic continuum, exhibiting either a bimodal or unimodal frequency distribution. During the test phase, only infants in the bimodal condition discriminated tokens from the endpoints of the continuum. These results demonstrate that infants are sensitive to the statistical distribution of speech sounds in the input language, and that this sensitivity influences speech perception. q 2002 Elsevier Science B.V. All rights reserved.},
  file = {/Users/megcychosz/Zotero/storage/FF5DQHYH/Maye et al. - 2002 - Infant sensitivity to distributional information c.pdf},
  journal = {Cognition},
  language = {en},
  number = {3}
}

@article{mayrAsymmetriesPhonologicalDevelopment2015,
  title = {Asymmetries in Phonological Development: The Case of Word-Final Cluster Acquisition in {{Welsh}}\textendash{{English}} Bilingual Children},
  shorttitle = {Asymmetries in Phonological Development},
  author = {Mayr, Robert and Howells, Gwennan and Lewis, Rhonwen},
  year = {2015},
  month = jan,
  volume = {42},
  pages = {146--179},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000913000603},
  abstract = {This study provides the first systematic account of word-final cluster acquisition in bilingual children. To this end, 40 Welsh-English bilingual children differing in language dominance and age (2;6 to 5;0) participated in a picture-naming task in English and Welsh. The results revealed significant age and dominance effects on cluster acquisition, with greater overall accuracy on the English clusters. Interestingly, although the Welsh-dominant children outperformed the English-dominant ones on the Welsh clusters, they did not exhibit a concomitant lag on the English clusters. It is argued that this asymmetry is a direct reflection of the sociolinguistic situation in Wales with English as the majority language and Welsh the minority language. The study also revealed accelerated rates of acquisition for English clusters compared with age-matched monolinguals reported elsewhere (Templin, 1957), thereby supporting claims that bilingual contexts may have a facilitative effect on phonological acquisition (Goldstein \& Bunta, 2012; Grech \& Dodd, 2008).},
  file = {/Users/megcychosz/Zotero/storage/Y8TVQ9XM/Mayr et al. - 2015 - Asymmetries in phonological development the case .pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {1}
}

@article{mayrDisentanglingEffectsLongterm2017,
  title = {Disentangling the Effects of Long-Term Language Contact and Individual Bilingualism: {{The}} Case of Monophthongs in {{Welsh}} and {{English}}},
  shorttitle = {Disentangling the Effects of Long-Term Language Contact and Individual Bilingualism},
  author = {Mayr, Robert and Morris, Jonathan and Mennen, Ineke and Williams, Daniel},
  year = {2017},
  month = jun,
  volume = {21},
  pages = {245--267},
  publisher = {{SAGE Publications Ltd}},
  issn = {1367-0069},
  doi = {10.1177/1367006915614921},
  abstract = {Aims and objectives:This study investigates the effects of individual bilingualism and long-term language contact on monophthongal vowel productions in English and Welsh.Design:To this end, we recorded the Welsh and English vowel productions of two sets of Welsh-English bilinguals differing in home language use, as well as the English vowel productions of English monolinguals.Data and analysis:The data were analysed acoustically, with a focus on spectral and temporal properties. Comparisons were then made within each language and cross-linguistically.Findings:The results of a cross-linguistic acoustic comparison revealed a high degree of convergence in the monophthong systems of Welsh and English, but also some language-specific categories. Interestingly, at the individual level we found no effect of linguistic experience on vowel production: the two sets of bilinguals and the English monolinguals did not differ in their realisation of English vowels, and the two sets of bilinguals did not differ in their realisation of Welsh vowels.Originality:This is one of few studies to examine the effect of linguistic background on variation in Welsh and English bilingual speech, and the first to compare the speech of Welsh-English bilinguals and English monolinguals. More specifically, it investigates the extent to which a speaker?s home language can affect phonetic variation in a close-knit community of speakers and in a situation characterised by long-term language contact.Implications:The findings demonstrate pervasive phonetic convergence in a language contact situation with a historical substrate. They also indicate that a homogeneous peer group with shared values can override the effects of individual linguistic experience.},
  file = {/Users/megcychosz/Zotero/storage/GLBLI4RG/Mayr et al. - 2017 - Disentangling the effects of long-term language co.pdf},
  journal = {International Journal of Bilingualism},
  number = {3}
}

@article{mayrIntergenerationalTransmissionMinority2018,
  title = {Inter-Generational Transmission in a Minority Language Setting: {{Stop}} Consonant Production by {{Bangladeshi}} Heritage Children and Adults},
  shorttitle = {Inter-Generational Transmission in a Minority Language Setting},
  author = {Mayr, Robert and Siddika, Aysha},
  year = {2018},
  month = jun,
  volume = {22},
  pages = {255--284},
  publisher = {{SAGE Publications Ltd}},
  issn = {1367-0069},
  doi = {10.1177/1367006916672590},
  abstract = {Aims and objectives:The purpose of this study was to gain a better understanding of speech development across successive generations of heritage language users, examining how cross-linguistic, developmental and socio-cultural factors affect stop consonant production.Design:To this end, we recorded Sylheti and English stop productions of two sets of Bangladeshi heritage families: (1) first-generation adult migrants from Bangladesh and their (second-generation) UK-born children, and (2) second-generation UK-born adult heritage language users and their (third-generation) UK-born children.Data and analysis:The data were analysed auditorily, using whole-word transcription, and acoustically, examining voice onset time. Comparisons were then made in both languages across the four groups of participants, and cross-linguistically.Findings:The results revealed non-native productions of English stops by the first-generation migrants but largely target-like patterns by the remaining sets of participants. The Sylheti stops exhibited incremental changes across successive generations of speakers, with the third-generation children?s productions showing the greatest influence from English.Originality:This is one of few studies to examine both the host and heritage language in an ethnic minority setting, and the first to demonstrate substantial differences in heritage language accent between age-matched second- and third-generation children. The study shows that current theories of bilingual speech learning do not go far enough in explaining how speech develops in heritage language settings.Implications:These findings have important implications for the maintenance, transmission and long-term survival of heritage languages, and show that investigations need to go beyond second-generation speakers, in particular in communities that do not see a steady influx of new migrants.},
  file = {/Users/megcychosz/Zotero/storage/J96E5EY5/Mayr and Siddika - 2018 - Inter-generational transmission in a minority lang.pdf},
  journal = {International Journal of Bilingualism},
  number = {3}
}

@article{mcallisterbyunAmapModelArticulatory2016,
  title = {The {{A}}-Map Model: {{Articulatory}} Reliability in Child-Specific Phonology},
  shorttitle = {The {{A}}-Map Model},
  author = {McAllister Byun, Tara and Inkelas, Sharon and Rose, Yvan},
  year = {2016},
  volume = {92},
  pages = {141--178},
  issn = {1535-0665},
  doi = {10.1353/lan.2016.0000},
  file = {/Users/megcychosz/Zotero/storage/8SKSBXDH/Byun et al. - 2016 - The A-map model Articulatory reliability in child.pdf;/Users/megcychosz/Zotero/storage/DAWWVHQY/a-map inkelas, mc-byun, rose 2016.docx},
  journal = {Language},
  language = {en},
  number = {1}
}

@article{mcallisterbyunCovertContrastVelar2016,
  title = {Covert Contrast in Velar Fronting: {{An}} Acoustic and Ultrasound Study},
  shorttitle = {Covert Contrast in Velar Fronting},
  author = {McAllister Byun, Tara and Buchwald, Adam and Mizoguchi, Ai},
  year = {2016},
  month = may,
  volume = {30},
  pages = {249--276},
  issn = {0269-9206, 1464-5076},
  doi = {10.3109/02699206.2015.1056884},
  abstract = {There is growing evidence that speech sound acquisition is a gradual process, with instrumental measures frequently revealing covert contrast in errors perceived to involve phonemic substitution. Ultrasound imaging has the potential to expand our understanding of covert contrast by showing whether a child uses different tongue shapes while producing sounds that are perceived as neutralised. This study used an ultrasound measure (Dorsum Excursion Index) and acoustic measures (VOT and spectral moments of the burst) to investigate overt and covert contrast between velar and alveolar stops in child speech. Participants were two children who produced a perceptually overt velar-alveolar contrast and two children who neutralised the contrast via velar fronting. Both acoustic and ultrasound measures revealed significant differences between perceptually distinct velar and alveolar targets. One child with velar fronting demonstrated covert contrast in one acoustic and one ultrasound measure; the other showed no evidence of contrast. Clinical implications are discussed in this article.},
  file = {/Users/megcychosz/Zotero/storage/INMX4ZJ2/McAllister Byun et al. - 2016 - Covert contrast in velar fronting An acoustic and.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {3-5}
}

@article{mcallisterbyunDerivingGradientMeasures2016a,
  title = {Deriving Gradient Measures of Child Speech from Crowdsourced Ratings},
  author = {McAllister Byun, Tara and Harel, Daphna and Halpin, Peter F. and Szeredi, Daniel},
  year = {2016},
  month = nov,
  volume = {64},
  pages = {91--102},
  issn = {00219924},
  doi = {10.1016/j.jcomdis.2016.07.001},
  abstract = {Recent research has demonstrated that perceptual ratings aggregated across multiple non-expert listeners can reveal gradient degrees of covert contrast between target and error sounds that listeners might transcribe identically. Aggregated ratings have been found to correlate strongly with acoustic gold standard measures both when individual raters use a continuous rating scale such as visual analog scaling (Munson, Johnson, \& Edwards, 2012) and when individual raters provide binary ratings (McAllister Byun, Halpin, \& Szeredi, 2015). In light of evidence that inexperienced listeners use continuous scales less consistently than experienced listeners, this study investigated the relative merits of binary versus continuous rating scales when aggregating responses over large numbers of naive listeners recruited through online crowdsourcing. Stimuli were words produced by children in treatment for misarticulation of North American English /r/. Each listener rated the same 40 tokens two times: once using Visual Analog Scaling (VAS) and once using a binary rating scale. The gradient rhoticity of each item was then estimated using (a) VAS click location, averaged across raters; (b) the proportion of raters who assigned the ``correct /r/'' label to each item in the binary rating task ({\^p}). First, we validate these two measures of rhoticity against each other and against an acoustic gold standard. Second, we explore the range of variability in individual response patterns that underlie these group-level data. Third, we integrate statistical, theoretical, and practical considerations to offer guidelines for determining which measure to use in a given situation.},
  file = {/Users/megcychosz/Zotero/storage/ZJINZV6F/McAllister Byun et al. - 2016 - Deriving gradient measures of child speech from cr.pdf},
  journal = {Journal of Communication Disorders},
  language = {en}
}

@article{mcallisterbyunGesturalAccountChildspecific2011,
  title = {A Gestural Account of a Child-Specific Neutralisation in Strong Position},
  author = {McAllister Byun, T},
  year = {2011},
  month = dec,
  volume = {28},
  pages = {371--412},
  issn = {0952-6757, 1469-8188},
  doi = {10.1017/S0952675711000297},
  file = {/Users/megcychosz/Zotero/storage/FDE9S4R2/Byun - 2011 - A gestural account of a child-specific neutralisat.pdf},
  journal = {Phonology},
  language = {en},
  number = {03}
}

@article{mcallisterbyunMotoracousticMappingsShape,
  title = {Motor-Acoustic Mappings Shape Child Phonology:  {{Evidence}} from a Circular Chain Shift},
  author = {McAllister Byun, Tara and Buchwald, Adam},
  pages = {25},
  file = {/Users/megcychosz/Zotero/storage/4U48HQ54/Byun and Buchwald - Motor-acoustic mappings shape child phonology  Ev.pdf},
  language = {en}
}

@article{mcallisterbyunMotorInfluencesGrammar2016,
  title = {Motor {{Influences}} on {{Grammar}} in an {{Emergentist Model}} of {{Phonology}}: {{Motor}} and {{Grammar}} in {{Emergentist Phonology}}},
  shorttitle = {Motor {{Influences}} on {{Grammar}} in an {{Emergentist Model}} of {{Phonology}}},
  author = {McAllister Byun, Tara and Tessier, Anne-Michelle},
  year = {2016},
  month = sep,
  volume = {10},
  pages = {431--452},
  issn = {1749818X},
  doi = {10.1111/lnc3.12205},
  file = {/Users/megcychosz/Zotero/storage/WQI4NUNB/Byun and Tessier - 2016 - Motor Influences on Grammar in an Emergentist Mode.pdf},
  journal = {Language and Linguistics Compass},
  language = {en},
  number = {9}
}

@article{mcallisterbyunPerceptionproductionRelationsLater2017,
  title = {Perception-Production Relations in Later Development of {{American English}} Rhotics},
  author = {McAllister Byun, Tara and Tiede, Mark},
  editor = {Allen, Philip},
  year = {2017},
  month = feb,
  volume = {12},
  pages = {e0172022},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0172022},
  abstract = {It is known that some adult listeners have more sharply defined perceptual categories than others, and listeners with more precise auditory targets are also more precise in their production of contrasts. There is additionally evidence that children who have not yet mastered production of a contrast show diminished performance on perceptual measures of the same contrast. To date, however, few studies have investigated developmental perception-production relations using the fine-grained measures typical of adult studies. Existing evidence suggests that perception and production can be closely connected in development, but this relationship may break down as perception and articulation mature at different rates. This study evaluated perception and production of the English /r-w/ contrast in 40 typically-developing children aged 9\textendash 14. Perceptual sensitivity was measured with a logistic function fitted over responses in a forced-choice identification task using two synthetic 10-step continua from rake to wake. Participants also produced rhotic and non-rhotic words. Across participants, there was a significant correlation between perceptual acuity and rhoticity in production, although this effect was only observed for one of two continua tested. These results provide preliminary evidence compatible with the hypothesis that children with a more refined auditory target for a sound also produce that sound more accurately. Published: February 16, 2017 Copyright: \textcopyright{} 2017 McAllister Byun, Tiede. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
  file = {/Users/megcychosz/Zotero/storage/8L7VQPS8/McAllister Byun and Tiede - 2017 - Perception-production relations in later developme.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {2}
}

@article{mcallisterbyunPositionalVelarFronting2012,
  title = {Positional Velar Fronting: {{An}} Updated Articulatory Account},
  shorttitle = {Positional Velar Fronting},
  author = {Mcallister Byun, Tara},
  year = {2012},
  month = nov,
  volume = {39},
  pages = {1043--1076},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000911000468},
  abstract = {This study develops the hypothesis that the child-specific phenomenon of positional velar fronting can be modeled as the product of phonologically encoded articulatory limitations unique to immature speakers. Children have difficulty executing discrete tongue movements, preferring to move the tongue and jaw as a single unit. This predisposes the child to produce undifferentiated linguopalatal contact, neutralizing the coronal\textendash velar contrast. Adopting a phonetically sensitive model of phonology, I propose that children's difficulty with discrete tongue movement can be encoded in a violable constraint, MOVE-AS-UNIT. The positional nature of fronting reflects the fact that discrete lingual movement is penalized more heavily in the motorically challenging context of a larger gesture. This analysis is supported with a longitudinal study of one child (3 ; 9 to 4; 4) whose fronting was conditioned by both segmental and prosodic factors. Adopting MOVE-AS-UNIT in a Harmonic Grammar framework makes it possible to reframe disparate-seeming conditioning factors as a unified grammatical system.},
  file = {/Users/megcychosz/Zotero/storage/98GCYR43/Mcallister Byun - 2012 - Positional velar fronting An updated articulatory.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {05}
}

@article{mcallisterbyunRetroflexBunchedTreatment2014,
  title = {Retroflex {{Versus Bunched}} in {{Treatment}} for {{Rhotic Misarticulation}}: {{Evidence From Ultrasound Biofeedback Intervention}}},
  shorttitle = {Retroflex {{Versus Bunched}} in {{Treatment}} for {{Rhotic Misarticulation}}},
  author = {McAllister Byun, T and Hitchcock, Elaine R. and Swartz, Michelle T.},
  year = {2014},
  month = dec,
  volume = {57},
  pages = {2116--2130},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2014_JSLHR-S-14-0034},
  abstract = {Purpose\textemdash To document the efficacy of ultrasound biofeedback treatment for misarticulation of the North American English rhotic in children. Because of limited progress in the first cohort, a series of two closely related studies was conducted in place of a single study. The studies differed primarily in the nature of tongue-shape targets (e.g., retroflex, bunched) cued during treatment. Method\textemdash Eight participants received 8 weeks of individual ultrasound biofeedback treatment targeting rhotics. In Study 1, all 4 participants were cued to match a bunched tongue-shape target. In Study 2, participants received individualized cues aimed at eliciting the tongue shape most facilitative of perceptually correct rhotics. Results\textemdash Participants in Study 1 showed only minimal treatment effects. In Study 2, all participants demonstrated improved production of rhotics in untreated words produced without biofeedback, with large to very large effect sizes. Conclusions\textemdash The results of Study 2 indicate that with proper parameters of treatment, ultrasound biofeedback can be a highly effective intervention for children with persistent rhotic errors. In addition, qualitative comparison of Studies 1 and 2 suggests that treatment for the North American English rhotic should include opportunities to explore different tongue shapes, to find the most facilitative variant for each individual speaker.},
  file = {/Users/megcychosz/Zotero/storage/CHN59TKV/Byun et al. - 2014 - Retroflex Versus Bunched in Treatment for Rhotic M.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {6}
}

@misc{mcauliffeMontrealForcedAligner2017,
  title = {Montreal {{Forced Aligner}}},
  author = {McAuliffe, M. and Socolof, M. and Mihuc, A. and Wagner, M. and Sonderegger, Morgan},
  year = {2017}
}

@article{mcbride-changLevelsPhonologicalAwareness2004,
  title = {Levels of Phonological Awareness in Three Cultures},
  author = {{McBride-Chang}, Catherine and Bialystok, Ellen and Chong, Karen K.Y. and Li, Yanping},
  year = {2004},
  month = oct,
  volume = {89},
  pages = {93--111},
  issn = {00220965},
  doi = {10.1016/j.jecp.2004.05.001},
  abstract = {This study focused on syllable phoneme onset levels of phonological awareness in relation to reading of Chinese and English in kindergarten and Wrst-grade children from Xian (China), Hong Kong, and Toronto, cultures that diVer substantially in approaches to reading instruction. English syllable awareness among native Chinese speakers was as good as or better than that among English speakers, indicating that the Chinese language may promote syllable-level awareness in children. Hong Kong children recognized signiWcantly more words in both English and Chinese but were signiWcantly poorer than the Xian children in both syllable and phoneme onset deletion tasks, suggesting that Pinyin training (given in Xian only) may promote phonological awareness even at the syllable level. In both Xian and Hong Kong, measures of syllable awareness consistently predicted Chinese character recognition better than did phoneme onset awareness. In contrast, English word recognition was predicted diVerently by syllable and phoneme onset awareness across cultures. These results underscore the roles of both language and writing system in understanding levels of phonological awareness.},
  file = {/Users/megcychosz/Zotero/storage/MK9TCKY2/McBride-Chang et al. - 2004 - Levels of phonological awareness in three cultures.pdf},
  journal = {Journal of Experimental Child Psychology},
  language = {en},
  number = {2}
}

@article{mcbride-changWhatWordMorphological2008,
  title = {What's in a Word? {{Morphological}} Awareness and Vocabulary Knowledge in Three Languages},
  shorttitle = {What's in a Word?},
  author = {{Mcbride-Chang}, Catherine and Tardif, Twila and Cho, Jeung-Ryeul and Shu, Hua and Fletcher, Paul and Stokes, Stephanie F. and Wong, Anita and Leung, Kawai},
  year = {2008},
  month = jul,
  volume = {29},
  pages = {437--462},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S014271640808020X},
  file = {/Users/megcychosz/Zotero/storage/UPSETDGF/Mcbride-Chang et al. - 2008 - What's in a word Morphological awareness and voca.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {3}
}

@article{mccarthyMTLDVocdDHDD2010,
  title = {{{MTLD}}, Vocd-{{D}}, and {{HD}}-{{D}}: {{A}} Validation Study of Sophisticated Approaches to Lexical Diversity Assessment},
  shorttitle = {{{MTLD}}, Vocd-{{D}}, and {{HD}}-{{D}}},
  author = {McCarthy, Philip M. and Jarvis, Scott},
  year = {2010},
  month = may,
  volume = {42},
  pages = {381--392},
  issn = {1554-351X, 1554-3528},
  doi = {10.3758/BRM.42.2.381},
  abstract = {In sum, all textual analyses are fraught with difficulty and disagreement, and LD is no exception. There is no agreement in the field as to the form of processing (sequential or nonsequential) or the composition of lexical terms (e.g., words, lemmas, bigrams, etc.); and even a common position with regard to the distinction between the terms lexical diversity, vocabulary diversity, and lexical richness remains unclear (Malvern et al., 2004). In this study, we do not attempt to remedy these issues. Instead, we argue that the field is sufficiently young to be still in need of exploring its potential to inform substantially. Thus, we include in our analyses the most sophisticated indices of LD that are currently available.},
  file = {/Users/megcychosz/Zotero/storage/ZLDUDYTL/McCarthy and Jarvis - 2010 - MTLD, vocd-D, and HD-D A validation study of soph.pdf},
  journal = {Behavior Research Methods},
  language = {en},
  number = {2}
}

@article{mccathrenRelationshipPrelinguisticVocalization1999,
  title = {The {{Relationship Between Prelinguistic Vocalization}} and {{Later Expressive Vocabulary}} in {{Young Children With Developmental Delay}}},
  author = {McCathren, Rebecca B. and Yoder, Paul J. and Warren, Steven F.},
  year = {1999},
  volume = {42},
  pages = {915--924},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/jslhr.4204.915},
  abstract = {Vanderbilt University Nashville, TN This study tested the relationship between prelinguistic vocalization and expressive vocabulary 1 year later in young children with mild to moderate developmental delays. Three vocalization variables were tested: rate of all vocalization, rate of vocalizations with consonants, and rate of vocalizations used interactively. The 58 toddlers in the study were 17\textendash 34 months old, not sensory impaired, and had Bayley Mental Development Indices (Bayley, 1969; Bayley, 1993) from 35\textendash 85. In addition, the children had fewer than 3 words in their expressive vocabularies and during classroom observation each showed at least one instance of intentional prelinguistic communication before testing. Selected sections of the Communication and Symbolic Behavior Scales procedures (CSBS; Wetherby \& Prizant, 1993) were administered at the beginning and at the end of the study. The vocal measures were obtained in the initial CSBS session. One measure of expressive vocabulary was obtained in the CSBS session at the end of the study. In addition, expressive vocabulary was measured in a nonstructured play session at the end of the study. We predicted that rate of vocalization, rate of vocalizations with consonants, and rate of vocalizations used interactively would all be positively related to later expressive vocabulary. The results confirmed the predictions.},
  file = {/Users/megcychosz/Zotero/storage/FS2MIUFJ/McCathren et al. - 1999 - The Relationship Between Prelinguistic Vocalizatio.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {4}
}

@article{mcclellandRulesConnectionsPasttense2002,
  title = {Rules or Connections in Past-Tense Inflections: What Does the Evidence Rule Out?},
  shorttitle = {Rules or Connections in Past-Tense Inflections},
  author = {McClelland, James L. and Patterson, Karalyn},
  year = {2002},
  month = nov,
  volume = {6},
  pages = {465--472},
  issn = {13646613},
  doi = {10.1016/S1364-6613(02)01993-9},
  file = {/Users/megcychosz/Zotero/storage/VKEGF97B/McClelland and Patterson - 2002 - Rules or connections in past-tense inflections wh.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {11}
}

@article{mcclellandWordsRulesCannot2002,
  title = {`{{Words}} or {{Rules}}' Cannot Exploit the Regularity in Exceptions},
  author = {McClelland, James L and Patterson, Karalyn},
  year = {2002},
  month = nov,
  volume = {6},
  pages = {464--465},
  issn = {13646613},
  doi = {10.1016/S1364-6613(02)02012-0},
  file = {/Users/megcychosz/Zotero/storage/N7PD9IQG/McClelland and Patterson - 2002 - ‘Words or Rules’ cannot exploit the regularity in .pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {11}
}

@misc{mccloyPhonR2016,
  title = {{{phonR}}},
  author = {McCloy, Daniel R.},
  year = {2016}
}

@article{mccuneEarlyPhoneticLexical2001,
  title = {Early Phonetic and Lexical Development: A Productivity Approach},
  author = {McCune, L and Vihman, Marilyn M},
  year = {2001},
  volume = {44},
  pages = {670--684},
  file = {/Users/megcychosz/Zotero/storage/TJWCHSI4/569ed55208ae2c638eb59bbf.pdf},
  journal = {Journal of Speech Language and Hearing Research}
}

@article{mcdanielPredictingExpressiveLanguage2020,
  title = {Predicting {{Expressive Language From Early Vocalizations}} in {{Young Children With Autism Spectrum Disorder}}: {{Which Vocal Measure Is Best}}?},
  shorttitle = {Predicting {{Expressive Language From Early Vocalizations}} in {{Young Children With Autism Spectrum Disorder}}},
  author = {McDaniel, Jena and Yoder, Paul and Estes, Annette and Rogers, Sally J.},
  year = {2020},
  month = may,
  volume = {63},
  pages = {1509--1520},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2020_JSLHR-19-00281},
  abstract = {Purpose               This study was designed to test the incremental validity of more expensive vocal development variables relative to less expensive variables for predicting later expressive language in children with autism spectrum disorder (ASD). We devote particular attention to the added value of coding the quality of vocalizations over the quantity of vocalizations because coding quality adds expense to the coding process. We are also interested in the added value of more costly human-coded vocal variables relative to those generated through automated analyses.                                         Method               Eighty-seven children with ASD aged 13\textendash 30 months at study initiation participated. For quantity of vocalizations, we derived one variable from human coding of brief communication samples and one from an automated process for daylong naturalistic audio samples. For quality of vocalizations, we derived four human-coded variables and one automated variable. A composite expressive language measure was derived at study entry, and 6 and 12 months later. The 12 months\textendash centered intercept of a simple linear growth trajectory was used to quantify later expressive language.                                         Results               When statistically controlling for human-coded or automated quantity of vocalization variables, human-coded quality of vocalization variables exhibited incremental validity for predicting later expressive language skills. Human-coded vocal variables also predicted later expressive language skills when controlling for the analogous automated vocal variables.                                         Conclusion               In sum, these findings support devoting resources to human coding of the quality of vocalizations from communication samples to predict later expressive language skills in young children with ASD despite the greater costs of deriving these variables.                                         Supplemental Material                                https://doi.org/10.23641/asha.12276458},
  file = {/Users/megcychosz/Zotero/storage/IUACHMQ8/McDaniel et al. - 2020 - Predicting Expressive Language From Early Vocaliza.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {5}
}

@article{mcdanielPrelinguisticVocalDevelopment2020,
  title = {Prelinguistic {{Vocal Development}} in {{Children With Cochlear Implants}}: {{A Systematic Review}}},
  shorttitle = {Prelinguistic {{Vocal Development}} in {{Children With Cochlear Implants}}},
  author = {McDaniel, Jena and Gifford, Ren{\'e} H.},
  year = {2020},
  month = sep,
  volume = {41},
  pages = {1064--1076},
  issn = {0196-0202},
  doi = {10.1097/AUD.0000000000000829},
  abstract = {Objectives: This systematic review is designed to (a) describe measures used to quantify vocal development in pediatric cochlear implant (CI) users, (b) synthesize the evidence on prelinguistic vocal development in young children before and after cochlear implantation, and (c) analyze the application of the current evidence for evaluating change in vocal development before and after cochlear implantation for young children. Investigations of prelinguistic vocal development after cochlear implantation are only beginning to uncover the expected course of prelinguistic vocal development in children with CIs and what factors influence that course, which varies substantially across pediatric CI users. A deeper understanding of prelinguistic vocal development will improve professionals' abilities to determine whether a child with a CI is exhibiting sufficient progress soon after implantation and to adjust intervention as needed. Design: We systematically searched PubMed, ProQuest, and CINAHL databases for primary reports of children who received a CI before 5 years 0 months of age that included at least one measure of nonword, nonvegetative vocalizations. We also completed supplementary searches. Results: Of the 1916 identified records, 59 met inclusion criteria. The included records included 1125 total participants, which came from 36 unique samples. Records included a median of 8 participants and rarely included children with disabilities other than hearing loss. Nearly all of the records met criteria for level 3 for quality of evidence on a scale of 1 (highest) to 4 (lowest). Records utilized a wide variety of vocalization measures but often incorporated features related to canonical babbling. The limited evidence from pediatric CI candidates before implantation suggests that they are likely to exhibit deficits in canonical syllables, a critical vocal development skill, and phonetic inventory size. Following cochlear implantation, multiple studies report similar patterns of growth, but faster rates producing canonical syllables in children with CIs than peers with comparable durations of robust hearing. However, caution is warranted because these demonstrated vocal development skills still occur at older chronological ages for children with CIs than chronological age peers with typical hearing. Conclusions: Despite including a relatively large number of records, the evidence in this review regarding changes in vocal development before and after cochlear implantation in young children remains limited. A deeper understanding of when prelinguistic skills are expected to develop, factors that explain deviation from that course, and the long-term impacts of variations in vocal prelinguistic development is needed. The diverse and dynamic nature of the relatively small population of pediatric CI users as well as relatively new vocal development measures present challenges for documenting and predicting vocal development in pediatric CI users before and after cochlear implantation. Synthesizing results across multiple institutions and completing rigorous studies with theoretically motivated, falsifiable research questions will address a number of challenges for understanding prelinguistic vocal development},
  file = {/Users/megcychosz/Zotero/storage/3JDR2T9G/McDaniel and Gifford - 2020 - Prelinguistic Vocal Development in Children With C.pdf},
  journal = {Ear \& Hearing},
  language = {en},
  number = {5}
}

@book{mcdivittMcDivittHomeBankCorpus2016,
  title = {{{McDivitt HomeBank Corpus}}},
  author = {McDivitt, K. and Soderstrom, Melanie},
  year = {2016},
  file = {/Users/megcychosz/Zotero/storage/UE86RY6J/McDivitt and Soderstrom - 2016 - McDivitt HomeBank Corpus.pdf}
}

@article{mcdonaldEvaluatingLanguageENvironment2021,
  title = {Evaluating the {{Language ENvironment Analysis System}} for {{Korean}}},
  author = {McDonald, Margarethe and Kwon, Taeahn and Kim, Hyunji and Lee, Youngki and Ko, Eon-Suk},
  year = {2021},
  month = mar,
  pages = {1--17},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2020_JSLHR-20-00489},
  abstract = {Purpose               The algorithm of the Language ENvironment Analysis (LENA) system for calculating language environment measures was trained on American English; thus, its validity with other languages cannot be assumed. This article evaluates the accuracy of the LENA system applied to Korean.                                         Method               We sampled sixty 5-min recording clips involving 38 key children aged 7\textendash 18 months from a larger data set. We establish the identification error rate, precision, and recall of LENA classification compared to human coders. We then examine the correlation between standard LENA measures of adult word count, child vocalization count, and conversational turn count and human counts of the same measures.                                         Results                                Our identification error rate (64\% or 67\%), including false alarm, confusion, and misses, was similar to the rate found in                 Cristia, Lavechin, et al. (2020)                 . The correlation between LENA and human counts for adult word count (                 r                 = .78 or .79) was similar to that found in the other studies, but the same measure for child vocalization count (                 r                 = .34\textendash.47) was lower than the value in Cristia, Lavechin, et al., though it fell within ranges found in other non-European languages. The correlation between LENA and human conversational turn count was not high (                 r                 = .36\textendash.47), similar to the findings in other studies.                                                        Conclusions               LENA technology is similarly reliable for Korean language environments as it is for other non-English language environments. Factors affecting the accuracy of diarization include speakers' pitch, duration of utterances, age, and the presence of noise and electronic sounds.},
  file = {/Users/megcychosz/Zotero/storage/PUL5I3LR/JSL6403_Ko.pdf;/Users/megcychosz/Zotero/storage/WIIFLDVE/McDonald et al. - 2021 - Evaluating the Language ENvironment Analysis Syste.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en}
}

@inproceedings{mcfeeLibrosaAudioMusic2015,
  title = {Librosa: {{Audio}} and {{Music Signal Analysis}} in {{Python}}},
  shorttitle = {Librosa},
  booktitle = {Proceedings of the 14th {{Python}} in Science Conference},
  author = {McFee, Brian and Raffel, Colin and Liang, Dawen and Ellis, Daniel and McVicar, Matt and Battenberg, Eric and Nieto, Oriol},
  year = {2015},
  pages = {18--24},
  address = {{Austin, Texas}},
  doi = {10.25080/Majora-7b98e3ed-003},
  abstract = {This document describes version 0.4.0 of librosa: a Python package for audio and music signal processing. At a high level, librosa provides implementations of a variety of common functions used throughout the field of music information retrieval. In this document, a brief overview of the library's functionality is provided, along with explanations of the design goals, software development practices, and notational conventions.},
  file = {/Users/megcychosz/Zotero/storage/TK3MCFJ5/McFee et al. - 2015 - librosa Audio and Music Signal Analysis in Python.pdf},
  language = {en}
}

@article{mcgillionWhatPavesWay2017,
  title = {What {{Paves}} the {{Way}} to {{Conventional Language}}? {{The Predictive Value}} of {{Babble}}, {{Pointing}}, and {{Socioeconomic Status}}},
  shorttitle = {What {{Paves}} the {{Way}} to {{Conventional Language}}?},
  author = {McGillion, Michelle and Herbert, Jane S. and Pine, Julian and Vihman, Marilyn and {dePaolis}, Rory and {Keren-Portnoy}, Tamar and Matthews, Danielle},
  year = {2017},
  month = jan,
  volume = {88},
  pages = {156--166},
  issn = {00093920},
  doi = {10.1111/cdev.12671},
  abstract = {A child's first words mark the emergence of a uniquely human ability. Theories of the developmental steps that pave the way for word production have proposed that either vocal or gestural precursors are key. These accounts were tested by assessing the developmental synchrony in the onset of babbling, pointing and word production for 46 infants observed monthly between the ages of 9 and 18 months. Babbling and pointing did not develop in tight synchrony and babble onset alone predicted first words. Pointing and maternal education emerged as predictors of lexical knowledge only in relation to a measure taken at 18months. This suggests a far more important role for early phonological development in the creation of the lexicon than previously thought.},
  file = {/Users/megcychosz/Zotero/storage/QC7FEI4B/cdev.12671.pdf},
  journal = {Child Development},
  language = {en},
  number = {1}
}

@article{mcgowanLongitudinalStudyVery2014,
  title = {A {{Longitudinal Study}} of {{Very Young Children}}'s {{Vowel Production}}},
  author = {McGowan, Rebecca W. and McGowan, Richard S. and Denny, Margaret and Nittrouer, Susan},
  year = {2014},
  month = feb,
  volume = {57},
  pages = {1--15},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2013/12-0112)},
  abstract = {Purpose\textemdash Ecologically realistic, spontaneous adult-directed longitudinal speech data of young children was described by acoustic analyses. Method\textemdash The first two formant frequencies of vowels produced by six children from different American English dialect regions were analyzed from ages 18 to 48 months. The vowels were from largely conversational contexts and were classified according to dictionary pronunciation. Results\textemdash Within-subject formant frequency variability remained relatively constant for the span of ages studied here. It was often difficult to detect overall decreases in the first two formant frequencies between the ages of 30 and 48 months. A study of the movement of the corner vowels with respect to the vowel centroid showed that the shape of the vowel space remained qualitatively constant from 30 through 48 months. Conclusions\textemdash The shape of the vowel space is established early in life. Some aspects of regional dialect were observed in some of the subjects at 42 months of age. The present paper adds to the existing data on the development of vowel spaces by describing ecologically realistic speech.},
  file = {/Users/megcychosz/Zotero/storage/5HLXTA2H/McGowan et al. - 2014 - A Longitudinal Study of Very Young Children's Vowe.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {1}
}

@article{mcgowanPerceptionSyntheticVowel2006,
  title = {Perception of Synthetic Vowel Exemplars of 4 Year Old Children and Estimation of Their Corresponding Vocal Tract Shapes},
  author = {McGowan, Richard S.},
  year = {2006},
  month = nov,
  volume = {120},
  pages = {2850--2858},
  issn = {0001-4966},
  doi = {10.1121/1.2345833},
  file = {/Users/megcychosz/Zotero/storage/NXJS2LDB/McGowan - 2006 - Perception of synthetic vowel exemplars of 4 year .pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{mcmurrayInfantDirectedSpeech2013,
  title = {Infant Directed Speech and the Development of Speech Perception: {{Enhancing}} Development or an Unintended Consequence?},
  shorttitle = {Infant Directed Speech and the Development of Speech Perception},
  author = {McMurray, Bob and {Kovack-Lesh}, Kristine A. and Goodwin, Dresden and McEchron, William},
  year = {2013},
  month = nov,
  volume = {129},
  pages = {362--378},
  issn = {00100277},
  doi = {10.1016/j.cognition.2013.07.015},
  abstract = {Infant directed speech (IDS) is a speech register characterized by simpler sentences, a slower rate, and more variable prosody. Recent work has implicated it in more subtle aspects of language development. Kuhl et al. (1997) demonstrated that segmental cues for vowels are affected by IDS in a way that may enhance development: the average locations of the extreme ``point'' vowels (/ a/, /i/ and /u/) are further apart in acoustic space. If infants learn speech categories, in part, from the statistical distributions of such cues, these changes may specifically enhance speech category learning. We revisited this by asking (1) if these findings extend to a new cue (Voice Onset Time, a cue for voicing); (2) whether they extend to the interior vowels which are much harder to learn and/or discriminate; and (3) whether these changes may be an unintended phonetic consequence of factors like speaking rate or prosodic changes associated with IDS. Eighteen caregivers were recorded reading a picture book including minimal pairs for voicing (e.g., beach/peach) and a variety of vowels to either an adult or their infant. Acoustic measurements suggested that VOT was different in IDS, but not in a way that necessarily supports better development, and that these changes are almost entirely due to slower rate of speech of IDS. Measurements of the vowel suggested that in addition to changes in the mean, there was also an increase in variance, and statistical modeling suggests that this may counteract the benefit of any expansion of the vowel space. As a whole this suggests that changes in segmental cues associated with IDS may be an unintended by-product of the slower rate of speech and different prosodic structure, and do not necessarily derive from a motivation to enhance development.},
  file = {/Users/megcychosz/Zotero/storage/AUA7L5T8/McMurray et al. - 2013 - Infant directed speech and the development of spee.pdf},
  journal = {Cognition},
  language = {en},
  number = {2}
}

@article{mcmurraySpeechCategorizationDevelops2018,
  title = {Speech Categorization Develops Slowly through Adolescence.},
  author = {McMurray, Bob and Danelz, Ani and Rigler, Hannah and Seedorff, Michael},
  year = {2018},
  month = aug,
  volume = {54},
  pages = {1472--1491},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/dev0000542},
  abstract = {The development of the ability to categorize speech sounds is often viewed as occurring primarily during infancy via perceptual learning mechanisms. However, a number of studies suggest that even after infancy, children's categories become more categorical and well-defined through about age 12. We investigated the cognitive changes that may be responsible for such development using a visual world paradigm experiment based on (McMurray, Tanenhaus, \& Aslin, 2002). Children from three age groups (7\textendash 8, 12\textendash 13, and 17\textendash 18 years) heard a token from either a b/p or s/{$\Elzesh$} continua spanning two words (beach/peach, ship/sip), and selected its referent from a screen containing four pictures of potential lexical candidates. Eye-movements to each object were monitored as a measure of how strongly children were committing to each candidate as perception unfolds in real-time. Results showed an ongoing sharpening of speech categories through 18, which was particularly apparent during the early stages of real-time perception. When analysis targeted to specifically within-category sensitivity to continuous detail, children exhibited increasingly gradient categories over development, suggesting that increasing sensitivity to finegrained detail in the signal enables these more discrete categorization. Together these suggest that speech development is a protracted process in which children's increasing sensitivity to withincategory detail in the signal enables increasingly sharp phonetic categories.},
  file = {/Users/megcychosz/Zotero/storage/5RY28LU8/McMurray et al. - 2018 - Speech categorization develops slowly through adol.pdf},
  journal = {Developmental Psychology},
  language = {en},
  number = {8}
}

@article{meadowInteractionsDeafMothers1981,
  title = {Interactions of {{Deaf Mothers}} and {{Deaf Preschool Children}}: {{Comparisons}} with {{Three Other Groups}} of {{Deaf}} and {{Hearing Dyads}}},
  shorttitle = {Interactions of {{Deaf Mothers}} and {{Deaf Preschool Children}}},
  author = {Meadow, Kathryn P. and Greenberg, Mark T. and Erting, Carol and Carmichael, Heather},
  year = {1981},
  volume = {126},
  pages = {454--468},
  issn = {1543-0375},
  doi = {10.1353/aad.2012.1463},
  file = {/Users/megcychosz/Zotero/storage/AJNITGEE/Meadow et al. - 1981 - Interactions of Deaf Mothers and Deaf Preschool Ch.pdf},
  journal = {American Annals of the Deaf},
  language = {en},
  number = {4}
}

@article{meakinsHowMuchInput2013,
  title = {How Much Input Is Enough? {{Correlating}} Comprehension and Child Language Input in an Endangered Language},
  shorttitle = {How Much Input Is Enough?},
  author = {Meakins, Felicity and Wigglesworth, Gillian},
  year = {2013},
  month = mar,
  volume = {34},
  pages = {171--188},
  issn = {0143-4632, 1747-7557},
  doi = {10.1080/01434632.2012.733010},
  file = {/Users/megcychosz/Zotero/storage/TP5UKGWX/Meakins and Wigglesworth - 2013 - How much input is enough Correlating comprehensio.pdf},
  journal = {Journal of Multilingual and Multicultural Development},
  language = {en},
  number = {2}
}

@article{mealingsAcousticInvestigationsLater2013,
  title = {Acoustic Investigations into the Later Acquisition of Syllabic -Es Plurals},
  author = {Mealings, Kiri T. and Cox, Felicity and Demuth, Katherine},
  year = {2013},
  volume = {56},
  pages = {1260--1271},
  issn = {1092-4388},
  doi = {10.1044/1092-4388(2012/12-0163)},
  abstract = {Purpose: Children acquire /-{$\Elzschwa$}z/ syllabic plurals (e.g., buses) later than /-s, -z/ segmental plurals (e.g., cats, dogs). In this study, the authors explored whether increased syllable number or segmental factors best explains poorer performance with syllabic plurals. Method: An elicited imitation experiment was conducted with 14 two-year-olds involving 8 familiar disyllabic target plural nouns, half with syllabic plurals (e.g., bus \`a buses) and half with segmental plurals (e.g., letter \`a letters). Children saw pictures of the target items on a computer and repeated prerecorded 3-word-utterances with the target word in utterance-medial position (e.g., ``The buses come'') and utterance-final position (e.g., ``Hear the buses''). Acoustic analysis determined the presence or absence of the plural morpheme and its duration. Results: Children had more trouble producing syllabic plurals compared with segmental plurals. Errors were especially evident in the utterance-medial position, where there was less time for the child to perceive/produce the word in the absence of phrase-final lengthening and where planning for the following word was still required. Conclusions: The results suggested that articulatory difficulties\textemdash rather than a word length effect\textemdash explain later acquisition of syllabic plurals relative to segmental plurals. These findings have implications for the nature of syllabic plural acquisition in children with hearing impairments and specific language impairment.},
  file = {/Users/megcychosz/Zotero/storage/9VTSHJQW/Mealings et al. - 2013 - Acoustic Investigations Into the Later Acquisition.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {4}
}

@article{mealingsRoleUtteranceLength2014,
  title = {The Role of Utterance Length and Position in 3-Year-Olds' Production of Third Person Singular},
  author = {Mealings, Kiri T. and Demuth, Katherine},
  year = {2014},
  volume = {57},
  pages = {484--494},
  issn = {1092-4388},
  doi = {10.1044/2013_JSLHR-L-12-0354},
  abstract = {Purpose: Evidence from children's spontaneous speech suggests that utterance length and utterance position may help explain why children omit grammatical morphemes in some contexts but not others. This study investigated whether increased utterance length (hence, increased grammatical complexity) adversely affects children's third person singular -s production in more controlled experimental conditions. Method: An elicited imitation task with 12 Australian English\textendash speaking children ages 2;9 (years;months) to 3;2 (Mage = 2;11) was conducted comparing third person singular -s production in 3-word and 5-word utterances, both utterance medially (e.g., He sits back; He sits back and swings) and utterance finally (e.g., There he sits; That's the way he sits) using a within-subjects design. Children were shown pictorial representations of each utterance on a computer and were invited to repeat 16 pseudorandomized prerecorded utterances. Acoustic analysis determined the presence/absence and duration of the third person singular morpheme. Results: Third person singular production was significantly lower utterance medially compared to utterance finally for the 5-word utterances and significantly lower utterance medially in the 5-word compared to 3-word utterances. Conclusion: These results suggest that increased utterance length results in significantly lower third person singular production, but only in the more articulatorily challenging utterance-medial position. Thus, morpheme omission is greatest at the intersection of grammatical and phonological complexity.},
  file = {/Users/megcychosz/Zotero/storage/N874KPCB/Mealings and Demuth - 2014 - The Role of Utterance Length and Position in 3-Yea.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {2}
}

@article{mehlElectronicallyActivatedRecorder2017,
  title = {The {{Electronically Activated Recorder}} ({{EAR}}): {{A Method}} for the {{Naturalistic Observation}} of {{Daily Social Behavior}}},
  shorttitle = {The {{Electronically Activated Recorder}} ({{EAR}})},
  author = {Mehl, Matthias R.},
  year = {2017},
  month = apr,
  volume = {26},
  pages = {184--190},
  issn = {0963-7214, 1467-8721},
  doi = {10.1177/0963721416680611},
  abstract = {This article reviews the Electronically Activated Recorder or EAR as an ambulatory ecological momentary assessment tool for the real-world observation of daily behavior. Technically, the EAR is an audio recorder that intermittently records snippets of ambient sounds while participants go about their lives. Conceptually, it is a naturalistic observation method that yields an acoustic log of a person's day as it unfolds. The power of the EAR lies in unobtrusively collecting authentic reallife observational data. In preserving a high degree of naturalism at the level of the raw recordings, it resembles ethnographic methods; through its sampling and coding, it enables larger empirical studies. The article provides an overview of the EAR method, reviews its validity, utility, and limitations, and discusses it in the context of current developments in ambulatory assessment, specifically the emerging field of mobile sensing.},
  file = {/Users/megcychosz/Zotero/storage/FKMAY5U6/Mehl - 2017 - The Electronically Activated Recorder (EAR) A Met.pdf},
  journal = {Current Directions in Psychological Science},
  language = {en},
  number = {2}
}

@article{mehlSoundsSocialLife2003,
  title = {The Sounds of Social Life: {{A}} Psychometric Analysis of Students' Daily Social Environments and Natural Conversations.},
  shorttitle = {The Sounds of Social Life},
  author = {Mehl, Matthias R. and Pennebaker, James W.},
  year = {2003},
  volume = {84},
  pages = {857--870},
  issn = {1939-1315, 0022-3514},
  doi = {10.1037/0022-3514.84.4.857},
  file = {/Users/megcychosz/Zotero/storage/59Q8U3XW/Mehl and Pennebaker - 2003 - The sounds of social life A psychometric analysis.pdf},
  journal = {Journal of Personality and Social Psychology},
  language = {en},
  number = {4}
}

@article{mehtaKARMAKalmanbasedAutoregressive2012,
  title = {{{KARMA}}: {{Kalman}}-Based Autoregressive Moving Average Modeling and Inference for Formant and Antiformant Tracking},
  shorttitle = {{{KARMA}}},
  author = {Mehta, Daryush D. and Rudoy, Daniel and Wolfe, Patrick J.},
  year = {2012},
  month = sep,
  volume = {132},
  pages = {1732--1746},
  issn = {0001-4966},
  doi = {10.1121/1.4739462},
  abstract = {Vocal tract resonance characteristics in acoustic speech signals are classically tracked using frame-by-frame point estimates of formant frequencies followed by candidate selection and smoothing using dynamic programming methods that minimize ad hoc cost functions. The goal of the current work is to provide both point estimates and associated uncertainties of center frequencies and bandwidths in a statistically principled state-space framework. Extended Kalman (K) algorithms take advantage of a linearized mapping to infer formant and antiformant parameters from frame-based estimates of autoregressive moving average (ARMA) cepstral coefficients. Error analysis of KARMA, WaveSurfer, and Praat is accomplished in the all-pole case using a manually marked formant database and synthesized speech waveforms. KARMA formant tracks exhibit lower overall root-mean-square error relative to the two benchmark algorithms, with third formant tracking more challenging. Antiformant tracking performance of KARMA is illustrated using synthesized and spoken nasal phonemes. The simultaneous tracking of uncertainty levels enables practitioners to recognize time-varying confidence in parameters of interest and adjust algorithmic settings accordingly.},
  archiveprefix = {arXiv},
  eprint = {1107.0076},
  eprinttype = {arxiv},
  file = {/Users/megcychosz/Zotero/storage/LBL5AE2H/Mehta et al. - 2012 - KARMA Kalman-based autoregressive moving average .pdf;/Users/megcychosz/Zotero/storage/YI4XUYNS/1107.html},
  journal = {The Journal of the Acoustical Society of America},
  keywords = {Computer Science - Sound,Statistics - Applications},
  note = {Comment: 13 pages, 7 figures; submitted for publication},
  number = {3}
}

@article{menardArticulatoryAcousticRelationships2007,
  title = {Articulatory\textendash Acoustic Relationships during Vocal Tract Growth for {{French}} Vowels: {{Analysis}} of Real Data and Simulations with an Articulatory Model},
  shorttitle = {Articulatory\textendash Acoustic Relationships during Vocal Tract Growth for {{French}} Vowels},
  author = {M{\'e}nard, Lucie and Schwartz, Jean-Luc and Bo{\"e}, Louis-Jean and Aubin, J{\'e}r{\^o}me},
  year = {2007},
  month = jan,
  volume = {35},
  pages = {1--19},
  issn = {00954470},
  doi = {10.1016/j.wocn.2006.01.003},
  abstract = {This paper reports on the articulatory\textendash acoustic relationships involved during vocal tract growth. Data were taken from a database of ten French vowels uttered by 15 speakers ranging in age from 3 years old to adulthood. Despite the important acoustic variation encountered, one feature is displayed by all the speakers: the production of extreme focal vowels /i/, /u/, /]/, and /y/, realized with a strong concentration of spectral energy related to the proximity of two formant peaks. This feature represents an acoustic goal guiding the speaker's task. Our simulations using an articulatory model demonstrate that the realization of the focalization feature may require different articulatory gestures for young children compared to adults, consisting of adaptive articulatory strategies exploited to compensate for the small pharynx of the former. Perceptual tests show that achieving focalization results in a lower intelligibility for the children than for the adults. Due to the relatively shorter pharyngeal cavity of the child compared to the adult, focalization cannot be achieved together with the perceptual objective related to rounded vowels /y/ in French. Results are discussed in light of the dispersionfocalization theory and the perception for action control theory (PACT).},
  file = {/Users/megcychosz/Zotero/storage/6IUSYFU8/Ménard et al. - 2007 - Articulatory–acoustic relationships during vocal t.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {1}
}

@article{menardCompensationLiptubePerturbation2016,
  title = {Compensation for a Lip-Tube Perturbation in 4-Year-Olds: {{Articulatory}}, Acoustic, and Perceptual Data Analyzed in Comparison with Adults},
  shorttitle = {Compensation for a Lip-Tube Perturbation in 4-Year-Olds},
  author = {M{\'e}nard, Lucie and Perrier, Pascal and Aubin, J{\'e}r{\^o}me},
  year = {2016},
  month = may,
  volume = {139},
  pages = {2514--2531},
  issn = {0001-4966},
  doi = {10.1121/1.4945718},
  file = {/Users/megcychosz/Zotero/storage/5ZNNMEGZ/Ménard et al. - 2016 - Compensation for a lip-tube perturbation in 4-year.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{menardCompensationStrategiesLiptube2008,
  title = {Compensation Strategies for a Lip-Tube Perturbation of {{French}} [u]: {{An}} Acoustic and Perceptual Study of 4-Year-Old Children},
  shorttitle = {Compensation Strategies for a Lip-Tube Perturbation of {{French}} [u]},
  author = {M{\'e}nard, Lucie and Perrier, Pascal and Aubin, Jer{\^o}me and Savariaux, Christophe and Thibeault, M{\'e}lanie},
  year = {2008},
  month = aug,
  volume = {124},
  pages = {1192--1206},
  issn = {0001-4966},
  doi = {10.1121/1.2945704},
  file = {/Users/megcychosz/Zotero/storage/W47GFYVS/Ménard et al. - 2008 - Compensation strategies for a lip-tube perturbatio.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@inproceedings{menardExploringVowelProduction2000,
  title = {Exploring Vowel Production Strategies from Infant to Adult by Means of Articulatory Inversion of Formant Data},
  booktitle = {Sixth {{International Conference}} on {{Spoken Language Processing}}},
  author = {M{\'e}nard, Lucie and Bo{\"e}, Louis-Jean},
  year = {2000},
  address = {{Beijing, China}},
  abstract = {It is well known that the adult's vocal tract is not a uniform scaled up version of a child vocal tract. Considering these morphological differences, what are the articulatory strategies used by the speaker throughout growth to produce the same vowels? Our previous simulation study [1] predicts that a speaker with a newborn-like vocal tract would employ a fronting articulation compared to an adult male, in order to produce the same acoustic targets. In this paper, we extend our simulations with the VLAM model to a 4-year-old and a 10-year-old children, a 16-year-old boy and an adult man. Articulatory positions, for each growth stage, for the 4 vowels [i], [y], [u], and [a] have been determined using a formant-to-articulatory inversion method. Analysis of real data is finally presented.},
  file = {/Users/megcychosz/Zotero/storage/FMNVC45Z/Ménard and Boë - EXPLORING VOWEL PRODUCTION STRATEGIES FROM INFANT .pdf},
  language = {en}
}

@article{menardRoleVocalTract2004,
  title = {Role of {{Vocal Tract Morphology}} in {{Speech Development}}: {{Perceptual Targets}} and {{Sensorimotor Maps}} for {{Synthesized French Vowels From Birth}} to {{Adulthood}}},
  shorttitle = {Role of {{Vocal Tract Morphology}} in {{Speech Development}}},
  author = {M{\'e}nard, Lucie and Schwartz, Jean-Luc and Bo{\"e}, Louis-Jean},
  year = {2004},
  month = oct,
  volume = {47},
  pages = {1059--1080},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2004/079)},
  file = {/Users/megcychosz/Zotero/storage/DHNKT7PX/Ménard et al. - 2004 - Role of Vocal Tract Morphology in Speech Developme.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {5}
}

@incollection{mennChallengesTheoriesCharges2013,
  title = {Challenges to Theories, Charges to a Model: The {{Linked}}-{{Attractor}} Model of Phonological Development},
  booktitle = {The Emergence of Phonology: {{Whole}}-Word Approaches and Cross-Linguistic Evidence},
  author = {Menn, Lise and Schmidt, Ellen and Nicholas, Brent},
  editor = {Vihman, Marilyn M. and {Keren-Portnoy}, Tamar},
  year = {2013},
  pages = {460--502},
  file = {/Users/megcychosz/Zotero/storage/3CVXKIXR/Menn linked attractor model notes.docx;/Users/megcychosz/Zotero/storage/MDTF6DCQ/MennLinkedAttractors.pdf}
}

@incollection{mennConnectionistModelingMicrostructure1993,
  title = {Connectionist {{Modeling}} and the {{Microstructure}} of {{Phonological Development}}: {{A Progress Report}}},
  shorttitle = {Connectionist {{Modeling}} and the {{Microstructure}} of {{Phonological Development}}},
  booktitle = {Developmental {{Neurocognition}}: {{Speech}} and {{Face Processing}} in the {{First Year}} of {{Life}}},
  author = {Menn, Lise and Markey, Kevin and Mozer, Michael and Lewis, Clayton},
  editor = {{Boysson-Bardies}, B{\'e}n{\'e}dicte and Schonen, Scania and Jusczyk, Peter and McNeilage, Peter and Morton, John},
  year = {1993},
  pages = {421--433},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  doi = {10.1007/978-94-015-8234-6_34},
  abstract = {Children learning to pronounce the sounds of their languages exhibit individual differences and a varying but often high degree of regularity in their rendering of adult words. The mappings from adult to child words show great phonetic context dependency and considerable stability over time, but often much lexical irregularity and other 'unruly behavior'. Standard child phonology models, derived from adult-based phonological theory, ignore such unruly phenomena as non-rule-governed template matching, crosstalk between rules, and fuzzy boundaries of rule domains. Connectionist learning models are in principle well adapted to simulating these properties; a model in progress, GEYKO, is sketched. Children have access to several feedback loops in learning to pronounce, both internal (auditory, motor, proprioceptive) and external (parental social and material reinforcement). GEYKO's speech gesture planning module is intended to learn production with the aid of such feedback, and its auditory planning module will learn perceptual categorization of spectral data by unsupervised learning methods.},
  file = {/Users/megcychosz/Zotero/storage/KZJHK8BJ/Menn et al. - 1993 - Connectionist Modeling and the Microstructure of P.pdf},
  isbn = {978-90-481-4251-4 978-94-015-8234-6},
  language = {en}
}

@article{metsalaExaminationWordFrequency1997,
  title = {An Examination of Word Frequency and Neighborhood Density in the Development of Spoken-Word Recognition},
  author = {Metsala, Jamie L.},
  year = {1997},
  month = jan,
  volume = {25},
  pages = {47--56},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03197284},
  file = {/Users/megcychosz/Zotero/storage/9ZQ3UQ5H/Metsala - 1997 - An examination of word frequency and neighborhood .pdf},
  journal = {Memory \& Cognition},
  language = {en},
  number = {1}
}

@incollection{metsalaSpokenVocabularyGrowth1998,
  title = {Spoken Vocabulary Growth and the Segmental Restructuring of Lexical Representations: {{Precurors}} to Phonemic Awareness and Early Reading Ability.},
  booktitle = {Word Recognition in Beginning Literacy},
  author = {Metsala, Jamie and Walley, A},
  year = {1998},
  pages = {89--120},
  publisher = {{Lawrence Erlbaum Associates}}
}

@article{metsalaYoungChildrenPhonological1999,
  title = {Young Children's Phonological Awareness and Nonword Repetition as a Function of Vocabulary Development},
  author = {Metsala, Jamie},
  year = {1999},
  volume = {91},
  pages = {3--19},
  file = {/Users/megcychosz/Zotero/storage/EZUDNDN7/Metsala and Walley - 1998 - Spoken vocabulary growth and the segmental restruc.pdf},
  journal = {Journal of Educational Psychology},
  number = {1}
}

@article{meyerPracticalTipsEthical2018,
  title = {Practical {{Tips}} for {{Ethical Data Sharing}}},
  author = {Meyer, Michelle N.},
  year = {2018},
  month = mar,
  volume = {1},
  pages = {131--144},
  issn = {2515-2459, 2515-2467},
  doi = {10.1177/2515245917747656},
  abstract = {This Tutorial provides practical dos and don'ts for sharing research data in ways that are effective, ethical, and compliant with the federal Common Rule. I first consider best practices for prospectively incorporating data-sharing plans into research, discussing what to say\textemdash and what not to say\textemdash in consent forms and institutional review board applications, tools for data de-identification and how to think about the risks of re-identification, and what to consider when selecting a data repository. Turning to data that have already been collected, I discuss the ethical and regulatory issues raised by sharing data when the consent form either was silent about data sharing or explicitly promised participants that the data would not be shared. Finally, I discuss ethical issues in sharing ``public'' data.},
  file = {/Users/megcychosz/Zotero/storage/K74DXM8N/Meyer - 2018 - Practical Tips for Ethical Data Sharing.pdf},
  journal = {Advances in Methods and Practices in Psychological Science},
  language = {en},
  number = {1}
}

@techreport{meylanChallengesLargeScaleWebbased2021,
  title = {The {{Challenges}} of {{Large}}-{{Scale}}, {{Web}}-Based {{Language Datasets}}: {{Word Length}} and {{Predictability Revisited}}},
  shorttitle = {The {{Challenges}} of {{Large}}-{{Scale}}, {{Web}}-Based {{Language Datasets}}},
  author = {Meylan, Stephan and Griffiths, Tom},
  year = {2021},
  month = mar,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/6832r},
  abstract = {Language research has come to rely heavily on large-scale, web-based datasets. These datasets can present significant methodological challenges, requiring researchers to make a number of decisions about how they are collected, represented, and analyzed. These decisions often concern long-standing challenges in corpus-based language research, including determining what counts as a word, deciding which words should be analyzed, and matching sets of words across languages. We illustrate these challenges by revisiting ``Word lengths are optimized for efficient communication'' (Piantadosi, Tily, \& Gibson, 2011), which found that word lengths in 11 languages are more strongly correlated with their average predictability (or average information content) than their frequency. Using what we argue to be best practices for large-scale corpus analyses, we find significantly attenuated support for this result, and demonstrate that a stronger relationship obtains between word frequency and length for a majority of the languages in the sample. We consider the implications of the results for language research more broadly and provide several recommendations to researchers regarding best practices.},
  file = {/Users/megcychosz/Zotero/storage/4FTGKSCV/Meylan and Griffiths - 2021 - The Challenges of Large-Scale, Web-based Language .pdf},
  language = {en},
  type = {Preprint}
}

@techreport{meylanChallengesLargeScaleWebbased2021a,
  title = {The {{Challenges}} of {{Large}}-{{Scale}}, {{Web}}-Based {{Language Datasets}}: {{Word Length}} and {{Predictability Revisited}}},
  shorttitle = {The {{Challenges}} of {{Large}}-{{Scale}}, {{Web}}-Based {{Language Datasets}}},
  author = {Meylan, Stephan and Griffiths, Tom},
  year = {2021},
  month = mar,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/6832r},
  abstract = {Language research has come to rely heavily on large-scale, web-based datasets. These datasets can present significant methodological challenges, requiring researchers to make a number of decisions about how they are collected, represented, and analyzed. These decisions often concern long-standing challenges in corpus-based language research, including determining what counts as a word, deciding which words should be analyzed, and matching sets of words across languages. We illustrate these challenges by revisiting ``Word lengths are optimized for efficient communication'' (Piantadosi, Tily, \& Gibson, 2011), which found that word lengths in 11 languages are more strongly correlated with their average predictability (or average information content) than their frequency. Using what we argue to be best practices for large-scale corpus analyses, we find significantly attenuated support for this result, and demonstrate that a stronger relationship obtains between word frequency and length for a majority of the languages in the sample. We consider the implications of the results for language research more broadly and provide several recommendations to researchers regarding best practices.},
  file = {/Users/megcychosz/Zotero/storage/2HMKTQUL/Meylan and Griffiths - 2021 - The Challenges of Large-Scale, Web-based Language .pdf},
  language = {en},
  type = {Preprint}
}

@article{meylanChilddirectedListeningHow2021,
  title = {Child-Directed {{Listening}}: {{How Caregiver Inference Enables Children}}'s {{Early Verbal Communication}}},
  shorttitle = {Child-Directed {{Listening}}},
  author = {Meylan, Stephan C. and Foushee, Ruthe and Bergelson, Elika and Levy, Roger P.},
  year = {2021},
  month = feb,
  abstract = {How do adults understand children's speech? Children's productions over the course of language development often bear little resemblance to typical adult pronunciations, yet caregivers nonetheless reliably recover meaning from them. Here, we employ a suite of Bayesian models of spoken word recognition to understand how adults overcome the noisiness of child language, showing that communicative success between children and adults relies heavily on adult inferential processes. By evaluating competing models on phonetically-annotated corpora, we show that adults' recovered meanings are best predicted by prior expectations fitted specifically to the child language environment, rather than to typical adult-adult language. After quantifying the contribution of this "child-directed listening" over developmental time, we discuss the consequences for theories of language acquisition, as well as the implications for commonly-used methods for assessing children's linguistic proficiency.},
  archiveprefix = {arXiv},
  eprint = {2102.03462},
  eprinttype = {arxiv},
  file = {/Users/megcychosz/Zotero/storage/GQ6U42E9/Meylan et al. - 2021 - Child-directed Listening How Caregiver Inference .pdf;/Users/megcychosz/Zotero/storage/2HVQYX9G/2102.html},
  journal = {arXiv:2102.03462 [cs]},
  keywords = {Computer Science - Computation and Language},
  note = {Comment: 13 pages, 3 figures, 2 tables. Edit \#1 fixes formatting on table 1 (fitting it onto a single page) and reports correct contents for table 1 (previous version reported ants, not bits)},
  primaryclass = {cs}
}

@article{meylanEmergenceAbstractGrammatical2017,
  title = {The Emergence of an Abstract Grammatical Category in Children's Early Speech},
  author = {Meylan, Stephan C. and Frank, Michael C. and Roy, Brandon C. and Levy, Roger},
  year = {2017},
  month = feb,
  volume = {28},
  pages = {181--192},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797616677753},
  abstract = {How do children begin to use language to say things they have never heard before? The origins of linguistic productivity have been a subject of heated debate: While generativist accounts posit that children's early language reflects the presence of syntactic abstractions, constructivist approaches instead emphasize gradual generalization over frequently-heard forms. Here we develop a Bayesian statistical model that measures the degree of abstraction implicit in children's early use of the determiners ``a'' and ``the.'' Our work reveals that many previously-used corpora are too small to adjudicate between these theoretical positions. Several datasets, including the Speechome Corpus\textemdash a new ultra-dense dataset for one child\textemdash show evidence of low initial levels of productivity and higher levels later in development, however. These findings are consistent with the hypothesis that children lack rich grammatical knowledge at the outset of language learning, but rapidly begin to generalize on the basis of structural regularities in their input.},
  file = {/Users/megcychosz/Zotero/storage/BW2H9LVG/Meylan et al. - 2017 - The Emergence of an Abstract Grammatical Category .pdf},
  journal = {Psychological Science},
  language = {en},
  number = {2}
}

@article{meylanWordFormsNot2017,
  title = {Word Forms - Not Just Their Lengths- Are Optimized for Efficient Communication},
  author = {Meylan, Stephan C. and Griffiths, Thomas L.},
  year = {2017},
  month = mar,
  abstract = {The inverse relationship between the length of a word and the frequency of its use, first identified by G.K. Zipf in 1935, is a classic empirical law that holds across a wide range of human languages. We demonstrate that length is one aspect of a much more general property of words: how distinctive they are with respect to other words in a language. Distinctiveness plays a critical role in recognizing words in fluent speech, in that it reflects the strength of potential competitors when selecting the best candidate for an ambiguous signal. Phonological information content, a measure of a word's string probability under a statistical model of a language's sound or character sequences, concisely captures distinctiveness. Examining largescale corpora from 13 languages, we find that distinctiveness significantly outperforms word length as a predictor of frequency. This finding provides evidence that listeners' processing constraints shape fine-grained aspects of word forms across languages.},
  archiveprefix = {arXiv},
  eprint = {1703.01694},
  eprinttype = {arxiv},
  file = {/Users/megcychosz/Zotero/storage/RPY28UDI/Meylan and Griffiths - 2017 - Word forms - not just their lengths- are optimized.pdf},
  journal = {arXiv:1703.01694 [cs]},
  keywords = {Computer Science - Computation and Language},
  language = {en},
  note = {Comment: 16 pages, 8 figures},
  primaryclass = {cs}
}

@article{michalczykRelationshipsQuantityNumber2013,
  title = {The Relationships between Quantity-number Competencies, Working Memory, and Phonological Awareness in 5- and 6-year-olds},
  author = {Michalczyk, Kurt and Krajewski, Kristin and Pressler, Anna-Lena and Hasselhorn, Marcus},
  year = {2013},
  volume = {31},
  pages = {408--424},
  journal = {British Journal of Developmental Psychology},
  number = {4}
}

@article{michelettiOptimalSamplingStrategies2020,
  title = {Optimal Sampling Strategies for Characterizing Behavior and Affect from Ambulatory Audio Recordings.},
  author = {Micheletti, Megan and {de Barbaro}, Kaya and Fellows, Michelle D. and Hixon, J. Gregory and Slatcher, Richard B. and Pennebaker, James W.},
  year = {2020},
  month = apr,
  issn = {1939-1293, 0893-3200},
  doi = {10.1037/fam0000654},
  abstract = {Advances in mobile and wearable technologies mean it is now feasible to record hours to days of participant behavior in its naturalistic context, a great boon for psychologists interested in family processes and development. While automated activity recognition algorithms exist for a limited set of behaviors, time-consuming human annotations are still required to robustly characterize the vast majority of behavioral and affective markers of interest. This report is the first to date which systematically tests the efficacy of different sampling strategies for characterizing behavior from audio recordings to provide practical guidelines for researchers. Using continuous audio recordings of the daily lives of 11 preschoolaged children, we compared sampling techniques to determine the most accurate and efficient approach. Results suggest that sampling both low and high frequency verbal and overt behaviors is best if samples are short in duration, systematically rather than randomly selected, and sampled to cover at least 12.5\% of recordings. Implications for assessment of real-world behavior are discussed.},
  file = {/Users/megcychosz/Zotero/storage/BXASCEW9/Micheletti et al. - 2020 - Optimal sampling strategies for characterizing beh.pdf},
  journal = {Journal of Family Psychology},
  language = {en}
}

@article{middlebrooksCochlearImplantsView2005,
  title = {Cochlear Implants: The View from the Brain},
  shorttitle = {Cochlear Implants},
  author = {Middlebrooks, John C and Bierer, Julie Arenberg and Snyder, Russell L},
  year = {2005},
  month = aug,
  volume = {15},
  pages = {488--493},
  issn = {09594388},
  doi = {10.1016/j.conb.2005.06.004},
  file = {/Users/megcychosz/Zotero/storage/9URGBCHU/Middlebrooks et al. - 2005 - Cochlear implants the view from the brain.pdf},
  journal = {Current Opinion in Neurobiology},
  language = {en},
  number = {4}
}

@article{mielkeIndividuallevelContactLimits2016,
  title = {Individual-Level Contact Limits Phonological Complexity: {{Evidence}} from Bunched and Retroflex /{$\Elztrnr$}/},
  shorttitle = {Individual-Level Contact Limits Phonological Complexity},
  author = {Mielke, Jeff and Baker, Adam and Archangeli, Diana},
  year = {2016},
  volume = {92},
  pages = {101--140},
  issn = {1535-0665},
  doi = {10.1353/lan.2016.0019},
  file = {/Users/megcychosz/Zotero/storage/MSLZBTZ5/Mielke et al. - 2016 - Individual-level contact limits phonological compl.pdf},
  journal = {Language},
  language = {en},
  number = {1}
}

@article{millerEffectsLateroccurringInformation1979,
  title = {Some Effects of Later-Occurring Information on the Perception of Stop Consonant and Semivowel},
  author = {Miller, Joanne L. and Liberman, Alvin M.},
  year = {1979},
  month = nov,
  volume = {25},
  pages = {457--465},
  issn = {0031-5117, 1532-5962},
  doi = {10.3758/BF03213823},
  file = {/Users/megcychosz/Zotero/storage/3K3FP46A/Miller and Liberman - 1979 - Some effects of later-occurring information on the.pdf},
  journal = {Perception \& Psychophysics},
  language = {en},
  number = {6}
}

@article{millerEffectsVariableInput2010,
  title = {Effects of Variable Input in the Acquisition of Plural in Two Dialects of {{Spanish}}},
  author = {Miller, Karen and Schmitt, Cristina},
  year = {2010},
  pages = {16},
  abstract = {In Mexico City Spanish, plural morphology is always overtly realized but in Chilean Spanish, due to a lenition process that targets syllable-final [s], plural morphology is not always realized, and the conditions of overt realization of plural morphology are subject to both linguistic and extra-linguistic factors. In this paper we show that variability in the input for grammatical morphology causes the performance of Chilean and Mexican children to differ from each other and from the adult control groups in production and comprehension tasks in ways that correlate with the reliability of plural marking in the input. Our results support Yang (2002)'s proposal that variability in the input does cause some children to assume a different grammar from the adult.},
  file = {/Users/megcychosz/Zotero/storage/CGFGZ3FG/Miller and Schmitt - 2010 - Effects of variable input in the acquisition of pl.pdf},
  language = {en}
}

@article{mintzInfantsSensitivityVowel2018,
  title = {Infants' {{Sensitivity}} to {{Vowel Harmony}} and Its {{Role}} in {{Segmenting Speech}}},
  author = {Mintz, Toben H. and Walker, Rachel L. and Welday, Ashlee and Kidd, Celeste},
  year = {2018},
  month = feb,
  volume = {171},
  pages = {95--107},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2017.10.020},
  abstract = {A critical part of infants' ability to acquire any language involves segmenting continuous speech input into discrete word-forms. Certain properties of words could provide infants with reliable cues to word boundaries. Here we investigate the potential utility of vowel harmony (VH), a phonological property whereby vowels within a word systematically exhibit similarity (``harmony'') for some aspect of the way they are pronounced. We present evidence that infants with no experience of VH in their native language nevertheless actively use these patterns to generate hypotheses about where words begin and end in the speech stream. In two sets of experiments, we exposed infants learning English, a language without VH, to a continuous speech stream in which the only systematic patterns available to be used as cues to word boundaries came from syllable sequences that showed VH or those that showed vowel disharmony (dissimilarity). After hearing less than one minute of the streams, infants showed evidence of sensitivity to VH cues. These results suggest that infants have an experience-independent sensitivity to VH, and are predisposed to segment speech according to harmony patterns. We also found that when the VH patterns were more subtle (Experiment 2), infants required more exposure to the speech stream before they segmented based on VH, consistent with previous work on infants' preferences relating to processing load. Our findings evidence a previously unknown mechanism by which infants could discover the words of their language, and they shed light on the perceptual mechanisms that might be responsible for the emergence of vowel harmony as an organizing principle for the sound structure of words in many languages.},
  file = {/Users/megcychosz/Zotero/storage/NICH3XER/Mintz et al. - 2018 - Infants’ Sensitivity to Vowel Harmony and its Role.pdf},
  journal = {Cognition},
  pmcid = {PMC5818326},
  pmid = {29121588}
}

@book{mirmanGrowthCurveAnalysis2016,
  title = {Growth Curve Analysis and Visualization Using {{R}}},
  author = {Mirman, D.},
  year = {2016},
  publisher = {{CRC Press}},
  address = {{New York}}
}

@article{mithunAcquisitionPolysynthesis1989,
  title = {The Acquisition of Polysynthesis},
  author = {Mithun, Marianne},
  year = {1989},
  month = jun,
  volume = {16},
  pages = {285--312},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000900010424},
  abstract = {Polysynthetic languages can present special extraction puzzles to children, due to the length of their words. A number of hypotheses concerning children's strategies for acquiring morphology, originally proposed on the basis of their approaches to somewhat simpler systems, are confirmed by observations of five children acquiring Mohawk. Among the Mohawk children, the earliest segmentation of words was phonological rather than morphological: stressed syllables, usually penultimate or antepenultimate, were extracted first. Ultimate syllables were then added, confirming the salience of the ends of words. During this time, distinctions expressed by adults in affixes were either omitted or expressed analytically. Acquisition then moved leftward by syllables. When most utterances were long enough to include pronominal prefixes as well as roots, morphological structure was apparently discovered. It is not surprising that the pronouns should trigger this awareness, since they are frequent, appearing with every verb and most nouns, they are functional, and they are semantically transparent. From this point on, the children acquired affixes primarily according to their utility and semantic transparency rather than their phonological shape or position.},
  file = {/Users/megcychosz/Zotero/storage/96YWISHG/Mithun - 1989 - The acquisition of polysynthesis.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {2}
}

@article{miyamotoCochlearImplantationInfants2017,
  title = {Cochlear Implantation in Infants below 12 Months of Age},
  author = {Miyamoto, Richard T. and Colson, Bethany and Henning, Shirley and Pisoni, David},
  year = {2017},
  month = dec,
  volume = {3},
  pages = {214--218},
  issn = {20958811},
  doi = {10.1016/j.wjorl.2017.12.001},
  abstract = {Methods: With the wide application of newborn hearing screening programs, infants with deafness are being identified at birth. When a hearing aid trial fails, cochlear implantation is the only option to restore hearing. Mounting evidence suggests that age at implantation is a strong predictor of language outcomes. Using the minimally invasive surgical technique we have employed for nearly two decades, a limited clinical trial was initiated in the year 2000 because this age limitation fell outside of FDA guidelines. The infants were initially assessed using the preferential listening paradigm to confirm that they could learn associations between speech sounds and objects. Sufficient time was allowed to pass to administer more traditional language measures. Results: No surgical or anesthetic complications occurred in this group of infants. The pattern of listening skill development mirrored that seen in normal hearing infants. Long-term language assessments using the Peabody Picture Vocabulary Test (PPVT) and other measures have demonstrated that many of infants achieved age appropriate language skills. Conclusion: Cochlear implantation in children less than 12 months of age is safe and efficacious as demonstrated by long-term PPVT language data. Copyright \textordfeminine{} 2017 Chinese Medical Association. Production and hosting by Elsevier B.V. on behalf of KeAi Communications Co., Ltd. This is an open access article under the CC BY-NCND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).},
  file = {/Users/megcychosz/Zotero/storage/N56K46QL/Miyamoto et al. - 2017 - Cochlear implantation in infants below 12 months o.pdf},
  journal = {World Journal of Otorhinolaryngology - Head and Neck Surgery},
  language = {en},
  number = {4}
}

@article{mokSpeechPerceptionBenefit2010,
  title = {Speech {{Perception Benefit}} for {{Children}} with a {{Cochlear Implant}} and a {{Hearing Aid}} in {{Opposite Ears}} and {{Children}} with {{Bilateral Cochlear Implants}}},
  author = {Mok, Mansze and Galvin, Karyn L. and Dowell, Richard C. and McKay, Colette M.},
  year = {2010},
  volume = {15},
  pages = {44--56},
  issn = {1421-9700, 1420-3030},
  doi = {10.1159/000219487},
  file = {/Users/megcychosz/Zotero/storage/JJCVT5KU/Mok et al. - 2010 - Speech Perception Benefit for Children with a Coch.PDF},
  journal = {Audiology and Neurotology},
  language = {en},
  number = {1}
}

@article{mollicaHumansStoreMegabytes2019,
  title = {Humans Store about 1.5 Megabytes of Information during Language Acquisition},
  author = {Mollica, Francis and Piantadosi, Steven T.},
  year = {2019},
  month = mar,
  volume = {6},
  pages = {181393},
  issn = {2054-5703, 2054-5703},
  doi = {10.1098/rsos.181393},
  file = {/Users/megcychosz/Zotero/storage/TYFPCUME/Mollica and Piantadosi - 2019 - Humans store about 1.5 megabytes of information du.pdf},
  journal = {Royal Society Open Science},
  language = {en},
  number = {3}
}

@article{montagSpeechIntelligibilityDeaf2014,
  title = {Speech {{Intelligibility}} in {{Deaf Children After Long}}-{{Term Cochlear Implant Use}}},
  author = {Montag, Jessica L. and AuBuchon, Angela M. and Pisoni, David B. and Kronenberger, William G.},
  year = {2014},
  month = dec,
  volume = {57},
  pages = {2332--2343},
  issn = {1092-4388},
  doi = {10.1044/2014_JSLHR-H-14-0190},
  abstract = {Purpose This study investigated long-term speech intelligibility outcomes in 63 prelingually deaf children, adolescents, and young adults who received cochlear implants (CIs) before age 7 (M = 2;11 [years;months], range = 0;8\textendash 6;3) and used their implants for at least 7 years (M = 12;1, range = 7;0\textendash 22;5). Method Speech intelligibility was assessed using playback methods with na\"ive, normal-hearing listeners. Results Mean intelligibility scores were lower than scores obtained from an age- and nonverbal IQ\textendash matched, normal-hearing control sample, although the majority of CI users scored within the range of the control sample. Our sample allowed us to investigate the contribution of several demographic and cognitive factors to speech intelligibility. CI users who used their implant for longer periods of time exhibited poorer speech intelligibility scores. Crucially, results from a hierarchical regression model suggested that this difference was due to more conservative candidacy criteria in CI users with more years of use. No other demographic variables accounted for significant variance in speech intelligibility scores beyond age of implantation and amount of spoken language experience (assessed by communication mode and family income measures). Conclusion Many factors that have been found to contribute to individual differences in language outcomes in normal-hearing children also contribute to long-term CI users' ability to produce intelligible speech.},
  file = {/Users/megcychosz/Zotero/storage/DSBPANZX/Montag et al. - 2014 - Speech Intelligibility in Deaf Children After Long.pdf},
  journal = {Journal of speech, language, and hearing research : JSLHR},
  number = {6},
  pmcid = {PMC4419697},
  pmid = {25260109}
}

@article{mooshammerInterarticulatorCohesionCoronal2006,
  title = {Interarticulator Cohesion within Coronal Consonant Production},
  author = {Mooshammer, Christine and Hoole, Philip and Geumann, Anja},
  year = {2006},
  volume = {120},
  pages = {1028--1039},
  issn = {0001-4966},
  doi = {10.1121/1.2208430},
  file = {/Users/megcychosz/Zotero/storage/29HUR9LA/Mooshammer et al. - 2006 - Interarticulator cohesion within coronal consonant.pdf},
  journal = {Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@article{moranRevisitingPopulationSize2012,
  title = {Revisiting Population Size vs. Phoneme Inventory Size},
  author = {Moran, Steven and McCloy, Daniel and Wright, Richard},
  year = {2012},
  volume = {88},
  pages = {877--893},
  publisher = {{Linguistic Society of America}},
  issn = {0097-8507},
  abstract = {In this discussion note we argue against the findings presented in Hay \& Bauer 2007, which show a positive correlation between population size and phoneme inventory size. We argue that the positive correlation is an artifact of the authors' statistical technique and biased data set. Using a hierarchical mixed model to account for genealogical relatedness of languages, and a much larger and more diverse sample of the world's languages, we find little support for population size as an explanatory predictor of phoneme inventory size once the genealogical relatedness of languages is accounted for.*},
  file = {/Users/megcychosz/Zotero/storage/EI3NTCYK/Moran et al. - 2012 - Revisiting population size vs. phoneme inventory s.pdf},
  journal = {Language},
  number = {4}
}

@article{morelliBringingRealWorld2018,
  title = {Bringing the {{Real World Into Developmental Science}}: {{A Commentary}} on {{Weber}}, {{Fernald}}, and {{Diop}} (2017)},
  shorttitle = {Bringing the {{Real World Into Developmental Science}}},
  author = {Morelli, Gilda and Bard, Kim and Chaudhary, Nandita and Gottlieb, Alma and Keller, Heidi and Murray, Marjorie and Quinn, Naomi and {Rosabal-Coto}, Mariano and Scheidecker, Gabriel and Takada, Akira and Vicedo, Marga},
  year = {2018},
  month = nov,
  volume = {89},
  pages = {e594-e603},
  issn = {00093920},
  doi = {10.1111/cdev.13115},
  file = {/Users/megcychosz/Zotero/storage/ERJJEGQ5/Morelli et al. - 2018 - Bringing the Real World Into Developmental Science.pdf},
  journal = {Child Development},
  language = {en},
  number = {6}
}

@article{moriniAdvancesPediatricHearing2017,
  title = {Advances in Pediatric Hearing Loss: {{A}} Road to Better Language Outcomes.},
  shorttitle = {Advances in Pediatric Hearing Loss},
  author = {Morini, Giovanna and Golinkoff, Roberta Michnick and Morlet, Thierry and Houston, Derek M.},
  year = {2017},
  month = mar,
  volume = {3},
  pages = {80--93},
  issn = {2332-2179, 2332-2136},
  doi = {10.1037/tps0000106},
  abstract = {This article outlines how methods from developmental psychology that probe how typical infants discriminate aspects of speech can be used to evaluate children with various degrees of hearing loss. This approach has the potential to improve intervention practices and language outcomes in children with hearing loss.},
  file = {/Users/megcychosz/Zotero/storage/E43CUZS7/Morini et al. - 2017 - Advances in pediatric hearing loss A road to bett.pdf},
  journal = {Translational Issues in Psychological Science},
  language = {en},
  number = {1}
}

@article{moriniDondeEstaBall2019,
  title = {D\'onde Est\'a La Ball? {{Examining}} the Effect of Code Switching on Bilingual Children's Word Recognition},
  shorttitle = {D\'onde Est\'a La Ball?},
  author = {Morini, Giovanna and Newman, Rochelle S.},
  year = {2019},
  month = nov,
  volume = {46},
  pages = {1238--1248},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000919000400},
  abstract = {Hearing words in sentences facilitates word recognition in monolingual children. Many children grow up receiving input in multiple languages \textendash{} including exposure to sentences that `mix' the languages. We explored Spanish\textendash English bilingual toddlers' (n = 24) ability to identify familiar words in three conditions: (i) SINGLE WORD (ball!); (ii) SAME-LANGUAGE SENTENCE (Where's the ball?); or (iii) MIXED-LANGUAGE SENTENCE (D\'onde est\'a la ball?). Children successfully identified words across conditions; however, the advantage linked to hearing words in sentences was present only in the same-language condition. This work hence suggests that language mixing plays an important role on bilingual children's ability to recognize spoken words.},
  file = {/Users/megcychosz/Zotero/storage/6KRLDGR6/Morini and Newman - 2019 - Dónde está la ball Examining the effect of code s.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {6}
}

@article{morrisonAgeAcquisitionNorms1997,
  title = {Age of {{Acquisition Norms}} for a {{Large Set}} of {{Object Names}} and {{Their Relation}} to {{Adult Estimates}} and {{Other Variables}}},
  author = {Morrison, Catriona M. and Chappell, Tameron D. and Ellis, Andrew W.},
  year = {1997},
  month = aug,
  volume = {50},
  pages = {528--559},
  issn = {0272-4987, 1464-0740},
  doi = {10.1080/027249897392017},
  file = {/Users/megcychosz/Zotero/storage/EWXYUUAG/Morrison et al. - 1997 - Age of Acquisition Norms for a Large Set of Object.pdf},
  journal = {The Quarterly Journal of Experimental Psychology Section A},
  language = {en},
  number = {3}
}

@article{morrisonAgeAcquisitionNot1992,
  title = {Age of Acquisition, Not Word Frequency, Affects Object Naming, Not Object Recognition},
  author = {Morrison, Catriona M. and Ellis, Andrew W. and Quinlan, Philip T.},
  year = {1992},
  month = nov,
  volume = {20},
  pages = {705--714},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03202720},
  file = {/Users/megcychosz/Zotero/storage/G39PEQWU/Morrison et al. - 1992 - Age of acquisition, not word frequency, affects ob.pdf},
  journal = {Memory \& Cognition},
  language = {en},
  number = {6}
}

@article{moulin-frierCOSMOCommunicatingObjects2015,
  title = {{{COSMO}} (``{{Communicating}} about {{Objects}} Using {{Sensory}}\textendash{{Motor Operations}}''): {{A Bayesian}} Modeling Framework for Studying Speech Communication and the Emergence of Phonological Systems},
  shorttitle = {{{COSMO}} (``{{Communicating}} about {{Objects}} Using {{Sensory}}\textendash{{Motor Operations}}'')},
  author = {{Moulin-Frier}, Cl{\'e}ment and Diard, Julien and Schwartz, Jean-Luc and Bessi{\`e}re, Pierre},
  year = {2015},
  month = nov,
  volume = {53},
  pages = {5--41},
  issn = {00954470},
  doi = {10.1016/j.wocn.2015.06.001},
  abstract = {While the origin of language remains a somewhat mysterious process, understanding how human language takes specific forms appears to be accessible by the experimental method. Languages, despite their wide variety, display obvious regularities. In this paper, we attempt to derive some properties of phonological systems (the sound systems for human languages) from speech communication principles. We introduce a model of the cognitive architecture of a communicating agent, called COSMO (for ``Communicating about Objects using Sensory\textendash Motor Operations') that allows a probabilistic expression of the main theoretical trends found in the speech production and perception literature. This enables a computational comparison of these theoretical trends, which helps us to identify the conditions that favor the emergence of linguistic codes. We present realistic simulations of phonological system emergence showing that COSMO is able to predict the main regularities in vowel, stop consonant and syllable systems in human languages.},
  file = {/Users/megcychosz/Zotero/storage/BIAENVSX/Moulin-Frier et al. - 2015 - COSMO (“Communicating about Objects using Sensory–.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{moulin-frierSelforganizationEarlyVocal2014,
  title = {Self-Organization of Early Vocal Development in Infants and Machines: The Role of Intrinsic Motivation},
  shorttitle = {Self-Organization of Early Vocal Development in Infants and Machines},
  author = {{Moulin-Frier}, Cl{\'e}ment and Nguyen, Sao M. and Oudeyer, Pierre-Yves},
  year = {2014},
  volume = {4},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2013.01006},
  abstract = {We bridge the gap between two issues in infant development: vocal development and intrinsic motivation. We propose and experimentally test the hypothesis that general mechanisms of intrinsically motivated spontaneous exploration, also called curiosity-driven learning, can self-organize developmental stages during early vocal learning. We introduce a computational model of intrinsically motivated vocal exploration, which allows the learner to autonomously structure its own vocal experiments, and thus its own learning schedule, through a drive to maximize competence progress. This model relies on a physical model of the vocal tract, the auditory system and the agent's motor control as well as vocalizations of social peers. We present computational experiments that show how such a mechanism can explain the adaptive transition from vocal self-exploration with little influence from the speech environment, to a later stage where vocal exploration becomes influenced by vocalizations of peers. Within the initial self-exploration phase, we show that a sequence of vocal production stages self-organizes, and shares properties with data from infant developmental psychology: the vocal learner first discovers how to control phonation, then focuses on vocal variations of unarticulated sounds, and finally automatically discovers and focuses on babbling with articulated proto-syllables. As the vocal learner becomes more proficient at producing complex sounds, imitating vocalizations of peers starts to provide high learning progress explaining an automatic shift from self-exploration to vocal imitation.},
  file = {/Users/megcychosz/Zotero/storage/W3BC6X6U/Moulin-Frier et al. - 2014 - Self-organization of early vocal development in in.pdf},
  journal = {Frontiers in Psychology},
  language = {en}
}

@inproceedings{mousikouMorphologicalEffectsPronunciation2015,
  title = {Morphological Effects on Pronunciation},
  booktitle = {Proceedings of the 18th {{ICPhS}}},
  author = {Mousikou, Petroula and Strycharczuk, Patrycja and Turk, Alice and Rastle, Kathleen and Scobbie, James M},
  year = {2015},
  address = {{Glasgow, Scotland}},
  abstract = {Converging, albeit inconsistent, empirical evidence suggests that the morphological structure of a word influences its pronunciation. We investigated this issue using Ultrasound Tongue Imaging in the context of an experimental cognitive psychology paradigm. Scottish speakers were trained on apparently homophonous monomorphemic and bimorphemic novel words (e.g. zord, zorred), and tested on speech production tasks. Monomorphemic items were realised acoustically with shorter durations than bimorphemic items; however, this difference was not statistically significant. Progressive coarticulatory effects were also observed in the monomorphemic condition for some speakers. A dynamic analysis of the articulatory data revealed that the observed differences in the pronunciations of the two types of items could be due to factors other than morphological structure. Our results, albeit inconclusive, make a significant contribution to the literature in this research domain insofar as the presence or absence of morphological effects on pronunciation has important implications for extant theories of speech production.},
  file = {/Users/megcychosz/Zotero/storage/K8764UHB/Mousikou et al. - MORPHOLOGICAL EFFECTS ON PRONUNCIATION.pdf},
  language = {en}
}

@article{munafoManifestoReproducibleScience2017,
  title = {A Manifesto for Reproducible Science},
  author = {Munaf{\`o}, Marcus R. and Nosek, Brian A. and Bishop, Dorothy V. M. and Button, Katherine S. and Chambers, Christopher D. and {Percie du Sert}, Nathalie and Simonsohn, Uri and Wagenmakers, Eric-Jan and Ware, Jennifer J. and Ioannidis, John P. A.},
  year = {2017},
  month = jan,
  volume = {1},
  pages = {0021},
  issn = {2397-3374},
  doi = {10.1038/s41562-016-0021},
  file = {/Users/megcychosz/Zotero/storage/SWWMZ28I/Munafò et al. - 2017 - A manifesto for reproducible science.pdf},
  journal = {Nature Human Behaviour},
  language = {en},
  number = {1}
}

@article{munhallCompensatoryShorteningMonosyllables1992,
  title = {``{{Compensatory}} Shortening'' in Monosyllables of Spoken {{English}}},
  author = {Munhall, Kevin and Fowler, Carol and Hawkins, Sarah and Saltzman, Elliot},
  year = {1992},
  month = apr,
  volume = {20},
  pages = {225--239},
  issn = {00954470},
  doi = {10.1016/S0095-4470(19)30624-2},
  file = {/Users/megcychosz/Zotero/storage/3QL37MGT/Munhall et al. - 1992 - “Compensatory shortening” in monosyllables of spok.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {2}
}

@article{munsonDeconstructingPhoneticTranscription2010,
  title = {Deconstructing {{Phonetic Transcription}}: {{Covert Contrast}}, {{Perceptual Bias}}, and an {{Extraterrestrial View}} of {{Vox Humana}}},
  shorttitle = {Deconstructing {{Phonetic Transcription}}},
  author = {Munson, Benjamin and Edwards, Jan and Schellinger, Sarah and Beckman, Mary E. and Meyer, Marie K.},
  year = {2010},
  month = jan,
  volume = {24},
  pages = {245--260},
  issn = {0269-9206},
  doi = {10.3109/02699200903532524},
  abstract = {This article honours Adele Miccio's life work by reflecting on the utility of phonetic transcription. The first section reviews the literature on cases where children whose speech appears to neutralize a contrast in the adult language are found on closer examination to produce a contrast (covert contrast). We present evidence from a new series of perception studies that covert contrast may be far more prevalent in children's speech than existing studies would suggest. The second section presents the results of a new study designed to examine whether na\"ive listeners' perception of children's /s/ and /\texttheta/ productions can be changed experimentally when they are led to believe that the children who produced the sounds were older or younger. Here, it is shown that, under the right circumstances, adults report more tokens of /\texttheta/ to be accurate productions of /s/ when they believe a talker to be an older child than when they believe the talker to be younger. This finding suggests that auditory information alone cannot be the sole basis for judging the accuracy of a sound. The final section presents recommendations for supplementing phonetic transcription with other measures, to gain a fuller picture of children's production abilities.},
  file = {/Users/megcychosz/Zotero/storage/EE54T344/Munson et al. - 2010 - Deconstructing Phonetic Transcription Covert Cont.pdf},
  journal = {Clinical linguistics \& phonetics},
  number = {4-5},
  pmcid = {PMC2941432},
  pmid = {20345255}
}

@article{munsonEffectPhonologicalNeighborhood2004,
  title = {The {{Effect}} of {{Phonological Neighborhood Density}} on {{Vowel Articulation}}},
  author = {Munson, Benjamin and Solomon, Nancy Pearl},
  year = {2004},
  month = oct,
  volume = {47},
  pages = {1048--1058},
  issn = {1092-4388},
  abstract = {Recent literature suggests that phonological neighborhood density and word frequency can affect speech production, in addition to the well-documented effects that they have on speech perception. This article describes 2 experiments that examined how phonological neighborhood density influences the durations and formant frequencies of adults' productions of vowels in real words. In Experiment 1, 10 normal speakers produced words that covaried in phonological neighborhood density and word frequency. Infrequent words with many phonological neighbors were produced with shorter durations and more expanded vowel spaces than frequent words with few phonological neighbors. Results of this experiment confirmed that this effect was not related to the duration of the vowels constituting the high- and low-density words. In Experiment 2, 15 adults produced words that varied in both word frequency and neighborhood density. Neighborhood density affected vowel articulation in both high- and low-frequency words. Moreover, frequent words were produced with more contracted vowel spaces than infrequent words. There was no interaction between these factors, and the vowel duration did not vary as a function of neighborhood density. Taken together, the results suggest that neighborhood density affects vowel production independent of word frequency and vowel duration.},
  file = {/Users/megcychosz/Zotero/storage/GNHU67ZP/Munson and Solomon - 2004 - The Effect of Phonological Neighborhood Density on.pdf},
  journal = {Journal of speech, language, and hearing research : JSLHR},
  number = {5},
  pmcid = {PMC4336539},
  pmid = {15605431}
}

@article{munsonGenderTypicalityChildren2015,
  title = {Gender Typicality in Children's Speech: {{A}} Comparison of Boys with and without Gender Identity Disorder},
  shorttitle = {Gender Typicality in Children's Speech},
  author = {Munson, Benjamin and Crocker, Laura and Pierrehumbert, Janet B. and {Owen-Anderson}, Allison and Zucker, Kenneth J.},
  year = {2015},
  month = apr,
  volume = {137},
  pages = {1995--2003},
  issn = {0001-4966},
  doi = {10.1121/1.4916202},
  file = {/Users/megcychosz/Zotero/storage/M9XJFUAU/Munson et al. - 2015 - Gender typicality in children's speech A comparis.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@article{munsonPhonologicalPatternFrequency2001,
  title = {Phonological {{Pattern Frequency}} and {{Speech Production}} in {{Adults}} and {{Children}}},
  author = {Munson, Benjamin},
  year = {2001},
  month = aug,
  volume = {44},
  pages = {778--792},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2001/061)},
  abstract = {The Ohio State University Columbus Recent studies have suggested that both adults and children are sensitive to information about phonological pattern frequency; however, the influence of phonological pattern frequency on speech production has not been studied extensively. The current study examined the effect of phonological pattern frequency on the fluency and flexibility of speech production. Normal- and fastrate nonsense-word repetitions of three groups of participants (preschool children, school-aged children, and adults) were analyzed. Subjective ratings of the wordlikeness of nonsense words, percentage phonemes correctly repeated, mean duration, and durational variability were measured. In the first experiment, ratings of the wordlikeness of nonsense words were found to correlate with the pattern frequency of sequences embedded in them. In the second analysis, it was found that children, but not adults, repeated infrequent sequences of phonemes less accurately than frequent sequences. In the third experiment, infrequent sequences were produced with longer durations than frequent ones, with children demonstrating a larger difference between frequent and infrequent sequences than adults. Phonological pattern frequency also influenced variability in duration: infrequent sequences of sounds were more variable than frequent ones. Thus, there appears to be an influence of phonological pattern frequency on speech, and, for some measures, a larger effect size is noted for children.},
  file = {/Users/megcychosz/Zotero/storage/327W6JDU/Munson - 2001 - Phonological Pattern Frequency and Speech Producti.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {4}
}

@incollection{munsonPhonologicalRepresentationsLanguage2011,
  title = {Phonological {{Representations}} in {{Language Acquisition}}: {{Climbing The Ladder}} of {{Abstraction}}},
  booktitle = {Handbook of {{Laboratory Phonology}}},
  author = {Munson, Benjamin and Edwards, Jan and Beckman, Mary E.},
  year = {2011},
  month = dec,
  pages = {288--309},
  publisher = {{Oxford University Press}},
  doi = {10.1093/oxfordhb/9780199575039.013.0012},
  file = {/Users/megcychosz/Zotero/storage/6URNG54Y/Munson et al. - 2011 - Phonological Representationsin Language Acquisitio.pdf},
  language = {en}
}

@article{munsonRelationshipsNonwordRepetition2005,
  title = {Relationships {{Between Nonword Repetition Accuracy}} and {{Other Measures}} of {{Linguistic Development}} in {{Children With Phonological Disorders}}},
  author = {Munson, Benjamin and Edwards, Jan and Beckman, Mary E.},
  year = {2005},
  month = feb,
  volume = {48},
  pages = {61--78},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2005/006)},
  abstract = {Ohio State University, Columbus A growing body of research has documented effects of phonotactic probability on young children's nonword repetition. This study extends this research in 2 ways. First, it compares nonword repetitions by 40 young children with phonological disorders with those by 40 same-age peers with typical phonological development on a nonword repetition task in which the frequency of embedded diphone sequences was varied. Second, it examines the relationship between the frequency effect in the nonword repetition task and other measures of linguistic ability in these children. Children in both groups repeated low-frequency sequences less accurately than high-frequency sequences. The children with phonological disorders were less accurate overall but showed no larger disadvantage for the low-frequency sequences than their age peers. Across the group, the size of the frequency effect was correlated with vocabulary size, but it was independent of measures of speech perception and articulatory ability. These results support the hypothesis that the production difficulty associated with lowfrequency sequences is related primarily to vocabulary growth rather than to developments in articulatory or perceptual ability. By contrast, production problems experienced by children with phonological disorders do not appear to result from difficulties in making abstractions over known lexical items. Instead, they may be associated with difficulties in building representations in the primary sensory and motor domains.},
  file = {/Users/megcychosz/Zotero/storage/YHAJH3T6/Munson et al. - 2005 - Relationships Between Nonword Repetition Accuracy .pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {1}
}

@article{munsonVariabilityProductionChildren2004,
  title = {Variability in /s/ {{Production}} in {{Children}} and {{Adults}}: {{Evidence From Dynamic Measures}} of {{Spectral Mean}}},
  author = {Munson, Benjamin},
  year = {2004},
  volume = {47},
  pages = {58--69},
  abstract = {University of Minnesota, Minneapolis Previous research has found developmental decreases in temporal variability in speech. Relatively less work has examined spectral variability, and, in particular, variability in consonant spectra. This article examined variability in productions of the consonant /s/ by adults and by 3 groups of children, with mean ages of 3;11 (years;months), 5;04, and 8;04. Specifically, it measured the influence of age, phonetic context, and syllabic context on variability. Spectral variability was estimated by measuring dynamic spectral characteristics of multiple productions of /s/ in sV, spV, and swV sequences, where the vowel was either /a/ or /u/. Mean duration, variability in duration, and coarticulation were also measured. Children were found to produce /s/ with greater temporal and spectral variability than adults. Duration and coarticulation were comparable across the 4 age groups. Spectral variability was greater in swV contexts than in sV or spV sequences. The lack of consistent effects of phonetic context on spectral variability suggests that the developmental differences were related to subtle variability in place of articulation for /s/ in the children's productions.},
  file = {/Users/megcychosz/Zotero/storage/YL6EDHDB/Munson - Variability in s Production in Children and Adul.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en}
}

@article{muyskenApproachesAffixOrder1986,
  title = {Approaches to Affix Order},
  author = {Muysken, Pieter},
  year = {1986},
  volume = {24},
  issn = {0024-3949, 1613-396X},
  doi = {10.1515/ling.1986.24.3.629},
  abstract = {This article is an attempt to survey a number o f recent approaches to affix order, compare the scope o f their empirical predictions, and illustrate them with data from Quechua suffixation. One approach in particular, in terms o f a matrix o f fix e d slots, is criticized on both empirical and theoretical grounds, and various alternatives to this approach are tentatively explored.},
  file = {/Users/megcychosz/Zotero/storage/ZIGSZLGI/Muysken - 1986 - Approaches to affix order.pdf},
  journal = {Linguistics},
  language = {en},
  number = {3}
}

@incollection{muyskenContactsIndigenousLanguages2012,
  title = {Contacts between Indigenous Languages in {{South America}}},
  booktitle = {The Indigenous Languages of {{South America}}: {{A}} Comprehensive Guide},
  author = {Muysken, P.},
  editor = {Campbell, Lyle and Grondona, V.},
  year = {2012},
  pages = {235--258},
  publisher = {{Walter de Gruyter}},
  address = {{Berlin, Germany}}
}

@article{muyskenMultilingualismMixedLanguage2019,
  title = {Multilingualism and Mixed Language in the Mines of {{Potos\'i}} ({{Bolivia}})},
  author = {Muysken, Pieter},
  year = {2019},
  month = jul,
  volume = {2019},
  pages = {121--142},
  publisher = {{De Gruyter}},
  issn = {1613-3668},
  doi = {10.1515/ijsl-2019-2031},
  abstract = {Using the methodology of historical sociolinguistics, this article explores multilingualism and language contact in the mines of Potos\'i (Bolivia) in the colonial period. Potos\'i was the destination of massive migration during its economic heydays around 1610 and one of the largest cities in the Western hemisphere at the time. In the mines special codes were developed, with a specialized lexicon that contains words from different languages. This lexicon was so different that the first vocabulary of the mining language was written in 1610, and many have followed from that date onward. Quechua most probably played a key role as intermediary language between two forms of speaking: the indigenous mining language of the free workers, yanaconas and mingas , probably a mix of Spanish and Quechua, and the language of the forced workers, mitayos , possibly a mix of Aymara and Quechua. The similarities between Aymara and Quechua must have contributed to this possibility of an intermediary language.},
  chapter = {International Journal of the Sociology of Language},
  file = {/Users/megcychosz/Zotero/storage/YPRYIYRH/Muysken - 2019 - Multilingualism and mixed language in the mines of.pdf;/Users/megcychosz/Zotero/storage/PN23IE32/html.html},
  journal = {International Journal of the Sociology of Language},
  language = {en},
  number = {258}
}

@article{muyskenSpanishAffixesQuechua2012,
  title = {Spanish Affixes in the {{Quechua}} Languages: {{A}} Multidimensional Perspective},
  author = {Muysken, P.},
  year = {2012},
  volume = {122},
  pages = {481--493},
  journal = {Lingua},
  number = {5}
}

@article{nairUnderstandingBilingualWord2017,
  title = {Understanding {{Bilingual Word Learning}}: {{The Role}} of {{Phonotactic Probability}} and {{Phonological Neighborhood Density}}},
  shorttitle = {Understanding {{Bilingual Word Learning}}},
  author = {Nair, Vishnu KK and Biedermann, Britta and Nickels, Lyndsey},
  year = {2017},
  month = dec,
  volume = {60},
  pages = {3551--3560},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2017_JSLHR-L-15-0376},
  abstract = {Purpose: Previous research has shown that the language learning mechanism is affected by bilingualism resulting in a novel word learning advantage for bilingual speakers. However, less is known about the factors that might influence this advantage. This paper reports an investigation of two factors: phonotactic probability and phonological neighborhood density. Method: Acquisition of fifteen novel words varying in phonotactic probability and phonological neighborhood density was examined in high proficiency, early onset, MandarinEnglish bilinguals and English monolinguals. Results: Both bilinguals and monolinguals demonstrated a significant effect of phonotactic probability and phonological neighborhood density. Novel word learning improved when the phonological neighborhood density was higher, in contrast, higher phonotactic probability resulted in worse learning. Although, the bilingual speakers showed significantly better novel word learning than monolingual speakers, this did not interact with phonotactic probability and phonological neighbourhood density manipulations. Conclusion: Both bilingual and monolingual word learning abilities are constrained by the same learning mechanisms. However, bilingual advantages may be underpinned by more effective allocation of cognitive resources due to their dual language experience.},
  file = {/Users/megcychosz/Zotero/storage/W45TA4JI/Nair et al. - 2017 - Understanding Bilingual Word Learning The Role of.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {12}
}

@article{nakaiVOTCategoryBoundary2016,
  title = {The {{VOT Category Boundary}} in {{Word}}-{{Initial Stops}}: {{Counter}}-{{Evidence Against Rate Normalization}} in {{English Spontaneous Speech}}},
  shorttitle = {The {{VOT Category Boundary}} in {{Word}}-{{Initial Stops}}},
  author = {Nakai, Satsuki and Scobbie, James M.},
  year = {2016},
  month = oct,
  volume = {7},
  pages = {13},
  issn = {1868-6354},
  doi = {10.5334/labphon.49},
  file = {/Users/megcychosz/Zotero/storage/X5RDHFP3/Nakai and Scobbie - 2016 - The VOT Category Boundary in Word-Initial Stops C.pdf},
  journal = {Laboratory Phonology},
  language = {en},
  number = {1}
}

@article{nakamuraDifferencesAcousticCharacteristics2008,
  title = {Differences between Acoustic Characteristics of Spontaneous and Read Speech and Their Effects on Speech Recognition Performance},
  author = {Nakamura, Masanobu and Iwano, Koji and Furui, Sadaoki},
  year = {2008},
  month = apr,
  volume = {22},
  pages = {171--184},
  issn = {08852308},
  doi = {10.1016/j.csl.2007.07.003},
  abstract = {Although speech derived from read texts, news broadcasts, and other similar prepared contexts can be recognized with high accuracy, recognition performance drastically decreases for spontaneous speech. This is due to the fact that spontaneous speech and read speech are significantly different acoustically as well as linguistically. This paper statistically and quantitatively analyzes differences in acoustic features between spontaneous and read speech using two large-scale speech corpora, ``Corpus of Spontaneous Japanese (CSJ)'' and ``Japanese Newspaper Article Sentences (JNAS)''. Experimental results show that spontaneous speech can be characterized by reduced spectral space in comparison with that of read speech, and that the more spontaneous, the more the spectral space shrinks. This paper also clarifies that reduction in the spectral space leads to reduction in phoneme recognition accuracy. This result indicates that spectral reduction is one major reason for the decrease of recognition accuracy in spontaneous speech.},
  file = {/Users/megcychosz/Zotero/storage/FYD2B4RA/Nakamura et al. - 2008 - Differences between acoustic characteristics of sp.pdf},
  journal = {Computer Speech \& Language},
  language = {en},
  number = {2}
}

@article{nathaniRobustnessVocalDevelopment2007,
  title = {On the {{Robustness}} of {{Vocal Development}}: {{An Examination}} of {{Infants With Moderate}}-to-{{Severe Hearing Loss}} and {{Additional Risk Factors}}},
  shorttitle = {On the {{Robustness}} of {{Vocal Development}}},
  author = {Nathani, Suneeti and Oller, D. Kimbrough and Neal, A. Rebecca},
  year = {2007},
  volume = {50},
  pages = {1425--1444},
  doi = {10.1044/1092-4388(2007/099)},
  abstract = {Onset of canonical babbling by 10 months of age is surprisingly robust in infancy, suggesting that there must be deep biological forces that keep the development of this key vocal capability on course. This study further evaluated the robustness of canonical babbling and other aspects of prelinguistic vocal development. Longitudinal observation was conducted on 4 infants who were at risk for abnormal vocal development because of bilateral moderate-to-severe sensorineural hearing loss and additional risk factors for developmental delay. Two of the infants were delayed in the onset of canonical babbling and showed greater fluctuation in canonical babbling ratios following its onset than did typically developing infants. On the same measures, the remaining 2 infants were within normal limits, although their age of onset for canonical babbling was later than the mean for typically developing infants. Volubility was not notably different from typically developing infants. Differences from typically developing infants were, however, observed in proportions of various prelinguistic syllable types produced across time. Results provided further evidence of robustness of canonical babbling and indicated the need for a large parametric study evaluating effects of varying degrees of hearing loss and other risk factors on vocal development.},
  journal = {Journal of Speech Language and Hearing Research}
}

@book{neareyPhoneticFeatureSystems1977,
  title = {Phonetic {{Feature Systems}} for {{Vowels}}},
  author = {Nearey, T.},
  year = {1977},
  address = {{University of Alberta}},
  series = {Unpublished Doctoral Dissertation}
}

@article{nelsonHowProsodicCues1989,
  title = {How the Prosodic Cues in Motherese Might Assist Language Learning},
  author = {Nelson, Deborah G Kemler and {Hirsh-Pasek}, Kathy and Jusczyk, Peter W and Cassidy, Kimberly Wright},
  year = {1989},
  volume = {16},
  pages = {55--68},
  file = {/Users/megcychosz/Zotero/storage/7L4536EA/Nelson et al. - How the prosodic cues in motherese might assist la.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {1}
}

@article{newmanChangesPreferenceInfantDirected2006,
  title = {Changes in {{Preference}} for {{Infant}}-{{Directed Speech}} in {{Low}} and {{Moderate Noise}} by 4.5- to 13-{{Month}}-{{Olds}}},
  author = {Newman, Rochelle S. and Hussain, Isma},
  year = {2006},
  volume = {10},
  pages = {61--76},
  issn = {1532-7078},
  doi = {10.1207/s15327078in1001_4},
  abstract = {Although a large literature discusses infants' preference for infant-directed speech (IDS), few studies have examined how this preference might change over time or across listening situations. The work reported here compares infants' preference for IDS while listening in a quiet versus a noisy environment, and across 3 points in development: 4.5 months of age, 9 months of age, and 13 months of age. Several studies have suggested that IDS might help infants to pick out speech in the context of noise (Colombo, Frick, Ryther, Coldren, \& Mitchell, 1995; Fernald, 1984; Newman, 2003); this might suggest that infants' preference for IDS would increase in these settings. However, this was not found to be the case; at all 3 ages, infants showed similar advantage (or lack thereof) for IDS as compared to adult-directed speech when presented in noise versus silence. There was, however, a significant interaction across ages: Infants aged 4.5 months showed an overall preference for IDS, whereas older infants did not, despite listening to the same stimuli. The lack of an effect with older infants replicates and extends recent findings by Hayashi, Tamekawa, and Kiritani (2001), suggesting that the variations in fundamental frequency and affect are not sufficient cues to IDS for older infants.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15327078in1001\_4},
  file = {/Users/megcychosz/Zotero/storage/UE6EWEDI/Newman and Hussain - 2006 - Changes in Preference for Infant-Directed Speech i.pdf;/Users/megcychosz/Zotero/storage/ST4CPV86/s15327078in1001_4.html},
  journal = {Infancy},
  language = {en},
  number = {1}
}

@article{newmanEffectsLexicalFactors2002,
  title = {Effects of {{Lexical Factors}} on {{Lexical Access}} among {{Typical Language}}-{{Learning Children}} and {{Children}} with {{Word}}-{{Finding Difficulties}}},
  author = {Newman, Rochelle S. and German, Diane J.},
  year = {2002},
  month = sep,
  volume = {45},
  pages = {285--317},
  publisher = {{SAGE Publications Ltd}},
  issn = {0023-8309},
  doi = {10.1177/00238309020450030401},
  abstract = {This investigation studied the influence of lexical factors, known to impact lexical access in adults, on the word retrieval of children. Participants included 320 typicaland atypical(word-finding difficulties) language-learning children, ranging in age from 7 to 12 years. Lexical factors examined included word frequency, age-of-acquisition, neighborhood density, neighborhood frequency, and stress pattern. Findings indicated that these factors did influence lexical access in children. Words which were high in frequency and neighborhood frequency, lowin neighborhood density and age-of-acquisition, and which contained the typical stress pattern for the language were easier to name. Further, the number of neighbors that were more frequent than the target word also had an effect on the word's ease of retrieval. Significant interactions indicated that age-of-acquisition effects decreased with maturation for typically-learning children whereas these effects continued to impact the lexical access of children with word-finding difficulties across the ages studied, suggesting that these children's difficulties in accessing words may have prevented them from developing strong access paths to these words. These findings support a view of lexical access in which access paths to words become strengthened with successful use.},
  file = {/Users/megcychosz/Zotero/storage/JWC3PBAL/Newman and German - 2002 - Effects of Lexical Factors on Lexical Access among.pdf},
  journal = {Language and Speech},
  number = {3}
}

@article{newmanForeignAccentToddlers2018,
  title = {Foreign {{Accent}} and {{Toddlers}}' {{Word Learning}}: {{The Effect}} of {{Phonological Contrast}}},
  shorttitle = {Foreign {{Accent}} and {{Toddlers}}' {{Word Learning}}},
  author = {Newman, Rochelle S. and Morini, Giovanna and Kozlovsky, Penina and Panza, Sabrina},
  year = {2018},
  month = apr,
  volume = {14},
  pages = {97--112},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2017.1412831},
  abstract = {Prior work demonstrated that toddlers can learn words from a speaker with a foreign accent and generalize that learning to the native accent when the accented variation does not cross phoneme boundaries. The current study explores the situation in which a vowel in the foreign accent is produced such that it could be confused with a different intended vowel in the native accent. Children were taught two new word-object pairings by a foreignaccented speaker; when vowels were produced similarly across accents, toddlers aged 32 months successfully accommodated a change in accent between training and test; when a novel word contained a vowel that was more affected by accent, toddlers did not later recognize the words in their native accent. This suggests that toddlers may face added difficulty when learning words from speakers of different accents when there is the potential for phonetic confusion across vowels.},
  file = {/Users/megcychosz/Zotero/storage/PVE4SAMD/Newman et al. - 2018 - Foreign Accent and Toddlers’ Word Learning The Ef.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {2}
}

@article{newmanInfantsEarlyAbility2006,
  title = {Infants' Early Ability to Segment the Conversational Speech Signal Predicts Later Language Development: {{A}} Retrospective Analysis.},
  shorttitle = {Infants' Early Ability to Segment the Conversational Speech Signal Predicts Later Language Development},
  author = {Newman, Rochelle and Ratner, Nan Bernstein and Jusczyk, Ann Marie and Jusczyk, Peter W. and Dow, Kathy Ayala},
  year = {2006},
  volume = {42},
  pages = {643--655},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/0012-1649.42.4.643},
  abstract = {Two studies examined relationships between infants' early speech processing performance and later language and cognitive outcomes. Study 1 found that performance on speech segmentation tasks before 12 months of age related to expressive vocabulary at 24 months. However, performance on other tasks was not related to 2-year vocabulary. Study 2 assessed linguistic and cognitive skills at 4 \textendash{} 6 years of age for children who had participated in segmentation studies as infants. Children who had been able to segment words from fluent speech scored higher on language measures, but not general IQ, as preschoolers. Results suggest that speech segmentation ability is an important prerequisite for successful language development, and they offer potential for developing measures to detect language impairment at an earlier age.},
  file = {/Users/megcychosz/Zotero/storage/9MZGEY7I/Newman et al. - 2006 - Infants' early ability to segment the conversation.pdf},
  journal = {Developmental Psychology},
  language = {en},
  number = {4}
}

@article{newmanInputUptakeMonths2016,
  title = {Input and Uptake at 7 Months Predicts Toddler Vocabulary: The Role of Child-Directed Speech and Infant Processing Skills in Language Development},
  shorttitle = {Input and Uptake at 7 Months Predicts Toddler Vocabulary},
  author = {Newman, Rochelle S. and Rowe, Meredith L. and Bernstein Ratner, Nan},
  year = {2016},
  month = sep,
  volume = {43},
  pages = {1158--1173},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000915000446},
  abstract = {Both the input directed to the child, and the child's ability to process that input, are likely to impact the child's language acquisition. We explore how these factors inter-relate by tracking the relationships among: (a) lexical properties of maternal child-directed speech to prelinguistic (month-old) infants (N = ); (b) these infants' abilities to segment lexical targets from conversational child-directed utterances in an experimental paradigm; and (c) the children's vocabulary outcomes at age ;. Both repetitiveness in maternal input and the child's speech segmentation skills at age ; predicted language outcomes at ;; moreover, while these factors were somewhat inter-related, they each had independent effects on toddler vocabulary skill, and there was no interaction between the two.},
  file = {/Users/megcychosz/Zotero/storage/TQVZTDMA/Newman et al. - 2016 - Input and uptake at 7 months predicts toddler voca.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {5}
}

@article{newmanLinguisticallybasedInformationalMasking2015,
  title = {Linguistically-Based Informational Masking in Preschool Children},
  author = {Newman, Rochelle S. and Morini, Giovanna and Ahsan, Faraz and Kidd, Gerald},
  year = {2015},
  month = jul,
  volume = {138},
  pages = {EL93-EL98},
  issn = {0001-4966},
  doi = {10.1121/1.4921677},
  abstract = {Previous work has shown that young children exhibit more difficulty understanding speech in the presence of speech-like distractors than do adults, and are more susceptible to at least some form of informational masking (IM). Yet little is known about how/when the ``susceptibility'' to linguistically-based IM develops. The authors tested adults, school-age children (aged 8 yrs), and preschool-age children (aged 4 yrs) on sentence recognition in the presence of normal speech, ``jumbled'' speech, and reversed speech distractors. As has been found previously with adults [e.g., Summers and Molis (2004). J. Speech, Lang. Hear. Res. 47, 245\textendash 256], children in both age groups showed a release of masking when the distractor was uninterpretable (reversed speech). This suggests that children already demonstrate linguisticallybased IM by the age of 4 yrs.},
  file = {/Users/megcychosz/Zotero/storage/657TMHDF/Newman et al. - 2015 - Linguistically-based informational masking in pres.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{newmanPerceptualNormalizationSpeaking1996,
  title = {Perceptual Normalization for Speaking Rate: {{Effects}} of Temporal Distance},
  shorttitle = {Perceptual Normalization for Speaking Rate},
  author = {Newman, Rochelle S. and Sawusch, James R.},
  year = {1996},
  volume = {58},
  pages = {540--560},
  issn = {1532-5962},
  doi = {10.3758/BF03213089},
  abstract = {A series of studies was undertaken to examine how rate normalization in speech perception would be influenced by the similarity, duration, and phonotactics of phonemes that were adjacent or distal from the initial, target phoneme. The duration of the adjacent (following) phoneme always had an effect on perception of the initial target. Neither phonotactics nor acoustic similarity seemed to have any influence on this rate normalization effect. However, effects of the duration of the nonadjacent (distal) phoneme were only found when that phoneme was temporally close to the target. These results suggest that there is a temporal window over which rate normalization occurs. In most cases, only the adjacent phoneme or adjacent two phonemes will fall within this window and thus influence perception of a phoneme distinction.},
  file = {/Users/megcychosz/Zotero/storage/A2SNPZWQ/Newman and Sawusch - 1996 - Perceptual normalization for speaking rate Effect.pdf},
  journal = {Perception \& Psychophysics},
  language = {en},
  number = {4}
}

@article{newmanPerceptualNormalizationSpeaking2009,
  title = {Perceptual Normalization for Speaking Rate {{III}}: {{Effects}} of the Rate of One Voice on Perception of Another},
  shorttitle = {Perceptual Normalization for Speaking Rate {{III}}},
  author = {Newman, Rochelle S. and Sawusch, James R.},
  year = {2009},
  volume = {37},
  pages = {46--65},
  issn = {0095-4470},
  doi = {10.1016/j.wocn.2008.09.001},
  abstract = {Individuals vary their speaking rate, and listeners use the speaking rate of precursor sentences to adjust for these changes (). Most of the research on this adjustment process has focused on situations in which there was only a single stream of speech over which such perceptual adjustment could occur. Yet listeners are often faced with environments in which multiple people are speaking simultaneously. Each of these voices provides speaking rate information. The challenge for the listener is to determine which sources of information should apply in a speech perception situation. Three studies examined when listeners would use rate information from one voice to adjust their perception of another voice. Results suggested that if only one source of duration information was available, listeners used that information, regardless of the speaker or the speaker's spatial location. When multiple sources were available, listeners primarily used information from the same source as the target item. However, even information from a source that differed in both location and talker still influenced perception to a slight degree.},
  file = {/Users/megcychosz/Zotero/storage/9X7N836X/Newman and Sawusch - 2009 - Perceptual normalization for speaking rate III Ef.pdf},
  journal = {Journal of Phonetics},
  number = {1},
  pmcid = {PMC2782831},
  pmid = {20046904}
}

@article{newmanRoleSelectedLexical2007,
  title = {The {{Role}} of {{Selected Lexical Factors}} on {{Confrontation Naming Accuracy}}, {{Speed}}, and {{Fluency}} in {{Adults Who Do}} and {{Do Not Stutter}}},
  author = {Newman, Rochelle S. and Bernstein Ratner, Nan},
  year = {2007},
  month = feb,
  volume = {50},
  pages = {196--213},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2007/016)},
  abstract = {Purpose: The purpose of this study was to investigate whether lexical access in adults who stutter (AWS) differs from that in people who do not stutter. Specifically, the authors examined the role of 3 lexical factors on naming speed, accuracy, and fluency: word frequency, neighborhood density, and neighborhood frequency. If stuttering results from an impairment in lexical access, these factors were hypothesized to differentially affect AWS performance on a confrontation naming task. Method: Twenty-five AWS and 25 normally fluent comparison speakers, matched for age and education, participated in a confrontation naming task designed to explore within-speaker performance on naming accuracy, speed, and fluency based on stimulus word frequency and neighborhood characteristics. Accuracy, fluency, and reaction time (from acoustic waveform analysis) were computed. Results: In general, AWS demonstrated the same effects of lexical factors on their naming as did adults who do not stutter. However, accuracy of naming was reduced for AWS. Stuttering rate was influenced by word frequency but not other factors. Conclusions: Results suggest that AWS could have a fundamental deficit in lexical retrieval, but this deficit is unlikely to be at the level of the word's abstract phonological representation. Implications for further research are discussed.},
  file = {/Users/megcychosz/Zotero/storage/XDKLP7Z8/Newman and Bernstein Ratner - 2007 - The Role of Selected Lexical Factors on Confrontat.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {1}
}

@article{newmanToddlersComprehensionDegraded2015,
  title = {Toddlers' Comprehension of Degraded Signals: {{Noise}}-Vocoded versus Sine-Wave Analogs},
  shorttitle = {Toddlers' Comprehension of Degraded Signals},
  author = {Newman, Rochelle S. and Chatterjee, Monita and Morini, Giovanna and Remez, Robert E.},
  year = {2015},
  month = sep,
  volume = {138},
  pages = {EL311-EL317},
  issn = {0001-4966},
  doi = {10.1121/1.4929731},
  abstract = {Recent findings suggest that development changes the ability to comprehend degraded speech. Preschool children showed greater difficulties perceiving noise-vocoded speech (a signal that integrates amplitude over broad frequency bands) than sine-wave speech (which maintains the spectral peaks without the spectrum envelope). In contrast, 27-month-old children in the present study could recognize speech with either type of degradation and performed slightly better with eight-channel vocoded speech than with sine-wave speech. This suggests that children's identification performance depends critically on the degree of degradation and that their success in recognizing unfamiliar speech encodings is encouraging overall.},
  file = {/Users/megcychosz/Zotero/storage/R2KI7TP2/Newman et al. - 2015 - Toddlers' comprehension of degraded signals Noise.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {3}
}

@article{newmanToddlersFastmappingNoisevocoded2020,
  title = {Toddlers' Fast-Mapping from Noise-Vocoded Speech.},
  author = {Newman, Rochelle S. and Morini, Giovanna and Shroads, Emily and Chatterjee, Monita},
  year = {2020},
  volume = {147},
  pages = {2432--2441},
  file = {/Users/megcychosz/Zotero/storage/QG3U7KGQ/Newman et al. - 2020 - Toddlers’ fast-mapping from noise-vocoded speech..pdf},
  journal = {Journal of the Acoustical Society of America},
  number = {4}
}

@article{ngonNonWordsNon2013,
  title = {({{Non}})Words, (Non)Words, (Non)Words: Evidence for a Protolexicon during the First Year of Life},
  shorttitle = {({{Non}})Words, (Non)Words, (Non)Words},
  author = {Ngon, C{\'e}line and Martin, Andrew and Dupoux, Emmanuel and Cabrol, Dominique and Dutat, Michel and Peperkamp, Sharon},
  year = {2013},
  month = jan,
  volume = {16},
  pages = {24--34},
  issn = {1363755X},
  doi = {10.1111/j.1467-7687.2012.01189.x},
  abstract = {Previous research with artificial language learning paradigms has shown that infants are sensitive to statistical cues to word boundaries (Saffran, Aslin \& Newport, 1996) and that they can use these cues to extract word-like units (Saffran, 2001). However, it is unknown whether infants use statistical information to construct a receptive lexicon when acquiring their native language. In order to investigate this issue, we rely on the fact that besides real words a statistical algorithm extracts sound sequences that are highly frequent in infant-directed speech but constitute nonwords. In three experiments, we use a preferential listening paradigm to test French-learning 11-month-old infants' recognition of highly frequent disyllabic sequences from their native language. In Experiments 1 and 2, we use nonword stimuli and find that infants listen longer to high-frequency than to low-frequency sequences. In Experiment 3, we compare high-frequency nonwords to real words in the same frequency range, and find that infants show no preference. Thus, at 11 months, French-learning infants recognize highly frequent sound sequences from their native language and fail to differentiate between words and nonwords among these sequences. These results are evidence that they have used statistical information to extract word candidates from their input and stored them in a `protolexicon', containing both words and nonwords.},
  file = {/Users/megcychosz/Zotero/storage/WKKQGNJD/Ngon et al. - 2013 - (Non)words, (non)words, (non)words evidence for a.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {1}
}

@article{ngungaPhoneticPhonologicalVowel2000,
  title = {Phonetic {\emph{versus}} Phonological Vowel Length in {{Ciyao}}},
  author = {Ngunga, Armindo S.A.},
  year = {2000},
  month = jan,
  volume = {20},
  pages = {103--114},
  issn = {0257-2117, 2305-1159},
  doi = {10.1080/02572117.2000.10587417},
  file = {/Users/megcychosz/Zotero/storage/64HPYEQ5/Ngunga - 2000 - Phonetic iversusi phonological vowel length i.pdf},
  journal = {South African Journal of African Languages},
  language = {en},
  number = {1}
}

@article{nguyenRoleImitationEmergence2015,
  title = {Role of Imitation in the Emergence of Phonological Systems},
  author = {Nguyen, No{\"e}l and Delvaux, V{\'e}ronique},
  year = {2015},
  month = nov,
  volume = {53},
  pages = {46--54},
  issn = {00954470},
  doi = {10.1016/j.wocn.2015.08.004},
  abstract = {The issue we address in this review paper is to what extent mutual adaptation plays a role in the emergence and evolution of phonological systems. Adaptation to the interlocutor has been shown to take many forms and to embrace all the levels of spoken language, from adjustments in vocal intensity to changes in word forms over the course of a conversational exchange, as well as lexical and syntactic alignment across speakers, to name but a few examples. Phonetic convergence, that is, the tendency for two speakers engaged in a conversational exchange to sound more like each other, is one important aspect of between-speaker adaptation. Empirical evidence has recently accumulated that shows that phonetic convergence is a recurrent phenomenon in mature speakers. This phenomenon relies on sensory-motor abilities that infants may already possess at birth. Phonetic convergence affects the way in which both speakers speak after their interaction has ended, and may build up over long periods of time. It may also be a driving mechanism in the acquisition of the phonology and phonetics of a second language.},
  file = {/Users/megcychosz/Zotero/storage/NYSVIKFC/Nguyen and Delvaux - 2015 - Role of imitation in the emergence of phonological.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@misc{nidcdScienceCapsuleCochlear2014,
  title = {Science {{Capsule}} - {{Cochlear Implants}}},
  author = {NIDCD},
  year = {2014},
  publisher = {{National Institutes of Health}}
}

@article{nieuwenhuisWeightedEffectCoding2017,
  title = {Weighted {{Effect Coding}} for {{Observational Data}} with Wec},
  author = {Nieuwenhuis, Rense and Grotenhuis, te, Manfred and Pelzer, Ben},
  year = {2017},
  volume = {9},
  pages = {477},
  issn = {2073-4859},
  doi = {10.32614/RJ-2017-017},
  abstract = {Weighted effect coding refers to a specific coding matrix to include factor variables in generalised linear regression models. With weighted effect coding, the effect for each category represents the deviation of that category from the weighted mean (which corresponds to the sample mean). This technique has particularly attractive properties when analysing observational data, that commonly are unbalanced. The wec package is introduced, that provides functions to apply weighted effect coding to factor variables, and to interactions between (a.) a factor variable and a continuous variable and between (b.) two factor variables.},
  file = {/Users/megcychosz/Zotero/storage/QYAMT5ME/Nieuwenhuis et al. - 2017 - Weighted Effect Coding for Observational Data with.pdf},
  journal = {The R Journal},
  language = {en},
  number = {1}
}

@article{nijlandCoarticulationPatternsChildren2002,
  title = {Coarticulation Patterns in Children with Developmental Apraxia of Speech},
  author = {Nijland, Lian and Maassen, Ben and der Meulen, Sjoeke Van and Gabre{\"e}ls, Fons and Kraaimaat, Floris W. and Schreuder, Rob},
  year = {2002},
  month = jan,
  volume = {16},
  pages = {461--483},
  issn = {0269-9206, 1464-5076},
  doi = {10.1080/02699200210159103},
  abstract = {The aim of this study was to enhance our insight into the underlying de\'ecit in developmental apraxia of speech (DAS). In particular, the involvement of planning and/or programming of speech movements in context was tested by analysing coarticulatory cohesion. For this purpose, second formant frequency measurements were conducted in repetitions of nonsense utterances ([@CV ] C=/s,x,b,d/; V=/i,a,u/), and compared across nine children with DAS, six normally speaking (NS) children and six adult women. The results showed both intra- and intersyllabic anticipatory coarticulation in NS children and adult women, in which the intersyllabic coarticulation was stronger in NS children than in adult women. The children with DAS showed more variability as compared to NS children, made, on average, less distinction between the vowels, and showed individually idiosyncratic coarticulation patterns. These results are discussed in the light of a delay as well as a deviance of speech development in children with DAS.},
  file = {/Users/megcychosz/Zotero/storage/7KW7WTHD/Nijland et al. - 2002 - Coarticulation patterns in children with developme.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {6}
}

@article{niparkoSpokenLanguageDevelopment2010,
  title = {Spoken {{Language Development}} in {{Children Following Cochlear Implantation}}},
  author = {Niparko, John K and Tobey, Emily A and Thal, Donna J and Eisenberg, Laurie S and Wang, Nae-Yuh and Quittner, Alexandra L and Fink, Nancy E},
  year = {2010},
  volume = {303},
  pages = {1498--1506},
  abstract = {Objective To prospectively assess spoken language acquisition following cochlear implantation in young children. Design, Setting, and Participants Prospective, longitudinal, and multidimensional assessment of spoken language development over a 3-year period in children who underwent cochlear implantation before 5 years of age (n=188) from 6 US centers and hearing children of similar ages (n=97) from 2 preschools recruited between November 2002 and December 2004. Follow-up completed between November 2005 and May 2008. Main Outcome Measures Performance on measures of spoken language comprehension and expression (Reynell Developmental Language Scales). Results Children undergoing cochlear implantation showed greater improvement in spoken language performance (10.4; 95\% confidence interval [CI], 9.6-11.2 points per year in comprehension; 8.4; 95\% CI, 7.8-9.0 in expression) than would be predicted by their preimplantation baseline scores (5.4; 95\% CI, 4.1-6.7, comprehension; 5.8; 95\% CI, 4.6-7.0, expression), although mean scores were not restored to age-appropriate levels after 3 years. Younger age at cochlear implantation was associated with significantly steeper rate increases in comprehension (1.1; 95\% CI, 0.51.7 points per year younger) and expression (1.0; 95\% CI, 0.6-1.5 points per year younger). Similarly, each 1-year shorter history of hearing deficit was associated with steeper rate increases in comprehension (0.8; 95\% CI, 0.2-1.2 points per year shorter) and expression (0.6; 95\% CI, 0.2-1.0 points per year shorter). In multivariable analyses, greater residual hearing prior to cochlear implantation, higher ratings of parentchild interactions, and higher socioeconomic status were associated with greater rates of improvement in comprehension and expression. Conclusion The use of cochlear implants in young children was associated with better spoken language learning than would be predicted from their preimplantation scores.},
  file = {/Users/megcychosz/Zotero/storage/9XNDV3AD/Niparko et al. - Spoken Language Development in Children Following .pdf},
  journal = {Journal of the American Medical Association},
  language = {en},
  number = {15}
}

@article{nittrouerEarlyPredictorsPhonological2016,
  title = {Early Predictors of Phonological and Morphosyntactic Skills in Second Graders with Cochlear Implants},
  author = {Nittrouer, Susan and Lowenstein, Joanna H. and Holloman, Christopher},
  year = {2016},
  month = aug,
  volume = {55},
  pages = {143--160},
  issn = {08914222},
  doi = {10.1016/j.ridd.2016.03.020},
  abstract = {Purpose\textemdash Newborn hearing screening has made it possible to provide early treatment of hearing loss to more children than ever before, raising expectations these children will be able to attend regular schools. But continuing deficits in spoken language skills have led to challenges in meeting those expectations. This study was conducted to (1) examine two kinds of language skills (phonological and morphosyntactic) at school age (second grade) for children with cochlear implants (CIs); (2) see which measures from earlier in life best predicted performance at second grade; (3) explore how well these skills supported other cognitive and language functions; and (4) examine how treatment factors affected measured outcomes. Methods\textemdash Data were analyzed from 100 second-grade, monolingual English-speaking children: 51 with CIs and 49 with normal hearing (NH). Ten measures of spoken language and related functions were collected: three each of phonological and morphosyntactic skills; and four of other cognitive and language functions. Six measures from preschool and seven from kindergarten served as predictor variables. The effects of treatment variables were examined. Results\textemdash Children with CIs were more delayed acquiring phonological than morphosyntactic skills. Mean length of utterance at earlier ages was the most consistent predictor of both phonological and morphosyntactic skills at second grade. Early bimodal stimulation had a weak, but positive effect on phonological skills at second grade; sign language experience during preschool had a negative effect on morphosyntactic structures in spoken language. Conclusions\textemdash Children with CIs are delayed in language acquisition, and especially so in phonological skills. Appropriate testing and treatments can help ameliorate these delays. Graphical abstract},
  file = {/Users/megcychosz/Zotero/storage/5FENZ966/Nittrouer et al. - 2016 - Early predictors of phonological and morphosyntact.pdf},
  journal = {Research in Developmental Disabilities},
  language = {en}
}

@article{nittrouerEmergenceMatureGestural1993,
  title = {The Emergence of Mature Gestural Patterns Is Not Uniform: {{Evidence}} from an Acoustic Study},
  author = {Nittrouer, Susan},
  year = {1993},
  month = oct,
  volume = {36},
  pages = {959--972},
  file = {/Users/megcychosz/Zotero/storage/DVBN9AST/JSLHR1993.pdf},
  journal = {Journal of Speech Language and Hearing Research}
}

@article{nittrouerEmergencePhoneticSegments1989,
  title = {The Emergence of Phonetic Segments: Evidence from the Spectral Structure of Fricative-Vowel Syllables Spoken by Children and Adults},
  author = {Nittrouer, Susan and {Studdert-Kennedy}, Michael and McGowan, Richard S.},
  year = {1989},
  volume = {32},
  pages = {120--132},
  abstract = {A variety of evidence, including the speech errors of normal and aphasic speakers, and the metalinguistic skills of literate individuals, demonstrates that speech has an underlying phonemic organization. However, we know little about how this organization develops in the child. The purpose of the present study was to test the hypothesis that phoneme-sized phonetic segments emerge as functional units of perceptuomotor control from the child's gradual reorganization of the gestures forming its early words or syllables. We investigated the acoustic structure of syllables produced by young children and adults. Fricative- vowel syllables spoken by 40 subjects (eight adults and eight children at each of the ages 3, 4, 5, and 7 years) were analyzed acoustically to determine how well different syllables-initial fricatives were contrasted and how strongly they were affected by vocalic context. Results indicated two independent developmental trends: The extent to which speakers differentiated between /J'/and /s/ increased with age, while the extent to which they coarticulated each fricative with its following vowel decreased. The results support the hypothesis that children initially organize and only gradually differentiate the syllable into patterns components.},
  file = {/Users/megcychosz/Zotero/storage/JQYPDUM3/The emergence of phonetic segments evidence from the spectral structure of fricative-vowel syllables spoken by children and adults.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en}
}

@article{nittrouerHowChildrenLearn1996,
  title = {How {{Children Learn}} to {{Organize Their Speech Gestures}}: {{Further Evidence From Fricative}}-{{Vowel Syllables}}},
  shorttitle = {How {{Children Learn}} to {{Organize Their Speech Gestures}}},
  author = {Nittrouer, Susan and {Studdert-Kennedy}, Michael and Neely, Stephen T.},
  year = {1996},
  volume = {39},
  pages = {379--389},
  issn = {1092-4388},
  doi = {10.1044/jshr.3902.379},
  file = {/Users/megcychosz/Zotero/storage/G2BW7QAQ/Nittrouer et al. - 1996 - How Children Learn to Organize Their Speech Gestur.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en}
}

@incollection{nittrouerLanguageLiteracySkills2016,
  title = {Language and {{Literacy Skills}} in {{Children}} with {{Cochlear Implants}}: {{Past}} and {{Present Findings}}},
  shorttitle = {Language and {{Literacy Skills}} in {{Children}} with {{Cochlear Implants}}},
  booktitle = {Pediatric {{Cochlear Implantation}}},
  author = {Nittrouer, Susan and {Caldwell-Tarr}, Amanda},
  editor = {Young, Nancy M and Iler Kirk, Karen},
  year = {2016},
  pages = {177--197},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4939-2788-3_11},
  abstract = {The vast majority of children with severe-to-profound hearing loss are born to parents with normal hearing who want their children to grow up with spoken language. Before the availability of cochlear implants, however, that goal was often unattainable, leaving these children to face lifetimes of greatly diminished capabilities. When the first generation of implants became available, dramatic improvements were immediately realized in these children's abilities to acquire spoken language and literacy: about half of the deaf children who received cochlear implants began demonstrating performance on a variety of language and literacy skills within the typical range, defined as better than one standard deviation below the means of children with normal hearing. But as promising as those early outcomes were, it does not appear that these performance levels have changed proportionately with changes in implant technology. This chapter reviews relevant research using standardized measures of spoken language to examine the veracity of that impression, and describes findings across a wide range of studies that explored the linguistic and cognitive mechanisms underlying those standardized measures.},
  file = {/Users/megcychosz/Zotero/storage/9MR4C84S/Nittrouer and Caldwell-Tarr - 2016 - Language and Literacy Skills in Children with Coch.pdf},
  isbn = {978-1-4939-2787-6 978-1-4939-2788-3},
  language = {en}
}

@article{nittrouerParentalLanguageInput2019,
  title = {Parental {{Language Input}} to {{Children With Hearing Loss}}: {{Does It Matter}} in the {{End}}?},
  shorttitle = {Parental {{Language Input}} to {{Children With Hearing Loss}}},
  author = {Nittrouer, Susan and Lowenstein, Joanna H. and Antonelli, Joseph},
  year = {2019},
  month = jan,
  volume = {63},
  pages = {234--258},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2019_JSLHR-19-00123},
  abstract = {Purpose               Parental language input (PLI) has reliably been found to influence child language development for children at risk of language delay, but previous work has generally restricted observations to the preschool years. The current study examined whether PLI during the early years explains variability in the spoken language abilities of children with hearing loss at those young ages, as well as later in childhood.                                         Participants               One hundred children participated: 34 with normal hearing, 24 with moderate losses who used hearing aids (HAs), and 42 with severe-to-profound losses who used cochlear implants (CIs). Mean socioeconomic status was middle class for all groups. Children with CIs generally received them early.                                         Method               Samples of parent\textendash child interactions were analyzed to characterize PLI during the preschool years. Child language abilities (CLAs) were assessed at 48 months and 10 years of age.                                         Results               No differences were observed across groups in how parents interacted with their children. Nonetheless, strong differences across groups were observed in the effects of PLI on CLAs at 48 months of age: Children with normal hearing were largely resilient to their parents' language styles. Children with HAs were most influenced by the amount of PLI. Children with CIs were most influenced by PLI that evoked child language and modeled more complex versions. When potential influences of preschool PLI on CLAs at 10 years of age were examined, those effects at preschool were replicated. When mediation analyses were performed, however, it was found that the influences of preschool PLI on CLAs at 10 years of age were partially mediated by CLAs at preschool.                                         Conclusion               PLI is critical to the long-term spoken language abilities of children with hearing loss, but the style of input that is most effective varies depending on the severity of risk for delay.},
  file = {/Users/megcychosz/Zotero/storage/95H8IJNP/Nittrouer et al. - 2019 - Parental Language Input to Children With Hearing L.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {1}
}

@article{nittrouerPerceptualWeightingStrategies2014,
  title = {Perceptual Weighting Strategies of Children with Cochlear Implants and Normal Hearing},
  author = {Nittrouer, Susan and {Caldwell-Tarr}, Amanda and Moberly, Aaron C. and Lowenstein, Joanna H.},
  year = {2014},
  month = nov,
  volume = {52},
  pages = {111--133},
  issn = {00219924},
  doi = {10.1016/j.jcomdis.2014.09.003},
  file = {/Users/megcychosz/Zotero/storage/ZJ2JSES5/Nittrouer et al. - 2014 - Perceptual weighting strategies of children with c.pdf},
  journal = {Journal of Communication Disorders},
  language = {en}
}

@article{nittrouerRoleEarlyLanguage2005,
  title = {The Role of Early Language Experience in the Development of Speech Perception and Phonological Processing Abilities: Evidence from 5-Year-Olds with Histories of Otitis Media with Effusion and Low Socioeconomic Status},
  shorttitle = {The Role of Early Language Experience in the Development of Speech Perception and Phonological Processing Abilities},
  author = {Nittrouer, Susan and Burton, Lisa Thuente},
  year = {2005},
  month = jan,
  volume = {38},
  pages = {29--63},
  issn = {00219924},
  doi = {10.1016/j.jcomdis.2004.03.006},
  abstract = {This study tested the hypothesis that early language experience facilitates the development of language-specific perceptual weighting strategies believed to be critical for accessing phonetic structure. In turn, that structure allows for efficient storage and retrieval of words in verbal working memory, which is necessary for sentence comprehension. Participants were forty-nine 5-year-olds, evenly distributed among four groups: those with chronic otitis media with effusion (OME), low socio-economic status (low-SES), both conditions (both), or neither condition (control). All children participated in tasks of speech perception and phonological awareness. Children in the control and OME groups participated in additional tasks examining verbal working memory, sentence comprehension, and temporal processing. The temporal-processing task tested the hypothesis that any deficits observed on the language-related tasks could be explained by temporal-processing deficits. Children in the three experimental groups demonstrated similar results to each other, but different from the control group for speech perception and phonological awareness. Children in the OME group differed from those in the control group on tasks involving verbal working memory and sentence comprehension, but not temporal processing. Overall these results supported the major hypothesis explored, but failed to support the hypothesis that language problems are explained to any extent by temporal-processing problems.},
  file = {/Users/megcychosz/Zotero/storage/EC22JHZU/Nittrouer and Burton - 2005 - The role of early language experience in the devel.pdf},
  journal = {Journal of Communication Disorders},
  language = {en},
  number = {1}
}

@article{nittrouerSpeechPerceptionSinewave2015,
  title = {Speech Perception of Sine-Wave Signals by Children with Cochlear Implants},
  author = {Nittrouer, Susan and Kuess, Jamie and Lowenstein, Joanna H.},
  year = {2015},
  month = may,
  volume = {137},
  pages = {2811--2822},
  issn = {0001-4966},
  doi = {10.1121/1.4919316},
  file = {/Users/megcychosz/Zotero/storage/EPARDQXF/Nittrouer et al. - 2015 - Speech perception of sine-wave signals by children.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{nittrouerVerbalWorkingMemory2017,
  title = {Verbal {{Working Memory}} in {{Children With Cochlear Implants}}},
  author = {Nittrouer, Susan and {Caldwell-Tarr}, Amanda and Low, Keri E. and Lowenstein, Joanna H.},
  year = {2017},
  month = nov,
  volume = {60},
  pages = {3342--3364},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2017_JSLHR-H-16-0474},
  abstract = {Purpose               Verbal working memory in children with cochlear implants and children with normal hearing was examined.                                         Participants               Ninety-three fourth graders (47 with normal hearing, 46 with cochlear implants) participated, all of whom were in a longitudinal study and had working memory assessed 2 years earlier.                                         Method               A dual-component model of working memory was adopted, and a serial recall task measured storage and processing. Potential predictor variables were phonological awareness, vocabulary knowledge, nonverbal IQ, and several treatment variables. Potential dependent functions were literacy, expressive language, and speech-in-noise recognition.                                         Results               Children with cochlear implants showed deficits in storage and processing, similar in size to those at second grade. Predictors of verbal working memory differed across groups: Phonological awareness explained the most variance in children with normal hearing; vocabulary explained the most variance in children with cochlear implants. Treatment variables explained little of the variance. Where potentially dependent functions were concerned, verbal working memory accounted for little variance once the variance explained by other predictors was removed.                                         Conclusions               The verbal working memory deficits of children with cochlear implants arise due to signal degradation, which limits their abilities to acquire phonological awareness. That hinders their abilities to store items using a phonological code.},
  file = {/Users/megcychosz/Zotero/storage/U996ERCK/Nittrouer et al. - 2017 - Verbal Working Memory in Children With Cochlear Im.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {11}
}

@article{nittrouerWeightingAcousticCues2015,
  title = {Weighting of {{Acoustic Cues}} to a {{Manner Distinction}} by {{Children With}} and {{Without Hearing Loss}}},
  author = {Nittrouer, Susan and Lowenstein, Joanna H.},
  year = {2015},
  month = jun,
  volume = {58},
  pages = {1077--1092},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2015_JSLHR-H-14-0263},
  abstract = {Purpose               Children must develop optimal perceptual weighting strategies for processing speech in their first language. Hearing loss can interfere with that development, especially if cochlear implants are required. The three goals of this study were to measure, for children with and without hearing loss: (a) cue weighting for a manner distinction, (b) sensitivity to those cues, and (c) real-world communication functions.                                         Method               One hundred and seven children (43 with normal hearing [NH], 17 with hearing aids [HAs], and 47 with cochlear implants [CIs]) performed several tasks: labeling of stimuli from /bɑ/-to-/wɑ/ continua varying in formant and amplitude rise time (FRT and ART), discrimination of ART, word recognition, and phonemic awareness.                                         Results               Children with hearing loss were less attentive overall to acoustic structure than children with NH. Children with CIs, but not those with HAs, weighted FRT less and ART more than children with NH. Sensitivity could not explain cue weighting. FRT cue weighting explained significant amounts of variability in word recognition and phonemic awareness; ART cue weighting did not.                                         Conclusion               Signal degradation inhibits access to spectral structure for children with CIs, but cannot explain their delayed development of optimal weighting strategies. Auditory training could strengthen the weighting of spectral cues for children with CIs, thus aiding spoken language acquisition.},
  file = {/Users/megcychosz/Zotero/storage/PAL7YSYF/Nittrouer and Lowenstein - 2015 - Weighting of Acoustic Cues to a Manner Distinction.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {3}
}

@article{noirayBackFutureNonlinear2019,
  title = {Back {{From}} the {{Future}}: {{Nonlinear Anticipation}} in {{Adults}}' and {{Children}}'s {{Speech}}},
  shorttitle = {Back {{From}} the {{Future}}},
  author = {Noiray, Aude and Wieling, Martijn and Abakarova, Dzhuma and Rubertus, Elina and Tiede, Mark},
  year = {2019},
  month = aug,
  volume = {62},
  pages = {3033--3054},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2019_JSLHR-S-CSMC7-18-0208},
  file = {/Users/megcychosz/Zotero/storage/UKIN7NCE/Noiray et al. - 2019 - Back From the Future Nonlinear Anticipation in Ad.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {8S}
}

@article{noirayChildrenCoarticulatoryPatternsunderreview,
  title = {Children's Coarticulatory Patterns Are Sensitive to Their Degree of Phonological Awareness and Vocabulary},
  author = {Noiray, Aude and Popescu, Anisia and Killmer, Helene and Rubertus, Elina and Kr{\"u}ger, Stella and Hintermeier, Lisa},
  year = {under review},
  file = {/Users/megcychosz/Zotero/storage/X3QXYEMA/Frontiers_Noiray_EtAl_2019_UnderReview.pdf},
  journal = {manuscript submitted to Frontiers in Psychology}
}

@article{noirayDevelopmentMotorSynergies2013,
  title = {The Development of Motor Synergies in Children: {{Ultrasound}} and Acoustic Measurements},
  shorttitle = {The Development of Motor Synergies in Children},
  author = {Noiray, Aude and M{\'e}nard, Lucie and Iskarous, Khalil},
  year = {2013},
  month = jan,
  volume = {133},
  pages = {444--452},
  issn = {0001-4966},
  doi = {10.1121/1.4763983},
  file = {/Users/megcychosz/Zotero/storage/4GSA4LAA/Noiray et al. - 2013 - The development of motor synergies in children Ul.pdf},
  journal = {Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{noirayHowChildrenOrganize2018,
  title = {How {{Do Children Organize Their Speech}} in the {{First Years}} of {{Life}}? {{Insight From Ultrasound Imaging}}},
  shorttitle = {How {{Do Children Organize Their Speech}} in the {{First Years}} of {{Life}}?},
  author = {Noiray, Aude and Abakarova, Dzhuma and Rubertus, Elina and Kr{\"u}ger, Stella and Tiede, Mark},
  year = {2018},
  month = jun,
  volume = {61},
  pages = {1355--1368},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2018_JSLHR-S-17-0148},
  file = {/Users/megcychosz/Zotero/storage/2ZZA8ZC8/Noiray et al. - 2018 - How Do Children Organize Their Speech in the First.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {6}
}

@article{noiraySpokenLanguageDevelopment2019,
  title = {Spoken {{Language Development}} and the {{Challenge}} of {{Skill Integration}}},
  author = {Noiray, Aude and Popescu, Anisia and Killmer, Helene and Rubertus, Elina and Kr{\"u}ger, Stella and Hintermeier, Lisa},
  year = {2019},
  volume = {10},
  pages = {1--17},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2019.02777},
  abstract = {The development of phonological awareness, the knowledge of the structural combinatoriality of a language, has been widely investigated in relation to reading (dis) ability across languages. However, the extent to which knowledge of phonemic units may interact with spoken language organization in (transparent) alphabetical languages has hardly been investigated. The present study examined whether phonemic awareness correlates with coarticulation degree, commonly used as a metric for estimating the size of children's production units. A speech production task was designed to test for developmental differences in intra-syllabic coarticulation degree in 41 German children from 4 to 7 years of age. The technique of ultrasound imaging allowed for comparing the articulatory foundations of children's coarticulatory patterns. Four behavioral tasks assessing various levels of phonological awareness from large to small units and expressive vocabulary were also administered. Generalized additive modeling revealed strong interactions between children's vocabulary and phonological awareness with coarticulatory patterns. Greater knowledge of sub-lexical units was associated with lower intra-syllabic coarticulation degree and greater differentiation of articulatory gestures for individual segments. This interaction was mostly nonlinear: an increase in children's phonological proficiency was not systematically associated with an equivalent change in coarticulation degree. Similar findings were drawn between vocabulary and coarticulatory patterns. Overall, results suggest that the process of developing spoken language fluency involves dynamical interactions between cognitive and speech motor domains. Arguments for an integrated-interactive approach to skill development are discussed.},
  file = {/Users/megcychosz/Zotero/storage/589G6IKX/Noiray et al. - 2019 - Spoken Language Development and the Challenge of S.pdf},
  journal = {Frontiers in Psychology},
  language = {en},
  number = {2777}
}

@inproceedings{nordstromNormalizationProcedureVowel1975,
  title = {A Normalization Procedure for Vowel Formant Data},
  booktitle = {Proceedings of the 8th {{International Congress}} of {{Phonetic Sciences}}},
  author = {Nordstrom, P. E. and Lindblom, B.},
  year = {1975},
  address = {{Leeds, England}}
}

@article{novakCochlearImplantsInfants,
  title = {Cochlear {{Implants}} in {{Infants}} and {{Toddlers}}},
  author = {Novak, Michael A and Firszt, Jill B},
  pages = {4},
  file = {/Users/megcychosz/Zotero/storage/FHDLIPWU/Novak and Firszt - Cochlear Implants in Infants and Toddlers.pdf},
  language = {en}
}

@book{ochsCultureLanguageDevelopment1988,
  title = {Culture and Language Development: {{Language}} Acquisition and Language Socialization in a {{Samoan}} Village},
  author = {Ochs, Elinor},
  year = {1988},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, UK}}
}

@article{ochsEthicalBlindSpots2020,
  title = {Ethical {{Blind Spots}} in {{Ethnographic}} and {{Developmental Approaches}} to the {{Language Gap Debate}}},
  author = {Ochs, Elinor and {Kremer-Sadl}, Tamar},
  year = {2020},
  volume = {N\textdegree 170},
  pages = {39},
  issn = {0181-4095, 2101-0382},
  doi = {10.3917/ls.170.0039},
  file = {/Users/megcychosz/Zotero/storage/4JITE7AR/Ochs and Kremer-Sadl - 2020 - Ethical Blind Spots in Ethnographic and Developmen.pdf},
  journal = {Langage et soci\'et\'e},
  language = {en},
  number = {2}
}

@article{ochsHowPostindustrialFamilies2015,
  title = {How {{Postindustrial Families Talk}}},
  author = {Ochs, Elinor and {Kremer-Sadlik}, Tamar},
  year = {2015},
  month = oct,
  volume = {44},
  pages = {87--103},
  issn = {0084-6570, 1545-4290},
  doi = {10.1146/annurev-anthro-102214-014027},
  abstract = {The nuclear family is both crucible and product of capitalism and modernity, carried forth and modified across generations through ordinary communicative and other social practices. Focusing on postindustrial middle-class families, this review analyzes key discursive practices that promote ``the entrepreneurial child'' who can display creative language and problem-solving skills requisite to enter the globalized knowledge class as adults. It also considers how the entrepreneurial thrust, including the democratization of the parent\textendash child relationship and exercise of individual desire, complicates family cooperation. Family quality time, heightened child-centeredness, children's social involvement as parental endeavor, children's autonomy and freedom, and postindustrial intimacies organize how family members communicate from morning to night.},
  file = {/Users/megcychosz/Zotero/storage/6RMJQF6I/Ochs and Kremer-Sadlik - 2015 - How Postindustrial Families Talk.pdf},
  journal = {Annual Review of Anthropology},
  language = {en},
  number = {1}
}

@book{odonnellProductivityReuseLanguage2015,
  title = {Productivity and {{Reuse In Language}}: {{A Theory}} of {{Linguistic Computation}} and {{Storage}}},
  shorttitle = {Productivity and {{Reuse In Language}}},
  author = {O'Donnell, Timothy J.},
  year = {2015},
  month = sep,
  publisher = {{The MIT Press}},
  doi = {10.7551/mitpress/9780262028844.001.0001},
  abstract = {We present a Bayesian model of the mirror image problems of linguistic productivity and reuse. The model, known as Fragment Grammar, is evaluated against several morphological datasets; its performance is compared to competing theoretical accounts including full\textendash parsing, full\textendash listing, and exemplar\textendash based models. The model is able to learn the correct patterns of productivity and reuse for two very different systems: the English past tense which is characterized by a sharp dichotomy in productivity between regular and irregular forms and English derivational morphology which is characterized by a graded cline from very productive (-ness) to very unproductive (-th).},
  file = {/Users/megcychosz/Zotero/storage/S4SU6YZW/O'Donnell - 2015 - Productivity and Reuse In Language A Theory of Li.pdf},
  isbn = {978-0-262-02884-4},
  language = {en}
}

@article{oflazerArchitectureImplementationFinite2006,
  title = {The Architecture and the Implementation of a Finite State Pronunciation Lexicon for {{Turkish}}},
  author = {Oflazer, K. and Inkelas, Sharon},
  year = {2006},
  volume = {20},
  pages = {80--106},
  journal = {Computer Speech and Language}
}

@article{ohmanCoarticulationVCVUtterances1966,
  title = {Coarticulation in {{VCV Utterances}}: {{Spectrographic Measurements}}},
  shorttitle = {Coarticulation in {{VCV Utterances}}},
  author = {{\"O}hman, S. E. G.},
  year = {1966},
  month = jan,
  volume = {39},
  pages = {151--168},
  issn = {0001-4966},
  doi = {10.1121/1.1909864},
  file = {/Users/megcychosz/Zotero/storage/C4EKJ995/Öhman - 1966 - Coarticulation in VCV Utterances Spectrographic M.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{olesonDetectingTimespecificDifferences2017,
  title = {Detecting Time-Specific Differences between Temporal Nonlinear Curves: {{Analyzing}} Data from the Visual World Paradigm},
  shorttitle = {Detecting Time-Specific Differences between Temporal Nonlinear Curves},
  author = {Oleson, Jacob J and Cavanaugh, Joseph E and McMurray, Bob and Brown, Grant},
  year = {2017},
  month = dec,
  volume = {26},
  pages = {2708--2725},
  issn = {0962-2802, 1477-0334},
  doi = {10.1177/0962280215607411},
  abstract = {In multiple fields of study, time series measured at high frequencies are used to estimate population curves that describe the temporal evolution of some characteristic of interest. These curves are typically nonlinear, and the deviations of each series from the corresponding curve are highly autocorrelated. In this scenario, we propose a procedure to compare the response curves for different groups at specific points in time. The method involves fitting the curves, performing potentially hundreds of serially correlated tests, and appropriately adjusting the overall alpha level of the tests. Our motivating application comes from psycholinguistics and the visual world paradigm. We describe how the proposed technique can be adapted to compare fixation curves within subjects as well as between groups. Our results lead to conclusions beyond the scope of previous analyses.},
  file = {/Users/megcychosz/Zotero/storage/XSBB9B7F/Oleson et al. - 2017 - Detecting time-specific differences between tempor.pdf},
  journal = {Statistical Methods in Medical Research},
  language = {en},
  number = {6}
}

@article{ollerDevelopmentPrecursorsSpeech1997,
  title = {Development of Precursors to Speech in Infants Exposed to Two Languages},
  author = {Oller, D. Kimbrough and Eilers, Rebecca E. and Urbano, Richard and {Cobo-Lewis}, Alan B.},
  year = {1997},
  month = jun,
  volume = {24},
  pages = {407--425},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000997003097},
  abstract = {The study of bilingualism has often focused on two contradictory   possibilities: that the learning of two languages may produce deficits  of  performance in each language by comparison with performance of  monolingual individuals, or on the contrary, that the learning of two  languages may produce linguistic or cognitive advantages with regard to   the monolingual learning experience. The work reported here addressed  the possibility that the very early bilingual experience of infancy may   affect the unfolding of vocal precursors to speech. The results of  longitudinal research with 73 infants aged 0;4 to 1;6 in monolingual and   bilingual environments provided no support for either a bilingual deficit   hypothesis nor for its opposite, a bilingual advantage hypothesis. Infants   reared in bilingual and monolingual environments manifested similar  ages of onset for canonical babbling (production of well-formed  syllables), an event known to be fundamentally related to speech  development. Further, quantitative measures of vocal performance  (proportion of usage of well-formed syllables and vowel-like sounds)  showed additional similarities between monolingual and bilingual  infants. The similarities applied to infants of middle and low socio-economic   status and to infants that were born at term or prematurely.  The results suggest that vocal development in the first year of life is   robust with respect to conditions of rearing. The biological foundations   of speech appear to be such as to resist modifications in the natural  schedule of vocal development.},
  file = {/Users/megcychosz/Zotero/storage/NVRSYVEA/Kimbrough Oller et al. - 1997 - Development of precursors to speech in infants exp.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {2}
}

@book{ollerEmergenceSpeechCapacity2000,
  title = {The Emergence of the Speech Capacity},
  author = {Oller, D.K.},
  year = {2000},
  publisher = {{Lawrence Erlbaum Associates}},
  address = {{Mahwah, NJ}}
}

@article{ollerInfantBoysAre2020,
  title = {Infant Boys Are More Vocal than Infant Girls},
  author = {Oller, D. Kimbrough and Griebel, Ulrike and Bowman, Dale D. and Bene, Edina and Long, Helen L. and Yoo, Hyunjoo and Ramsay, Gordon},
  year = {2020},
  month = may,
  volume = {30},
  pages = {R426-R427},
  issn = {09609822},
  doi = {10.1016/j.cub.2020.03.049},
  file = {/Users/megcychosz/Zotero/storage/4QBH74GA/Oller et al. - 2020 - Infant boys are more vocal than infant girls.pdf},
  journal = {Current Biology},
  language = {en},
  number = {10}
}

@article{ollerPhonologicalTranslationBilingual1998a,
  title = {Phonological Translation in Bilingual and Monolingual Children},
  author = {Oller, D. Kimbrough and {Cobo-Lewis}, Alan B. and Eilers, Rebecca E.},
  year = {1998},
  month = apr,
  volume = {19},
  pages = {259--278},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716400010067},
  abstract = {Bilingual children face a variety of challenges that their monolingual peers do not. For instance, switching between languages requires the phonological translation of proper names, a skill that requires mapping the phonemic units of one language onto the phonemic units of the other. Proficiency of phonological awareness has been linked to reading success, but little information is available about phonological awareness across multiple phonologies. Furthermore, the relationship between this kind of phonological awareness and reading has never been addressed. The current study investigated phonological translation using a task designed to measure children's ability to map one phonological system onto another. A total of 425 kindergarten and second grade monolingual and bilingual students were evaluated. The results suggest that monolinguals generally performed poorly. Bilinguals translated real names more accurately than fictitious names, in both directions. Correlations between phonological translation and measures of reading ability were moderate, but reliable. Phonological translation is proposed as a tool with which to evaluate phonological awareness through the perspective of children who live with two languages and two attendant phonemic systems.},
  file = {/Users/megcychosz/Zotero/storage/93QUNRYB/Oller et al. - 1998 - Phonological translation in bilingual and monoling.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {2}
}

@article{ollerPrecursorsSpeechInfancy1999,
  title = {Precursors to Speech in Infancy: {{The}} Prediction of Speech and Language Disorders},
  author = {Oller, D Kimbrough and Eilers, Rebecca E and Neal, A Rebecca and Schwartz, Heidi K},
  year = {1999},
  volume = {32},
  pages = {223--245},
  abstract = {Educational Objectives: The reader will become acquainted with four stages of vocal development in the first year of life; learn that during the canonical stage infants produce wellformed syllables that can function as words in languages; learn that the vast majority of infants enter the canonical stage by 10 months of age and that infants who are delayed in the onset are at extreme risk for hearing impairment and other speech and language-related disorders; find that parents almost always recognize the canonical stage when it occurs in infants; and become acquainted with evidence that an important screening for speech and language-related disorders can be conducted through a simple interview with parents of infants at 11 or 12 months of age.},
  file = {/Users/megcychosz/Zotero/storage/9DVH9GEB/Oller et al. - PRECURSORS TO SPEECH IN INFANCY THE PREDICTION OF.pdf},
  journal = {Journal of Communication Disorders},
  language = {en}
}

@article{ollerPretermFullTerm2019,
  title = {Preterm and Full Term Infant Vocalization and the Origin of Language},
  author = {Oller, D. Kimbrough and Caskey, Melinda and Yoo, Hyunjoo and Bene, Edina R. and Jhang, Yuna and Lee, Chia-Cheng and Bowman, Dale D. and Long, Helen L. and Buder, Eugene H. and Vohr, Betty},
  year = {2019},
  month = dec,
  volume = {9},
  pages = {14734},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-51352-0},
  file = {/Users/megcychosz/Zotero/storage/LI6HARDH/Oller et al. - 2019 - Preterm and full term infant vocalization and the .pdf},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@article{ollerRoleAuditionInfant1988,
  title = {The {{Role}} of {{Audition}} in {{Infant Babbling}}},
  author = {Oller, D Kimbrough and Eilers, Rebecca E},
  year = {1988},
  volume = {59},
  pages = {441--449},
  file = {/Users/megcychosz/Zotero/storage/7JLUCGSX/Oiler and Eilers - The Role of Audition in Infant Babbling.pdf},
  journal = {Child Development},
  language = {en},
  number = {2}
}

@article{ollerSpeechlikeVocalizationsInfancy1994,
  title = {Speech-like Vocalizations in Infancy: An Evaluation of Potential Risk Factors},
  shorttitle = {Speech-like Vocalizations in Infancy},
  author = {Oller, D. Kimbrough and Eilers, Rebecca E. and Steffens, Michele L. and Lynch, Michael P. and Urbano, Richard},
  year = {1994},
  month = feb,
  volume = {21},
  pages = {33--58},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000900008667},
  abstract = {This work reports longitudinal evaluation of the speech-like vocal development of infants born at risk due to prematurity or low socioeconomic status (SES) and infants not subject to such risk. Twenty infants were preterm (10 of low SES) and 33 were full term (16 of low SES), and all were studied from o;4 through 1 ;6. The study provides the indication that at-risk infants are not generally delayed in the ability to produce well-formed speech-like sounds as indicated in taperecorded vocal samples. At the same time, premature infants show a tendency to produce well-formed syllables less consistently than full terms after the point at which parents and laboratory personnel note the onset of the canonical babbling stage (the point after which well-formed syllables are well established in the infant vocal repertoires). Further, even though low SES infants produce well-formed speech-like structures on schedule, they show a reliably lower tendency to vocalize in general, as reflected by fewer utterances per minute in recorded samples.},
  file = {/Users/megcychosz/Zotero/storage/GFX6PSHJ/Oller et al. - 1994 - Speech-like vocalizations in infancy an evaluatio.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {1}
}

@misc{orenaHowWellParent2018,
  title = {How Well Do Parent Reports Reflect Their Bilingual Children's Language Environment?},
  author = {Orena, A.J. and {Byers-Heinlein}, K. and Polka, L.},
  year = {2018},
  month = jun,
  address = {{Philadelphia, PA}},
  type = {[Poster Presentation]}
}

@article{orenaReliabilityLanguageEnvironment2019,
  title = {Reliability of the {{Language Environment Analysis}} ({{LENA}}) in {{French}}-{{English Bilingual Speech}}},
  author = {Orena, Adriel John and {Byers-Heinlein}, Krista and Polka, Linda},
  year = {2019},
  volume = {67},
  pages = {2491--2500},
  doi = {10.31234/osf.io/3xcvu},
  abstract = {Purpose: This study examined the utility of the Language ENvironment Analysis (LENA) recording system for investigating the language input to bilingual infants. Method: Twenty-one French-English bilingual families with a 10-month-old infant participated in this study. Using the LENA recording system, each family contributed three full days of recordings within a one-month period. A portion of these recordings (945 minutes) were manually transcribed, and the word counts from these transcriptions were compared against the LENAgenerated adult word counts. Results: Data analyses reveal that the LENA algorithms were reliable in counting words in both Canadian English and Canadian French, even when both languages are present in the same recording. While the LENA system tended to underestimate the amount of speech in the recordings, there was a strong correlation between the LENA-generated and human transcribed adult word counts for each language. Importantly, this relationship holds when accounting for different-gendered and different-accented speech. Conclusions: The LENA recording system is a reliable tool for estimating word counts, even for bilingual input. Special considerations and limitations for using the LENA recording system in a bilingual population are discussed. These results open up possibilities for investigating caregiver talk to bilingual infants in more detail.},
  file = {/Users/megcychosz/Zotero/storage/KTX7YE8I/Orena et al. - Reliability of the Language Environment Analysis (.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {2}
}

@article{orenaWhatBilingualInfants2020,
  title = {What Do Bilingual Infants Actually Hear? {{Evaluating}} Measures of Language Input to Bilingual-learning 10-month-olds},
  shorttitle = {What Do Bilingual Infants Actually Hear?},
  author = {Orena, Adriel John and Byers-Heinlein, Krista and Polka, Linda},
  year = {2020},
  month = mar,
  volume = {23},
  pages = {1--14},
  issn = {1363-755X, 1467-7687},
  doi = {10.1111/desc.12901},
  abstract = {Examining how bilingual infants experience their dual language input is important for understanding bilingual language acquisition. To assess these language experiences, researchers typically conduct language interviews with caregivers. However, little is known about the reliability of these parent reports in describing how bilingual children actually experience dual language input. Here, we explored the quantitative nature of dual language input to bilingual infants. Furthermore, we described some of the heterogeneity of bilingual exposure in a sample of French\textendash English bilingual families. Participants were 21 families with a 10-month-old infant residing in Montr\'eal, Canada. First, we conducted language interviews with the caregivers. Then, each family completed three full-day recordings at home using the Language Environment Analysis recording system. Results showed that children's proportion exposure to each language was consistent across the two measurement approaches, indicating that parent reports are reliable for assessing a bilingual child's language experiences. Further exploratory analyses revealed three unique findings: (a) there can be considerable variability in the absolute amount of input among infants hearing the same proportion of input, (b) infants can hear different proportions of language input when considering infant-directed versus overheard speech, (c) proportion of language input can vary by day, depending on who is caring for the infant. We conclude that collecting naturalistic recordings is complementary to parent-report measures for assessing infant's language experiences and for establishing bilingual profiles.},
  file = {/Users/megcychosz/Zotero/storage/S32IAF3J/Orena et al. - 2020 - What do bilingual infants actually hear Evaluatin.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {2}
}

@article{oshannessyHowOrdinaryChild2020,
  title = {How Ordinary Child Language Acquisition Processes Can Lead to the Unusual Outcome of a Mixed Language},
  author = {O'Shannessy, Carmel},
  year = {2020},
  month = jun,
  pages = {1367006920924957},
  publisher = {{SAGE Publications Ltd}},
  issn = {1367-0069},
  doi = {10.1177/1367006920924957},
  abstract = {Aims and Objectives:The aim of this study is to examine the language processing mechanisms involved when young children bring structural innovations into their community way of speaking, as part of conventionalising code-switching practices to become a mixed language.Approach:The study takes a qualitative approach to the analysis of child language acquisition and adult speech data in two contexts.Data and Analysis:The study analyses naturalistic and spontaneous speech data of children and adults speaking the mixed language, Light Warlpiri, and adults older than that age group who do not speak the new mixed language. It compares an innovative auxiliary form in Light Warlpiri to child non-target speech in English with data taken from the Child Language Data Exchange System corpus.Findings:The findings are that the Light Warlpiri-speaking children used processes of re-analysis that are commonly found in child first language acquisition in other contexts to re-analyse elements of the verbal input, but because of the sociolinguistic context they created an innovative structure.Originality:The study is the first to directly compare processes of innovation in language contact with those of non-target structures in monolingual child language acquisition, identifying the same processes in each. It is also the first to show that a dramatic structural change from a linguistic perspective may be a small, incremental change from a child learner?s perspective.Significance/Implications:The significance of the study is that until now processes of innovation in language contact situations have been thought by many to differ in quality from those in monolingual child language acquisition contexts. This study shows that the child language acquisition processes are the same in each situation, but different sociolinguistic contexts lead to different outcomes for the communities? ways of speaking. It also shows that children do not bring in new structure that is not motivated by their input; rather, they make small changes to the input they receive.},
  file = {/Users/megcychosz/Zotero/storage/TF3TB59T/O’Shannessy - 2020 - How ordinary child language acquisition processes .pdf},
  journal = {International Journal of Bilingualism}
}

@article{oshannessyRoleCodeswitchedInput2012,
  title = {The Role of Codeswitched Input to Children in the Origin of a New Mixed Language},
  author = {O'Shannessy, Carmel},
  year = {2012},
  month = jan,
  volume = {50},
  doi = {10.1515/ling-2012-0011},
  abstract = {Light Warlpiri is a mixed language, with Warlpiri and Aboriginal English! Kriol as its sources. It was developed by a group who received codeswitched input in a baby talk register from when they were young. The innovating group conventionalized the input they received and developed morphosyntactic structures beyond those in the input. The development of Light Warlpiri shows that commonly occurring processes in language contact situations, codeswitching and re-analyses of existing forms, play an important role in the extreme outcome of the development of a mixed language, through a two-part process: a) an adult group directed codeswitched speech to children, and b) the children conventionalized and expanded the morphosyntactic structures they heard. The new code is an in-group language and did not emerge in order to indicate a new dual-cultural identity, but since its development it has come to signal the identity of young Warlpiri from Lajamanu.},
  file = {/Users/megcychosz/Zotero/storage/S4WJCJT5/O'Shannessy - 2012 - The role of codeswitched input to children in the .pdf},
  journal = {Linguistics}
}

@article{paceIdentifyingPathwaysSocioeconomic2017,
  title = {Identifying {{Pathways Between Socioeconomic Status}} and {{Language Development}}},
  author = {Pace, Amy and Luo, Rufan and {Hirsh-Pasek}, Kathy and Golinkoff, Roberta Michnick},
  year = {2017},
  month = jan,
  volume = {3},
  pages = {285--308},
  issn = {2333-9683, 2333-9691},
  doi = {10.1146/annurev-linguistics-011516-034226},
  abstract = {Children from low-income backgrounds consistently perform below their more advantaged peers on standardized measures of language ability, setting long-term trajectories that translate into gaps in academic achievement. Our primary goals in this review are to describe how and why this is so, in order to focus attention on ways to enrich early language experiences across socioeconomic strata. We first review the literature on the relation between socioeconomic status (SES) and language ability across domains in early childhood. We then identify three potential pathways by which SES might influence language development\textemdash child characteristics, parent\textendash child interaction, and availability of learning resources\textemdash recognizing the complicated interaction between the child's own language learning skill and his/her environmental support. Finally, we review interventions that target these three pathways with an eye toward best practice. Future research should focus on the diversity of contexts in which children acquire language and adopt methods of language measurement that are sensitive to cultural variation.},
  file = {/Users/megcychosz/Zotero/storage/KK22IUCU/Pace et al. - 2017 - Identifying Pathways Between Socioeconomic Status .pdf},
  journal = {Annual Review of Linguistics},
  language = {en},
  number = {1}
}

@article{parikhVocalizationPatternsYoung2018,
  title = {Vocalization Patterns in Young Children with {{Down}} Syndrome: {{Utilizing}} the Language Environment Analysis ({{LENA}}) to Inform Behavioral Phenotypes},
  shorttitle = {Vocalization Patterns in Young Children with {{Down}} Syndrome},
  author = {Parikh, Chandni and Mastergeorge, Ann M},
  year = {2018},
  month = dec,
  volume = {22},
  pages = {328--345},
  issn = {1744-6295, 1744-6309},
  doi = {10.1177/1744629517708091},
  abstract = {Children with Down syndrome (DS) are at higher risk for both delayed expressive language and poor speech intelligibility. The current study utilized the quantitative automated language environment analysis (LENA) to depict mother and child vocalizations and conversational patterns in the home of 43 children with DS, chronologically aged 24\textendash 64 months. Children with DS displayed fewer utterances than typically developing children; however, there was wide variability. Furthermore, children with DS did not show increased vocalization counts across their chronological ages. In contrast to previous findings, this study found that the mothers of children with DS had a reduced number of vocalizations. However, the vocalizations increased with age in comparison to mothers of typically developing children. Implications for targeted interventions that facilitate learning opportunities in bidirectional contexts for children with DS and their parents are discussed, with particular attention to quantify behavioral phenotypes utilizing a novel expressive language assessment tool.},
  file = {/Users/megcychosz/Zotero/storage/57TIA4SW/Parikh and Mastergeorge - 2018 - Vocalization patterns in young children with Down .pdf;/Users/megcychosz/Zotero/storage/8WIBANGP/Parikh&Mastergeorge_2017_notes.rtf},
  journal = {Journal of Intellectual Disabilities},
  language = {en},
  number = {4}
}

@article{parkAgeFullTimeUse2019,
  title = {Age at {{Full}}-{{Time Use Predicts Language Outcomes Better Than Age}} of {{Surgery}} in {{Children Who Use Cochlear Implants}}},
  author = {Park, Lisa R. and Gagnon, Erika B. and Thompson, Erin and Brown, Kevin D.},
  year = {2019},
  month = dec,
  volume = {28},
  pages = {986--992},
  issn = {1059-0889, 1558-9137},
  doi = {10.1044/2019_AJA-19-0073},
  abstract = {Purpose               The aims of this study were to (a) determine a metric for describing full-time use (FTU), (b) establish whether age at FTU in children with cochlear implants (CIs) predicts language at 3 years of age better than age at surgery, and (c) describe the extent of FTU and length of time it took to establish FTU in this population.                                         Method               This retrospective analysis examined receptive and expressive language outcomes at 3 years of age for 40  children with CIs. Multiple linear regression analyses were run with age at surgery and age at FTU as predictor variables. FTU definitions included 8 hr of device use and 80\% of average waking hours for a typically developing child. Descriptive statistics were used to describe the establishment and degree of FTU.                                         Results               Although 8 hr of daily wear is typically considered FTU in the literature, the 80\% hearing hours percentage metric accounts for more variability in outcomes. For both receptive and expressive language, age at FTU was found to be a better predictor of outcomes than age at surgery. It took an average of 17 months for children in this cohort to establish FTU, and only 52.5\% reached this milestone by the time they were 3 years old.                                         Conclusions               Children with normal hearing can access spoken language whenever they are awake, and the amount of time young children are awake increases with age. A metric that incorporates the percentage of time that children with CIs have access to sound as compared to their same-aged peers with normal hearing accounts for more variability in outcomes than using an arbitrary number of hours. Although early FTU is not possible without surgery occurring at a young age, device placement does not guarantee use and does not predict language outcomes as well as age at FTU.                        ,},
  file = {/Users/megcychosz/Zotero/storage/3XDS2FD8/Park et al. - 2019 - Age at Full-Time Use Predicts Language Outcomes Be.pdf},
  journal = {American Journal of Audiology},
  language = {en},
  number = {4}
}

@article{parraRelationsLanguageExposure2011,
  title = {Relations among {{Language Exposure}}, {{Phonological Memory}}, and {{Language Development}} in {{Spanish}}-{{English Bilingually}}-{{Developing Two}}-{{Year}}-{{Olds}}},
  author = {Parra, Marisol and Hoff, Erika and Core, Cynthia},
  year = {2011},
  month = jan,
  volume = {108},
  pages = {113--125},
  issn = {0022-0965},
  doi = {10.1016/j.jecp.2010.07.011},
  abstract = {The relation of phonological memory to language experience and development was investigated in 41 Spanish-English bilingual first language learners. The children's relative exposure to English and Spanish and phonological memory for English-like and Spanish-like nonwords were assessed at 22 months; their productive vocabulary and grammar in both languages were assessed at 25 months. Phonological memory for English- and Spanish-like nonwords were highly correlated, and each was related to vocabulary and grammar in both languages, suggesting a language-general component to phonological memory skill. In addition, there was evidence of language-specific benefits of language exposure to phonological memory skill and of language-specific benefits of phonological memory skill to language development.},
  file = {/Users/megcychosz/Zotero/storage/RQYLW3FD/Parra et al. - 2011 - Relations among Language Exposure, Phonological Me.pdf},
  journal = {Journal of experimental child psychology},
  number = {1},
  pmcid = {PMC4073230},
  pmid = {20828710}
}

@article{paterConstraintConflictCluster2003,
  title = {Constraint Conflict in Cluster Reduction {{Selections}} of This Material Were Presented in Talks at {{Cornell University}} and {{McGill University}}; at the {{Child Phonology Conference}}, {{Boston}}; the {{Boston University Conference}} on {{Language Development}}; {{Generative Linguistics}} in {{Poland}}, {{Warsaw}}, and the {{West Coast Conference}} on {{Formal Linguistics}}, {{Santa Cruz}}. {{Thanks}} to Participants at Those Events, as Well as {{Daniel Dinnsen}}, {{Heather Goad}}, {{Paul}} de {{Lacy}}, {{John McCarthy}}, {{Brigit}} van Der {{Pas}} and {{Carol Stoel}}-{{Gammon}} for Helpful Discussion. {{We}} Also Benefited from the Insightful Comments of Three Anonymous Reviewers. {{Some}} of the Data Presented Here Were Drawn from the Archives of a Large-Scale Longitudinal Study of Children with Phonological Delay Which Was Supported in Part by a Grant from the {{National Institutes}} of {{Health}} to {{Indiana University}}, {{DC01694}}. {{We}} Thank {{Daniel Dinnsen}} and {{Judith Gierut}} for Sharing Those Data with Us, as Well as {{A}}. {{J}}. {{Compton}} for Sharing the Other Data Presented Here. {{This}} Research Was Also Supported in Part by a Grant from the {{National Institutes}} of {{Health}} to {{San Diego State University}}, {{DC05754}}.},
  author = {Pater, Joe and Barlow, Jessica A.},
  year = {2003},
  month = aug,
  volume = {30},
  pages = {487--526},
  issn = {03050009, 14697602},
  doi = {10.1017/S0305000903005658},
  file = {/Users/megcychosz/Zotero/storage/W235VRUH/Pater and Barlow - 2003 - Constraint conflict in cluster reduction Selection.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {3}
}

@article{paterGenerativeLinguisticsNeural2019,
  title = {Generative Linguistics and Neural Networks at 60: {{Foundation}}, Friction, and Fusion},
  shorttitle = {Generative Linguistics and Neural Networks at 60},
  author = {Pater, Joe},
  year = {2019},
  issn = {1535-0665},
  doi = {10.1353/lan.2019.0005},
  file = {/Users/megcychosz/Zotero/storage/I7FTCJ4J/Pater - 2019 - Generative linguistics and neural networks at 60 .pdf},
  journal = {Language},
  language = {en}
}

@article{pattenVocalPatternsInfants2014,
  title = {Vocal {{Patterns}} in {{Infants}} with {{Autism Spectrum Disorder}}: {{Canonical Babbling Status}} and {{Vocalization Frequency}}},
  shorttitle = {Vocal {{Patterns}} in {{Infants}} with {{Autism Spectrum Disorder}}},
  author = {Patten, Elena and Belardi, Katie and Baranek, Grace T. and Watson, Linda R. and Labban, Jeffrey D. and Oller, D. Kimbrough},
  year = {2014},
  month = oct,
  volume = {44},
  pages = {2413--2428},
  issn = {0162-3257, 1573-3432},
  doi = {10.1007/s10803-014-2047-4},
  abstract = {Canonical babbling is a critical milestone for speech development and is usually well in place by 10 months. The possibility that infants with ASD show late onset of canonical babbling has so far eluded evaluation. Rate of vocalization or ``volubility'' has also been suggested as possibly aberrant in infants with ASD. We conducted a retrospective video study examining vocalizations of 37 infants at 9\textendash 12 and 15\textendash 18 months. Twenty-three of the 37 infants were later diagnosed with ASD and indeed produced low rates of canonical babbling and low volubility by comparison with the 14 typically developing infants. The study thus supports suggestions that very early vocal patterns may prove to be a useful component of early screening and diagnosis of ASD.},
  file = {/Users/megcychosz/Zotero/storage/56IHZXN9/Patten et al. - 2014 - Vocal Patterns in Infants with Autism Spectrum Dis.pdf},
  journal = {Journal of Autism and Developmental Disorders},
  language = {en},
  number = {10}
}

@inproceedings{pawarAutomaticAnalysisLENA2017,
  title = {Automatic Analysis of {{LENA}} Recordings for Language Assessment in Children Aged Five to Fourteen Years with Application to Individuals with Autism},
  booktitle = {2017 {{IEEE EMBS International Conference}} on {{Biomedical}} \& {{Health Informatics}} ({{BHI}})},
  author = {Pawar, Rahul and Albin, Aaron and Gupta, Udit and Rao, Hrishikesh and Carberry, Caroline and Hamo, Amarelle and Jones, Rebecca M. and Lord, Catherine and Clements, Mark A.},
  year = {2017},
  pages = {245--248},
  publisher = {{IEEE}},
  address = {{Orland, FL, USA}},
  doi = {10.1109/BHI.2017.7897251},
  abstract = {Detecting child and adult vocalizations, and computing their characteristics from audio recorded in natural home environments can be useful in many applications. The current study is interested in monitoring children with autism spectrum disorder to ultimately provide outcome measures that can track the efficacy of clinical treatments. In this paper, we show that it is possible to automate detection of child and adult vocalizations from audio recorded in controlled clinic environments as well as in naturalistic home settings. The results show both high precision and recall for children aged five to fourteen years who have been diagnosed with autism. Further, we describe a highly accurate speaker-independent laughter detector for this age group which will be useful for affect estimation.},
  file = {/Users/megcychosz/Zotero/storage/P43EQJH4/Pawar et al. - 2017 - Automatic analysis of LENA recordings for language.pdf},
  isbn = {978-1-5090-4179-4},
  language = {en}
}

@article{pearlPovertyStimulusTears,
  title = {Poverty of the {{Stimulus Without Tears}}},
  author = {Pearl, Lisa},
  pages = {48},
  abstract = {Poverty of the stimulus has been at the heart of ferocious and tear-filled debates at the nexus of psychology, linguistics, and philosophy for decades. This review is intended as a guide for readers without a formal linguistics or philosophy background, focusing on what poverty of the stimulus is and how it's been interpreted, which is traditionally where the tears have come in. I discuss poverty of the stimulus from the perspective of language development, highlighting how poverty of the stimulus relates to expectations about learning and the data available to learn from. I describe common interpretations of what poverty of the stimulus means when it occurs, and approaches for determining when poverty of the stimulus is in fact occurring. I close with illustrative examples of poverty of the stimulus in the domains of syntax, lexical semantics, and phonology, and discuss the value of identifying instances of poverty of the stimulus when it comes to understanding language development.},
  file = {/Users/megcychosz/Zotero/storage/W586GE7S/Pearl - Poverty of the Stimulus Without Tears.pdf},
  language = {en}
}

@article{pearlWhenDomainGeneralLearning2009,
  title = {When {{Domain}}-{{General Learning Fails}} and {{When It Succeeds}}: {{Identifying}} the {{Contribution}} of {{Domain Specificity}}},
  shorttitle = {When {{Domain}}-{{General Learning Fails}} and {{When It Succeeds}}},
  author = {Pearl, Lisa and Lidz, Jeffrey},
  year = {2009},
  month = sep,
  volume = {5},
  pages = {235--265},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475440902979907},
  file = {/Users/megcychosz/Zotero/storage/BCQKI93D/Pearl and Lidz - 2009 - When Domain-General Learning Fails and When It Suc.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {4}
}

@article{pearsonRelationInputFactors1997,
  title = {The Relation of Input Factors to Lexical Learning by Bilingual Infants},
  author = {Pearson, Barbara Z. and Fernandez, Sylvia C. and Lewedeg, Vanessa and Oller, D.Kimbrough},
  year = {1997},
  month = jan,
  volume = {18},
  pages = {41--58},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716400009863},
  abstract = {The bilingual child is seen as a unique source of information about the relation between input and intake. The strength of the association between language exposure estimates and vocabulary learning was examined for 25 simultaneous bilingual infants (ages 8 to 30 months) with differing patterns of exposure to the languages being learned. Using the MacArthur Communicative Development Inventories, standardized parent report forms in English and Spanish, the percentage of all words that were known in each language was calculated and then plotted against the estimates of language input (also in percentages). A significant correlation was found, r(25) = .82, p {$<$} .001. The correlation was also strong when examined pointby-point, even for children whose language environments changed by more than 2O"7o between observations, although it was not reliable at lower levels of exposure to Spanish. Especially for children with less input in the minority language, the factors which appeared to affect the strength of the association between input and amount learned in a language are discussed.},
  file = {/Users/megcychosz/Zotero/storage/LLWZ86AQ/Pearson et al. - 1997 - The relation of input factors to lexical learning .pdf;/Users/megcychosz/Zotero/storage/NIHEGAZ7/Pearson et al. - 1997 - The relation of input factors to lexical learning .pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {1}
}

@article{pelucchiStatisticalLearningNatural2009,
  title = {Statistical {{Learning}} in a {{Natural Language}} by 8-{{Month}}-{{Old Infants}}},
  author = {Pelucchi, Bruna and Hay, Jessica F. and Saffran, Jenny R.},
  year = {2009},
  volume = {80},
  pages = {674--685},
  issn = {1467-8624},
  doi = {10.1111/j.1467-8624.2009.01290.x},
  abstract = {Numerous studies over the past decade support the claim that infants are equipped with powerful statistical language learning mechanisms. The primary evidence for statistical language learning in word segmentation comes from studies using artificial languages, continuous streams of synthesized syllables that are highly simplified relative to real speech. To what extent can these conclusions be scaled up to natural language learning? In the current experiments, English-learning 8-month-old infants' ability to track transitional probabilities in fluent infant-directed Italian speech was tested (N = 72). The results suggest that infants are sensitive to transitional probability cues in unfamiliar natural language stimuli, and support the claim that statistical learning is sufficiently robust to support aspects of real-world language acquisition.},
  annotation = {\_eprint: https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8624.2009.01290.x},
  file = {/Users/megcychosz/Zotero/storage/86Y8LHY9/Pelucchi et al. - 2009 - Statistical Learning in a Natural Language by 8-Mo.pdf;/Users/megcychosz/Zotero/storage/5XAUACTI/j.1467-8624.2009.01290.html},
  journal = {Child Development},
  language = {en},
  number = {3}
}

@article{pengAssessingFineGrainedSpeech2019,
  title = {Assessing {{Fine}}-{{Grained Speech Discrimination}} in {{Young Children With Bilateral Cochlear Implants}}:},
  shorttitle = {Assessing {{Fine}}-{{Grained Speech Discrimination}} in {{Young Children With Bilateral Cochlear Implants}}},
  author = {Peng, Zhao Ellen and Hess, Christi and Saffran, Jenny R. and Edwards, Jan R. and Litovsky, Ruth Y.},
  year = {2019},
  month = mar,
  volume = {40},
  pages = {e191-e197},
  issn = {1531-7129},
  doi = {10.1097/MAO.0000000000002115},
  file = {/Users/megcychosz/Zotero/storage/G2XFELIJ/Peng et al. - 2019 - Assessing Fine-Grained Speech Discrimination in Yo.pdf},
  journal = {Otology \& Neurotology},
  language = {en},
  number = {3}
}

@article{perfettiPhonemicKnowledgeLearning1987,
  title = {Phonemic {{Knowledge}} and {{Learning}} to {{Read}} Are {{Reciprocal}}: {{A Longitudinal Study}} of {{First Grade Children}}},
  author = {Perfetti, Charles A and Beck, Isabel and Bell, Laura C and Hughes, Carol},
  year = {1987},
  volume = {33},
  pages = {283--319},
  file = {/Users/megcychosz/Zotero/storage/NJWZFUXG/Perfetti et al. - Phonemic Knowledge and Learning to Read are Recipr.pdf},
  journal = {Merrill-Palmer Quarterly},
  language = {en},
  number = {3}
}

@article{perkellFiveDecadesResearch2013,
  title = {Five {{Decades}} of {{Research}} in {{Speech Motor Control}}: {{What Have We Learned}}, and {{Where Should We Go From Here}}?},
  shorttitle = {Five {{Decades}} of {{Research}} in {{Speech Motor Control}}},
  author = {Perkell, Joseph S.},
  year = {2013},
  month = dec,
  volume = {56},
  pages = {1857--1874},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2013/12-0382)},
  abstract = {Purpose: The author presents a view of research in speech motor control over the past 5 decades, as observed from within Ken Stevens's Speech Communication Group (SCG) in the Research Laboratory of Electronics at MIT. Method: The author presents a limited overview of some important developments and discoveries. The perspective is based largely on the research interests of the Speech Motor Control Group (SMCG) within the SCG; thus, it is selective, focusing on normal motor control of the vocal tract in the production of sound segments and syllables. It also covers the particular theories and models that drove the research. Following a brief introduction, there are sections on methodological advances, scientific advances, and conclusions. Results: Scientific and methodological advances have been closely interrelated. Advances in instrumentation and computer hardware and software have made it possible to record and process increasingly large, multifaceted data sets; introduce new paradigms for feedback perturbation; image brain activity; and develop more sophisticated, computational physiological and neural models. Such approaches have led to increased understanding of the widespread variability in speech, motor-equivalent trading relations, sensory goals, and the nature of feedback and feedforward neural control mechanisms. Conclusions: Some ideas about important future directions for speech research are presented.},
  file = {/Users/megcychosz/Zotero/storage/XWSQX597/Perkell - 2013 - Five Decades of Research in Speech Motor Control .pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {6}
}

@book{perkellInvarianceVariabilitySpeech2014,
  title = {Invariance and Variability in Speech Processes},
  editor = {Perkell, Joseph S and Klatt, D.H.},
  year = {2014},
  publisher = {{Psychology Press}},
  address = {{New  York and London}}
}

@article{perkellMovementGoalsFeedback2012,
  title = {Movement Goals and Feedback and Feedforward Control Mechanisms in Speech Production},
  author = {Perkell, Joseph S.},
  year = {2012},
  month = sep,
  volume = {25},
  pages = {382--407},
  issn = {0911-6044},
  doi = {10.1016/j.jneuroling.2010.02.011},
  abstract = {Studies of speech motor control are described that support a theoretical framework in which fundamental control variables for phonemic movements are multi-dimensional regions in auditory and somatosensory spaces. Auditory feedback is used to acquire and maintain auditory goals and in the development and function of feedback and feedforward control mechanisms. Several lines of evidence support the idea that speakers with more acute sensory discrimination acquire more distinct goal regions and therefore produce speech sounds with greater contrast. Feedback modification findings indicate that fluently produced sound sequences are encoded as feedforward commands, and feedback control serves to correct mismatches between expected and produced sensory consequences.},
  file = {/Users/megcychosz/Zotero/storage/IHMJJ8WM/Perkell - 2012 - Movement goals and feedback and feedforward contro.pdf},
  journal = {Journal of neurolinguistics},
  number = {5},
  pmcid = {PMC3361736},
  pmid = {22661828}
}

@article{petersonControlMethodsUsed1952,
  title = {Control {{Methods Used}} in a {{Study}} of the {{Vowels}}},
  author = {Peterson, Gordon E and Barney, Harold L},
  year = {1952},
  volume = {24},
  pages = {175--184},
  file = {/Users/megcychosz/Zotero/storage/FN5PM4T4/Control Methods Used in a Study of the Vowels.pdf},
  journal = {Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@article{pettinatoVowelSpaceArea2016,
  title = {Vowel Space Area in Later Childhood and Adolescence: {{Effects}} of Age, Sex and Ease of Communication},
  shorttitle = {Vowel Space Area in Later Childhood and Adolescence},
  author = {Pettinato, Mich{\`e}le and Tuomainen, Outi and Granlund, Sonia and Hazan, Valerie},
  year = {2016},
  month = jan,
  volume = {54},
  pages = {1--14},
  issn = {00954470},
  doi = {10.1016/j.wocn.2015.07.002},
  abstract = {This study investigated vowel space area (VSA) development in childhood and adolescence and its impact on the ability to hyperarticulate vowels. In experiment 1, 96 participants aged 9\textendash 14 years carried out an interactive task when communication was easy (no barrier, `NB') and difficult (the speech of one participant was filtered through a vocoder, `VOC'). Previous recordings from 20 adults were used as reference. Measures of VSA (ERB2), F1 and F2 ranges (ERB) and articulation rate were obtained. Children's VSA were significantly larger than adults'. From the age of 11, vowel hyperarticulation was evident in VOC, but only because VSA were gradually reducing with age in NB. The results suggest that whilst large VSA do not prevent children from hyperarticulating vowels, the manner in which this is achieved may not be adult-like. Experiment 2 was conducted to verify that large VSA were not a by-product of children being unable to see each other. Thirteen participants carried out the same task faceto-face with their interlocutor. Comparisons to matched participants from experiment 1 showed no differences in VSA, indicating that the audio-only modality did not influence results. Possible reasons for larger VSA in the spontaneous speech of children and adolescents are discussed.},
  file = {/Users/megcychosz/Zotero/storage/A6H9IP2Y/Pettinato et al. - 2016 - Vowel space area in later childhood and adolescenc.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{peuteEarlyConsonantProduction,
  title = {Early Consonant Production in {{Tseltal}} and {{Y\'el\^i Dnye}}},
  author = {Peute, Bram and Casillas, Marisa},
  pages = {17},
  abstract = {Recent evidence shows that children reach expected basic linguistic milestones in two rural Indigenous communities, Tseltal and Y\'el\^i Dnye, despite infrequent exposure to child-directed speech. However, those results were partly based on vocal maturity measures that are fairly robust to environmental variation, e.g. the onset of babbling. Directed speech input has been traditionally linked to lexical development, which is by contrast environmentally sensitive. We investigate the relation between childdirected speech and early phonological development in these two communities, focussing on a phonological benchmark that links children's pre-lexical and early lexical development: the production of consonants. We find that, while Tseltal and Y\'el\^i children's canonical babble onset align with previously attested patterns, their early consonant acquisition shows some divergence from prior expectations. These preliminary results suggest that early consonant production may demonstrate greater environmental sensitivity than canonical babble, possibly via similar mechanisms that link linguistic input and lexical development.},
  file = {/Users/megcychosz/Zotero/storage/9EELE6AP/Peute et al. - Early consonant production in Tseltal and Yélî Dny.pdf},
  language = {en}
}

@article{pfeilerRECONSTRUCCIONADQUISICIONFONOLOGICA,
  title = {{LA RECONSTRUCCI\'ON DE LA ADQUISICI\'ON FONOL\'OGICA DEL PROTO-MAYA}},
  author = {Pfeiler, Barbara and Pye, Clifton and Mateo, Pedro and Stengel, Donald},
  pages = {20},
  file = {/Users/megcychosz/Zotero/storage/MFVHISEC/Pfeiler et al. - LA RECONSTRUCCIÓN DE LA ADQUISICIÓN FONOLÓGICA DEL.pdf},
  language = {es}
}

@article{pharrSyllableStructureDevelopment2000,
  title = {Syllable Structure Development of Toddlers with Expressive Specific Language Impairment},
  author = {Pharr, Aim{\'e}e Baird and Ratner, Nan Bernstein and Rescorla, Leslie},
  year = {2000},
  month = dec,
  volume = {21},
  pages = {429--449},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S014271640000401X},
  abstract = {A total of 35 children \textendash{} 20 with expressive specific language impairment (SLI-E) and 15 typically developing (TD) peers \textendash{} were compared longitudinally from 24 to 36 months with respect to their production of syllable shapes in 10-minute spontaneous speech samples. SLI-E 24-month-olds predominantly produced earlier developing syllable shapes containing vowels, liquids, and glides. TD 24-month-olds and SLI-E 36-month-olds produced approximately the same proportion of syllable types, with the exception of consonant clusters, where TD 24-month-olds produced more than SLI-E 36-month-olds. TD children at 36 months showed the greatest use of syllable shapes containing two different consonants and consonant clusters. Detailed analyses revealed that SLI-E children produced fewer syllable shapes containing final consonants, more than one consonant type, and consonant clusters. Furthermore, the children with SLI-E were found to vocalize less often than their TD peers. The possible relationships between these findings, SLI-E children's concomitant deficits in morphology and syntax, and the implications for diagnosis and remediation are discussed.},
  file = {/Users/megcychosz/Zotero/storage/S444R3EH/Pharr et al. - 2000 - Syllable structure development of toddlers with ex.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {4}
}

@article{philippsenGoalDirectedExplorationLearning2021,
  title = {Goal-{{Directed Exploration}} for {{Learning Vowels}} and {{Syllables}}: {{A Computational Model}} of {{Speech Acquisition}}},
  shorttitle = {Goal-{{Directed Exploration}} for {{Learning Vowels}} and {{Syllables}}},
  author = {Philippsen, Anja},
  year = {2021},
  month = mar,
  volume = {35},
  pages = {53--70},
  issn = {0933-1875, 1610-1987},
  doi = {10.1007/s13218-021-00704-y},
  abstract = {Infants learn to speak rapidly during their first years of life, gradually improving from simple vowel-like sounds to larger consonant-vowel complexes. Learning to control their vocal tract in order to produce meaningful speech sounds is a complex process which requires to learn the relationship between motor and sensory processes. In this paper, a computational framework is proposed that models the problem of learning articulatory control for a physiologically plausible 3-D vocal tract model using a developmentally-inspired approach. The system babbles and explores efficiently in a low-dimensional space of goals that are relevant to the learner in its synthetic environment. The learning process is goal-directed and selforganized, and yields an inverse model of the mapping between sensory space and motor commands. This study provides a unified framework that can be used for learning static as well as dynamic motor representations. The successful learning of vowel and syllable sounds as well as the benefit of active and adaptive learning strategies are demonstrated. Categorical perception is found in the acquired models, suggesting that the framework has the potential to replicate phenomena of human speech acquisition.},
  file = {/Users/megcychosz/Zotero/storage/69LRNIRV/Philippsen - 2021 - Goal-Directed Exploration for Learning Vowels and .pdf},
  journal = {KI - K\"unstliche Intelligenz},
  language = {en},
  number = {1}
}

@article{pierceVariationsPhonologicalWorking2017,
  title = {Variations in Phonological Working Memory: {{Linking}} Early Language Experiences and Language Learning Outcomes},
  shorttitle = {Variations in Phonological Working Memory},
  author = {Pierce, Lara J. and Genesee, Fred and Delcenserie, Audrey and Morgan, Gary},
  year = {2017},
  month = nov,
  volume = {38},
  pages = {1265--1300},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716417000236},
  abstract = {ABSTRACT             In order to build complex language from perceptual input, children must have access to a powerful information processing system that can analyze, store, and use regularities in the signal to which the child is exposed. In this article, we propose that one of the most important parts of this underlying machinery is the linked set of cognitive and language processing components that comprise the child's developing working memory (WM). To examine this hypothesis, we explore how variations in the timing, quality, and quantity of language input during the earliest stages of development are related to variations in WM, especially phonological WM (PWM), and in turn language learning outcomes. In order to tease apart the relationships between early language experience, WM, and language development, we review research findings from studies of groups of language learners who clearly differ with respect to these aspects of input. Specifically, we consider the development of PWM in children with delayed exposure to language, that is, children born profoundly deaf and exposed to oral language following cochlear implantation and internationally adopted children who have delayed exposed to the adoption language; children who experience impoverished language input, that is, children who experience early bouts of otitis media and signing deaf children born to nonsigning hearing parents; and children with enriched early language input, that is, simultaneous bilinguals and second language learners.},
  file = {/Users/megcychosz/Zotero/storage/G2WGKIY9/Pierce et al. - 2017 - Variations in phonological working memory Linking.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {6}
}

@article{pierrehumbertPhoneticDiversityStatistical2003,
  title = {Phonetic {{Diversity}}, {{Statistical Learning}}, and {{Acquisition}} of {{Phonology}}},
  author = {Pierrehumbert, Janet B.},
  year = {2003},
  month = jun,
  volume = {46},
  pages = {115--154},
  issn = {0023-8309, 1756-6053},
  doi = {10.1177/00238309030460020501},
  file = {/Users/megcychosz/Zotero/storage/68EILLKH/Pierrehumbert - 2003 - Phonetic Diversity, Statistical Learning, and Acqu.pdf},
  journal = {Language and Speech},
  language = {en},
  number = {2-3}
}

@article{pierrehumbertPhonologicalRepresentationAbstract2016,
  title = {Phonological Representation: {{Beyond}} Abstract versus Episodic.},
  author = {Pierrehumbert, Janet B},
  year = {2016},
  volume = {2},
  pages = {33--52},
  file = {/Users/megcychosz/Zotero/storage/RWMVLQV7/Pierrehumbert - Phonological representation Beyond abstract versu.pdf;/Users/megcychosz/Zotero/storage/SGJ6WNFJ/Pierrehumbert - Phonological representation Beyond abstract versu.pdf},
  journal = {Annual Review of Linguistics},
  language = {en}
}

@article{pinkerFutureTense2002,
  title = {The Past and Future of the Past Tense},
  author = {Pinker, Steven and Ullman, Michael T.},
  year = {2002},
  month = nov,
  volume = {6},
  pages = {456--463},
  issn = {13646613},
  doi = {10.1016/S1364-6613(02)01990-3},
  file = {/Users/megcychosz/Zotero/storage/QQAW92K9/Pinker and Ullman - 2002 - The past and future of the past tense.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {11}
}

@incollection{pinkerRegularIrregularMorphology1994,
  title = {Regular and Irregular Morphology and the Psychological Status of Rules of Grammar},
  booktitle = {The {{Reality}} of {{Linguistic Rules}}},
  author = {Pinker, Steven and Prince, A.},
  editor = {Lima, Susan. D. and Corrigan, Roberta L. and Iverson, Gregory K.},
  year = {1994},
  pages = {321--351},
  publisher = {{John Benjamins Publishing Company}},
  address = {{Amsterdam/Philadelphia}}
}

@article{pisaniHumanSubjectsProtection2016,
  title = {Human {{Subjects Protection}} and {{Technology}} in {{Prevention Science}}: {{Selected Opportunities}} and {{Challenges}}},
  shorttitle = {Human {{Subjects Protection}} and {{Technology}} in {{Prevention Science}}},
  author = {Pisani, Anthony R. and Wyman, Peter A. and Mohr, David C. and Perrino, Tatiana and Gallo, Carlos and Villamar, Juan and Kendziora, Kimberly and Howe, George W. and Sloboda, Zili and Brown, C. Hendricks},
  year = {2016},
  month = aug,
  volume = {17},
  pages = {765--778},
  issn = {1389-4986, 1573-6695},
  doi = {10.1007/s11121-016-0664-1},
  file = {/Users/megcychosz/Zotero/storage/8H44FT3W/Pisani et al. - 2016 - Human Subjects Protection and Technology in Preven.pdf},
  journal = {Prevention Science},
  language = {en},
  number = {6}
}

@article{pisoniSpeechPerceptionWord1985,
  title = {Speech Perception, Word Recognition and the Structure of the Lexicon},
  author = {Pisoni, David B. and Nusbaum, Howard C. and Luce, Paul A. and Slowiaczek, Louisa M.},
  year = {1985},
  month = aug,
  volume = {4},
  pages = {75--95},
  issn = {01676393},
  doi = {10.1016/0167-6393(85)90037-8},
  abstract = {This paper reports the results of three projects concerned with auditory word recognition and the structure of the lexicon. The first project was designed to experimentally test several specific predictions derived from MACS, a simulation model of the Cohort Theory of word recognition. Using a priming paradigm, evidence was obtained for acoustic-phonetic activation in word recognition in three experiments. The second project describes the results of analyses of the structure and distribution of words in the lexicon using a large lexical database. Statistics about similarity spaces for high and low frequency words were applied to previously published data on the intelligibility of words presented in noise. Differences in identification were shown to be related to structural factors about the specific words and the distribution of similar words in their neighborhoods. Finally, the third project describes efforts at developing a new theory of word recognition known as Phonetic Refinement Theory. The theory is based on findings from human listeners and was designed to incorporate some of the detailed acoustic-phonetic and phonotactic knowledge that human listeners have about the internal structure of words and the organization of words in the lexicon, and how, they use this knowledge in word recognition. Taken together, the results of these projects demonstrate a number of new and important findings about the relation between speech perception and auditory word recognition, two areas of research that have traditionally been approached from quite different perspectives in the past.},
  file = {/Users/megcychosz/Zotero/storage/SMRDBF3G/Pisoni et al. - 1985 - Speech perception, word recognition and the struct.pdf},
  journal = {Speech Communication},
  language = {en},
  number = {1-3}
}

@book{pittBuckeyeCorpusConversational2007,
  title = {Buckeye {{Corpus}} of {{Conversational Speech}}},
  author = {Pitt, M.A. and Dilley, L. and Johnson, Keith and Kiesling, S. and Raymond, W. and Hume, E. and {Fosler-Lussier}, E.},
  year = {2007},
  edition = {2nd release},
  publisher = {{The Ohio State University: Department of Psychology}},
  address = {{Columbus, OH}}
}

@article{placeEffectsNoneffectsInput2016,
  title = {Effects and Noneffects of Input in Bilingual Environments on Dual Language Skills in 2 {$\frac{1}{2}$}-Year-Olds},
  author = {Place, Silvia and Hoff, Erika},
  year = {2016},
  month = nov,
  volume = {19},
  pages = {1023--1041},
  issn = {1366-7289, 1469-1841},
  doi = {10.1017/S1366728915000322},
  abstract = {Recent findings suggest some properties of input in dual-language environments that influence its value for bilingual development, but the extant data base is small and sometimes inconclusive. The present study sought additional evidence regarding three quality indicators: the percent of input provided by native speakers, the number of different speakers providing input, and the frequency of language mixing. Participants were 90 thirty-month-olds exposed to Spanish and English. Using the Language Diary method to assess input and using multiple measures of children's bilingual skills, results replicated previous findings that the percent of input provided by native speakers is a positive quality indicator and found suggestive evidence that the number of speakers is also a positive quality indicator. There was little evidence that the frequency of language mixing is a negative indicator. These findings advance understanding of sources of variability in bilingual outcomes and have implications for programs to support bilingual development.},
  file = {/Users/megcychosz/Zotero/storage/BD4FNFAR/Place and Hoff - 2016 - Effects and noneffects of input in bilingual envir.pdf},
  journal = {Bilingualism: Language and Cognition},
  language = {en},
  number = {5}
}

@article{placePropertiesDualLanguage2011,
  title = {Properties of {{Dual Language Exposure That Influence}} 2-{{Year}}-{{Olds}}' {{Bilingual Proficiency}}: {{Dual Language Exposure}} and {{Bilingual Proficiency}}},
  shorttitle = {Properties of {{Dual Language Exposure That Influence}} 2-{{Year}}-{{Olds}}' {{Bilingual Proficiency}}},
  author = {Place, Silvia and Hoff, Erika},
  year = {2011},
  month = nov,
  volume = {82},
  pages = {1834--1849},
  issn = {00093920},
  doi = {10.1111/j.1467-8624.2011.01660.x},
  file = {/Users/megcychosz/Zotero/storage/95CKN8VG/Place and Hoff - 2011 - Properties of Dual Language Exposure That Influenc.pdf},
  journal = {Child Development},
  language = {en},
  number = {6}
}

@article{plagHomophonyMorphologyAcoustics2017,
  title = {Homophony and Morphology: {{The}} Acoustics of Word-Final {{S}} in {{English}}},
  shorttitle = {Homophony and Morphology},
  author = {Plag, Ingo and Homann, Julia and Kunter, Gero},
  year = {2017},
  month = feb,
  volume = {53},
  pages = {181--216},
  issn = {0022-2267, 1469-7742},
  doi = {10.1017/S0022226715000183},
  file = {/Users/megcychosz/Zotero/storage/E9Z3RU22/Plag et al. - 2017 - Homophony and morphology The acoustics of word-fi.pdf},
  journal = {Journal of Linguistics},
  language = {en},
  number = {01}
}

@article{plagITPLURALGENITIVEPLURAL,
  title = {{{AN}} {$<$}{{S}}{$>$} {{IS AN}} {$<$}{{S}}'{$>$}, {{OR IS IT}}? {{PLURAL AND GENITIVE}}-{{PLURAL ARE NOT HOMOPHONOUS}}},
  author = {Plag, Ingo and Hedia, Sonia Ben and Lohmann, Arne and Zimmermann, Julia},
  pages = {37},
  file = {/Users/megcychosz/Zotero/storage/P99F3ED2/Plag et al. - AN S IS AN S’, OR IS IT PLURAL AND GENITIVE-P.pdf},
  language = {en}
}

@article{plagPhoneticsNewlyDerived2018,
  title = {The Phonetics of Newly Derived Words: {{Testing}} the Effect of Morphological Segmentability on Affix Duration},
  author = {Plag, I and Ben Hedia, Sonia},
  year = {2018},
  pages = {93--116},
  file = {/Users/megcychosz/Zotero/storage/K9DVV8M6/1002605.pdf}
}

@article{plagPhonologicalPhoneticVariability2014,
  title = {Phonological and Phonetic Variability in Complex Words: {{An}} Uncharted Territory},
  author = {Plag, Ingo},
  year = {2014},
  volume = {26},
  pages = {209--228},
  file = {/Users/megcychosz/Zotero/storage/DZAK2YGD/Plag - Phonological and phonetic variability in complex w.pdf},
  journal = {Rivista di Linguistica},
  language = {en},
  number = {2}
}

@book{plazaQhichwaSimipSimi2015,
  title = {Qhichwa {{Simip Simi Pirwan}}, {{Diccionario}} de La {{Naci\'on Quechua}}},
  author = {Plaza, P. Martinez},
  year = {2015},
  publisher = {{Consejo Educativo de la Naci\'on Quechua "CENAQ"}}
}

@phdthesis{plummerAcquisitionVowelNormalization2014,
  title = {The {{Acquisition}} of {{Vowel Normalization}} during {{Early Infancy}}: {{Theory}} and {{Computational Framework}}},
  author = {Plummer, Andrew},
  year = {2014},
  school = {The Ohio State University},
  type = {Dissertation}
}

@book{plummerAcquisitionVowelNormalization2014a,
  title = {The {{Acquisition}} of {{Vowel Normalization}} during {{Early Infancy}}: {{Theory}} and {{Computational Framework}}},
  author = {Plummer, A.},
  year = {2014},
  publisher = {{The Ohio State University}},
  address = {{Columbus, OH}}
}

@article{plummerFramingSocioindexicalBasis2015,
  title = {Framing a Socio-Indexical Basis for the Emergence and Cultural Transmission of Phonological Systems},
  author = {Plummer, Andrew R. and Beckman, Mary E.},
  year = {2015},
  month = nov,
  volume = {53},
  pages = {66--78},
  issn = {00954470},
  doi = {10.1016/j.wocn.2015.09.004},
  abstract = {Moulin-Frier et al. (2016) pro{$\carriagereturn$}er a conceptual framework and computational modeling architecture for the investigation of the emergence of phonological universals for spoken languages. They validate the framework and architecture by testing to see whether universals such as the prevalence of triangular vowel systems that show adequate dispersion in the F1-F2-F3 space can fall out of simulations of referential communication between social agents, without building principles such as dispersion directly into the model. In this paper, we examine the assumptions underlying the framework, beginning with the assumption that it is such substantive universals that are in need of explanation rather than the rich diversity of phonological systems observed across human cultures and the compositional (``prosodic'') structure that characterizes signed as well as spoken languages. Also, when emergence is construed at the time-scales of the biological evolution of the species and of the cultural evolution of distinct speech communities, it is the a liative or a{$\carriagereturn$}ective rather than the referential function that has the greater significance for our understanding of how phonological systems can emerge de novo in ontogeny.},
  file = {/Users/megcychosz/Zotero/storage/EEKFC4TU/Plummer and Beckman - 2015 - Framing a socio-indexical basis for the emergence .pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@incollection{pluymaekersMorphologicalEffectsFine2010,
  title = {Morphological Effects on Fine Phonetic Detail: {{The}} Case of {{Dutch}} -Igheid},
  shorttitle = {Morphological Effects on Fine Phonetic Detail},
  booktitle = {Laboratory {{Phonology}}},
  author = {Pluymaekers, Mark and Ernestus, Mirjam and Baayen, R. Harald and Booij, Geert},
  year = {2010},
  month = jan,
  volume = {10},
  pages = {511--531},
  doi = {10.1515/9783110224917.5.511},
  abstract = {This study investigated the role of morphological structure in explaining pronunciation variation. The focus was on the Dutch derivational suffix -igheid (//), which occurs in two types of words. In the first type, -igheid is analyzed as a single suffix. In the second type, there is a morphological boundary between -ig and -heid. The main research question was whether this difference is reflected in the duration of the // cluster. Two hypotheses were distinguished: one based on prosodic structure, which predicts that the cluster is shorter in the first type than in the second type, and one based on the informativeness of the affix given the morphological paradigm, which makes the opposite prediction. All occurrences of -igheid in a corpus of read speech were acoustically analyzed using Automatic Speech Recognition technology. The duration of the // cluster was found to be shorter in words of the second type than in words of the first type. This can be explained by the observation that words of the second type have sparser morphological paradigms, making the cluster less informative with respect to word identity. Furthermore, this finding shows that morphological effects on fine phonetic detail cannot always be explained by prosodic structure.},
  file = {/Users/megcychosz/Zotero/storage/ADPBSJF3/Fougeron et al. - 2010 - Morphological effects on fine phonetic detail The.pdf},
  language = {en}
}

@article{politzer-ahlesVisualizingPhoneticData2018,
  title = {On Visualizing Phonetic Data from Repeated Measures Experiments with Multiple Random Effects},
  author = {{Politzer-Ahles}, Stephen and Piccinini, Page},
  year = {2018},
  month = sep,
  volume = {70},
  pages = {56--69},
  issn = {00954470},
  doi = {10.1016/j.wocn.2018.05.002},
  abstract = {In recent years, phonetic sciences has hosted several debates about the best way to statistically analyze data. The main discussion has been about moving away from analyses of variance (ANOVAs) to linear mixed effects models. Mixed models have the advantage both of allowing for including all data points produced by a participant (instead of computing means for each participant) and accounting for both by-participant and by-item variance. However, plotting of data has not always followed this trend. Often researchers plot participant means and standard error (as based on the number of participants), which, while potentially representative of the data used for an ANOVA, do not match the data used for a mixed effects model. The present paper discusses the shortcomings of traditional data visualization practices, solutions to these shortcomings that have been discussed in recent years, and the special challenges that come with trying to extend these solutions to phonetic data with crossed (withinparticipant and within-item) designs. For each of the problems discussed, we provide examples with simulated data to demonstrate how different plotting techniques can correctly, or incorrectly, represent the underlying structure of data. Ultimately we conclude that there is no single type of plot that can show everything one needs to know about this type of data, and we advocate for an approach that involves using different types of plots throughout data analysis, and making data publicly available.},
  file = {/Users/megcychosz/Zotero/storage/Z233J9YR/Politzer-Ahles and Piccinini - 2018 - On visualizing phonetic data from repeated measure.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{polkaSegmentingWordsFluent2017,
  title = {Segmenting Words from Fluent Speech during Infancy - Challenges and Opportunities in a Bilingual Context},
  author = {Polka, Linda and Orena, Adriel John and Sundara, Megha and Worrall, Jennifer},
  year = {2017},
  month = jan,
  volume = {20},
  pages = {e12419},
  issn = {1363755X},
  doi = {10.1111/desc.12419},
  abstract = {Previous research shows that word segmentation is a language-specific skill. Here, we tested segmentation of bi-syllabic words in two languages (French; English) within the same infants in a single test session. In Experiment 1, monolingual 8-month-olds (French; English) segmented bi-syllabic words in their native language, but not in an unfamiliar and rhythmically different language. In Experiment 2, bilingual infants acquiring French and English demonstrated successful segmentation for French when it was tested first, but not for English and not for either language when tested second. There were no effects of language exposure on this pattern of findings. In Experiment 3, bilingual infants segmented the same English materials used in Experiment 2 when they were tested using the standard segmentation procedure, which provided more exposure to the test stimuli. These findings show that segmenting words in both their native languages in the dual-language task poses a distinct challenge for bilingual 8-month-olds acquiring French and English. Further research exploring early word segmentation will advance our understanding of bilingual acquisition and expand our fundamental knowledge of language and cognitive development.},
  file = {/Users/megcychosz/Zotero/storage/56TT8882/Polka et al. - 2017 - Segmenting words from fluent speech during infancy.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {1}
}

@article{polkaWhoTalkingNow2014,
  title = {Who's {{Talking Now}}? {{Infants}}' {{Perception}} of {{Vowels With Infant Vocal Properties}}},
  shorttitle = {Who's {{Talking Now}}?},
  author = {Polka, Linda and Masapollo, Matthew and M{\'e}nard, Lucie},
  year = {2014},
  month = jul,
  volume = {25},
  pages = {1448--1456},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797614533571},
  abstract = {Little is known about infants' abilities to perceive and categorize their own speech sounds or vocalizations produced by other infants. In the present study, prebabbling infants were habituated to /i/ (``ee'') or /a/ (``ah'') vowels synthesized to simulate men, women, and children, and then were presented with new instances of the habituation vowel and a contrasting vowel on different trials, with all vowels simulating infant talkers. Infants showed greater recovery of interest to the contrasting vowel than to the habituation vowel, which demonstrates recognition of the habituationvowel category when it was produced by an infant. A second experiment showed that encoding the vowel category and detecting the novel vowel required additional processing when infant vowels were included in the habituation set. Despite these added cognitive demands, infants demonstrated the ability to track vowel categories in a multitalker array that included infant talkers. These findings raise the possibility that young infants can categorize their own vocalizations, which has important implications for early vocal learning.},
  file = {/Users/megcychosz/Zotero/storage/YTWGMDQW/Polka et al. - 2014 - Who’s Talking Now Infants’ Perception of Vowels W.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {7}
}

@article{polonenkoLimitingAsymmetricHearing2018,
  title = {Limiting Asymmetric Hearing Improves Benefits of Bilateral Hearing in Children Using Cochlear Implants},
  author = {Polonenko, Melissa Jane and Papsin, Blake Croll and Gordon, Karen Ann},
  year = {2018},
  month = dec,
  volume = {8},
  pages = {13201},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-31546-8},
  file = {/Users/megcychosz/Zotero/storage/LEYB9TB8/Polonenko et al. - 2018 - Limiting asymmetric hearing improves benefits of b.pdf},
  journal = {Scientific Reports},
  language = {en},
  number = {1}
}

@article{potterBilingualToddlersComprehension2019,
  title = {Bilingual Toddlers' Comprehension of Mixed Sentences Is Asymmetrical across Their Two Languages},
  author = {Potter, Christine E. and Fourakis, Eva and {Morin-Lessard}, Elizabeth and {Byers-Heinlein}, Krista and {Lew-Williams}, Casey},
  year = {2019},
  month = jul,
  volume = {22},
  pages = {e12794},
  issn = {1363755X},
  doi = {10.1111/desc.12794},
  abstract = {In bilingual language environments, infants and toddlers listen to two separate languages during the same key years that monolingual children listen to just one and bilinguals rarely learn each of their two languages at the same rate. Learning to understand language requires them to cope with challenges not found in monolingual input, notably the use of two languages within the same utterance (e.g., Do you like the perro? or \textquestiondown Te gusta el doggy?). For bilinguals of all ages, switching between two languages can reduce the efficiency in real-time language processing. But language switching is a dynamic phenomenon in bilingual environments, presenting the young learner with many junctures where comprehension can be derailed or even supported. In this study, we tested 20 Spanish\textendash English bilingual toddlers (18- to 30months) who varied substantially in language dominance. Toddlers' eye movements were monitored as they looked at familiar objects and listened to single-language and mixed-language sentences in both of their languages. We found asymmetrical switch costs when toddlers were tested in their dominant versus non-dominant language, and critically, they benefited from hearing nouns produced in their dominant language, independent of switching. While bilingualism does present unique challenges, our results suggest a united picture of early monolingual and bilingual learning. Just like monolinguals, experience shapes bilingual toddlers' word knowledge, and with more robust representations, toddlers are better able to recognize words in diverse sentences.},
  file = {/Users/megcychosz/Zotero/storage/ABEN9V99/Potter et al. - 2019 - Bilingual toddlers’ comprehension of mixed sentenc.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {4}
}

@article{poulin-duboisEffectsBilingualismToddlers2011,
  title = {The Effects of Bilingualism on Toddlers' Executive Functioning},
  author = {{Poulin-Dubois}, Diane and Blaye, Agnes and Coutya, Julie and Bialystok, Ellen},
  year = {2011},
  month = mar,
  volume = {108},
  pages = {567--579},
  issn = {00220965},
  doi = {10.1016/j.jecp.2010.10.009},
  abstract = {Bilingual children have been shown to outperform monolingual children on tasks measuring executive functioning skills. This advantage is usually attributed to bilinguals' extensive practice in exercising selective attention and cognitive flexibility during language use because both languages are active when one of them is being used. We examined whether this advantage is observed in 24-month-olds who have had much less experience in language production. A battery of executive functioning tasks and the cognitive scale of the Bayley test were administered to 63 monolingual and bilingual children. Native bilingual children performed significantly better than monolingual children on the Stroop task, with no difference between groups on the other tasks, confirming the specificity of bilingual effects to conflict tasks reported in older children. These results demonstrate that bilingual advantages in executive control emerge at an age not previously shown.},
  file = {/Users/megcychosz/Zotero/storage/6QWLC62Y/Poulin-Dubois et al. - 2011 - The effects of bilingualism on toddlers’ executive.pdf},
  journal = {Journal of Experimental Child Psychology},
  language = {en},
  number = {3}
}

@article{pratherArticulationDevelopmentChildren1975,
  title = {Articulation Development in Children Aged Two to Four Years},
  author = {Prather, Elizabeth and Dona Lee, Hedrick and Kern, Carolyn A.},
  year = {1975},
  volume = {40},
  pages = {179--191},
  abstract = {The articulation skills of 147 children aged 24 to 48 months were tested and the results compared with earlier classical studies and distinctive feature development. The results of the present study indicate consistently earlier age levels for the cor- recl sound and feature usage than the previous studies, though the general sequences of development are strikingly similar in all studies.},
  file = {/Users/megcychosz/Zotero/storage/9YCED7DJ/Yantis - iurnal of speech and hearing disorders.pdf},
  journal = {Journal of Speech and Hearning Disorders},
  language = {en}
}

@article{pressmanMaternalSensitivityPredicts1999,
  title = {Maternal Sensitivity Predicts Language Gain in Preschool Children Who Are Deaf and Hard of Hearing},
  author = {Pressman, L},
  year = {1999},
  month = dec,
  volume = {4},
  pages = {294--304},
  issn = {14657325},
  doi = {10.1093/deafed/4.4.294},
  file = {/Users/megcychosz/Zotero/storage/LIKNXA4H/Pressman - 1999 - Maternal sensitivity predicts language gain in pre.pdf},
  journal = {Journal of Deaf Studies and Deaf Education},
  language = {en},
  number = {4}
}

@article{prestonRemediatingResidualRhotic2019a,
  title = {Remediating {{Residual Rhotic Errors With Traditional}} and {{Ultrasound}}-{{Enhanced Treatment}}: {{A Single}}-{{Case Experimental Study}}},
  shorttitle = {Remediating {{Residual Rhotic Errors With Traditional}} and {{Ultrasound}}-{{Enhanced Treatment}}},
  author = {Preston, Jonathan L. and McAllister, Tara and Phillips, Emily and Boyce, Suzanne and Tiede, Mark and Kim, Jackie Sihyun and Whalen, Douglas H.},
  year = {2019},
  month = aug,
  volume = {28},
  pages = {1167--1183},
  issn = {1058-0360, 1558-9110},
  doi = {10.1044/2019_AJSLP-18-0261},
  abstract = {Purpose               The aim of the study was to examine how ultrasound visual feedback (UVF) treatment impacts speech sound learning in children with residual speech errors affecting /{$\Elztrnr$}/.                                         Method               Twelve children, ages 9\textendash 14 years, received treatment for vocalic /{$\Elztrnr$}/ errors in a multiple-baseline across-subjects design comparing 8 sessions of UVF treatment and 8 sessions of traditional (no-biofeedback) treatment. All participants were exposed to both treatment conditions, with order counterbalanced across participants. To monitor progress, na\"ive listeners rated the accuracy of vocalic /{$\Elztrnr$}/ in untreated words.                                         Results               After the first 8 sessions, children who received UVF were judged to produce more accurate vocalic /{$\Elztrnr$}/ than those who received traditional treatment. After the second 8 sessions, within-participant comparisons revealed individual variation in treatment response. However, group-level comparisons revealed greater accuracy in children whose treatment order was UVF followed by traditional treatment versus children who received the reverse treatment order.                                         Conclusion               On average, 8 sessions of UVF were more effective than 8 sessions of traditional treatment for remediating vocalic /{$\Elztrnr$}/ errors. Better outcomes were also observed when UVF was provided in the early rather than later stages of learning. However, there remains a significant individual variation in response to UVF and traditional treatment, and larger group-level studies are needed.                                         Supplemental Material                                https://doi.org/10.23641/asha.8206640},
  file = {/Users/megcychosz/Zotero/storage/H4ITSCX4/Preston et al. - 2019 - Remediating Residual Rhotic Errors With Traditiona.pdf},
  journal = {American Journal of Speech-Language Pathology},
  language = {en},
  number = {3}
}

@article{pretzerInfantAdultVocalInteraction,
  title = {Infant-{{Adult Vocal Interaction Dynamics Depend}} on {{Infant Vocal Type}}, {{Child}}-{{Directedness}} of {{Adult Speech}}, and {{Timeframe}}},
  author = {Pretzer, G.M.},
  file = {/Users/megcychosz/Zotero/storage/A6MFZFF9/PretzerEtAl_02262018.3.pdf;/Users/megcychosz/Zotero/storage/B4CQ7DEZ/PretzerEtAl_02262018.docx;/Users/megcychosz/Zotero/storage/JYBALAZQ/PretzerEtAl_02262018.2.pdf;/Users/megcychosz/Zotero/storage/YWPRHC6B/PretzerEtAl_02262018.pdf}
}

@article{pretzerInfantadultVocalInteraction2019,
  title = {Infant-Adult Vocal Interaction Dynamics Depend on Infant Vocal Type, Child-Directedness of Adult Speech, and Timeframe},
  author = {Pretzer, Gina M. and Lopez, Lukas D. and Walle, Eric A. and Warlaumont, Anne S.},
  year = {2019},
  month = nov,
  volume = {57},
  pages = {101325},
  issn = {01636383},
  doi = {10.1016/j.infbeh.2019.04.007},
  abstract = {This study explored the temporal contingencies between infant and adult vocalizations as a function of the type of infant vocalization, whether adult caregivers' vocalizations were infantdirected or other-directed, and the timescale of analysis. We analyzed excerpts taken from daylong home audio recordings that were collected from nineteen 12- to 13-month-old American infants and their caregivers using the LENA system. Three 5-minute sections having high child vocalization rates were identified within each recording and coded by trained researchers. Infant and adult vocalizations were sequenced and defined as contingent if they occurred within 1 s, 2 s, or 5 s of each other. When using 1 s or 2 s definitions of temporal adjacency, infant vocalizations generally predicted subsequent infant-directed adult vocalizations. A reflexive vocalization (i.e. a cry or a laugh) was the strongest predictor. Likewise, within 1\textendash 2 s timeframes, infant-directed adult speech generally predicted infant vocalizations with reflexive vocalizations being particularly predictive. Infant vocalizations predicted fewer subsequent other-directed adult vocalizations and were less likely following other-directed adult vocalizations when considering up to 5 s lags. This suggests an understudied communicative role for infants of non-infant-directed adult speech. These results demonstrate the importance of timescale in studying infant-adult interactions, support the communicative significance of reflexive infant vocalizations and otherdirected adult speech in addition to more commonly studied vocalization types, and highlight the challenges of determining direction(s) of influence when using only two-event sequences.},
  file = {/Users/megcychosz/Zotero/storage/AR7GPF9B/Pretzer et al. - 2019 - Infant-adult vocal interaction dynamics depend on .pdf},
  journal = {Infant Behavior and Development},
  language = {en}
}

@article{pyeAnalysisVariationMayan2017,
  title = {Analysis of Variation in {{Mayan}} Child Phonologies},
  author = {Pye, Clifton and Mateo, Pedro and Pfeiler, Barbara and Stengel, Donald},
  year = {2017},
  month = oct,
  volume = {198},
  pages = {38--52},
  issn = {00243841},
  doi = {10.1016/j.lingua.2017.07.001},
  abstract = {This paper uses the methods of consonant inventories and discriminant analysis to examine the variation in word-initial consonants produced by 24 children acquiring six Mayan languages. The range of variation in the consonants that children produce has significant implications for theories that predict children follow universal processes of consonant development as well as theories that predict individual children exhibit unique developments. The results show variation exists between children acquiring the same language as well as between children acquiring different languages. Both the qualitative and quantitative results demonstrate the structure of the adult phonologies restricts the range of the children's variation within each language even though the children omit a variety of word-initial prefixes. The investigation of language acquisition in related languages reveals how children's attention to the adult language limits the operation of both universal and individual processes.},
  file = {/Users/megcychosz/Zotero/storage/WW4993ZQ/Pye et al. - 2017 - Analysis of variation in Mayan child phonologies.pdf},
  journal = {Lingua},
  language = {en}
}

@article{pyeAnalysisVariationMayan2017a,
  title = {Analysis of Variation in {{Mayan}} Child Phonologies},
  author = {Pye, Clifton and Mateo, Pedro and Pfeiler, Barbara and Stengel, Donald},
  year = {2017},
  month = oct,
  volume = {198},
  pages = {38--52},
  issn = {00243841},
  doi = {10.1016/j.lingua.2017.07.001},
  abstract = {This paper uses the methods of consonant inventories and discriminant analysis to examine the variation in word-initial consonants produced by 24 children acquiring six Mayan languages. The range of variation in the consonants that children produce has significant implications for theories that predict children follow universal processes of consonant development as well as theories that predict individual children exhibit unique developments. The results show variation exists between children acquiring the same language as well as between children acquiring different languages. Both the qualitative and quantitative results demonstrate the structure of the adult phonologies restricts the range of the children's variation within each language even though the children omit a variety of word-initial prefixes. The investigation of language acquisition in related languages reveals how children's attention to the adult language limits the operation of both universal and individual processes.},
  file = {/Users/megcychosz/Zotero/storage/VKCZ5WJX/Pye et al. - 2017 - Analysis of variation in Mayan child phonologies.pdf},
  journal = {Lingua},
  language = {en}
}

@incollection{pyeComparisonInitialConsonant1987,
  title = {A Comparison of Initial Consonant Acquisition in {{English}} and {{Quich\'e}}},
  booktitle = {Children's {{Language}}},
  author = {Pye, C. and Ingram, D. and List, H.},
  editor = {Nelson, K. and {van Kleeck}, A.},
  year = {1987},
  volume = {6},
  pages = {175--190},
  publisher = {{Erlbaum}},
  address = {{Hillsdale, NJ}},
  file = {/Users/megcychosz/Zotero/storage/DD6YTAPQ/PyeIngramList1987.pdf}
}

@article{pyeDocumentingAcquisitionIndigenous2020,
  title = {Documenting the Acquisition of Indigenous Languages},
  author = {Pye, Clifton},
  year = {2020},
  month = jun,
  pages = {1--26},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000920000318},
  abstract = {The outstanding property of human language is its diversity, and yet acquisition data is only available for three percent of the world's 6000+ spoken languages. Due to the rapid pace of language loss, it may not be possible to document how children acquire half of the world's indigenous languages in as little as two decades. This loss permanently diminishes the scope of acquisition theory by removing its empirical base. In the face of pervasive language loss, the question of how best to document the language of the last children to acquire indigenous languages assumes critical importance. A collaborative effort by researchers is required to identify the most efficient procedures for documenting children's language, and share them worldwide. This paper makes the case for documenting diversity and outlines steps needed to accomplish this goal.},
  file = {/Users/megcychosz/Zotero/storage/JI443V9N/Pye - 2020 - Documenting the acquisition of indigenous language.pdf},
  journal = {Journal of Child Language},
  language = {en}
}

@misc{Qualtrics2019,
  title = {Qualtrics},
  year = {2019},
  address = {{Provo, Utah}},
  howpublished = {Qualtrics}
}

@article{queenBilingualIntonationPatterns2001,
  title = {Bilingual {{Intonation Patterns}}: {{Evidence}} of {{Language Change}} from {{Turkish}}-{{German Bilingual Children}}},
  shorttitle = {Bilingual {{Intonation Patterns}}},
  author = {Queen, Robin M.},
  year = {2001},
  volume = {30},
  pages = {55--80},
  publisher = {{Cambridge University Press}},
  issn = {0047-4045},
  abstract = {This article discusses Turkish-German bilingual children's intonation patterns as they relate to processes of contact-induced language change. Bilingual speakers use two distinct rises in both Turkish and German. One rise (L*HH\%) resembles a characteristic German rise, while the other (L\%H\%) resembles a characteristic Turkish rise. The rises pattern pragmatically in ways that are non-normative for both Turkish and German. Although this pattern is not clearly attributable to language interference (either borrowing or shift-induced language change), it is certainly the result of language contact. Fusion is proposed to account for the two-way influence between the two languages.},
  file = {/Users/megcychosz/Zotero/storage/TAYBLMXG/Queen - 2001 - Bilingual Intonation Patterns Evidence of Languag.pdf},
  journal = {Language in Society},
  number = {1}
}

@article{quittnerEffectsMaternalSensitivity2013,
  title = {Effects of {{Maternal Sensitivity}} and {{Cognitive}} and {{Linguistic Stimulation}} on {{Cochlear Implant Users}}' {{Language Development}} over {{Four Years}}},
  author = {Quittner, Alexandra L. and Cruz, Ivette and Barker, David H. and Tobey, Emily and Eisenberg, Laurie S. and Niparko, John K.},
  year = {2013},
  month = feb,
  volume = {162},
  pages = {343-348.e3},
  issn = {00223476},
  doi = {10.1016/j.jpeds.2012.08.003},
  abstract = {Objectives\textemdash To examine the effects of observed maternal sensitivity (MS), cognitive stimulation (CS), and linguistic stimulation on the 4-year growth of oral language in young, deaf children receiving a cochlear implant. Previous studies of cochlear implants have not considered the effects of parental behaviors on language outcomes.},
  file = {/Users/megcychosz/Zotero/storage/H6ZWXWXL/Quittner et al. - 2013 - Effects of Maternal Sensitivity and Cognitive and .pdf},
  journal = {The Journal of Pediatrics},
  language = {en},
  number = {2}
}

@article{raczMorphologicalConvergenceOnlinetoappear,
  title = {Morphological Convergence as On-Line Lexical Analogy},
  author = {Racz, Peter and Beckner, Clay and Hay, Jennifer B and Pierrehumbert, Janet B},
  year = {to appear},
  abstract = {The English past-tense contains pockets of variation, where regular and irregular forms compete (e.g. learned/learnt, or weaved/wove). Individuals vary considerably in the degree to which they prefer irregular forms. This paper examines the degree to which individuals may converge on their regularization patterns and preferences. We report on a novel experimental methodology, using a cooperative game involving nonce verbs. Analysis of participants' post-game responses indicates that their behavior has shifted in response to an automated co-player's preferences, on two dimensions. First, players regularize more after playing with peers with high regularization rates, and less after playing with peers with low regularization rates. Second, players' overall pattern of regularization is also affected by the particular distribution of (ir)regular forms produced by the peer.},
  file = {/Users/megcychosz/Zotero/storage/WKKDQBQW/Racz et al. - Morphological convergence as on-line lexical analo.pdf},
  journal = {Language},
  language = {en}
}

@article{ramirez-esparzaImpactEarlySocial2017,
  title = {The {{Impact}} of {{Early Social Interactions}} on {{Later Language Development}} in {{Spanish}}-{{English Bilingual Infants}}},
  author = {{Ram{\'i}rez-Esparza}, Nair{\'a}n and {Garc{\'i}a-Sierra}, Adri{\'a}n and Kuhl, Patricia K.},
  year = {2017},
  month = jul,
  volume = {88},
  pages = {1216--1234},
  issn = {00093920},
  doi = {10.1111/cdev.12648},
  file = {/Users/megcychosz/Zotero/storage/EHYP9RBF/Ramírez-Esparza et al. - 2017 - The Impact of Early Social Interactions on Later L.pdf;/Users/megcychosz/Zotero/storage/HICKSIHM/Ramírez-Esparza et al. - 2017 - The Impact of Early Social Interactions on Later L.pdf},
  journal = {Child Development},
  language = {en},
  number = {4}
}

@article{ramirez-esparzaLookWhoTalking2014,
  title = {Look Who's Talking: Speech Style and Social Context in Language Input to Infants Are Linked to Concurrent and Future Speech Development},
  shorttitle = {Look Who's Talking},
  author = {{Ram{\'i}rez-Esparza}, Nair{\'a}n and {Garc{\'i}a-Sierra}, Adri{\'a}n and Kuhl, Patricia K.},
  year = {2014},
  month = nov,
  volume = {17},
  pages = {880--891},
  issn = {1363755X},
  doi = {10.1111/desc.12172},
  abstract = {Language input is necessary for language learning, yet little is known about whether, in natural environments, the speech style and social context of language input to children impacts language development. In the present study we investigated the relationship between language input and language development, examining both the style of parental speech, comparing `parentese' speech to standard speech, and the social context in which speech is directed to children, comparing one-on-one (1:1) to group social interactions. Importantly, the language input variables were assessed at home using digital first-person perspective recordings of the infants' auditory environment as they went about their daily lives (N =26, 11- and 14-months-old). We measured language development using (a) concurrent speech utterances, and (b) word production at 24 months. Parentese speech in 1:1 contexts is positively correlated with both concurrent speech and later word production. Mediation analyses further show that the effect of parentese speech-1:1 on infants' later language is mediated by concurrent speech. Our results suggest that both the social context and the style of speech in language addressed to children are strongly linked to a child's future language development.},
  file = {/Users/megcychosz/Zotero/storage/7KBH9FN3/desc.12172.pdf;/Users/megcychosz/Zotero/storage/U9RF22D2/desc.12172.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {6}
}

@article{ramirez-esparzaLookWhoTalking2017,
  title = {Look {{Who}}'s {{Talking NOW}}! {{Parentese Speech}}, {{Social Context}}, and {{Language Development Across Time}}},
  author = {{Ram{\'i}rez-Esparza}, Nair{\'a}n and {Garc{\'i}a-Sierra}, Adri{\'a}n and Kuhl, Patricia K.},
  year = {2017},
  month = jun,
  volume = {8},
  pages = {1--12},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2017.01008},
  abstract = {In previous studies, we found that the social interactions infants experience in their everyday lives at 11- and 14-months of age affect language ability at 24 months of age. These studies investigated relationships between the speech style (i.e., parentese speech vs. standard speech) and social context [i.e., one-on-one (1:1) vs. group] of language input in infancy and later speech development (i.e., at 24 months of age), controlling for socioeconomic status (SES). Results showed that the amount of exposure to parentese speech-1:1 in infancy was related to productive vocabulary at 24 months. The general goal of the present study was to investigate changes in (1) the pattern of social interactions between caregivers and their children from infancy to childhood and (2) relationships among speech style, social context, and language learning across time. Our study sample consisted of 30 participants from the previously published infant studies, evaluated at 33 months of age. Social interactions were assessed at home using digital first-person perspective recordings of the auditory environment. We found that caregivers use less parentese speech-1:1, and more standard speech-1:1, as their children get older. Furthermore, we found that the effects of parentese speech-1:1 in infancy on later language development at 24 months persist at 33 months of age. Finally, we found that exposure to standard speech-1:1 in childhood was the only social interaction that related to concurrent word production/use. Mediation analyses showed that standard speech-1:1 in childhood fully mediated the effects of parentese speech1:1 in infancy on language development in childhood, controlling for SES. This study demonstrates that engaging in one-on-one interactions in infancy and later in life has important implications for language development.},
  file = {/Users/megcychosz/Zotero/storage/AKEHY5C5/Ramírez-Esparza et al. - 2017 - Look Who’s Talking NOW! Parentese Speech, Social C.pdf},
  journal = {Frontiers in Psychology},
  language = {en},
  number = {1008}
}

@article{ramsayMultitaperHarmonicAnalysis2018,
  title = {Multitaper Harmonic Analysis of Infant Vocalizations},
  author = {Ramsay, G.},
  year = {2018},
  volume = {144},
  pages = {1767--1768},
  journal = {Journal of the Acoustical Society of America},
  number = {3}
}

@article{raneriChangeMaternalSpeech2020,
  title = {Change in Maternal Speech Rate to Preverbal Infants over the First Two Years of Life},
  author = {Raneri, Daniele and Von Holzen, Katie and Newman, Rochelle and Bernstein Ratner, Nan},
  year = {2020},
  month = nov,
  volume = {47},
  pages = {1263--1275},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S030500091900093X},
  abstract = {Aims: Although IDS is typically described as slower than adult-directed speech (ADS), potential impacts of slower speech on language development have not been examined. We explored whether IDS speech rates in 42 mother\textendash infant dyads at four time periods predicted children's language outcomes at two years. Method: We correlated IDS speech rate with child language outcomes at two years, and contrasted outcomes in dyads displaying high/low rate profiles. Outcomes: Slower IDS rate at 7 months significantly correlated with vocabulary knowledge at two years. Slowed IDS may benefit child language learning even before children first speak.},
  file = {/Users/megcychosz/Zotero/storage/FFIN46G7/Raneri et al. - 2020 - Change in maternal speech rate to preverbal infant.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {6}
}

@article{rankineLanguageENvironmentAnalysis2017,
  title = {Language {{ENvironment Analysis}} ({{LENA}}) in {{Phelan}}-{{McDermid Syndrome}}: {{Validity}} and {{Suggestions}} for {{Use}} in {{Minimally Verbal Children}} with {{Autism Spectrum Disorder}}},
  shorttitle = {Language {{ENvironment Analysis}} ({{LENA}}) in {{Phelan}}-{{McDermid Syndrome}}},
  author = {Rankine, Jacquelin and Li, Erin and Lurie, Stacey and Rieger, Hillary and Fourie, Emily and Siper, Paige M. and Wang, A. Ting and Buxbaum, Joseph D. and Kolevzon, Alexander},
  year = {2017},
  month = jun,
  volume = {47},
  pages = {1605--1617},
  issn = {0162-3257, 1573-3432},
  doi = {10.1007/s10803-017-3082-8},
  file = {/Users/megcychosz/Zotero/storage/PJ94SZJK/Rankine et al. - 2017 - Language ENvironment Analysis (LENA) in Phelan-McD.pdf},
  journal = {Journal of Autism and Developmental Disorders},
  language = {en},
  number = {6}
}

@article{rasanenALICEOpensourceTool2020,
  title = {{{ALICE}}: {{An}} Open-Source Tool for Automatic Measurement of Phoneme, Syllable, and Word Counts from Child-Centered Daylong Recordings},
  shorttitle = {{{ALICE}}},
  author = {R{\"a}s{\"a}nen, Okko and Seshadri, Shreyas and Lavechin, Marvin and Cristia, Alejandrina and Casillas, Marisa},
  year = {2020},
  month = sep,
  issn = {1554-3528},
  doi = {10.3758/s13428-020-01460-x},
  abstract = {Recordings captured by wearable microphones are a standard method for investigating young children's language environments. A key measure to quantify from such data is the amount of speech present in children's home environments. To this end, the LENA recorder and software\textemdash a popular system for measuring linguistic input\textemdash estimates the number of adult words that children may hear over the course of a recording. However, word count estimation is challenging to do in a language- independent manner; the relationship between observable acoustic patterns and language-specific lexical entities is far from uniform across human languages. In this paper, we ask whether some alternative linguistic units, namely phone(me)s or syllables, could be measured instead of, or in parallel with, words in order to achieve improved cross-linguistic applicability and comparability of an automated system for measuring child language input. We discuss the advantages and disadvantages of measuring different units from theoretical and technical points of view. We also investigate the practical applicability of measuring such units using a novel system called Automatic LInguistic unit Count Estimator (ALICE) together with audio from seven child-centered daylong audio corpora from diverse cultural and linguistic environments. We show that language-independent measurement of phoneme counts is somewhat more accurate than syllables or words, but all three are highly correlated with human annotations on the same data. We share an open-source implementation of ALICE for use by the language research community, enabling automatic phoneme, syllable, and word count estimation from child-centered audio recordings.},
  file = {/Users/megcychosz/Zotero/storage/FFMBUS44/Räsänen et al. - 2020 - ALICE An open-source tool for automatic measureme.pdf},
  journal = {Behavior Research Methods},
  language = {en}
}

@article{ratnerHigherPitchBT1984,
  title = {Higher Pitch in {{BT}} Is Not Universal: Acoustic Evidence from {{Quiche Mayan}}},
  shorttitle = {Higher Pitch in {{BT}} Is Not Universal},
  author = {Ratner, Nan Bernstein and Pye, Clifton},
  year = {1984},
  month = oct,
  volume = {11},
  pages = {515--522},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000900005924},
  abstract = {Although higher pitch has been described as a universal feature of babytalk (BT) registers worldwide, analysis of a sample of three Quiche Mayan-speaking mothers addressing their infant children indicated that their BT register does not utilize this feature. Quiche mothers either make no pitch distinction in speech to young children, or actually lower pitch slightly in comparison with their Adult-Adult interaction style. A comparison group of American mothers raised pitch 35\textemdash 70 Hz when addressing infants of the same age and language maturity. We posit that pitch-raising strategies may be sociolinguistically determined and may serve different functions across languages.},
  file = {/Users/megcychosz/Zotero/storage/WDG3K4JD/Ratner and Pye - 1984 - Higher pitch in BT is not universal acoustic evid.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {3}
}

@article{ratnerPatternsVowelModification1984,
  title = {Patterns of Vowel Modification in Mother\textendash Child Speech},
  author = {Ratner, Nan Bernstein},
  year = {1984},
  month = oct,
  volume = {11},
  pages = {557--578},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S030500090000595X},
  abstract = {ABSTRACT             Patterns of vowel articulation in conversational speech to an adult and to child listeners were analysed in the speech of nine mothers. Formant frequency analysis of vowels embedded in 2,406 words found in varying syntactic environments and uttered by women to pre-verbal, holophrastic and more advanced child listeners (MLUs 2{$\cdot$}5\textendash 4{$\cdot$}0) revealed an emerging pattern of content word clarification, as measured by wider dispersion and decreased overlap between vowel phoneme categories in formant characteristics. Additionally, function word clarification was noted in speech to the oldest children. Vowel production appears to be modulated by child\textendash addressee language ability. Earlier studies suggesting a lack of phonetic clarification in mother\textendash child speech may have investigated speech to children too mature to elicit maternal clarification behaviours.},
  file = {/Users/megcychosz/Zotero/storage/5HENNWJ2/Ratner - 1984 - Patterns of vowel modification in mother–child spe.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {3}
}

@misc{rcoreteamLanguageEnvironmentStatistical2019,
  title = {R: {{A}} Language and Environment for Statistical Computing.},
  author = {R Core Team},
  year = {2019},
  address = {{Vienna, Austria}},
  howpublished = {R Foundation for Statistical Computing}
}

@article{recasensArticulatoryInvestigationLingual2009,
  title = {An Articulatory Investigation of Lingual Coarticulatory Resistance and Aggressiveness for Consonants and Vowels in {{Catalan}}},
  author = {Recasens, Daniel and Espinosa, Aina},
  year = {2009},
  volume = {125},
  pages = {2288--2298},
  issn = {0001-4966},
  doi = {10.1121/1.3089222},
  file = {/Users/megcychosz/Zotero/storage/TGAIZF8Q/Recasens and Espinosa - 2009 - An articulatory investigation of lingual coarticul.pdf},
  journal = {Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@article{recasensCoarticulatoryPatternsDegrees1985,
  title = {Coarticulatory Patterns and Degrees of Coarticulatory Resistance in {{Catalan CV}} Sequences},
  author = {Recasens, Daniel},
  year = {1985},
  volume = {28},
  pages = {97--114},
  issn = {0023-8309, 1756-6053},
  doi = {10.1177/002383098502800201},
  file = {/Users/megcychosz/Zotero/storage/BQ4LTLGR/desc.12762.pdf;/Users/megcychosz/Zotero/storage/FUC5BLWB/Recasens - 1985 - Coarticulatory Patterns and Degrees of Coarticulat.pdf},
  journal = {Language and Speech},
  language = {en},
  number = {2}
}

@article{recasensDispersionVariabilityCatalan2006,
  title = {Dispersion and Variability of {{Catalan}} Vowels},
  author = {Recasens, Daniel and Espinosa, Aina},
  year = {2006},
  month = jun,
  volume = {48},
  pages = {645--666},
  issn = {01676393},
  doi = {10.1016/j.specom.2005.09.011},
  abstract = {Formant frequency data for Catalan vowels reveal essentially the same degree of expansion for three dialect systems with seven vowels (Valencian, Eastern Catalan, Western Catalan). A slightly larger vowel space dispersion for a fourth system with those same vowels and stressed /c/ (Majorcan) is not clearly associated with a larger vowel system size but rather with a local effect of schwa in repelling neighbouring vowels or with specific requirements on the production of some peripheral vowels. Schwa appears to be targetless or specified for a widely defined mid central target. Intervocalic distances were found to vary according to dialect and to vowel pair, and to compensate with each other such that the maximal formant frequency range between point vowels is kept constant across dialects. These findings are partially in support of the Adaptive Dispersion Theory, i.e., they are in agreement with the claim that vowel system expansion should be proportional to vowel system size but not with the notion that adjacent vowels should be evenly spaced in identical vowel systems. Patterns of vowel variability differ depending on the contextual or non-contextual factors involved, i.e., F1 shows more contextual and token-to-token variation for open vs. close vowels, while F2 exhibits little contextual variation and much token-dependent variation for /i/ and the opposite trend for /u/ and /c/. These patterns are accounted for assuming that random variability for vowels is ruled by the precision involved in achieving a specific articulatory target, and that contextual variability is determined by the vowel articulatory requirements and by the relative compatibility between the articulatory gestures for adjacent vowels and consonants.},
  file = {/Users/megcychosz/Zotero/storage/R5H7HM8K/Dispersion and variability of Catalan vowels.pdf},
  journal = {Speech Communication},
  language = {en},
  number = {6}
}

@article{recasensDispersionVariabilityCatalan2009,
  title = {Dispersion and Variability in {{Catalan}} Five and Six Peripheral Vowel Systems},
  author = {Recasens, Daniel and Espinosa, Aina},
  year = {2009},
  month = mar,
  volume = {51},
  pages = {240--258},
  issn = {01676393},
  doi = {10.1016/j.specom.2008.09.002},
  abstract = {This study compares F1 and F2 for the vowels of the five and six peripheral vowel systems of four minor dialects of Catalan (Felanitxer, Giron\'i, Sitget\`a, Rossellon\`es), with those of the seven peripheral vowel systems of the major dialects those minor dialects belong to (Majorcan, Eastern). Results indicate that most mid vowel pairs subjected to neutralization may be characterized as near-mergers. Merging appears to have proceeded through two stages: in the first place, one of the two mid vowel pairs undergoes neutralization yielding a relatively close mid vowel in the resulting six vowel system; then, the members of the second vowel pair approach each other until they cease to be contrastive, and the front and back mid vowels of the resulting five vowel system tend to occupy a fairly equidistant position with respect to the mid high and mid low cognates. Moreover, in six vowel systems wih a single mid vowel pair, the contrasting members of this pair approach each other if belonging to the back series but not if belonging to the front series. These findings are in support of two hypotheses: vowel systems tend to be symmetrical; reparation of six vowel systems is most prone to occur if the system is unoptimal. Predictions of the Adaptive Dispersion Theory were not supported by the data. Thus, smaller vowel systems turned out not to be less disperse than larger ones, and mid vowels were not clearly more variable in five or six vowel systems than in seven vowel systems. It appears that for these predictions to come into play, the systems being compared need to differ considerably in number of vowels.},
  file = {/Users/megcychosz/Zotero/storage/J75GP7TF/Recasens and Espinosa - 2009 - Dispersion and variability in Catalan five and six.pdf},
  journal = {Speech Communication},
  language = {en},
  number = {3}
}

@article{recasensEffectStressSpeech2015,
  title = {The {{Effect}} of {{Stress}} and {{Speech Rate}} on {{Vowel Coarticulation}} in {{Catalan Vowel}}\textendash{{Consonant}}\textendash{{Vowel Sequences}}},
  author = {Recasens, Daniel},
  year = {2015},
  month = oct,
  volume = {58},
  pages = {1407--1424},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2015_JSLHR-S-14-0196},
  abstract = {Purpose               The goal of this study was to ascertain the effect of changes in stress and speech rate on vowel coarticulation in vowel\textendash consonant\textendash vowel sequences.                                         Method               Data on second formant coarticulatory effects as a function of changing /i/ versus /a/ were collected for five Catalan speakers' productions of vowel\textendash consonant\textendash vowel sequences with the fixed vowels /i/ and /a/ and consonants: the approximant /{$\delta$}/, the alveolopalatal nasal /\Elzltln/, and /l/, which in the Catalan language differs in darkness degree according to speaker.                                         Results               In agreement with predictions formulated by the degree-of-articulation-constraint model of coarticulation, the size of the vowel coarticulatory effects was inversely related to the degree of articulatory constraint for the consonant, and the direction of those effects was mostly carryover or anticipatory in vowel\textendash consonant\textendash vowel sequences with highly constrained consonants (/\Elzltln/, dark /l/) and more variable whenever the intervocalic consonant was less constrained (/{$\delta$}/, clear /l/). Stress and speech-rate variations had an effect on overall vowel duration, second formant frequency, and coarticulation size but not on the consonant-specific patterns of degree and direction of vowel coarticulation.                                         Conclusion               These results indicate that prosodically induced coarticulatory changes conform to the basic principles of segmental coarticulatory organization.},
  file = {/Users/megcychosz/Zotero/storage/4CJKJN3R/Recasens - 2015 - The Effect of Stress and Speech Rate on Vowel Coar.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {5}
}

@article{recasensModelLingualCoarticulation1997,
  title = {A Model of Lingual Coarticulation Based on Articulatory Constraints},
  author = {Recasens, Daniel and Pallar{\`e}s, Maria Dolors and Fontdevila, Jordi},
  year = {1997},
  volume = {102},
  pages = {544--561},
  issn = {0001-4966},
  doi = {10.1121/1.419727},
  file = {/Users/megcychosz/Zotero/storage/3UMPE83A/Recasens et al. - 1997 - A model of lingual coarticulation based on articul.pdf},
  journal = {Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{redfordEffectsAcquisitionRate2008,
  title = {Effects of {{Acquisition Rate}} on {{Emergent Structure}} in {{Phonological Development}}},
  author = {Redford, Melissa A. and Miikkulainen, Risto.},
  year = {2008},
  volume = {83},
  pages = {737--769},
  issn = {1535-0665},
  doi = {10.1353/lan.2008.0040},
  file = {/Users/megcychosz/Zotero/storage/QZDYTH3W/Redford and Miikkulainen - 2008 - Effects of Acquisition Rate on Emergent Structure .pdf},
  journal = {Language},
  language = {en},
  number = {4}
}

@article{redfordGrammaticalWordProduction2018,
  title = {Grammatical {{Word Production Across Metrical Contexts}} in {{School}}-{{Aged Children}}'s and {{Adults}}' {{Speech}}},
  author = {Redford, Melissa A.},
  year = {2018},
  month = jun,
  volume = {61},
  pages = {1339--1354},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2018_JSLHR-S-17-0126},
  abstract = {Purpose: Test whether age-related differences in grammatical word production are due to differences in how children and adults chunk speech for output or to immature articulatory timing control in children. Method: Two groups of 12 children, 5 and 8 years old, and one group of 12 adults produced sentences with phrase-medial determiners. Preceding verbs were varied to create different metrical contexts for chunking the determiner with an adjacent content word. Following noun onsets were varied to assess the coherence of determiner-noun sequences. Determiner vowel duration, amplitude, and formant frequencies were measured. Results: Children produced significantly longer and louder determiners than adults regardless of metrical context. The effect of noun onset on F1 was stronger in children's speech than in adult speech; the effect of noun onset on F2 was stronger in adults' speech than in children's. Effects of metrical context on anticipatory formant patterns were more evident in children's speech than in adults' speech. Conclusion: The results suggest that both immature articulatory timing control and agerelated differences in how chunks are accessed or planned influence grammatical word production in school-aged children's speech. Future work will focus on the development of long-distance coarticulation to reveal the evolution of speech plan structure over time.},
  file = {/Users/megcychosz/Zotero/storage/5SK3DNVC/Redford - 2018 - Grammatical Word Production Across Metrical Contex.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {6}
}

@article{redfordPerceivedClarityChildren2014,
  title = {The Perceived Clarity of Children's Speech Varies as a Function of Their Default Articulation Rate},
  author = {Redford, Melissa A.},
  year = {2014},
  month = may,
  volume = {135},
  pages = {2952--2963},
  issn = {0001-4966},
  doi = {10.1121/1.4869820},
  file = {/Users/megcychosz/Zotero/storage/VPVDELPR/Redford - 2014 - The perceived clarity of children's speech varies .pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{redfordProductivePitfallsPhonetic2018,
  title = {Productive Pitfalls in the Phonetic Pursuit of Psycholinguistic Questions},
  author = {Redford, M. and Kallay, J. and Potratz, J.},
  year = {2018},
  volume = {144},
  pages = {1723},
  journal = {ABSTRACT: The Journal of the Acoustical Society of America},
  number = {3}
}

@article{redfordRepresentationExecutionArticulatory2017,
  title = {The Representation and Execution of Articulatory Timing in First and Second Language Acquisition},
  author = {Redford, Melissa A. and Oh, Grace E.},
  year = {2017},
  month = jul,
  volume = {63},
  pages = {127--138},
  issn = {00954470},
  doi = {10.1016/j.wocn.2017.01.004},
  abstract = {The early acquisition of language-specific temporal patterns relative to the late development of speech motor control suggests a dissociation between the representation and execution of articulatory timing. The current study tested for such a dissociation in first and second language acquisition. American English-speaking children (5- and 8-year-olds) and Korean-speaking adult learners of English repeatedly produced real English words in a simple carrier sentence. The words were designed to elicit different language-specific vowel length contrasts. Measures of absolute duration and variability in single vowel productions were extracted to evaluate the realization of contrasts (representation) and to index speech motor abilities (execution). Results were mostly consistent with a dissociation. Native English-speaking children produced the same language-specific temporal patterns as native English-speaking adults, but their productions were more variable than the adults'. In contrast, Korean-speaking adult learners of English typically produced different temporal patterns than native English-speaking adults, but their productions were as stable as the native speakers'. Implications of the results are discussed with reference to different models of speech production.},
  file = {/Users/megcychosz/Zotero/storage/H2KA7YUA/Redford and Oh - 2017 - The representation and execution of articulatory t.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{redfordSpeechProductionDevelopmental2019,
  title = {Speech {{Production From}} a {{Developmental Perspective}}},
  author = {Redford, Melissa A.},
  year = {2019},
  month = aug,
  volume = {62},
  pages = {2946--2962},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2019_JSLHR-S-CSMC7-18-0130},
  file = {/Users/megcychosz/Zotero/storage/PNVUZXEN/Redford - 2019 - Speech Production From a Developmental Perspective.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {8S}
}

@article{redfordUnifyingSpeechLanguage2015,
  title = {Unifying Speech and Language in a Developmentally Sensitive Model of Production},
  author = {Redford, Melissa A.},
  year = {2015},
  month = nov,
  volume = {53},
  pages = {141--152},
  issn = {00954470},
  doi = {10.1016/j.wocn.2015.06.006},
  abstract = {Speaking is an intentional activity. It is also a complex motor skill; one that exhibits protracted development and the fully automatic character of an overlearned behavior. Together these observations suggest an analogy with skilled behavior in the non-language domain. This analogy is used here to argue for a model of production that is grounded in the activity of speaking and structured during language acquisition. The focus is on the plan that controls the execution of fluent speech; specifically, on the units that are activated during the production of an intonational phrase. These units are schemas: temporally structured sequences of remembered actions and their sensory outcomes. Schemas are activated and inhibited via associated goals, which are linked to specific meanings. Schemas may fuse together over developmental time with repeated use to form larger units, thereby affecting the relative timing of sequential action in participating schemas. In this way, the hierarchical structure of the speech plan and ensuing rhythm patterns of speech are a product of development. Individual schemas may also become differentiated during development, but only if subsequences are associated with meaning. The necessary association of action and meaning gives rise to assumptions about the primacy of certain linguistic forms in the production process. Overall, schema representations connect usage-based theories of language to the action of speaking.},
  file = {/Users/megcychosz/Zotero/storage/DVZTX7M7/Redford - 2015 - Unifying speech and language in a developmentally .pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{reidyAcousticsWordInitialFricatives2017,
  title = {The {{Acoustics}} of {{Word}}-{{Initial Fricatives}} and {{Their Effect}} on {{Word}}-{{Level Intelligibility}} in {{Children With Bilateral Cochlear Implants}}:},
  shorttitle = {The {{Acoustics}} of {{Word}}-{{Initial Fricatives}} and {{Their Effect}} on {{Word}}-{{Level Intelligibility}} in {{Children With Bilateral Cochlear Implants}}},
  author = {Reidy, Patrick F. and Kristensen, Kayla and Winn, Matthew B. and Litovsky, Ruth Y. and Edwards, Jan R.},
  year = {2017},
  volume = {38},
  pages = {42--56},
  issn = {0196-0202},
  doi = {10.1097/AUD.0000000000000349},
  abstract = {Objectives\textemdash Previous research has found that, relative to their peers with normal hearing (NH), children with cochlear implants (CIs) produce the sibilant fricatives /s/ and /{$\Elzesh$}/ less accurately and with less subphonemic acoustic contrast. The current study sought to further investigate these differences across groups in two ways. First, subphonemic acoustic properties were investigated in terms of dynamic acoustic features that indexed more than just the contrast between /s/ and /{$\Elzesh$}/. Second, we investigated whether such differences in subphonemic acoustic contrast between sibilant fricatives affected the intelligibility of sibilant-initial single word productions by children with CIs and their peers with NH. Design\textemdash In Experiment 1, productions of /s/ and /{$\Elzesh$}/ in word-initial prevocalic contexts were elicited from 22 children with bilateral CIs (aged 4 to 7 years) who had at least 2 years of CI experience and from 22 chronological age-matched peers with NH. Acoustic features were measured from 17 points across the fricatives: peak frequency was measured to index the place of articulation contrast; spectral variance and amplitude drop were measured to index the degree of sibilance. These acoustic trajectories were fitted with growth-curve models to analyze timevarying spectral change. In Experiment 2, phonemically accurate word productions that were elicited in Experiment 1 were embedded within four-talker babble and played to 80 adult listeners with NH. Listeners were asked to repeat the words, and their accuracy rate was used as a measure of the intelligibility of the word productions. Regression analyses were run to test which acoustic properties measured in Experiment 1 predicted the intelligibility scores from Experiment 2.},
  file = {/Users/megcychosz/Zotero/storage/38UJ8VXA/Reidy et al. - 2017 - The Acoustics of Word-Initial Fricatives and Their.pdf},
  journal = {Ear and Hearing},
  language = {en},
  number = {1}
}

@article{reidyComparisonSpectralEstimation2015,
  title = {A Comparison of Spectral Estimation Methods for the Analysis of Sibilant Fricatives},
  author = {Reidy, Patrick F.},
  year = {2015},
  month = apr,
  volume = {137},
  pages = {EL248-EL254},
  issn = {0001-4966},
  doi = {10.1121/1.4915064},
  abstract = {It has been argued that, to ensure accurate spectral feature estimates for sibilants, the spectral estimation method should include a low-variance spectral estimator; however, no empirical evaluation of estimation methods in terms of feature estimates has been given. The spectra of /s/ and /S/ were estimated with different methods that varied the pre-emphasis filter and estimator. These methods were evaluated in terms of effects on two features (centroid and degree of sibilance) and on the detection of four linguistic contrasts within these features. Estimation method affected the spectral features but none of the tested linguistic contrasts.},
  file = {/Users/megcychosz/Zotero/storage/HHI5F2DI/Reidy - 2015 - A comparison of spectral estimation methods for th.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@phdthesis{reidySpectralDynamicsVoiceless2015,
  title = {The Spectral Dynamics of Voiceless Sibilant Fricatives in {{English}} and {{Japanese}}},
  author = {Reidy, Patrick F},
  year = {2015},
  school = {The Ohio State University},
  type = {Dissertation}
}

@article{reinischSpeakerspecificProcessingLocal2016,
  title = {Speaker-Specific Processing and Local Context Information: {{The}} Case of Speaking Rate},
  shorttitle = {Speaker-Specific Processing and Local Context Information},
  author = {Reinisch, Eva},
  year = {2016},
  month = nov,
  volume = {37},
  pages = {1397--1415},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716415000612},
  abstract = {To deal with variation in the speech signal, listeners rely on local context, such as speaking rate in a carrier sentence directly preceding a target, as well as more global properties of the speech signal, such as speaker-specific pronunciation variants. The present study addressed whether, despite its variability even within one speaker, habitual speaking rate can be tracked as a speaker-specific property and how such speaker-specific tracking of habitual rate would interact with effects of local-rate normalization. In two experiments, listeners were exposed to a 2-min dialogue between a fast and a slow speaker. At test, listeners categorized minimal word pair continua differing in the German /a/\textendash/a:/ duration contrast spoken by the same two speakers. The results showed that listeners responded with /a:/ more often for the fast speaker but only when words were presented in isolation and not when presented with additional local-rate information. That is, despite the general assumption that duration cues and speaking rate are too variable to be used in a speaker-specific fashion, tracking habitual speaking rate may help speech perception. The results are discussed in relation to a belief-updating model of perceptual adaptation and exemplar models.},
  file = {/Users/megcychosz/Zotero/storage/6RML754P/Reinisch - 2016 - Speaker-specific processing and local context info.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {6}
}

@article{reinischUptakeSpectralTemporal2013,
  title = {The Uptake of Spectral and Temporal Cues in Vowel Perception Is Rapidly Influenced by Context},
  author = {Reinisch, Eva and Sjerps, Matthias J.},
  year = {2013},
  month = mar,
  volume = {41},
  pages = {101--116},
  issn = {00954470},
  doi = {10.1016/j.wocn.2013.01.002},
  abstract = {Speech perception is dependent on auditory information within phonemes such as spectral or temporal cues. The perception of those cues, however, is affected by auditory information in surrounding context (e.g., a fast context sentence can make a target vowel sound subjectively longer). In a two-by-two design the current experiments investigated when these different factors influence vowel perception. Dutch listeners categorized minimal word pairs such as /t k/\textendash/ta k/ (``branch''\textendash ``task'') embedded in a context sentence. Critically, the Dutch / /\textendash/a / contrast is cued by spectral and temporal information. We varied the second formant (F2) frequencies and durations of the target vowels. Independently, we also varied the F2 and duration of all segments in the context sentence. The timecourse of cue uptake on the targets was measured in a printedword eye-tracking paradigm. Results show that the uptake of spectral cues slightly precedes the uptake of temporal cues. Furthermore, acoustic manipulations of the context sentences influenced the uptake of cues in the target vowel immediately. That is, listeners did not need additional time to integrate spectral or temporal cues of a target sound with auditory information in the context. These findings argue for an early locus of contextual influences in speech perception.},
  file = {/Users/megcychosz/Zotero/storage/38GUJJES/Reinisch and Sjerps - 2013 - The uptake of spectral and temporal cues in vowel .pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {2}
}

@article{renziTwoMindsAre2017,
  title = {Two Minds Are Better than One: {{Cooperative}} Communication as a New Framework for Understanding Infant Language Learning.},
  shorttitle = {Two Minds Are Better than One},
  author = {Renzi, Doireann T. and Romberg, Alexa R. and Bolger, Donald J. and Newman, Rochelle S.},
  year = {2017},
  volume = {3},
  pages = {19--33},
  issn = {2332-2179, 2332-2136},
  doi = {10.1037/tps0000088},
  abstract = {This review proposes ``cooperative communication'' as a new framework for understanding the social mechanisms underpinning infant language learning. Understanding how infants learn language depends not just on understanding the input the parent provides, or the behaviors of the infant, but on the dynamic interplay between shared verbal and nonverbal communication in early parent\textendash infant interactions. The review integrates prior work in the fields of social development and developmental psycholinguistics, and suggests directions for operationalizing cooperative communication and other future work.},
  file = {/Users/megcychosz/Zotero/storage/EVYH79GP/Renzi et al. - 2017 - Two minds are better than one Cooperative communi.pdf},
  journal = {Translational Issues in Psychological Science},
  language = {en},
  number = {1}
}

@article{reppObservationsDevelopmentAnticipatory1986,
  title = {Some Observations on the Development of Anticipatory Coarticulation},
  author = {Repp, Bruno H.},
  year = {1986},
  month = may,
  volume = {79},
  pages = {1616--1619},
  issn = {0001-4966},
  doi = {10.1121/1.393298},
  file = {/Users/megcychosz/Zotero/storage/AP2HINLP/Repp - 1986 - Some observations on the development of anticipato.pdf},
  journal = {Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{rescorlaPhoneticProfilesToddlers1996,
  title = {Phonetic {{Profiles}} of {{Toddlers With Specific Expressive Language Impairment}} ({{SLI}}-{{E}})},
  author = {Rescorla, Leslie and Ratner, Nan Bernstein},
  year = {1996},
  month = feb,
  volume = {39},
  pages = {153--165},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/jshr.3901.153},
  abstract = {Spontaneous language samples of 30 24-month-old toddlers diagnosed with Specific Expressive Language Impairment (SLI-E) were compared with samples produced by an age-matched group of 30 typically developing toddlers. Vocalization patterns, phonetic inventories, and syllable formation patterns were compared. Toddlers with SLI-E vocalized significantly less often than their typically developing peers, had proportionately smaller consonantal and vowel inventories, and used a more restricted and less mature array of syllable shapes. Although the mean incidence of phoneme usage varied significantly inall comparisons, profiles of consonant usage were similar between the two groups for initial phoneme usage, but considerably different for final consonant closure. Such patterns of vocal and phonetic behavior confirm earlier reports of phonetic delay in SLI-E, and suggest that nongrammatical factors contribute to the development of expressive language deficits in toddlers. We further propose a bidirectional model for the expressive deficits in SLI-E, in which the child's limited phonetic capacity interacts with propensities in caretaker interaction to further reduce opportunities for expressive language learning and practice.},
  file = {/Users/megcychosz/Zotero/storage/SPF8QSEG/Rescorla and Ratner - 1996 - Phonetic Profiles of Toddlers With Specific Expres.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {1}
}

@article{ribotLanguageUseContributes2018,
  title = {Language {{Use Contributes}} to {{Expressive Language Growth}}: {{Evidence From Bilingual Children}}},
  shorttitle = {Language {{Use Contributes}} to {{Expressive Language Growth}}},
  author = {Ribot, Krystal M. and Hoff, Erika and Burridge, Andrea},
  year = {2018},
  month = may,
  volume = {89},
  pages = {929--940},
  issn = {00093920},
  doi = {10.1111/cdev.12770},
  file = {/Users/megcychosz/Zotero/storage/AFXHI6PM/Ribot et al. - 2018 - Language Use Contributes to Expressive Language Gr.pdf},
  journal = {Child Development},
  language = {en},
  number = {3}
}

@article{riceMeanLengthUtterance2010,
  title = {Mean {{Length}} of {{Utterance Levels}} in 6-{{Month Intervals}} for {{Children}} 3 to 9 {{Years With}} and {{Without Language Impairments}}},
  author = {Rice, Mabel L. and Smolik, Filip and Perpich, Denise and Thompson, Travis and Rytting, Nathan and Blossom, Megan},
  year = {2010},
  month = apr,
  volume = {53},
  pages = {333--349},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2009/08-0183)},
  abstract = {Purpose\textemdash The mean length of children's utterances is a valuable estimate of their early language acquisition. The available normative data lacks documentation of language and nonverbal intelligence levels of the samples. This study reports age-referenced MLU data from children with specific language impairment and children without language impairments. Method\textemdash 306 child participants were drawn from a data archive, ages 2;6\textendash 9;0 years, 170 with SLI and 136 control children. 1564 spontaneous language samples were collected, transcribed and analyzed for sample size and MLU in words and morphemes. Means, standard deviations, and effect sizes for group differences are reported for MLUs, along with concurrent language and nonverbal intelligence assessments, per 6-month intervals. Results\textemdash The results document an age progression in MLU words and morphemes, and a persistent lower level of performance for children with SLI. Conclusions\textemdash The results support the reliability and validity of MLU as an index of normative language acquisition and a marker of language impairment. The findings can be used for clinical benchmarking of deficits and language intervention outcomes, as well as comparisons across research samples.},
  file = {/Users/megcychosz/Zotero/storage/69LMFQ6L/Rice et al. - 2010 - Mean Length of Utterance Levels in 6-Month Interva.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {2}
}

@article{richardsonAuditoryProcessingSkills2004,
  title = {Auditory Processing Skills and Phonological Representation in {{Dyslexic}} Children},
  author = {Richardson, Ulla and Thomson, Jennifer M. and Scott, Sophie K. and Goswami, Usha},
  year = {2004},
  month = aug,
  volume = {10},
  pages = {215--233},
  issn = {1076-9242, 1099-0909},
  doi = {10.1002/dys.276},
  file = {/Users/megcychosz/Zotero/storage/3EYLJDPC/Richardson et al. - 2004 - Auditory processing skills and phonological repres.pdf},
  journal = {Dyslexia},
  language = {en},
  number = {3}
}

@article{richardsonAuditoryProcessingSkills2004a,
  title = {Auditory Processing Skills and Phonological Representation in {{Dyslexic}} Children},
  author = {Richardson, Ulla and Thomson, Jennifer M. and Scott, Sophie K. and Goswami, Usha},
  year = {2004},
  month = aug,
  volume = {10},
  pages = {215--233},
  issn = {1076-9242, 1099-0909},
  doi = {10.1002/dys.276},
  file = {/Users/megcychosz/Zotero/storage/994A3MZH/Richardson et al. - 2004 - Auditory processing skills and phonological repres.pdf},
  journal = {Dyslexia},
  language = {en},
  number = {3}
}

@article{richesVerbLearningChildren,
  title = {Verb {{Learning}} in {{Children With SLI}}: {{Frequency}} and {{Spacing Effects}}},
  author = {Riches, N G and Tomasello, M and {Conti-Ramsden}, Gina},
  pages = {15},
  abstract = {Purpose: This study explored the effect of frequency (number of presentations), and spacing (period between presentations) on verb learning in children with specific language impairment (SLI). Children learn words more efficiently when presentations are frequent and appropriately spaced, and this study investigated whether children with SLI likewise benefit. Given that these children demonstrate greater frequency dependence and rapid forgetting of recently acquired words, an investigation of frequency and spacing in this population is especially warranted. Method: Twenty-four children with SLI (mean age 5;6 [years;months]) and 24 language-matched control children (mean age 3;4) were taught novel verbs during play sessions. In a repeated measures design, 4 experimental conditions combined frequency (12 or 18 presentations) and spacing (all presentations in 1 session, or spread over 4 days). Comprehension and production probes were administered after the final session and 1 week later. Results: Although the children with SLI benefited significantly from frequent and widely spaced presentations, there were no significant effect in the control group. The language-impaired children showed rapid forgetting. Conclusions: The frequency and spacing of presentations crucially affect the verb learning of children with SLI. A training regimen characterized by appropriately spaced intervals and moderate repetition will optimally benefit lexical learning.},
  file = {/Users/megcychosz/Zotero/storage/NKGQRCIP/Riches et al. - Verb Learning in Children With SLI Frequency and .pdf},
  language = {en}
}

@article{rickfordLanguageLinguisticsTrial2016,
  title = {Language and Linguistics on Trial: {{Hearing Rachel Jeantel}} (and Other Vernacular Speakers) in the Courtroom and Beyond},
  shorttitle = {Language and Linguistics on Trial},
  author = {Rickford, John R. and King, Sharese},
  year = {2016},
  volume = {92},
  pages = {948--988},
  issn = {1535-0665},
  doi = {10.1353/lan.2016.0078},
  file = {/Users/megcychosz/Zotero/storage/S9A5N4NL/Rickford and King - 2016 - Language and linguistics on trial Hearing Rachel .pdf},
  journal = {Language},
  language = {en},
  number = {4}
}

@article{robbinsPracticalSuggestionsLegal2017,
  title = {Practical {{Suggestions}} for {{Legal}} and {{Ethical Concerns With Social Environment Sampling Methods}}},
  author = {Robbins, Megan L.},
  year = {2017},
  month = jul,
  volume = {8},
  pages = {573--580},
  issn = {1948-5506, 1948-5514},
  doi = {10.1177/1948550617699253},
  abstract = {The capabilities offered to psychology researchers by new technology have catapulted the field toward a deeper understanding of people's social experiences. However, it concurrently increases the need to consider the ethical and legal concerns of capturing information about bystanders. This article outlines the legal and ethical issues that researchers should consider when conducting social environment sampling research. The goal is to serve as a ``quick start guide'' to the unique legal and ethical challenges that arise with social environment sampling, and to offer some solutions.},
  file = {/Users/megcychosz/Zotero/storage/TWVGDAU7/Robbins - 2017 - Practical Suggestions for Legal and Ethical Concer.pdf},
  journal = {Social Psychological and Personality Science},
  language = {en},
  number = {5}
}

@article{robbNotePrespeechEarly1997,
  title = {A Note on Prespeech and Early Speech Coarticulation},
  author = {Robb, Michael and Wolk, Lesley},
  year = {1997},
  month = jan,
  volume = {22},
  pages = {99--104},
  issn = {1401-5439, 1651-2022},
  doi = {10.3109/14015439709075321},
  file = {/Users/megcychosz/Zotero/storage/G78PHYFC/Robb and Wolk - 1997 - A note on prespeech and early speech coarticulatio.pdf},
  journal = {Logopedics Phoniatrics Vocology},
  language = {en},
  number = {3}
}

@article{robertsFormalApproachGrammaticalization1999,
  title = {A Formal Approach to "Grammaticalization"},
  author = {Roberts, I. and Roussou, A},
  year = {1999},
  volume = {37},
  pages = {1011--1041},
  journal = {Linguistics},
  number = {6}
}

@article{robertsRacialInequalityPsychological,
  title = {Racial {{Inequality}} in {{Psychological Research}}: {{Trends}} of the {{Past}} and {{Recommendations}} for the {{Future}}},
  author = {Roberts, Steven O and {Bareket-Shavit}, Carmelle and Dollins, Forrest A and Goldie, Peter D and Mortenson, Elizabeth},
  pages = {15},
  abstract = {Race plays an important role in how people think, develop, and behave. In the current article, we queried more than 26,000 empirical articles published between 1974 and 2018 in top-tier cognitive, developmental, and social psychology journals to document how often psychological research acknowledges this reality and to examine whether people who edit, write, and participate in the research are systematically connected. We note several findings. First, across the past five decades, psychological publications that highlight race have been rare, and although they have increased in developmental and social psychology, they have remained virtually nonexistent in cognitive psychology. Second, most publications have been edited by White editors, under which there have been significantly fewer publications that highlight race. Third, many of the publications that highlight race have been written by White authors who employed significantly fewer participants of color. In many cases, we document variation as a function of area and decade. We argue that systemic inequality exists within psychological research and that systemic changes are needed to ensure that psychological research benefits from diversity in editing, writing, and participation. To this end, and in the spirit of the field's recent emphasis on metascience, we offer recommendations for journals and authors.},
  file = {/Users/megcychosz/Zotero/storage/GHTK8MDC/Roberts et al. - Racial Inequality in Psychological Research Trend.pdf},
  language = {en}
}

@article{roettgerResearcherDegreesFreedom2018,
  title = {Researcher Degrees of Freedom in Phonetic Research},
  author = {Roettger, Timo B},
  year = {2018},
  pages = {34},
  abstract = {The results of published research critically depend on methodological decisions that have been made during data analysis. These so-called ``researcher degrees of freedom'' (Simmons, Nelson, \& Simonsohn, 2011) can affect the results and the conclusions researcher draw from it. It is argued that phonetic research faces a large number of researcher degrees of freedom due to its scientific object \textendash{} speech \textendash{} being inherently multidimensional and exhibiting complex interactions between multiple covariates. A Type-I error simulation is presented that demonstrates the severe inflation of false positives when exploring researcher degrees of freedom. It is argued that combined with common cognitive fallacies, exploitation of researcher degrees of freedom introduces strong bias and poses a serious challenge to quantitative phonetics as an empirical science. This paper discusses potential remedies for this problem including adjusting the threshold for significance; drawing a clear line between confirmatory and exploratory analyses via preregistration; open, honest and transparent practices in communicating data analytical decisions; and direct replications.},
  file = {/Users/megcychosz/Zotero/storage/HILBL9IJ/Roettger - Researcher degrees of freedom in phonetic research.pdf},
  language = {en}
}

@article{romeo30MillionWordGapChildren2018,
  title = {Beyond the 30-{{Million}}-{{Word Gap}}: {{Children}}'s {{Conversational Exposure Is Associated With Language}}-{{Related Brain Function}}},
  shorttitle = {Beyond the 30-{{Million}}-{{Word Gap}}},
  author = {Romeo, Rachel R. and Leonard, Julia A. and Robinson, Sydney T. and West, Martin R. and Mackey, Allyson P. and Rowe, Meredith L. and Gabrieli, John D. E.},
  year = {2018},
  month = may,
  volume = {29},
  pages = {700--710},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797617742725},
  abstract = {Children's early language exposure impacts their later linguistic skills, cognitive abilities, and academic achievement, and large disparities in language exposure are associated with family socioeconomic status (SES). However, there is little evidence about the neural mechanism(s) underlying the relation between language experience and linguistic/cognitive development.},
  file = {/Users/megcychosz/Zotero/storage/T5CDPNBS/Romeo et al. - 2018 - Beyond the 30-Million-Word Gap Children’s Convers.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {5}
}

@article{ronsonWordFrequencyStuttering1976,
  title = {Word Frequency and Stuttering: {{The}} Relationship to Sentence Structure},
  author = {Ronson, I.},
  year = {1976},
  volume = {19},
  pages = {813--819},
  journal = {Journal of Speech Language and Hearing Research},
  number = {4}
}

@incollection{roseInterpretationPhonologicalPatterns2011,
  title = {The {{Interpretation}} of {{Phonological Patterns}} in {{First Language Acquisition}}: {{The Interpretation}} of {{Phonological Patterns}} in {{First Language Acquisition}}},
  shorttitle = {The {{Interpretation}} of {{Phonological Patterns}} in {{First Language Acquisition}}},
  booktitle = {The {{Blackwell Companion}} to {{Phonology}}},
  author = {Rose, Yvan and Inkelas, Sharon},
  editor = {{van Oostendorp}, Marc and Ewen, Colin J. and Hume, Elizabeth and Rice, Keren},
  year = {2011},
  month = apr,
  pages = {1--25},
  publisher = {{John Wiley \& Sons, Ltd}},
  address = {{Oxford, UK}},
  doi = {10.1002/9781444335262.wbctp0101},
  file = {/Users/megcychosz/Zotero/storage/U67MQXKL/Rose and Inkelas - 2011 - The Interpretation of Phonological Patterns in Fir.pdf},
  isbn = {978-1-4443-3526-2},
  language = {en}
}

@article{rossUsheringNewEra,
  title = {Ushering in a New Era of Open Science through Data Sharing: {{The}} Wall Must Come Down},
  author = {Ross, Joseph and Krumholz, Harlan},
  volume = {309},
  pages = {1355--1356},
  journal = {Journal of the American Medical Association},
  number = {13}
}

@article{rouvierChildLanguageResearch,
  title = {Child {{Language Research}} and {{Revitalization Working Group}}:},
  author = {Rouvier, Ruth and Korne, Haley De and Ironstrack, George and {Knapp-Philo}, Joanne and {Baker-Oglesbee}, Alissa and Chelliah, Shobhana and Flaada, Jordyn and Hermes, Mary and Lalonde, Christopher and {Manatowa-Bailey}, Jacob and Meek, Barbra and Mosley, Susan and Oster, Richard and Sims, Chris and Sparrow, Joshua and Weston, Jennifer and Avishay, Amy and Priyanto, Frederica},
  pages = {31},
  file = {/Users/megcychosz/Zotero/storage/SDLMCTDW/Rouvier et al. - Child Language Research and Revitalization Working.pdf},
  language = {en}
}

@article{roweChilddirectedSpeechRelation2008,
  title = {Child-Directed Speech: Relation to Socioeconomic Status, Knowledge of Child Development, and Child Vocabulary Skill},
  author = {Rowe, Meredith},
  year = {2008},
  volume = {35},
  pages = {185--205},
  journal = {Journal of Child Language},
  number = {1}
}

@article{roweChilddirectedSpeechRelation2008a,
  title = {Child-Directed Speech: Relation to Socioeconomic Status, Knowledge of Child Development and Child Vocabulary Skill},
  shorttitle = {Child-Directed Speech},
  author = {Rowe, Meredith L.},
  year = {2008},
  month = feb,
  volume = {35},
  pages = {185--205},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000907008343},
  abstract = {This study sought to determine why American parents from different socioeconomic backgrounds communicate in different ways with their children. Forty-seven parent\textendash child dyads were videotaped engaging in naturalistic interactions in the home for ninety minutes at child age 2; 6. Transcripts of these interactions provided measures of child-directed speech. Children's vocabulary comprehension skills were measured using the Peabody Picture Vocabulary Test at 2 ;6 and one year later at 3 ; 6. Results indicate that : (1) child-directed speech with toddlers aged 2; 6 predicts child vocabulary skill one year later, controlling for earlier toddler vocabulary skill ; (2) child-directed speech relates to socioeconomic status as measured by income and education ; and (3) the relation between socioeconomic status and child-directed speech is mediated by parental knowledge of child development. Potential mechanisms through which parental knowledge influences communicative behavior are discussed.},
  file = {/Users/megcychosz/Zotero/storage/W58HKQQ6/Rowe - 2008 - Child-directed speech relation to socioeconomic s.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {1}
}

@article{roweLanguageDevelopmentContext2020,
  title = {Language {{Development}} in {{Context}}},
  author = {Rowe, Meredith L and Weisleder, Adriana},
  year = {2020},
  pages = {23},
  abstract = {Young children learn to communicate in the language(s) of their communities, yet the individual trajectories of language development and the particular language varieties and modes of communication children acquire vary depending on the contexts in which they live. This review describes how context shapes language development. Building on the bioecological model of development, we conceptualize context as a set of nested systems surrounding the child, from the national policies and cultural norms that shape the broader environment to the particular communicative interactions in which children experience language being used. In addition, we describe how children's developing sensory-motor, perceptual, and social-cognitive capacities respond to and are tuned by the surrounding environment. Closer integration of research on the mechanisms of language learning with investigation of the contexts in which this learning takes place will provide critical insights into the process of language development.},
  file = {/Users/megcychosz/Zotero/storage/8E2HQBKI/Rowe and Weisleder - 2020 - Language Development in Context.pdf},
  language = {en}
}

@article{roweLongitudinalInvestigationRole2012,
  title = {A {{Longitudinal Investigation}} of the {{Role}} of {{Quantity}} and {{Quality}} of {{Child}}-{{Directed Speech}} in {{Vocabulary Development}}: {{Child}}-{{Directed Speech}} and {{Vocabulary}}},
  shorttitle = {A {{Longitudinal Investigation}} of the {{Role}} of {{Quantity}} and {{Quality}} of {{Child}}-{{Directed Speech}} in {{Vocabulary Development}}},
  author = {Rowe, Meredith L.},
  year = {2012},
  month = sep,
  volume = {83},
  pages = {1762--1774},
  issn = {00093920},
  doi = {10.1111/j.1467-8624.2012.01805.x},
  file = {/Users/megcychosz/Zotero/storage/LV7LCEVF/Rowe - 2012 - A Longitudinal Investigation of the Role of Quanti.pdf},
  journal = {Child Development},
  language = {en},
  number = {5}
}

@article{rowePaceVocabularyGrowth2012,
  title = {The {{Pace}} of {{Vocabulary Growth Helps Predict Later Vocabulary Skill}}},
  author = {Rowe, Meredith L. and Raudenbush, Stephen W. and Goldin-Meadow, Susan},
  year = {2012},
  volume = {83},
  pages = {508--525},
  issn = {1467-8624},
  doi = {10.1111/j.1467-8624.2011.01710.x},
  abstract = {Children vary widely in the rate at which they acquire words\textemdash some start slow and speed up, others start fast and continue at a steady pace. Do early developmental variations of this sort help predict vocabulary skill just prior to kindergarten entry? This longitudinal study starts by examining important predictors (socioeconomic status [SES], parent input, child gesture) of vocabulary growth between 14 and 46 months (n = 62) and then uses growth estimates to predict children's vocabulary at 54 months. Velocity and acceleration in vocabulary development at 30 months predicted later vocabulary, particularly for children from low-SES backgrounds. Understanding the pace of early vocabulary growth thus improves our ability to predict school readiness and may help identify children at risk for starting behind.},
  annotation = {\_eprint: https://srcd.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8624.2011.01710.x},
  file = {/Users/megcychosz/Zotero/storage/BBHE6ALQ/Rowe et al. - 2012 - The Pace of Vocabulary Growth Helps Predict Later .pdf;/Users/megcychosz/Zotero/storage/SC9RVWZ8/j.1467-8624.2011.01710.html},
  journal = {Child Development},
  language = {en},
  number = {2}
}

@book{rstudioteamRStudioIntegratedDevelopment2020,
  title = {{{RStudio}}: {{Integrated Development}} for {{R}}},
  author = {RStudioTeam},
  year = {2020},
  publisher = {{RStudio, Inc.}},
  address = {{Boston, MA}}
}

@inproceedings{rubertusAnticipatoryVtoVCoarticulation2013,
  title = {Anticipatory {{V}}-to-{{V Coarticulation}} in {{German Preschoolers}}},
  booktitle = {Tagungsband Der 12. {{Tagung}} 9 {{Phonetik}} Und {{Phonologie}} Im Deutschsprachigen {{Raum}}},
  author = {Rubertus, Elina and Abakarova, Dzhuma and Ries, Jan and Noiray, Aude},
  editor = {Draxler, C. and Kleber, F.},
  year = {2013},
  pages = {12--14},
  address = {{Ludwig-maximilians-Universitat Munchen}},
  abstract = {This study investigates lingual V-to-V anticipatory coarticulation in German preschoolers and adults using ultrasound measures. In light of conflicting results in the literature, the aim was to study effects in large cohorts and with a widespread set of vowels. Results provide evidence for V-to-V coarticulation in children as well as adults, independent of the intervocalic consonant. Interestingly, coarticulation magnitude decreases with age.},
  file = {/Users/megcychosz/Zotero/storage/N7H9EQBW/Rubertus et al. - Anticipatory V-to-V Coarticulation in German Presc.pdf},
  language = {en}
}

@article{rubertusDevelopmentGesturalOrganization2018,
  title = {On the Development of Gestural Organization: {{A}} Cross-Sectional Study of Vowel-to-Vowel Anticipatory Coarticulation},
  shorttitle = {On the Development of Gestural Organization},
  author = {Rubertus, Elina and Noiray, Aude},
  editor = {Perlman, Marcus},
  year = {2018},
  volume = {13},
  pages = {1--21},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0203562},
  abstract = {In the first years of life, children differ greatly from adults in the temporal organization of their speech gestures in fluent language production. However, dissent remains as to the maturational direction of such organization. The present study sheds new light on this process by tracking the development of anticipatory vowel-to-vowel coarticulation in a cross-sectional investigation of 62 German children (from 3.5 to 7 years of age) and 13 adults. It focuses on gestures of the tongue, a complex organ whose spatiotemporal control is indispensable for speech production. The goal of the study was threefold: 1) investigate whether children as well as adults initiate the articulation for a target vowel in advance of its acoustic onset, 2) test if the identity of the intervocalic consonant matters and finally, 3) describe age-related developments of these lingual coarticulatory patterns. To achieve this goal, ultrasound tongue imaging was used to record lingual movements and quantify changes in coarticulation degree as a function of consonantal context and age. Results from linear mixed effects models indicate that like adults, children initiate vowels' lingual gestures well ahead of their acoustic onset. Second, while the identity of the intervocalic consonant affects the degree of vocalic anticipation in adults, it does not in children at any age. Finally, the degree of vowelto-vowel coarticulation is significantly higher in all cohorts of children than in adults. However, among children, a developmental decrease of vocalic coarticulation is only found for sequences including the alveolar stop /d/ which requires finer spatiotemporal coordination of the tongue's subparts compared to labial and velar stops. Altogether, results suggest greater gestural overlap in child than in adult speech and support the view of a non-uniform and protracted maturation of lingual coarticulation calling for thorough considerations of the articulatory intricacies from which subtle developmental differences may originate.},
  file = {/Users/megcychosz/Zotero/storage/DE8TZJ27/Rubertus and Noiray - 2018 - On the development of gestural organization A cro.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {9}
}

@article{rubertusVocalicActivationWidth2020,
  title = {Vocalic Activation Width Decreases across Childhood: {{Evidence}} from Carryover Coarticulation},
  shorttitle = {Vocalic Activation Width Decreases across Childhood},
  author = {Rubertus, Elina and Noiray, Aude},
  year = {2020},
  month = jun,
  volume = {11},
  pages = {7},
  issn = {1868-6354, 1868-6354},
  doi = {10.5334/labphon.228},
  file = {/Users/megcychosz/Zotero/storage/QPKMMV2E/Rubertus and Noiray - 2020 - Vocalic activation width decreases across childhoo.pdf},
  journal = {Laboratory Phonology: Journal of the Association for Laboratory Phonology},
  language = {en},
  number = {1}
}

@article{rufsvoldImpactLanguageInput2018,
  title = {The {{Impact}} of {{Language Input}} on {{Deaf}} and {{Hard}} of {{Hearing Preschool Children Who Use Listening}} and {{Spoken Language}}},
  author = {Rufsvold, Ronda and Wang, Ye and Hartman, Maria C. and Arora, Sonia B. and Smolen, Elaine R.},
  year = {2018},
  volume = {163},
  pages = {35--60},
  issn = {1543-0375},
  doi = {10.1353/aad.2018.0010},
  abstract = {The researchers investigated the effects of adult language input on the quantity of language, vocabulary development, and understanding of basic concepts of deaf and hard of hearing (DHH) children who used listening and spoken language. Using audio recording and Language ENvironment Analysis (LENA) software, the study involved 30 preschool DHH children who used spoken language as their communication modality and 11 typically hearing same-age peers. The children's language and the language spoken to them during all waking hours over a 2-day period (16 hours per day) were recorded and analyzed quantitatively and were compared to the children's performance on the Boehm Test of Basic Concepts and the Peabody Picture Vocabulary Test. The results highlight the relationship between the quantity of adult language and the language, vocabulary, and basic concept knowledge of DHH preschool children who use listening and spoken language.},
  file = {/Users/megcychosz/Zotero/storage/N8BTBGMN/Rufsvold et al. - 2018 - The Impact of Language Input on Deaf and Hard of H.pdf},
  journal = {American Annals of the Deaf},
  language = {en},
  number = {1}
}

@article{rvachewDevelopmentalCrosslinguisticVariation2006,
  title = {Developmental and Cross-Linguistic Variation in the Infant Vowel Space: {{The}} Case of {{Canadian English}} and {{Canadian French}}},
  shorttitle = {Developmental and Cross-Linguistic Variation in the Infant Vowel Space},
  author = {Rvachew, Susan and Mattock, Karen and Polka, Linda and M{\'e}nard, Lucie},
  year = {2006},
  month = oct,
  volume = {120},
  pages = {2250--2259},
  issn = {0001-4966},
  doi = {10.1121/1.2266460},
  file = {/Users/megcychosz/Zotero/storage/MTXDEJ2L/Rvachew et al. - 2006 - Developmental and cross-linguistic variation in th.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@article{rvachewPhonologicalAwarenessPhonemic2003,
  title = {Phonological {{Awareness}} and {{Phonemic Perception}} in 4-{{Year}}-{{Old Children With Delayed Expressive Phonology Skills}}},
  author = {Rvachew, Susan and Ohberg, Alyssa and Grawburg, Meghann and Heyding, Joan},
  year = {2003},
  month = nov,
  volume = {12},
  pages = {463--471},
  issn = {1058-0360, 1558-9110},
  doi = {10.1044/1058-0360(2003/092)},
  abstract = {The purpose of this study was to compare the phonological awareness abilities of 2 groups of 4-year-old children: one with normally developing speech and language skills and the other with moderately or severely delayed expressive phonological skills but age-appropriate receptive vocabulary skills. Each group received tests of articulation, receptive vocabulary, phonemic perception, early literacy, and phonological awareness skills. The groups were matched for receptive language skills, age, socioeconomic status, and emergent literacy knowledge. The children with expressive phonological delays demonstrated significantly poorer phonemic perception and phonological awareness skills than their normally developing peers. The results suggest that preschool children with delayed expressive phonological abilities should be screened for their phonological awareness skills even when their language skills are otherwise normally developing.},
  file = {/Users/megcychosz/Zotero/storage/3ZZNU655/Rvachew et al. - 2003 - Phonological Awareness and Phonemic Perception in .pdf},
  journal = {American Journal of Speech-Language Pathology},
  language = {en},
  number = {4}
}

@article{sacksPilotTestingParentdirected2014,
  title = {Pilot Testing of a Parent-Directed Intervention ({{Project ASPIRE}}) for Underserved Children Who Are Deaf or Hard of Hearing},
  author = {Sacks, Chana and Shay, Sophie and Repplinger, Lyra and Leffel, Kristin R and Sapolich, Shannon G and Suskind, Elizabeth and Tannenbaum, Sally and Suskind, Dana},
  year = {2014},
  month = feb,
  volume = {30},
  pages = {91--102},
  issn = {0265-6590, 1477-0865},
  doi = {10.1177/0265659013494873},
  file = {/Users/megcychosz/Zotero/storage/Y2Z4ZTIX/Sacks et al. - 2014 - Pilot testing of a parent-directed intervention (P.pdf},
  journal = {Child Language Teaching and Therapy},
  language = {en},
  number = {1}
}

@article{sacksPilotTestingParentdirected2014a,
  title = {Pilot Testing of a Parent-Directed Intervention ({{Project ASPIRE}}) for Underserved Children Who Are Deaf or Hard of Hearing},
  author = {Sacks, Chana and Shay, Sophie and Repplinger, Lyra and Leffel, Kristin R and Sapolich, Shannon G and Suskind, Elizabeth and Tannenbaum, Sally and Suskind, Dana},
  year = {2014},
  month = feb,
  volume = {30},
  pages = {91--102},
  issn = {0265-6590, 1477-0865},
  doi = {10.1177/0265659013494873},
  file = {/Users/megcychosz/Zotero/storage/LBMT8W2M/Sacks et al. - 2014 - Pilot testing of a parent-directed intervention (P.pdf},
  journal = {Child Language Teaching and Therapy},
  language = {en},
  number = {1}
}

@article{saffranStatisticalLanguageLearning2003,
  title = {Statistical {{Language Learning}}: {{Mechanisms}} and {{Constraints}}},
  shorttitle = {Statistical {{Language Learning}}},
  author = {Saffran, Jenny R.},
  year = {2003},
  month = aug,
  volume = {12},
  pages = {110--114},
  issn = {0963-7214, 1467-8721},
  doi = {10.1111/1467-8721.01243},
  abstract = {What types of mechanisms underlie the acquisition of human language? Recent evidence suggests that learners, including infants, can use statistical properties of linguistic input to discover structure, including sound patterns, words, and the beginnings of grammar. These abilities appear to be both powerful and constrained, such that some statistical patterns are more readily detected and used than others. Implications for the structure of human languages are discussed.},
  file = {/Users/megcychosz/Zotero/storage/9M6RQ8VV/Saffran - 2003 - Statistical Language Learning Mechanisms and Cons.pdf},
  journal = {Current Directions in Psychological Science},
  language = {en},
  number = {4}
}

@article{sassenhagenCommonMisapplicationStatistical2016,
  title = {A Common Misapplication of Statistical Inference: Nuisance Control with Null-Hypothesis Significance Tests},
  shorttitle = {A Common Misapplication of Statistical Inference},
  author = {Sassenhagen, Jona and Alday, Phillip M.},
  year = {2016},
  month = nov,
  volume = {162},
  pages = {42--45},
  issn = {0093934X},
  doi = {10.1016/j.bandl.2016.08.001},
  abstract = {Experimental research on behavior and cognition frequently rests on stimulus or subject selection where not all characteristics can be fully controlled, even when attempting strict matching. For example, when contrasting patients to controls, variables such as intelligence or socioeconomic status are often correlated with patient status. Similarly, when presenting word stimuli, variables such as word frequency are often correlated with primary variables of interest. One procedure very commonly employed to control for such nuisance effects is conducting inferential tests on confounding stimulus or subject characteristics. For example, if word length is not significantly different for two stimulus sets, they are considered as matched for word length. Such a test has high error rates and is conceptually misguided. It reflects a common misunderstanding of statistical tests: interpreting significance not to refer to inference about a particular population parameter, but about 1. the sample in question, 2. the practical relevance of a sample difference (so that a nonsignificant test is taken to indicate evidence for the absence of relevant differences). We show inferential testing for assessing nuisance effects to be inappropriate both pragmatically and philosophically, present a survey showing its high prevalence, and briefly discuss an alternative in the form of regression including nuisance variables.},
  archiveprefix = {arXiv},
  eprint = {1602.04565},
  eprinttype = {arxiv},
  file = {/Users/megcychosz/Zotero/storage/44CDUPW5/Sassenhagen and Alday - 2016 - A common misapplication of statistical inference .pdf},
  journal = {Brain and Language},
  keywords = {Statistics - Methodology},
  language = {en}
}

@article{savaleiSTRUCTURALEQUATIONMODELING,
  title = {{{STRUCTURAL EQUATION MODELING}}},
  author = {Savalei, Victoria and Bentler, Peter M},
  pages = {61},
  file = {/Users/megcychosz/Zotero/storage/7D9Y4J6Z/Savalei and Bentler - STRUCTURAL EQUATION MODELING.pdf},
  language = {en}
}

@article{savariauxCompensationStrategiesPerturbation1995,
  title = {Compensation Strategies for the Perturbation of the Rounded Vowel [u] Using a Lip Tube: {{A}} Study of the Control Space in Speech Production},
  shorttitle = {Compensation Strategies for the Perturbation of the Rounded Vowel [u] Using a Lip Tube},
  author = {Savariaux, Christophe and Perrier, Pascal and Orliaguet, Jean Pierre},
  year = {1995},
  month = nov,
  volume = {98},
  pages = {2428--2442},
  issn = {0001-4966},
  doi = {10.1121/1.413277},
  file = {/Users/megcychosz/Zotero/storage/PYWT4M5G/Savariaux et al. - 1995 - Compensation strategies for the perturbation of th.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{saviciuteRolesWordformFrequency2018,
  title = {The Roles of Word-Form Frequency and Phonological Neighbourhood Density in the Acquisition of {{Lithuanian}} Noun Morphology},
  author = {Savi{\v c}i{\=u}t{\.e}, Egl{\.e} and Ambridge, Ben and Pine, Julian M.},
  year = {2018},
  month = may,
  volume = {45},
  pages = {641--672},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S030500091700037X},
  abstract = {Abstract             Four- and five-year-old children took part in an elicited familiar and novel Lithuanian noun production task to test predictions of input-based accounts of the acquisition of inflectional morphology. Two major findings emerged. First, as predicted by input-based accounts, correct production rates were correlated with the input frequency of the target form, and with the phonological neighbourhood density of the noun. Second, the error patterns were not compatible with the systematic substitution of target forms by either (a) the most frequent form of that noun or (b) a single morphosyntactic default form, as might be predicted by naive versions of a constructivist and generativist account, respectively. Rather, most errors reflected near-miss substitutions of singular for plural, masculine for feminine, or nominative/accusative for a less frequent case. Together, these findings provide support for an input-based approach to morphological acquisition, but are not adequately explained by any single account in its current form.},
  file = {/Users/megcychosz/Zotero/storage/FE2HA6XW/Savičiūtė et al. - 2018 - The roles of word-form frequency and phonological .pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {3}
}

@article{saviciuteRolesWordformFrequency2018a,
  title = {The Roles of Word-Form Frequency and Phonological Neighbourhood Density in the Acquisition of {{Lithuanian}} Noun Morphology},
  author = {Savi{\v c}i{\=u}t{\.e}, Egl{\.e} and Ambridge, Ben and Pine, Julian M.},
  year = {2018},
  month = may,
  volume = {45},
  pages = {641--672},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S030500091700037X},
  abstract = {Abstract             Four- and five-year-old children took part in an elicited familiar and novel Lithuanian noun production task to test predictions of input-based accounts of the acquisition of inflectional morphology. Two major findings emerged. First, as predicted by input-based accounts, correct production rates were correlated with the input frequency of the target form, and with the phonological neighbourhood density of the noun. Second, the error patterns were not compatible with the systematic substitution of target forms by either (a) the most frequent form of that noun or (b) a single morphosyntactic default form, as might be predicted by naive versions of a constructivist and generativist account, respectively. Rather, most errors reflected near-miss substitutions of singular for plural, masculine for feminine, or nominative/accusative for a less frequent case. Together, these findings provide support for an input-based approach to morphological acquisition, but are not adequately explained by any single account in its current form.},
  file = {/Users/megcychosz/Zotero/storage/ZLFXYZUI/Savičiūtė et al. - 2018 - The roles of word-form frequency and phonological .pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {3}
}

@article{sawuschPerceptualNormalizationSpeaking2000,
  title = {Perceptual Normalization for Speaking Rate {{II}}: {{Effects}} of Signal Discontinuities},
  shorttitle = {Perceptual Normalization for Speaking Rate {{II}}},
  author = {Sawusch, James R. and Newman, Rochelle S.},
  year = {2000},
  volume = {62},
  pages = {285--300},
  issn = {0031-5117, 1532-5962},
  doi = {10.3758/BF03205549},
  file = {/Users/megcychosz/Zotero/storage/FU79CJDG/Sawusch and Newman - 2000 - Perceptual normalization for speaking rate II Eff.pdf},
  journal = {Perception \& Psychophysics},
  language = {en},
  number = {2}
}

@article{sawuschSelectiveAdaptationEffects1976,
  title = {Selective Adaptation Effects on End-Point Stimuli in a Speech Series},
  author = {Sawusch, James R},
  year = {1976},
  month = jan,
  volume = {20},
  pages = {61--65},
  issn = {0031-5117, 1532-5962},
  doi = {10.3758/BF03198707},
  file = {/Users/megcychosz/Zotero/storage/W2GBSML8/Sawusch - 1976 - Selective adaptation effects on end-point stimuli .pdf},
  journal = {Perception \& Psychophysics},
  language = {en},
  number = {1}
}

@book{scaffDaylongRecordingsYoung2018,
  title = {Daylong Recordings from Young Children Learning {{Tsimane}} in {{Bolivia}}},
  author = {Scaff, C. and Stieglitz, Jonathan and Cristi{\`a}, Alejandrina},
  year = {2018}
}

@misc{SCALaBlueprintComputational,
  title = {{{SCALa}}: {{A}} Blueprint for Computational Models of Language Acquisition in Social Context | {{Elsevier Enhanced Reader}}},
  shorttitle = {{{SCALa}}},
  doi = {10.1016/j.cognition.2021.104779},
  file = {/Users/megcychosz/Zotero/storage/CQTURECT/S0010027721001980.html},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S0010027721001980?token=BCBC601C450693DDDB848B5636BE7AB65EB1381EF29CF8841A5B085634D0EBCAB5257C5FC937DE57DB22D570E8CF1208\&originRegion=us-east-1\&originCreation=20210612113641},
  language = {en}
}

@phdthesis{scarboroughCoarticulationStructureLexicon2005,
  title = {Coarticulation and the Structure of the Lexicon},
  author = {Scarborough, Rebecca},
  year = {2005},
  address = {{Log Angeles, CA}},
  school = {University of California, Los Angeles},
  type = {Unpublished Doctoral Dissertation}
}

@article{schatzEarlyPhoneticLearning2021,
  title = {Early Phonetic Learning without Phonetic Categories: {{Insights}} from Large-Scale Simulations on Realistic Input},
  shorttitle = {Early Phonetic Learning without Phonetic Categories},
  author = {Schatz, Thomas and Feldman, Naomi H. and Goldwater, Sharon and Cao, Xuan-Nga and Dupoux, Emmanuel},
  year = {2021},
  month = feb,
  volume = {118},
  pages = {e2001844118},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2001844118},
  abstract = {Before they even speak, infants become attuned to the sounds of the language(s) they hear, processing native phonetic contrasts more easily than nonnative ones. For example, between 6 to 8 mo and 10 to 12 mo, infants learning American English get better at distinguishing English and [l], as in ``rock'' vs. ``lock,'' relative to infants learning Japanese. Influential accounts of this               early phonetic learning               phenomenon initially proposed that infants group sounds into native vowel- and consonant-like phonetic categories\textemdash like and [l] in English\textemdash through a statistical clustering mechanism dubbed ``distributional learning.'' The feasibility of this mechanism for learning phonetic categories has been challenged, however. Here, we demonstrate that a distributional learning algorithm operating on naturalistic speech can predict early phonetic learning, as observed in Japanese and American English infants, suggesting that infants might learn through distributional learning after all. We further show, however, that, contrary to the original distributional learning proposal, our model learns units too brief and too fine-grained acoustically to correspond to phonetic categories. This challenges the influential idea that what infants learn are phonetic categories. More broadly, our work introduces a               mechanism-driven               approach to the study of early phonetic learning, together with a quantitative modeling framework that can handle realistic input. This allows accounts of early phonetic learning to be linked to concrete, systematic predictions regarding infants' attunement.},
  file = {/Users/megcychosz/Zotero/storage/JBK9W5WU/Schatz et al. - 2021 - Early phonetic learning without phonetic categorie.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {7}
}

@article{schenkChangesVowelQuality2003,
  title = {Changes in {{Vowel Quality}} after {{Cochlear Implantation}}},
  author = {Schenk, Barbara S. and Baumgartner, Wolf-Dieter and Hamzavi, Jafar S.},
  year = {2003},
  volume = {65},
  pages = {184--188},
  issn = {0301-1569, 1423-0275},
  doi = {10.1159/000072257},
  abstract = {Since auditory feedback is partially restored after cochlear implantation, the aim of the present study was to investigate features of vowels, which reflect improvements in speech production. Ten postlingually deafened subjects (5 male/5 female) were recorded reading a German text before and 3 and 12 months after implantation, respectively. Selected vowels were analysed regarding the fundamental frequency (F0), the formant frequencies (F1, F2, F3) and the vowel space (difference between F1 and F2 in hertz). The F0 decreased only descriptively after 3 and 12 months, respectively. F1 of the vowel /e/ was significantly lower after 12 months (411 B 20 compared to 349 B 25 Hz, p \^ 0.05) and for /o/ after 3 months (446 B 29 compared to 408 B 31 Hz, p \^ 0.05) for the male patients: their vowel space also expanded significantly for the vowel /o/ (372 B 37 compared to 467 B 32 Hz, p \^ 0.05) after 12 months. Regained auditory feedback after cochlear implantation had an effect on the improvement of the production of vowels.},
  file = {/Users/megcychosz/Zotero/storage/M75FTBFX/Schenk et al. - 2003 - Changes in Vowel Quality after Cochlear Implantati.pdf},
  journal = {ORL},
  language = {en},
  number = {3}
}

@article{schneiderAuditorySensitivityPreschool1985,
  title = {Auditory {{Sensitivity}} in {{Preschool Children}}},
  author = {Schneider, B A and Trehub, S E and Morrongiello, B A and Thorpe, L A},
  year = {1985},
  volume = {79},
  pages = {447--452},
  file = {/Users/megcychosz/Zotero/storage/2YT6USJT/Schneider et al. - Auditory Sensitivity in Preschool Children.pdf},
  language = {en},
  number = {2}
}

@misc{schneiderEPrime2012,
  title = {E-{{Prime}}},
  author = {Schneider, W. and Eschman, A. and Zuccolotto, A.},
  year = {2012},
  address = {{Pittsburgh, PA}},
  howpublished = {Psychology Softwre Tools, Inc.}
}

@article{schwartzChildrenPickChoose1982,
  title = {Do Children Pick and Choose? An Examination of Phonological Selection and Avoidance in Early Lexical Acquisition},
  shorttitle = {Do Children Pick and Choose?},
  author = {Schwartz, Richard G. and Leonard, Laurence B.},
  year = {1982},
  month = jun,
  volume = {9},
  pages = {319--336},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000900004748},
  abstract = {The influence of phonological selection and avoidance upon early lexical acquisition was examined within an experimental paradigm. During 10 bi-weekly experimental sessions, 12 children (i;o.2i to 153.1s at the outset) were presented with 16 contrived lexical concepts, each consisting of a nonsense word and four unfamiliar referents. For each child, eight words involved phonological characteristics which had been evidenced in production (IN) and eight had characteristics which had not been evidenced in production or selection (OUT), IN words were produced imitatively and non-imitatively in greater numbers and in earlier sessions than OUT words, providing evidence for the influence of selection and avoidance. The degree of phonetic accuracy of these two types of productions did not differ. These findings are discussed in terms of a proposal concerning early phonological representation and acquisition.},
  file = {/Users/megcychosz/Zotero/storage/TLT4TFLE/Schwartz and Leonard - 1982 - Do children pick and choose an examination of pho.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {2}
}

@incollection{sebastian-gallesCrossLanguageSpeechPerception2005,
  title = {Cross-{{Language Speech Perception}}},
  booktitle = {The {{Handbook}} of {{Speech Perception}}},
  author = {{Sebastian-Galles}, Nuria},
  editor = {Pisoni, David B. and Remez, Robert E.},
  year = {2005},
  month = jan,
  pages = {546--566},
  publisher = {{Blackwell Publishing Ltd}},
  address = {{Oxford, UK}},
  doi = {10.1002/9780470757024.ch22},
  file = {/Users/megcychosz/Zotero/storage/VCRAAHQH/Sebastin-Galls - 2005 - Cross-Language Speech Perception.pdf},
  isbn = {978-0-470-75702-4 978-0-631-22927-8},
  language = {en}
}

@article{seguiPhonemeMonitoringSyllable1981,
  title = {Phoneme Monitoring, Syllable Monitoring and Lexical Access},
  author = {Segui, J. and Frauenfelder, U. and Mehler, J.},
  year = {1981},
  month = nov,
  volume = {72},
  pages = {471--477},
  issn = {00071269},
  doi = {10.1111/j.2044-8295.1981.tb01776.x},
  abstract = {In this experiment we investigated the role of the lexical status (word/non-word) of the target item in the determination of phoneme and syllable detection times. Subjects monitored either the initial stop consonants (/b/, /d/, /p/) or the initial CV syllables (/ba/, /de/, /pi/) in bisyllabic target items (word/non-word) in mixed lists. The lexical status of the target item did not introduce significant differences for phoneme or syllable detection times. However, significant differences were found between the phoneme and syllable detection times. In addition, a strong correlation between the phoneme and syllable RTs for each item (word/non-word) was obtained. The first result shows that subjects can respond to both initial phonemes and syllables prior to lexical access. The second result suggests that phoneme detection is highly dependent on syllable identification.},
  file = {/Users/megcychosz/Zotero/storage/RSSALYRR/Segui et al. - 1981 - Phoneme monitoring, syllable monitoring and lexica.pdf},
  journal = {British Journal of Psychology},
  language = {en},
  number = {4}
}

@inproceedings{seidlDetectionCanonicalBabbling2019,
  title = {Towards {{Detection}} of {{Canonical Babbling}} by {{Citizen Scientists}}: {{Performance}} as a {{Function}} of {{Clip Length}}},
  shorttitle = {Towards {{Detection}} of {{Canonical Babbling}} by {{Citizen Scientists}}},
  booktitle = {Interspeech 2019},
  author = {Seidl, Amanda and Warlaumont, Anne S. and Cristia, Alejandrina},
  year = {2019},
  month = sep,
  pages = {3579--3583},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2019-1773},
  abstract = {Theoretical, empirical, and intervention research requires access to a large, unbiased, annotated dataset of infant vocalizations for training speech technology to detect and differentiate consonant-vowel (canonical) syllables in infants' vocalizations from less mature vocalizations. Citizen scientists could help us to achieve the goal of this dataset, if classification is accurate regardless of coders' native language and training and can be completed on clips short enough to avoid revealing personal identifying information. Three groups of coders participated in an experiment: trained native, semi-trained native, and minimally-trained foreign. When vocalizations were presented whole, reliability was highest across the trained coders, with little difference between the semi-trained and minimallytrained coders. Among minimally-trained coders, reliability for 400ms-long clips was very similar to that found for full clips, with lower values for 200 and 600ms clips. Finally, error rates were minimized when 400ms-long clips were used. In sum, minimally-trained coders can achieve fairly reliable and accurate results, even when their native language does not match infants' target language and when provided with very short clips. Since shorter clips protect the identity of the child and her family, this manner of data annotation may provide us with a way of building a large, unbiased dataset of infant vocalizations.},
  file = {/Users/megcychosz/Zotero/storage/4KSDUMKX/Seidl et al. - 2019 - Towards Detection of Canonical Babbling by Citizen.pdf},
  language = {en}
}

@article{seidlInfantsLearningPhonological2012,
  title = {Infants' {{Learning}} of {{Phonological Status}}},
  author = {Seidl, Amanda and Cristi{\`a}, Alejandrina},
  year = {2012},
  volume = {3},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2012.00448},
  abstract = {There is a substantial literature describing how infants become more sensitive to differences between native phonemes (sounds that are both present and meaningful in the input) and less sensitive to differences between non-native phonemes (sounds that are neither present nor meaningful in the input) over the course of development. Here, we review an emergent strand of literature that gives a more nuanced notion of the problem of sound category learning. This research documents infants' discovery of phonological status, signaled by a decrease in sensitivity to sounds that map onto the same phonemic category vs. different phonemic categories. The former phones are present in the input, but their difference does not cue meaning distinctions because they are tied to one and the same phoneme. For example, the diphthong I in I'm should map to the same underlying category as the diphthong in I'd, despite the fact that the first vowel is nasal and the second oral. Because such pairs of sounds are processed differently than those than map onto different phonemes by adult speakers, the learner has to come to treat them differently as well. Interestingly, there is some evidence that infants' sensitivity to dimensions that are allophonic in the ambient language declines as early as 11 months. We lay out behavioral research, corpora analyses, and computational work which sheds light on how infants achieve this feat at such a young age. Collectively, this work suggests that the computation of complementary distribution and the calculation of phonetic similarity operate in concert to guide infants toward a functional interpretation of sounds that are present in the input, yet not lexically contrastive. In addition to reviewing this literature, we discuss broader implications for other fundamental theoretical and empirical questions.},
  file = {/Users/megcychosz/Zotero/storage/Y8D9YX6H/Seidl and Cristia - 2012 - Infants’ Learning of Phonological Status.pdf},
  journal = {Frontiers in Psychology},
  language = {en}
}

@article{seidlTalkerVariationAids2014a,
  title = {Talker {{Variation Aids Young Infants}}' {{Phonotactic Learning}}},
  author = {Seidl, Amanda and Onishi, Kristine H. and Cristia, Alejandrina},
  year = {2014},
  month = oct,
  volume = {10},
  pages = {297--307},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2013.858575},
  file = {/Users/megcychosz/Zotero/storage/JD9ZW26X/Seidl et al. - 2014 - Talker Variation Aids Young Infants’ Phonotactic L.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {4}
}

@article{seidlWhyBodyComes2015,
  title = {Why the Body Comes First: Effects of Experimenter Touch on Infants' Word Finding},
  shorttitle = {Why the Body Comes First},
  author = {Seidl, Amanda and Tincoff, Ruth and Baker, Christopher and Cristia, Alejandrina},
  year = {2015},
  month = jan,
  volume = {18},
  pages = {155--164},
  issn = {1363755X},
  doi = {10.1111/desc.12182},
  abstract = {The lexicon of 6-month-olds is comprised of names and body part words. Unlike names, body part words do not often occur in isolation in the input. This presents a puzzle: How have infants been able to pull out these words from the continuous stream of speech at such a young age? We hypothesize that caregivers' interactions directed at and on the infant's body may be at the root of their early acquisition of body part words. An artificial language segmentation study shows that experimenter-provided synchronous tactile cues help 4-month-olds to find words in continuous speech. A follow-up study suggests that this facilitation cannot be reduced to the highly social situation in which the directed interaction occurs. Taken together, these studies suggest that direct caregiver\textendash infant interaction, exemplified in this study by touch cues, may play a key role in infants' ability to find word boundaries, and suggests that early vocabulary items may consist of words often linked with caregiver touches.},
  file = {/Users/megcychosz/Zotero/storage/X8MRYSG5/Seidl et al. - 2015 - Why the body comes first effects of experimenter .pdf},
  journal = {Developmental Science},
  language = {en},
  number = {1}
}

@article{sekhonMultivariatePropensityScore2011,
  title = {Multivariate and {{Propensity Score Matching Software}} with       {{Automated Balance Optimization}}: {{The}} \{\vphantom\}{{Matching}}\vphantom\{\} {{Package}} for \{\vphantom\}{{R}}\vphantom\{\}},
  author = {Sekhon, Jasjeet S.},
  year = {2011},
  volume = {42},
  pages = {1--52},
  journal = {Journal of Statistical Software},
  number = {7}
}

@article{semenzinDescribingVocalizationsYoung2020,
  title = {Describing Vocalizations in Young Children: {{A}} Big Data Approach through Citizen Science Annotation},
  author = {Semenzin, Chiara and Hamrick, Lisa and Seidl, Amanda and Kelleher, Bridgette and Cristia, Alejandrina},
  year = {2020},
  pages = {42},
  abstract = {Method: Segments identified by LENATM as produced by the key child were 29 extracted from one daylong recording for each of 20 participants: 10 low-risk control children 30 and 10 children diagnosed with Angelman syndrome, a neurogenetic syndrome characterized 31 by severe language impairments. Speech samples were annotated by trained annotators in 32 the laboratory as well as by citizen scientists on Zooniverse. All annotators assigned one of 33 five labels to each sample: Canonical, Non-Canonical, Crying, Laughing, and Junk. This 34 allowed the derivation of two child-level vocalization metrics: the Linguistic Proportion, and 35 the Canonical Proportion. 36 37 Results: At the segment level, Zooniverse classifications had moderate precision and 38 recall. More importantly, the Linguistic Proportion and the Canonical Proportion derived 39 from Zooniverse annotations were highly correlated with those derived from laboratory 40 annotations. 41 42 Conclusion: Annotations obtained through a citizen science platform can help us 43 overcome challenges posed by the process of annotating daylong speech recordings. 44 Particularly when used in composites or derived metrics, such annotations can be used to 45 investigate early markers of language delays in non-typically developing children.},
  file = {/Users/megcychosz/Zotero/storage/5AWCB4ND/Describing vocalizations in young children A big .pdf},
  language = {en}
}

@inproceedings{semenzinLargescaleDataAnnotation2020,
  title = {Towards Large-Scale Data Annotation of Audio from Wearables: Validating {{Zooniverse}} Annotations of Infant Vocalization Types},
  booktitle = {Proceedings of the {{IEEE Spoken Language Technology Workshop}}},
  author = {Semenzin, Chiara and Hamrick, Lisa and Seidl, Amanda and Kelleher, Bridgette and Cristia, Alejandrina},
  year = {2020},
  pages = {1--7},
  address = {{Shenzen, China}},
  abstract = {Recent developments allow the collection of audio data from lightweight wearable devices, potentially enabling us to study language use from everyday life samples. However, extracting useful information from these data is currently impossible with automatized routines, and overly expensive with trained human annotators. We explore a strategy fit to the 21st century, relying on the collaboration of citizen scientists. A large dataset of infant speech was uploaded on a citizen science platform. The same data were annotated in the laboratory by highly trained annotators. We investigate whether crowdsourced annotations are qualitatively and quantitatively comparable to those produced by expert annotators in a dataset of children at high- and low-risk for language disorders. Our results reveal that classification of individual vocalizations on Zooniverse was overall moderately accurate compared to the laboratory gold standard. The analysis of descriptors defined at the level of individual children found strong correlations between descriptors derived from Zooniverse versus laboratory annotations.},
  file = {/Users/megcychosz/Zotero/storage/LD5WNTS9/Semenzin et al. - TOWARDS LARGE-SCALE DATA ANNOTATION OF AUDIO FROM .pdf},
  language = {en}
}

@article{senghasChildrenCreatingCore2004,
  title = {Children {{Creating Core Properties}} of {{Language}}: {{Evidence}} from an {{Emerging Sign Language}} in {{Nicaragua}}},
  shorttitle = {Children {{Creating Core Properties}} of {{Language}}},
  author = {Senghas, A. and Sotaro, Kita and {\"O}zy{\"u}rek, A.},
  year = {2004},
  month = sep,
  volume = {305},
  pages = {1779--1782},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1100199},
  file = {/Users/megcychosz/Zotero/storage/PMVTF5IM/Senghas - 2004 - Children Creating Core Properties of Language Evi.pdf},
  journal = {Science},
  language = {en},
  number = {5691}
}

@article{serenoAcousticAnalysesPerceptual1987,
  title = {Acoustic Analyses and Perceptual Data on Anticipatory Labial},
  author = {Sereno, Joan A and Baum, Shari R and Marean, G Cameron and Lieberman, Philip},
  year = {1987},
  volume = {81},
  pages = {512--519},
  file = {/Users/megcychosz/Zotero/storage/4VL528IG/Sereno et al. - Acoustic analyses and perceptual data on anticipat.pdf},
  journal = {Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@article{serenoDevelopmentalAspectsLingual1987,
  title = {Developmental Aspects of Lingual Coarticulation},
  author = {Sereno, Joan A and Lieberman, Philip},
  year = {1987},
  volume = {15},
  pages = {247--257},
  file = {/Users/megcychosz/Zotero/storage/7QQYEBC7/Developmental aspects of lingual coarticulation.pdf},
  journal = {Journal of Phonetics}
}

@article{seyfarthAcousticDifferencesMorphologicallydistinct2018,
  title = {Acoustic Differences in Morphologically-Distinct Homophones},
  author = {Seyfarth, Scott and Garellek, Marc and Gillingham, Gwendolyn and Ackerman, Farrell and Malouf, Robert},
  year = {2018},
  month = jan,
  volume = {33},
  pages = {32--49},
  issn = {2327-3798, 2327-3801},
  doi = {10.1080/23273798.2017.1359634},
  abstract = {Previous work demonstrates that a word's status as morphologically-simple or complex may be reflected in its phonetic realisation. One possible source for these effects is phonetic paradigm uniformity, in which an intended word's phonetic realisation is influenced by its morphological relatives. For example, the realisation of the inflected word frees should be influenced by the phonological plan for free, and thus be non-homophonous with the morphologically-simple word freeze. We test this prediction by analysing productions of forty such inflected/simple word pairs, embedded in pseudo-conversational speech structured to avoid metalinguistic task effects, and balanced for frequency, orthography, as well as segmental and prosodic context. We find that stem and suffix durations are significantly longer by about 4\textendash 7\% in fricative-final inflected words (frees, laps) compared to their simple counterparts (freeze, lapse), while we find a null effect for stop-final words. The result suggests that wordforms influence production of their relatives.},
  file = {/Users/megcychosz/Zotero/storage/D83EW2VW/Seyfarth et al. - 2018 - Acoustic differences in morphologically-distinct h.pdf},
  journal = {Language, Cognition and Neuroscience},
  language = {en},
  number = {1}
}

@article{shapiroComparativeStudyVarious1968,
  title = {A {{Comparative Study}} of {{Various Tests}} for {{Normality}}},
  author = {Shapiro, S. S. and Wilk, M. B. and Chen, H. J.},
  year = {1968},
  month = dec,
  volume = {63},
  pages = {1343--1372},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.1968.10480932},
  file = {/Users/megcychosz/Zotero/storage/UT4G6MIF/Shapiro et al. - 1968 - A Comparative Study of Various Tests for Normality.pdf},
  journal = {Journal of the American Statistical Association},
  language = {en},
  number = {324}
}

@article{sharpCanNovelWord2013,
  title = {Can a Novel Word Repetition Task Be a Language-Neutral Assessment Tool? {{Evidence}} from {{Welsh}}\textendash{{English}} Bilingual Children},
  shorttitle = {Can a Novel Word Repetition Task Be a Language-Neutral Assessment Tool?},
  author = {Sharp, Kathryn M and Gathercole, Virginia C Mueller},
  year = {2013},
  month = feb,
  volume = {29},
  pages = {77--89},
  publisher = {{SAGE Publications Ltd}},
  issn = {0265-6590},
  doi = {10.1177/0265659012465208},
  abstract = {In recent years, there has been growing recognition of a need for a general, non-language-specific assessment tool that could be used to evaluate general speech and language abilities in children, especially to assist in identifying atypical development in bilingual children who speak a language unfamiliar to the assessor. It has been suggested that a non-word repetition task (NWRT) may be a suitable candidate to fill this role, as it does not rely on knowledge of particular words for performance, and it may be possible to devise non-words that are not specific to any given language. The current study reports performance on a Welsh non-word repetition task by typically developing Welsh?English bilingual children with varying levels of exposure to Welsh in the home (Only Welsh at Home, Only English at Home, or Welsh and English at Home). The focus of the study was on repetition of initial consonants and consonant clusters in novel words. Both quantitative and qualitative differences were found across groups, according to level of exposure to Welsh, on sounds unique to Welsh, but not on sounds shared by Welsh and English. The data suggest that level of knowledge of the language tested has an important impact on children?s performance on non-word repetition and that the use of the NWRT as a universal speech and language assessment tool should be adopted with caution.},
  file = {/Users/megcychosz/Zotero/storage/YXH8W69H/Sharp and Gathercole - 2013 - Can a novel word repetition task be a language-neu.pdf},
  journal = {Child Language Teaching and Therapy},
  number = {1}
}

@article{shavlikEarlyWordlearningSkills2021,
  title = {Early Word-Learning Skills: {{A}} Missing Link in Understanding the Vocabulary Gap?},
  shorttitle = {Early Word-Learning Skills},
  author = {Shavlik, Margaret and {Davis-Kean}, Pamela E. and Schwab, Jessica F. and Booth, Amy E.},
  year = {2021},
  volume = {24},
  pages = {e13034},
  issn = {1467-7687},
  doi = {10.1111/desc.13034},
  abstract = {Socioeconomic status (SES) has been repeatedly linked to the developmental trajectory of vocabulary acquisition in young children. However, the nature of this relationship remains underspecified. In particular, despite an extensive literature documenting young children's reliance on a host of skills and strategies to learn new words, little attention has been paid to whether and how these skills relate to measures of SES and vocabulary acquisition. To evaluate these relationships, we conducted two studies. In Study 1, 205 2.5- to 3.5-year-old children from widely varying socioeconomic backgrounds were tested on a broad range of word-learning skills that tap their ability to resolve cases of ambiguous reference and to extend words appropriately. Children's executive functioning and phonological memory skills were also assessed. In Study 2, 77 of those children returned for a follow-up session several months later, at which time two additional measures of vocabulary were obtained. Using Structural Equation Modeling (SEM) and multivariate regression, we provide evidence of the mediating role of word-learning skills on the relationship between SES and vocabulary skill over the course of early development.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/desc.13034},
  file = {/Users/megcychosz/Zotero/storage/XENZ6CH4/Shavlik et al. - 2021 - Early word-learning skills A missing link in unde.pdf;/Users/megcychosz/Zotero/storage/XQC8KAXS/desc.13034.pdf;/Users/megcychosz/Zotero/storage/G3DIIL42/desc.html},
  journal = {Developmental Science},
  keywords = {early development,SEM,SES,vocabulary development,vocabulary gap,word-learning skills},
  language = {en},
  number = {2}
}

@article{shawEffectsSurprisalEntropy2019,
  title = {Effects of {{Surprisal}} and {{Entropy}} on {{Vowel Duration}} in {{Japanese}}},
  author = {Shaw, Jason A. and Kawahara, Shigeto},
  year = {2019},
  month = mar,
  volume = {62},
  pages = {80--114},
  issn = {0023-8309, 1756-6053},
  doi = {10.1177/0023830917737331},
  abstract = {Research on English and other languages has shown that syllables and words that contain more information tend to be produced with longer duration. This research is evolving into a general thesis that speakers articulate linguistic units with more information more robustly. While this hypothesis seems plausible from the perspective of communicative efficiency, previous support for it has come mainly from English and some other Indo-European languages. Moreover, most previous studies focus on global effects, such as the interaction of word duration and sentential/ semantic predictability. The current study is focused at the level of phonotactics, exploring the effects of local predictability on vowel duration in Japanese, using the Corpus of Spontaneous Japanese. To examine gradient consonant-vowel phonotactics within a consonant\textendash vowel-mora, consonant-conditioned Surprisal and Shannon Entropy were calculated, and their effects on vowel duration were examined, together with other linguistic factors that are known from previous research to affect vowel duration. Results show significant effects of both Surprisal and Entropy, as well as notable interactions with vowel length and vowel quality. The effect of Entropy is stronger on peripheral vowels than on central vowels. Surprisal has a stronger positive effect on short vowels than on long vowels. We interpret the main patterns and the interactions by conceptualizing Surprisal as an index of motor fluency and Entropy as an index of competition in vowel selection.},
  file = {/Users/megcychosz/Zotero/storage/CQ73CP9U/Shaw and Kawahara - 2019 - Effects of Surprisal and Entropy on Vowel Duration.pdf},
  journal = {Language and Speech},
  language = {en},
  number = {1}
}

@article{shawInfluencesToneVowel2016,
  title = {Influences of {{Tone}} on {{Vowel Articulation}} in {{Mandarin Chinese}}},
  author = {Shaw, Jason A. and Chen, Wei-rong and Proctor, Michael I. and Derrick, Donald},
  year = {2016},
  month = dec,
  volume = {59},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2015_JSLHR-S-15-0031},
  file = {/Users/megcychosz/Zotero/storage/VZV6LBJF/Shaw et al. - 2016 - Influences of Tone on Vowel Articulation in Mandar.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {6}
}

@article{shawSurvivingTruncationInformativity2014,
  title = {Surviving Truncation: Informativity at the Interface of Morphology and Phonology},
  shorttitle = {Surviving Truncation},
  author = {Shaw, Jason A. and Han, Chong and Ma, Yuan},
  year = {2014},
  month = nov,
  volume = {24},
  pages = {407--432},
  issn = {1871-5621, 1871-5656},
  doi = {10.1007/s11525-014-9249-5},
  abstract = {When disyllabic words of Chinese are compounded, truncation often applies to yield a disyllabic output that draws one syllable from each of the contributing words, e.g., xi\`adie\textasciimacron{} + f\'ud\`u \textrightarrow{} xi\`adie\textasciimacron{} + f\'ud\`u \textrightarrow{} die\textasciimacron f\'u. A substantial portion of new words enter Chinese via this process, and all combinations of four underlying syllables are attested in disyllabic neologisms. Variation in which syllable of the base escapes truncation has been described as arbitrary, but our analysis uncovers a clear pattern. Informative syllables survive. We fit a logistic regression model to Chinese truncation patterns using two indices of informativity, constituent family size and frequency ratio. Both of these factors were significant predictors. To further explore the nature of informativity-based constraints on surface forms, we analysed the truncation probabilities predicted by the model for each base in the neologism corpus. As truncation probabilities increased so too did model accuracy. We interpret this result as evidence for a constraint regulating the degree of uncertainty in base-truncation mappings.},
  file = {/Users/megcychosz/Zotero/storage/9RXWJKA9/Shaw_2014_notes.rtf;/Users/megcychosz/Zotero/storage/X7DXGJMA/Shaw et al. - 2014 - Surviving truncation informativity at the interfa.pdf},
  journal = {Morphology},
  language = {en},
  number = {4}
}

@article{shillerImportanceAuditoryPerceptual2010,
  title = {Importance of the Auditory Perceptual Target to the Achievement of Speech Production Accuracy},
  author = {Shiller, Douglas M and Rvachew, Susan and {Brosseau-Lapr{\'e}}, Francoise},
  year = {2010},
  volume = {34},
  pages = {181--192},
  abstract = {The purpose of this paper is to discuss the clinical implications of a model of the segmental component of speech motor control called the DIVA model (Directions into Velocities of Articulators). The DIVA model is implemented on the assumption that the infant has perceptual knowledge of the auditory targets in place before learning accurate production of speech sounds and suggests that difficulties with speech perception would lead to imprecise speech and inaccurate articulation. We demonstrate through a literature review that children with speech delay, on average, have significant difficulty with perceptual knowledge of speech sounds that they misarticulate. We hypothesize, on the basis of the DIVA model, that a child with speech delay who has good perceptual knowledge of a phonological target will learn to make the appropriate articulatory adjustments to achieve phonological goals. We support the hypothesis with two case studies. The first case study involved short-term learning in a laboratory task by a child with speech delay. Although the child misarticulated sibilants, he had good perceptual and articulatory knowledge of vowels. He demonstrated that he was fully capable of spontaneously adapting his articulatory patterns to compensate for altered feedback of his own speech output. The second case study involved longer-term learning during speech therapy. This francophone child received 6 weeks of intervention that was largely directed at improving her perceptual knowledge of /{$\Elzesh$}/, leading to significant improvements in her ability to produce this phoneme correctly, both during minimal pair activities in therapy and during post-treatment testing.},
  file = {/Users/megcychosz/Zotero/storage/HUIDEP52/Shiller et al. - Importance of the auditory perceptual target to th.pdf},
  journal = {Canadian Journal of Speech-Language Pathology and Audiology},
  language = {en},
  number = {3}
}

@article{shinnLimitationsContextConditioned1985,
  title = {Limitations of Context Conditioned Effects in the Perception of [b] and [w]},
  author = {Shinn, P. C. and Blumstein, S. E. and Jongman, A.},
  year = {1985},
  month = sep,
  volume = {38},
  pages = {397--407},
  issn = {0031-5117, 1532-5962},
  doi = {10.3758/BF03207170},
  file = {/Users/megcychosz/Zotero/storage/EIEIBW9L/Shinn et al. - 1985 - Limitations of context conditioned effects in the .pdf},
  journal = {Perception \& Psychophysics},
  language = {en},
  number = {5}
}

@article{shivakumarEndtoEndNeuralSystems2021,
  title = {End-to-{{End Neural Systems}} for {{Automatic Children Speech Recognition}}: {{An Empirical Study}}},
  shorttitle = {End-to-{{End Neural Systems}} for {{Automatic Children Speech Recognition}}},
  author = {Shivakumar, Prashanth Gurunath and Narayanan, Shrikanth},
  year = {2021},
  month = feb,
  abstract = {A key desiderata for inclusive and accessible speech recognition technology is ensuring its robust performance to children's speech. Notably, this includes the rapidly advancing neural network based end-to-end speech recognition systems. Children speech recognition is more challenging due to the larger intra-inter speaker variability in terms of acoustic and linguistic characteristics compared to adult speech. Furthermore, the lack of adequate and appropriate children speech resources adds to the challenge of designing robust end-to-end neural architectures. This study provides a critical assessment of automatic children speech recognition through an empirical study of contemporary state-of-the-art end-to-end speech recognition systems. Insights are provided on the aspects of training data requirements, adaptation on children data, and the effect of children age, utterance lengths, different architectures and loss functions for end-to-end systems and role of language models on the speech recognition performance.},
  archiveprefix = {arXiv},
  eprint = {2102.09918},
  eprinttype = {arxiv},
  file = {/Users/megcychosz/Zotero/storage/8849D44B/Shivakumar and Narayanan - 2021 - End-to-End Neural Systems for Automatic Children S.pdf;/Users/megcychosz/Zotero/storage/CKTH2SHR/2102.html},
  journal = {arXiv:2102.09918 [cs, eess]},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  primaryclass = {cs, eess}
}

@article{shivakumarImprovingSpeechRecognition,
  title = {Improving {{Speech Recognition}} for {{Children}} Using {{Acoustic Adaptation}} and {{Pronunciation Modeling}}},
  author = {Shivakumar, Prashanth Gurunath and Potamianos, Alexandros and Lee, Sungbok and Narayanan, Shrikanth},
  pages = {5},
  abstract = {Developing a robust Automatic Speech Recognition (ASR) system for children is a challenging task because of increased variability in acoustic and linguistic correlates as function of young age. The acoustic variability is mainly due to the developmental changes associated with vocal tract growth. On the linguistic side, the variability is associated with limited knowledge of vocabulary, pronunciations and other linguistic constructs. This paper presents a preliminary study towards better acoustic modeling, pronunciation modeling and front-end processing for children's speech. Results are presented as a function of age. Speaker adaptation significantly reduces mismatch and variability improving recognition results across age groups. In addition, introduction of pronunciation modeling shows promising performance improvements.},
  file = {/Users/megcychosz/Zotero/storage/H4LYBLC3/Shivakumar et al. - Improving Speech Recognition for Children using Ac.pdf},
  language = {en}
}

@article{shneidmanAreChilddirectedInteractions2016a,
  title = {Are Child-Directed Interactions the Cradle of Social Learning?},
  author = {Shneidman, Laura and Woodward, Amanda L.},
  year = {2016},
  month = jan,
  volume = {142},
  pages = {1--17},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/bul0000023},
  file = {/Users/megcychosz/Zotero/storage/7NUM9QRZ/Shneidman and Woodward - 2016 - Are child-directed interactions the cradle of soci.pdf},
  journal = {Psychological Bulletin},
  language = {en},
  number = {1}
}

@article{shneidmanLanguageInputAcquisition2012,
  title = {Language Input and Acquisition in a {{Mayan}} Village: How Important Is Directed Speech?},
  shorttitle = {Language Input and Acquisition in a {{Mayan}} Village},
  author = {Shneidman, Laura A. and {Goldin-Meadow}, Susan},
  year = {2012},
  month = sep,
  volume = {15},
  pages = {659--673},
  issn = {1363-755X},
  doi = {10.1111/j.1467-7687.2012.01168.x},
  abstract = {Theories of language acquisition have highlighted the importance of adult speakers as active participants in children's language learning. However, in many communities children are reported to be directly engaged by their caregivers only rarely (). This observation raises the possibility that these children learn language from observing, rather than participating in, communicative exchanges. In this paper, we quantify naturally occurring language input in one community where directed interaction with children has been reported to be rare (Yucatec Mayan). We compare this input to the input heard by children growing up in large families in the United States, and we consider how directed and overheard input relate to Mayan children's later vocabulary. In Study 1, we demonstrate that 1-year-old Mayan children do indeed hear a smaller proportion of total input in directed speech than children from the US. In Study 2, we show that for Mayan (but not US) children, there are great increases in the proportion of directed input that children receive between 13 and 35 months. In Study 3, we explore the validity of using videotaped data in a Mayan village. In Study 4, we demonstrate that word types directed to Mayan children from adults at 24 months (but not word types overheard by children or word types directed from other children) predict later vocabulary. These findings suggest that adult talk directed to children is important for early word learning, even in communities where much of children's early language input comes from overheard speech.},
  file = {/Users/megcychosz/Zotero/storage/2K8N5I3J/Shneidman and Goldin-Meadow - 2012 - Language input and acquisition in a Mayan village.pdf},
  journal = {Developmental science},
  number = {5},
  pmcid = {PMC3538130},
  pmid = {22925514}
}

@article{shneidmanWhatCountsEffective2013,
  title = {What Counts as Effective Input for Word Learning?},
  author = {Shneidman, Laura A. and Arroyo, Michelle E. and Levine, Susan C. and {Goldin-Meadow}, Susan},
  year = {2013},
  month = jun,
  volume = {40},
  pages = {672--686},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000912000141},
  abstract = {The talk children hear from their primary caregivers predicts the size of their vocabularies. But children who spend time with multiple individuals also hear talk that others direct to them, as well as talk not directed to them at all. We investigated the effect of linguistic input on vocabulary acquisition in children who routinely spent time with one vs. multiple individuals. For all children, the number of words primary caregivers directed to them at age 2; 6 predicted vocabulary size at age 3 ; 6. For children who spent time with multiple individuals, child-directed words from ALL household members also predicted later vocabulary and accounted for more variance in vocabulary than words from primary caregivers alone. Interestingly, overheard words added no predictive value to the model. These findings suggest that speech directed to children is important for early word learning, even in households where a sizable proportion of input comes from overheard speech.},
  file = {/Users/megcychosz/Zotero/storage/AVP25R6T/Shneidman et al. - 2013 - What counts as effective input for word learning.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {3}
}

@article{shuPhonologicalAwarenessYoung2008a,
  title = {Phonological Awareness in Young {{Chinese}} Children},
  author = {Shu, Hua and Peng, Hong and {McBride-Chang}, Catherine},
  year = {2008},
  month = jan,
  volume = {11},
  pages = {171--181},
  issn = {1363755X, 14677687},
  doi = {10.1111/j.1467-7687.2007.00654.x},
  abstract = {Two studies explored the nature of phonological awareness (PA) in Chinese. In Study 1, involving 146 children, awareness of phoneme onset did not differ from chance levels at ages 3\textendash 5 years in preschool but increased to 70\% correct in first grade, when children first received phonological coding (Pinyin) instruction. Similarly, tone awareness was at better than chance levels from second year kindergarten (age 4), but increased strongly and significantly in first grade to 74\% accuracy. In contrast, syllable and rime awareness increased gradually and steadily across ages 3\textendash 6 years. Patterns suggest different influences of age and literacy instruction for different PA levels. In Study 2, involving 202 preschoolers, variance in Chinese character recognition was best explained by tasks of syllable awareness, tone awareness, and speeded naming. Findings underscore the unique importance of both tone and syllable for early character acquisition in Chinese children.},
  file = {/Users/megcychosz/Zotero/storage/RB9K7X6P/Shu et al. - 2008 - Phonological awareness in young Chinese children.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {1}
}

@article{silveyEffectsTimevaryingParent2020,
  title = {Effects of Time-Varying Parent Input on Child Language Outcomes Differ for Vocabulary and Syntax},
  author = {Silvey, Catriona and {Demir-Lira}, Ece and {Goldin-Meadow}, Susan and Raudenbush, Stephen},
  year = {2020},
  file = {/Users/megcychosz/Zotero/storage/YK7TR3B6/vocab_syntax_accepted.pdf},
  journal = {Psychological Science}
}

@article{singhInfantsListeningPreferences2002,
  title = {Infants' {{Listening Preferences}}: {{Baby Talk}} or {{Happy Talk}}?},
  shorttitle = {Infants' {{Listening Preferences}}},
  author = {Singh, Leher and Morgan, James L. and Best, Catherine T.},
  year = {2002},
  volume = {3},
  pages = {365--394},
  issn = {1532-7078},
  doi = {10.1207/S15327078IN0303_5},
  abstract = {The most robust finding on infants' listening preferences has been widely characterized as a preference for baby talk (BT) over adult-directed speech (ADS). Although prosodic modifications characteristic of BT also convey positive affect, differences in affect across BT and ADS speech registers have not been controlled in previous studies. This set of experiments sought to elucidate the basis for 6-month-olds' listening preference by independently manipulating affect and speech register. When affect was held constant, no preference for any speech register was observed. Moreover, when ADS stimuli presented more positive affect than BT stimuli, infants' preferences followed the positive affect. Higher and more variable pitch was neither necessary nor sufficient for determining infants' preferences, although pitch characteristics may modulate affect-based preferences. The BT preference is thus attributable to a more general preference for speech that imparts relatively positive affect, a preference perhaps ascribable to a preexisting general-purpose mechanism opportunistically exploited by language.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1207/S15327078IN0303\_5},
  file = {/Users/megcychosz/Zotero/storage/SGNT8G9U/Singh et al. - 2002 - Infants' Listening Preferences Baby Talk or Happy.pdf;/Users/megcychosz/Zotero/storage/36QN8JXI/S15327078IN0303_5.html},
  journal = {Infancy},
  language = {en},
  number = {3}
}

@article{singhInfluencesInfantDirectedSpeech2009,
  title = {Influences of {{Infant}}-{{Directed Speech}} on {{Early Word Recognition}}},
  author = {Singh, Leher and Nestor, Sarah and Parikh, Chandni and Yull, Ashley},
  year = {2009},
  volume = {14},
  pages = {654--666},
  issn = {1532-7078},
  doi = {10.1080/15250000903263973},
  abstract = {When addressing infants, many adults adopt a particular type of speech, known as infant-directed speech (IDS). IDS is characterized by exaggerated intonation, as well as reduced speech rate, shorter utterance duration, and grammatical simplification. It is commonly asserted that IDS serves in part to facilitate language learning. Although intuitively appealing, direct empirical tests of this claim are surprisingly scarce. Additionally, studies that have examined associations between IDS and language learning have measured learning within a single laboratory session rather than the type of long-term storage of information necessary for word learning. In this study, 7- and 8-month-old infants' long-term memory for words was assessed when words were spoken in IDS and adult-directed speech (ADS). Word recognition over the long term was successful for words introduced in IDS, but not for those introduced in ADS, regardless of the register in which recognition stimuli were produced. Findings are discussed in the context of the influence of particular input styles on emergent word knowledge in prelexical infants.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1080/15250000903263973},
  file = {/Users/megcychosz/Zotero/storage/8587VQJN/Singh et al. - 2009 - Influences of Infant-Directed Speech on Early Word.pdf;/Users/megcychosz/Zotero/storage/G55D57PZ/15250000903263973.html},
  journal = {Infancy},
  language = {en},
  number = {6}
}

@article{sjonsArticulationRateChilddirected,
  title = {Articulation Rate in Child-Directed Speech Increases as a Function of Child Age},
  author = {Sjons, Johan and H{\"o}rberg, Thomas},
  pages = {7},
  abstract = {It has been shown that articulation rate (AR), the number of produced linguistic units per time unit with pauses excluded, is lower in child-directed speech (CDS) than in adult-directed speech (ADS). The present study is the first corpus-based longitudinal study to investigate AR in Swedish CDS as a function of child age while also controlling for utterance length in terms of number of syllables and for individual differences between speakers. AR in transcribed utterances of 7 parents directed at their respective child during different ages was analyzed with mixed effects modeling. Results show a significantly higher AR in longer than in shorter utterances and a significant increase in AR as a function of infant age. Future studies include comparison with entropy-based measures.},
  file = {/Users/megcychosz/Zotero/storage/LYUDF9L8/Sjons and Hörberg - Articulation rate in child-directed speech increas.pdf},
  language = {en}
}

@article{sjonsArticulationRateSwedish2017,
  title = {Articulation Rate in {{Swedish}} Child-Directed Speech Increases as a Function of the Age of the Child Even When Surprisal Is Controlled For},
  author = {Sjons, Johan and H{\"o}rberg, Thomas and {\"O}stling, Robert and Bjerva, Johannes},
  year = {2017},
  month = nov,
  abstract = {In earlier work, we have shown that articulation rate in Swedish child-directed speech (CDS) increases as a function of the age of the child, even when utterance length and differences in articulation rate between subjects are controlled for. In this paper we show on utterance level in spontaneous Swedish speech that i) for the youngest children, articulation rate in CDS is lower than in adult-directed speech (ADS), ii) there is a significant negative correlation between articulation rate and surprisal (the negative log probability) in ADS, and iii) the increase in articulation rate in Swedish CDS as a function of the age of the child holds, even when surprisal along with utterance length and differences in articulation rate between speakers are controlled for. These results indicate that adults adjust their articulation rate to make it fit the linguistic capacity of the child.},
  archiveprefix = {arXiv},
  eprint = {1706.03216},
  eprinttype = {arxiv},
  file = {/Users/megcychosz/Zotero/storage/MEZXVZHN/Sjons et al. - 2017 - Articulation rate in Swedish child-directed speech.pdf;/Users/megcychosz/Zotero/storage/WUABG8WJ/1706.html},
  journal = {arXiv:1706.03216 [cs]},
  keywords = {Computer Science - Computation and Language},
  note = {Comment: 5 pages, Interspeech 2017},
  primaryclass = {cs}
}

@book{skinnerVerbalBehavior1957,
  title = {Verbal {{Behavior}}},
  author = {Skinner, B. F.},
  year = {1957},
  publisher = {{Copley Publishing Group}},
  address = {{Acton, MA}}
}

@article{slisAnalysingSpectralChanges2021,
  title = {Analysing Spectral Changes over Time to Identify Articulatory Impairments in Dysarthria},
  author = {Slis, A. and L{\'e}v{\^e}que, N. and Fougeron, C. and Pernon, M. and Assal, F. and Lancia, L.},
  year = {2021},
  month = feb,
  volume = {149},
  pages = {758--769},
  issn = {0001-4966},
  doi = {10.1121/10.0003332},
  abstract = {Identifying characteristics of articulatory impairment in speech motor disorders is complicated due to the timeconsuming nature of kinematic measures. The goal is to explore whether analysing the acoustic signal in terms of total squared changes of Mel-Frequency Cepstral Coefficients (TSC\_MFCC) and its pattern over time provides sufficient spectral information to distinguish mild and moderate dysarthric French speakers with Amyotrophic Lateral Sclerosis (ALS) and Parkinson's Disease (PD) from each other and from healthy speakers. Participants produced the vowel-glide sequences /ajajaj/, /ujujuj/, and /wiwiwi/. From the time course of TSC\_MFCCs, event-related and global measures were extracted to capture the degree of acoustic change and its variability. In addition, durational measures were obtained. For both mild and moderately impaired PD and ALS speakers, the degree of acoustic change and its variability, averaged over the complete contour, separated PD and ALS speakers from each other and from healthy speakers, especially when producing the sequences /ujujuj/ and /wiwiwi/. Durational measures separated the moderate ALS from healthy and moderate PD speakers. Using the approach on repetitive sequences targeting the lingual and labial articulators to characterize articulatory impairment in speech motor disorders is promising. Findings are discussed against prior findings of articulatory impairment in the populations studied.},
  file = {/Users/megcychosz/Zotero/storage/PUZBHNHI/Slis et al. - 2021 - Analysing spectral changes over time to identify a.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@inproceedings{sloetjesAnnotationCategoryELAN2008,
  title = {Annotation by Category - {{ELAN}} and {{ISO DCR}}},
  booktitle = {Proceedings of the 6th {{International Conference}} on {{Language Resources}} and {{Evaluation}}},
  author = {Sloetjes, H. and Wittenburg, P},
  year = {2008}
}

@article{smithDevelopmentDynamicSystem2003,
  title = {Development as a Dynamic System},
  author = {Smith, Linda B. and Thelen, Esther},
  year = {2003},
  month = aug,
  volume = {7},
  pages = {343--348},
  issn = {13646613},
  doi = {10.1016/S1364-6613(03)00156-6},
  file = {/Users/megcychosz/Zotero/storage/GI7VHE73/Smith and Thelen - 2003 - Development as a dynamic system.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {8}
}

@article{smithDevelopmentFunctionalSynergies2004,
  title = {Development of Functional Synergies for Speech Motor Coordination in Childhood and Adolescence},
  author = {Smith, Anne and Zelaznik, Howard N.},
  year = {2004},
  month = jul,
  volume = {45},
  pages = {22--33},
  issn = {0012-1630, 1098-2302},
  doi = {10.1002/dev.20009},
  abstract = {Adults produce rapid, interleaved sequences of speech sounds by controlling the relative motions in time and space of the oral articulators. The control and coordination of these effectors appear to be automatic, effortless, and usually error free. If speech production is viewed within the framework of classical motor control theories, we can infer that adults have organized functional synergies (consistent patterns of activation of muscle collectives) that act as stable subunits. In this study, the development of these stable functional synergies is examined. Motion of the upper lip, lower lip, and jaw was recorded during sentence production in 180 children and adults (aged 4\textendash 22 years). Two indices of oral motor coordination were computed, which reflect the degree of trial-to-trial consistency in intereffector relationships and thus the stability of the underlying functional synergies. Major findings are: (a) The time course of development for speech motor coordination is protracted, (b) speech motor control processes are not adultlike until after age 14 years for both females and males, (c) boys (until age 5 years) show a slower maturational course of speech motor development, and (d) late childhood (the 7- to 12-year period) is characterized by a plateau in the development of these coordinative synergies for speech production. We posit that multiple factors are likely to contribute to the protracted development of oral motor coordination for speech, including maturation of components of the motor system itself and maturation of the brain subsystems for language processing.},
  file = {/Users/megcychosz/Zotero/storage/75QT986K/Smith and Zelaznik - 2004 - Development of functional synergies for speech mot.pdf},
  journal = {Developmental Psychobiology},
  language = {en},
  number = {1}
}

@article{smithPhoneticDetailThat2012,
  title = {Phonetic Detail That Distinguishes Prefixed from Pseudo-Prefixed Words},
  author = {Smith, Rachel and Baker, Rachel and Hawkins, Sarah},
  year = {2012},
  month = sep,
  volume = {40},
  pages = {689--705},
  issn = {00954470},
  doi = {10.1016/j.wocn.2012.04.002},
  abstract = {Most English prefixes are syllables that can also begin words in which they do not function as a productive prefix. The literature notes a pronunciation difference such that true-prefixes, e.g. /dis/ in discolour, have a heavier rhythmic beat than pseudo-prefixes, e.g. /dis/ in discover. When the syllable following dis- or mis- begins with a voiceless stop, there is a clear difference in its VOT, but differences in dis/mis itself are more subtle and have not been systematically measured. Five speakers of Southern British English engaged in 40 scripted dialogues which contained such words in controlled phonetic contexts. Prefixed words were longer up to voicing onset in syllable 2 and had longer and more peripheral [i], longer VOT, and shorter [s] than pseudo-prefixed words. These differences produced distinctive acoustic patterns consistent with the difference in perceived beat. Effects due to nuclear/ postnuclear accent and word frequency were observed, but appear to be secondary to effects of morphological status. We conclude that the morphological status of these syllables is the primary cause of their characteristic acoustic patterns, and that their segmental composition dictates further reduction processes they may undergo due to weaker prosodic contexts, higher word frequency, casual register, and other influences.},
  file = {/Users/megcychosz/Zotero/storage/QZ9WCRZH/Smith et al. - 2012 - Phonetic detail that distinguishes prefixed from p.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {5}
}

@article{smithPhonologicalDevelopmentLexically2006,
  title = {Phonological Development in Lexically Precocious 2-Year-Olds},
  author = {Smith, Bruce L. and Mcgregor, Karla K. and Demille, Darcie},
  year = {2006},
  month = jul,
  volume = {27},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716406060310},
  abstract = {To examine interactions between young children's vocabulary size and their phonological abilities, spontaneous language samples were collected from 24-month-olds with precocious lexicons, their age mates (24-month-olds with average-sized lexicons), and their vocabulary mates (30-month-olds with average-sized lexicons). Phonological ability was measured in a variety of ways, such as the number of different consonants that were targeted, the number of different consonants produced correctly, the percentage of consonants produced correctly, and the occurrence of phonological processes. The lexically precocious 24-month-olds were similar to their vocabulary mates on most measures of phonological ability, and both of these groups were generally superior to the 24-month-olds with smaller lexicons. These findings supported a hypothesized relationship between lexicon size and phonological performance, and demonstrated that 2-year-olds' phonological development is more closely related to size of the lexicon than chronological age.},
  file = {/Users/megcychosz/Zotero/storage/SUSRGNSZ/Smith et al. - 2006 - Phonological development in lexically precocious 2.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {03}
}

@article{smithPhonologicalDevelopmentLexically2006a,
  title = {Phonological Development in Lexically Precocious 2-Year-Olds},
  author = {Smith, Bruce L. and Mcgregor, Karla K. and Demille, Darcie},
  year = {2006},
  month = jul,
  volume = {27},
  pages = {355--375},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716406060310},
  abstract = {To examine interactions between young children's vocabulary size and their phonological abilities, spontaneous language samples were collected from 24-month-olds with precocious lexicons, their age mates (24-month-olds with average-sized lexicons), and their vocabulary mates (30-month-olds with average-sized lexicons). Phonological ability was measured in a variety of ways, such as the number of different consonants that were targeted, the number of different consonants produced correctly, the percentage of consonants produced correctly, and the occurrence of phonological processes. The lexically precocious 24-month-olds were similar to their vocabulary mates on most measures of phonological ability, and both of these groups were generally superior to the 24-month-olds with smaller lexicons. These findings supported a hypothesized relationship between lexicon size and phonological performance, and demonstrated that 2-year-olds' phonological development is more closely related to size of the lexicon than chronological age.},
  file = {/Users/megcychosz/Zotero/storage/ZLPFFADL/Smith et al. - 2006 - Phonological development in lexically precocious 2.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {3}
}

@article{smithRelationshipsDurationTemporal1992,
  title = {Relationships between Duration and Temporal Variability in Children's Speech},
  author = {Smith, Bruce L.},
  year = {1992},
  month = apr,
  volume = {91},
  pages = {2165--2174},
  issn = {0001-4966},
  doi = {10.1121/1.403675},
  file = {/Users/megcychosz/Zotero/storage/E4WYFNEW/Smith - 1992 - Relationships between duration and temporal variab.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@article{smithStabilityPatterningSpeech1998,
  title = {Stability and {{Patterning}} of {{Speech Movement Sequences}} in {{Children}} and {{Adults}}},
  author = {Smith, Anne and Goffman, Lisa},
  year = {1998},
  month = feb,
  volume = {41},
  pages = {18--30},
  issn = {1092-4388},
  doi = {10.1044/jslhr.4101.18},
  abstract = {Children (aged 4 and 7 years) and young adults produced a six-syllable utterance 15 times. The displacement of the lower lip was recorded with an Optotrak system and analyzed in a number of ways. First, using a procedure recently developed in our laboratory, displacement records from the 15 repetitions were amplitude- and time-normalized, and the spatiotemporal index (the STI) was computed. The STI reflects the degree to which repeated performance of a task produces movement trajectories that converge on a single pattern. Children produced less stable movement trajectories, as reflected in higher values on the STI. In a second analysis, standard measurements of amplitude and peak velocity were made for two opening and two closing lip movements. These measures suggested that, relative to the size of their oral structures, children have large movement ranges in speech. Also, children tend to move with a lower peak velocity. This large-amplitude, low-velocity movement style may reflect different underlying control processes. Finally, another analysis focused on open-dose movement sequences associated with two words of the utterance. A pattern-recognition algorithm applied to the normalized waveforms from the open--close sequences revealed that children and adults produced equally distinctive movement trajectories for the two syllables. Taken together, these preliminary results suggest that nonlinear and nonuniform changes occur in components of the speech motor system during development.},
  file = {/Users/megcychosz/Zotero/storage/L8US3LW9/Smith and Goffman - 1998 - Stability and Patterning of Speech Movement Sequen.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {1}
}

@article{smithUniversalDialectspecificPathways2009,
  title = {Universal and Dialect-Specific Pathways of Acquisition: {{Caregivers}}, Children, and t/d Deletion},
  shorttitle = {Universal and Dialect-Specific Pathways of Acquisition},
  author = {Smith, Jennifer and Durham, Mercedes and Fortune, Liane},
  year = {2009},
  month = mar,
  volume = {21},
  pages = {69--95},
  issn = {0954-3945, 1469-8021},
  doi = {10.1017/S0954394509000039},
  abstract = {T/d deletion is one of the most widely studied variables in sociolinguistic research, and findings demonstrate universal morphological and phonological constraints across a range of dialects. Research into the acquisition of this variable suggests that articulatory constraints are learned first, followed by grammatical, and finally stylistic and social constraints. Dialect-specific constraints are also found, implicating the caregiver in the process of acquisition. In this article, we contribute to this research on the acquisition of t/d through the examination of the speech of preschool children in interaction with their primary caregivers in a community in Scotland. Our results mirror previous results on how and when particular constraints are acquired, providing further evidence for universal order of acquisition of this form. We also demonstrate dialect-specific constraints on use that can be mapped directly to caregiver speech. This provides additional evidence on how variable forms are transmitted from parent to child in these early stages.},
  file = {/Users/megcychosz/Zotero/storage/9ATTLUCX/Smith et al. - 2009 - Universal and dialect-specific pathways of acquisi.pdf},
  journal = {Language Variation and Change},
  language = {en},
  number = {1}
}

@article{smitIowaArticulationNorms1991,
  title = {The {{Iowa Articulation Norms Project}} and {{Its Nebraska Replication}}},
  author = {Smit, A. B. and Hand, L. and Freilinger, J. J. and Bernthal, J. E. and Bird, A.},
  year = {1991},
  month = apr,
  volume = {34},
  pages = {446},
  issn = {1092-4388},
  doi = {10.1044/jshr.3402.446},
  abstract = {The purpose of the Iowa Articulation Norms Project and its Nebraska replication was to provide normative information about speech sound acquisition in these two states. An assessment instrument consisting of photographs and a checklist form for narrow phonetic transcription was administered by school-based speech-language pathologists to stratified samples of children in the age range 3-9 years. The resulting data were not influenced by the demographic variables of population density (rural/urban), SES (based on parental education), or state of residence (Iowa/Nebraska); however, sex of the child exerted a significant influence in some of the preschool age groups. The criteria used to determine acceptability of a production appeared to influence outcomes for some speech sounds. Acquisition curves were plotted for individual phoneme targets or groups of targets. These curves were used to develop recommended ages of acquisition for the tested speech sounds, with recommendations based generally on a 90\% level of acquisition. Special considerations were required for the phonemes / s z/.},
  file = {/Users/megcychosz/Zotero/storage/B42M48BA/Smit et al. - 1991 - The Iowa Articulation Norms Project and Its Nebras.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {2}
}

@article{snedekerStartingInternationalAdoption2007,
  title = {Starting {{Over}}: {{International Adoption}} as a {{Natural Experiment}} in {{Language Development}}},
  shorttitle = {Starting {{Over}}},
  author = {Snedeker, Jesse and Geren, Joy and Shafto, Carissa L.},
  year = {2007},
  month = jan,
  volume = {18},
  pages = {79--87},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/j.1467-9280.2007.01852.x},
  abstract = {Language development is characterized by predictable shifts in the words children produce and the complexity of their utterances. Because acquisition typically occurs simultaneously with maturation and cognitive development, it is difficult to determine the causes of these shifts. We explored how acquisition proceeds in the absence of possible cognitive or maturational roadblocks, by examining the acquisition of English in internationally adopted preschoolers. Like infants, and unlike other second-language learners, these children acquire language from child-directed speech, without access to bilingual informants. Parental reports and speech samples were collected from 27 preschoolers, 3 to 18 months after they were adopted from China. These children showed the same developmental patterns in language production as monolingual infants (matched for vocabulary size). Early on, their vocabularies were dominated by nouns, their utterances were short, and grammatical morphemes were generally omitted. Children at later stages had more diverse vocabularies and produced longer utterances with more grammatical morphemes.},
  file = {/Users/megcychosz/Zotero/storage/WPDF6M4Y/Snedeker et al. - 2007 - Starting Over International Adoption as a Natural.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {1}
}

@article{snowMothersSpeechChildren1972,
  title = {Mothers' {{Speech}} to {{Children Learning Language}}},
  author = {Snow, Catherine E.},
  year = {1972},
  volume = {43},
  pages = {549--565},
  publisher = {{[Wiley, Society for Research in Child Development]}},
  issn = {0009-3920},
  doi = {10.2307/1127555},
  abstract = {The assumption that language acquisition is relatively independent of the amount and kind of language input must be assessed in light of information about the speech actually heard by young children. The speech of middle-class mothers to 2-year-old children was found to be simpler and more redundant than their speech to 10-year-old children. The mothers modified their speech less when talking to children whose responses they could not observe, indicating that the children played some role in eliciting the speech modifications. Task difficulty did not contribute to the mothers' production of simplified, redundant speech. Experienced mothers were only slightly better than nonmothers in predicting the speech-style modifications required by young children. These findings indicate that children who are learning language have available a sample of speech which is simpler, more redundant, and less confusing than normal adult speech.},
  file = {/Users/megcychosz/Zotero/storage/LTBU895M/Snow - 1972 - Mothers' Speech to Children Learning Language.pdf},
  journal = {Child Development},
  number = {2}
}

@article{soderstromBabytalkReevaluatingNature2007,
  title = {Beyond Babytalk: {{Re}}-Evaluating the Nature and Content of Speech Input to Preverbal Infants},
  shorttitle = {Beyond Babytalk},
  author = {Soderstrom, Melanie},
  year = {2007},
  month = dec,
  volume = {27},
  pages = {501--532},
  issn = {02732297},
  doi = {10.1016/j.dr.2007.06.002},
  abstract = {Infant-directed maternal speech is an important component of infants' linguistic input. However, speech from other speakers and speech directed to others constitute a large amount of the linguistic environment. What are the properties of infant-directed speech that differentiate it from other components of infants' speech environment? To what extent should these other aspects be considered as part of the linguistic input? This review examines the characteristics of the speech input to preverbal infants, including phonological, morphological, and syntactic characteristics, specifically how these properties might support language development. While maternal, infant-directed speech is privileged in the input, other aspects of the environment, such as adult-directed speech, may also play a role. Furthermore, the input is variable in nature, dependent on the age and linguistic development of the infant, the social context, and the interaction between the infant and speakers in the environment. \'O 2007 Elsevier Inc. All rights reserved.},
  file = {/Users/megcychosz/Zotero/storage/ZU7P9RMM/Soderstrom - 2007 - Beyond babytalk Re-evaluating the nature and cont.pdf},
  journal = {Developmental Review},
  language = {en},
  number = {4}
}

@inproceedings{soderstromComparingHumanMachineannotated2016,
  title = {Comparing Human- and Machine-Annotated Language Input across Childcare Settings},
  booktitle = {Internationaal {{Congress}} for {{Infant Studies}}},
  author = {Soderstrom, Melanie and Franz, W.},
  year = {2016},
  address = {{Dublin, Ireland}}
}

@article{solaTrackingHomeLanguage2021,
  title = {Tracking {{Home Language Production}} and {{Environment}} in {{Children Who Are Deaf}} or {{Hard}} of {{Hearing}}},
  author = {Sola, Ana Marija and Brodie, Kara D. and Stephans, Jihyun and Scarpelli, Chiara and Chan, Dylan K.},
  year = {2021},
  month = may,
  pages = {01945998211013785},
  publisher = {{SAGE Publications Inc}},
  issn = {0194-5998},
  doi = {10.1177/01945998211013785},
  abstract = {ObjectiveTo use an automated speech-processing technology to identify patterns in sound environments and language output for deaf or hard-of-hearing infants and toddlers.Study DesignObservational study based on a convenience sample.SettingHome observation conducted by tertiary children?s hospital.MethodsThe system analyzed 115 naturalistic recordings of 28 children {$<$}3.5 years old. Hearing ability was stratified into groups by access to sound. Outcomes were compared across hearing groups, and multivariable linear regression was used to test associations.ResultsThere was a significant difference in age-adjusted child vocalizations (P = .042), conversational turns (P = .022), and language development scores (P = .05) between hearing groups but no significant difference in adult words (P = .11). Conversational turns were positively associated with each language development measure, while adult words were not. For each hour of electronic media, there were significant reductions in child vocalizations (? = ?0.47; 95\% CI, ?0.71 to ?0.19), conversational turns (? = ?0.45; 95\% CI, ?0.65 to ?0.22), and language development (? = ?0.37; 95\% CI, ?0.61 to ?0.15).ConclusionsConversational turn scores differ among hearing groups and are positively associated with language development outcomes. Electronic media is associated with reduced discernible adult speech, child vocalizations, conversational turns, and language development scores. This effect was larger in children who are deaf or hard of hearing as compared with other reports in typically hearing populations. These findings underscore the need to optimize early language environments and limit electronic noise exposure in children who are deaf or hard of hearing.},
  journal = {Otolaryngology\textendash Head and Neck Surgery},
  keywords = {automated speech processing,deaf and hard of hearing,early intervention,electronic noise,language development},
  language = {en}
}

@article{soliSecondFormantsFricatives1981,
  title = {Second Formants in Fricatives: {{Acoustic}} Consequences of Fricative-vowel Coarticulation},
  shorttitle = {Second Formants in Fricatives},
  author = {Soli, Sigfrid D.},
  year = {1981},
  month = oct,
  volume = {70},
  pages = {976--984},
  issn = {0001-4966},
  doi = {10.1121/1.387032},
  file = {/Users/megcychosz/Zotero/storage/BWPNAIM4/Soli - 1981 - Second formants in fricatives Acoustic consequenc.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@article{songCompensatoryVowelLengthening2008,
  title = {Compensatory {{Vowel Lengthening}} for {{Omitted Coda Consonants}}: {{A Phonetic Investigation}} of {{Children}}'s {{Early Representations}} of {{Prosodic Words}}},
  shorttitle = {Compensatory {{Vowel Lengthening}} for {{Omitted Coda Consonants}}},
  author = {Song, Jae Yung and Demuth, Katherine},
  year = {2008},
  month = dec,
  volume = {51},
  pages = {385--402},
  issn = {0023-8309, 1756-6053},
  doi = {10.1177/0023830908099071},
  file = {/Users/megcychosz/Zotero/storage/CYFXKLMM/Jae Yung Song and Demuth - 2008 - Compensatory Vowel Lengthening for Omitted Coda Co.pdf},
  journal = {Language and Speech},
  language = {en},
  number = {4}
}

@article{songDevelopmentPhoneticVariants2015,
  title = {Development of Phonetic Variants (Allophones) in 2-Year-Olds Learning {{American English}}: {{A}} Study of Alveolar Stop /t, d/ Codas},
  shorttitle = {Development of Phonetic Variants (Allophones) in 2-Year-Olds Learning {{American English}}},
  author = {Song, Jae Yung and {Shattuck-Hufnagel}, Stefanie and Demuth, Katherine},
  year = {2015},
  month = sep,
  volume = {52},
  pages = {152--169},
  issn = {00954470},
  doi = {10.1016/j.wocn.2015.06.003},
  abstract = {This study examined the emergence of the phonetic variants (often called allophones) of alveolar phonemes in the speech production of 2-year-olds. Our specific question was: Does the child start by producing a ``canonical'' form of a phoneme (e.g., /t/ with a clear closure and a release burst), only later learning to produce its other phonetic variants (e.g., unreleased stop, flap, and glottal stop)? Or, does the child start by producing the appropriate phonetic variants in the appropriate contexts and only later learn that they are phonetic variants of the same phoneme? In order to address this question, we investigated the production of three phonetic variants (unreleased stop, flap, and glottal stop) of the alveolar stop codas /t, d/ in the spontaneous speech of 6 AmericanEnglish-speaking mother\textendash child dyads, using both acoustic and perceptual coding. The results showed that 2year-old children produced all three variants significantly less often than their mothers, and produced acoustic cues to canonical /t, d/ more often. This supports the view that young children start out by producing a fully articulated canonical variant of a phoneme in contexts where an adult would produce non-canonical forms. The implications of these findings for early phonological representations are discussed.},
  file = {/Users/megcychosz/Zotero/storage/KKPBHML4/Song et al. - 2015 - Development of phonetic variants (allophones) in 2.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{songDurationalCuesFricative2013,
  title = {Durational Cues to Fricative Codas in 2-Year-Olds' {{American English}}: {{Voicing}} and Morphemic Factors},
  shorttitle = {Durational Cues to Fricative Codas in 2-Year-Olds' {{American English}}},
  author = {Song, Jae Yung and Demuth, Katherine and Evans, Karen and {Shattuck-Hufnagel}, Stefanie},
  year = {2013},
  month = may,
  volume = {133},
  pages = {2931--2946},
  issn = {0001-4966},
  doi = {10.1121/1.4795772},
  abstract = {In the process of phonological development, fricatives are generally assumed to be later acquired than stops. However, most of the observational work on which this claim is based has concerned itself with word-initial onset consonants; little is known about how and when fricatives are mastered in word-final coda position (e.g., nose). This is all the more critical in a language like English, where word-final fricatives often carry important morphological information (e.g., toes, goes). This study examines the development of duration cues to the voicing feature contrast in coda fricatives, using longitudinal spontaneous speech data from CVC words (e.g., noise vs face) produced by three children (1;6\textendash 2;6 years) and six mothers. Results show that the children were remarkably adult-like in the use of duration cues to voicing contrasts in fricatives even in this early age range. Furthermore the children, like the mothers, had longer frication noise durations for morphemic compared to non-morphemic fricatives (e.g., toes vs nose) when these segments occurred in utterance-final position. These results suggest that although children's fricatives tend to be overall longer and more voiced compared to those of adults, the voicing and morphological contrasts for fricative codas are acquired early in production.},
  file = {/Users/megcychosz/Zotero/storage/3RXV3AR3/Yung Song et al. - 2013 - Durational cues to fricative codas in 2-year-olds'.pdf},
  journal = {Journal of the Acoustical Society of America},
  number = {5},
  pmcid = {PMC3663930},
  pmid = {23654398}
}

@article{songEffectsAcousticProperties,
  title = {Effects of the Acoustic Properties of Infant-Directed Speech on Infant Word Recognition},
  author = {Song, Jae Yung and Demuth, Katherine and Morgan, James},
  pages = {13},
  file = {/Users/megcychosz/Zotero/storage/X5TATCVD/Song et al. - Effects of the acoustic properties of infant-direc.pdf},
  language = {en}
}

@article{songEffectsCoarticulationMorphological2013,
  title = {The Effects of Coarticulation and Morphological Complexity on the Production of {{English}} Coda Clusters: {{Acoustic}} and Articulatory Evidence from 2-Year-Olds and Adults Using Ultrasound},
  shorttitle = {The Effects of Coarticulation and Morphological Complexity on the Production of {{English}} Coda Clusters},
  author = {Song, Jae Yung and Demuth, Katherine and {Shattuck-Hufnagel}, Stefanie and M{\'e}nard, Lucie},
  year = {2013},
  month = may,
  volume = {41},
  pages = {281--295},
  issn = {00954470},
  doi = {10.1016/j.wocn.2013.03.004},
  abstract = {Most studies of phonological development have explored the acquisition of segments, syllables and words using perceptual/transcription methods. Less is known about the articulatory aspects of early speech, or the development of articulatory-acoustic mapping. Recent research on adult speech finds that coarticulation effects are evidenced in both the acoustics and the articulatory gestures, and suggests tighter coarticulation and less variability for monomorphemic compared to polymorphemic segment sequences. The present study explored phonological context and morphological effects in the speech of five adults and five 2-year-olds, combining acoustic and articulatory analysis from ultrasound recordings. The results show that coarticulation effects are found in the word-final consonant cluster (box) for both adults and children. For children, these were evidenced only in the articulatory data. In addition, both age groups showed differences in tongue height between the monomorphemic (box) and bimorphemic (rocks) clusters, suggesting a possible morphological effect. These findings confirm that ultrasound methods can be successfully employed to explore aspects of early gestural development in children as young as 2, and raise many questions regarding the nature of speech planning processes as a function of lexical versus morphological form.},
  file = {/Users/megcychosz/Zotero/storage/E7XLNQJ5/Song et al. - 2013 - The effects of coarticulation and morphological co.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{sosaAssociationTypeToy2016,
  title = {Association of the {{Type}} of {{Toy Used During Play With}} the {{Quantity}} and {{Quality}} of {{Parent}}-{{Infant Communication}}},
  author = {Sosa, Anna V.},
  year = {2016},
  month = feb,
  volume = {170},
  pages = {132},
  issn = {2168-6203},
  doi = {10.1001/jamapediatrics.2015.3753},
  abstract = {OBJECTIVE To investigate whether the type of toy used during play is associated with the parent-infant communicative interaction. DESIGN, SETTING, AND PARTICIPANTS Controlled experiment in a natural environment of parent-infant communication during play with 3 different toy sets. Participant recruitment and data collection were conducted between February 1, 2013, and June 30, 2014. The volunteer sample included 26 parent-infant (aged 10-16 months) dyads. Editorial page 112 Related article page 184 EXPOSURES Fifteen-minute in-home parent-infant play sessions with electronic toys, traditional toys, and books. MAIN OUTCOMES AND MEASURES Numbers of adult words, child vocalizations, conversational turns, parent verbal responses to child utterances, and words produced by parents in 3 different semantic categories (content-specific words) per minute during play sessions. RESULTS Among the 26 parent-infant dyads, toy type was associated with all outcome measures. During play with electronic toys, there were fewer adult words (mean, 39.62; 95\% CI, 33.36-45.65), fewer conversational turns (mean, 1.64; 95\% CI, 1.12-2.19), fewer parental responses (mean, 1.31; 95\% CI, 0.87-1.77), and fewer productions of content-specific words (mean, 1.89; 95\% CI, 1.49-2.35) than during play with traditional toys or books. Children vocalized less during play with electronic toys (mean per minute, 2.9; 95\% CI, 2.16-3.69) than during play with books (mean per minute, 3.91; 95\% CI, 3.09-4.68). Parents produced fewer words during play with traditional toys (mean per minute, 55.56; 95\% CI, 46.49-64.17) than during play with books (mean per minute, 66.89; 95\% CI, 59.93-74.19) and use of content-specific words was lower during play with traditional toys (mean per minute, 4.09; 95\% CI, 3.26-4.99) than during play with books (mean per minute, 6.96; 95\% CI, 6.07-7.97). CONCLUSIONS AND RELEVANCE Play with electronic toys is associated with decreased quantity and quality of language input compared with play with books or traditional toys. To promote early language development, play with electronic toys should be discouraged. Traditional toys may be a valuable alternative for parent-infant play time if book reading is not a preferred activity.},
  file = {/Users/megcychosz/Zotero/storage/MRJNX7K6/Sosa_notes.rtf;/Users/megcychosz/Zotero/storage/TQD64M8P/Sosa - 2016 - Association of the Type of Toy Used During Play Wi.pdf},
  journal = {JAMA Pediatrics},
  language = {en},
  number = {2}
}

@article{sosaLexicalPhonologicalEffects2012,
  title = {Lexical and {{Phonological Effects}} in {{Early Word Production}}},
  author = {Sosa, Anna V. and {Stoel-Gammon}, Carol},
  year = {2012},
  month = apr,
  volume = {55},
  pages = {596},
  issn = {1092-4388},
  doi = {10.1044/1092-4388(2011/10-0113)},
  abstract = {Purpose\textemdash This study examines the influence of word frequency, phonological neighborhood density (PND), age-of-acquisition (AoA), and phonotactic probability on production variability and accuracy of known words by toddlers with no history of speech, hearing, or language disorders. Method\textemdash Fifteen toddlers between 2;0 and 2;5 produced monosyllabic target words varying in word frequency, PND, AoA, and phonotactic probability. Phonetic transcription was used to determine (1) whole-word variability and (2) proportion of whole-word proximity (PWP) (Ingram, 2002) of each target word produced. Results\textemdash Results showed a significant effect of PND on both proximity and variability (words from dense neighborhoods were closer to the adult targets and less variable than those from sparse neighborhoods), a significant effect of word frequency on variability (high frequency words were less variable) but not proximity, and a significant effect of AoA on proximity (earlier acquired words were farther from the adult target than later acquired words) but not variability. Conclusions\textemdash Results provide new information regarding the role lexical and phonological factors play in the speech of young children; specifically, several factors are identified that influence variability of production. Additionally, by examining lexical and phonological factors simultaneously, the current study is able to isolate differential effects of individual factors that have often been conflated in previous work. Implications for our understanding of emerging phonological representations are discussed.},
  file = {/Users/megcychosz/Zotero/storage/CW95SGH6/Sosa and Stoel-Gammon - 2012 - Lexical and Phonological Effects in Early Word Pro.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {2}
}

@article{stackTactileStimulationComponent1990,
  title = {Tactile Stimulation as a Component of Social Interchange: {{New}} Interpretations for the Still-Face Effect},
  shorttitle = {Tactile Stimulation as a Component of Social Interchange},
  author = {Stack, Dale M. and Muir, Darwin W.},
  year = {1990},
  volume = {8},
  pages = {131--145},
  issn = {2044-835X},
  doi = {10.1111/j.2044-835X.1990.tb00828.x},
  abstract = {Three experiments were conducted to isolate the effect of touch as a component of mother-infant interaction in the still-face (SF) paradigm and to determine the impact of adult touch on infant affect and attention. In Expt 1 it was established that the amount of maternal touching which occurred during the normal periods of the SF procedure was greater than 65 per cent for 3-, 6-, and 9-month-olds. In Expts 2 (cross-sectional) and 3 (longitudinal), the SF no-touch period was compared with a SF period where mothers could touch their 3- to 9-month-olds. Infants who received touch while their mothers were still-faced smiled more, grimaced less, and were more content relative to infants receiving the standard SF, no-touch procedure. Adult touch proved to be an interactive component which, in isolation, reduced the SF effect by eliciting infants' positive affect and directing their attention toward the mothers' hands. The relevance of this work for better comprehension of early infant social interaction and new interpretations of the SF effect are discussed.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-835X.1990.tb00828.x},
  file = {/Users/megcychosz/Zotero/storage/ESJUI2NG/Stack and Muir - 1990 - Tactile stimulation as a component of social inter.pdf;/Users/megcychosz/Zotero/storage/8UH42XV8/j.2044-835X.1990.tb00828.html},
  journal = {British Journal of Developmental Psychology},
  language = {en},
  number = {2}
}

@article{stanleyWhatMetaanalysesReveal2018,
  title = {What Meta-Analyses Reveal about the Replicability of Psychological Research.},
  author = {Stanley, T. D. and Carter, Evan C. and Doucouliagos, Hristos},
  year = {2018},
  month = dec,
  volume = {144},
  pages = {1325--1346},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/bul0000169},
  abstract = {A survey of 12,065 estimated effects from nearly 8,000 research papers finds that the average statistical power in psychology is 36\% and only 8\% of studies have adequate power. Typical heterogeneity is nearly three times larger than reported sampling error variation. Heterogeneity this large easily explains recent highly publicized failures to replicate in psychology. In most cases, we find little evidence that publication bias is a major factor.},
  file = {/Users/megcychosz/Zotero/storage/Q4XBMRSS/Stanley et al. - 2018 - What meta-analyses reveal about the replicability .pdf},
  journal = {Psychological Bulletin},
  language = {en},
  number = {12}
}

@article{stanleyWhatMetaanalysesReveal2018a,
  title = {What Meta-Analyses Reveal about the Replicability of Psychological Research.},
  author = {Stanley, T. D. and Carter, Evan C. and Doucouliagos, Hristos},
  year = {2018},
  month = dec,
  volume = {144},
  pages = {1325--1346},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/bul0000169},
  abstract = {A survey of 12,065 estimated effects from nearly 8,000 research papers finds that the average statistical power in psychology is 36\% and only 8\% of studies have adequate power. Typical heterogeneity is nearly three times larger than reported sampling error variation. Heterogeneity this large easily explains recent highly publicized failures to replicate in psychology. In most cases, we find little evidence that publication bias is a major factor.},
  file = {/Users/megcychosz/Zotero/storage/ZX9FPV6H/Stanley et al. - 2018 - What meta-analyses reveal about the replicability .pdf},
  journal = {Psychological Bulletin},
  language = {en},
  number = {12}
}

@article{stanovichDevelopmentalChangesCognitive1986,
  title = {Developmental {{Changes}} in the {{Cognitive Correlates}} of {{Reading Ability}} and the {{Developmental Lag Hypothesis}}},
  author = {Stanovich, Keith E. and Nathan, Ruth G. and {Vala-Rossi}, Marilyn},
  year = {1986},
  volume = {21},
  pages = {267--283},
  issn = {00340553},
  doi = {10.2307/747709},
  file = {/Users/megcychosz/Zotero/storage/IJQTBCBY/Stanovich et al. - 1986 - Developmental Changes in the Cognitive Correlates .pdf},
  journal = {Reading Research Quarterly},
  language = {en},
  number = {3}
}

@book{starkSucreQuechuaPedagogical1971,
  title = {Sucre {{Quechua}}: {{A Pedagogical Grammar}}.},
  author = {Stark, L.R. and Segovia Bayo, M. and Segovia Polo, F.},
  year = {1971},
  address = {{Department of Anthropology, University of Wisconsin}}
}

@article{steffmanIntonationalStructureMediates2019,
  title = {Intonational Structure Mediates Speech Rate Normalization in the Perception of Segmental Categories},
  author = {Steffman, Jeremy},
  year = {2019},
  month = may,
  volume = {74},
  pages = {114--129},
  issn = {00954470},
  doi = {10.1016/j.wocn.2019.03.002},
  abstract = {The question of if and to what extent listeners' perceptual phonetic categories are sensitive to prosodically driven variability has been a topic of interest in the literature. The present study reports on two experiments which address this question in light of recent research. In Experiment 1, listeners categorized a VOT continuum as /p/ or /b/ in a target syllable (/pɑ/ or /bɑ/). The target was placed in a carrier phrase where the duration and f0 of the pre-target syllable were manipulated. Results suggest listeners are sensitive to intonational structure in their computation of speech rate, interpreting a short syllable with low-rising f0 (created from an L-H\% boundary tone in English intonational phonology) as an increase in speech rate. This perceived increase in rate shifts the category boundary of the subsequent target VOT. Experiment 2 showed listeners similarly adjusted categorization of a vowel duration continuum, where vowel duration is a cue to a following obstruent's voicing (categorized as ``coat'' or ``code''). Taken together, these results suggest that listeners are sensitive to intonational structure in their perception of segmental contrasts and use the distribution of tonal targets over a given temporal interval in computing speech rate.},
  file = {/Users/megcychosz/Zotero/storage/QGVW6XWS/Steffman - 2019 - Intonational structure mediates speech rate normal.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{sternProsodyMaternalSpeech1983,
  title = {The Prosody of Maternal Speech: Infant Age and Context Related Changes.},
  author = {Stern, D.N. and Spieker, S. and Barnett, R.K. and MacKain, K.},
  year = {1983},
  volume = {10},
  pages = {1--15},
  file = {/Users/megcychosz/Zotero/storage/MDRJ4SEN/1438466.pdf},
  journal = {Journal of Child Language},
  number = {1}
}

@article{sternRecentEpidemiologyPediatric2005,
  title = {Recent {{Epidemiology}} of {{Pediatric Cochlear Implantation}} in the {{United States}}: {{Disparity Among Children}} of {{Different Ethnicity}} and {{Socioeconomic Status}}},
  shorttitle = {Recent {{Epidemiology}} of {{Pediatric Cochlear Implantation}} in the {{United States}}},
  author = {Stern, Ryan E. and Yueh, Bevan and Lewis, Charlotte and Norton, Susan and Sie, Kathleen C. Y.},
  year = {2005},
  month = jan,
  volume = {115},
  pages = {125--131},
  issn = {0023852X, 15314995},
  doi = {10.1097/01.mlg.0000150698.61624.3c},
  file = {/Users/megcychosz/Zotero/storage/LF6IRKVI/Stern et al. - 2005 - Recent Epidemiology of Pediatric Cochlear Implanta.pdf},
  journal = {The Laryngoscope},
  language = {en},
  number = {1}
}

@article{stevensQuantalNatureSpeech1989,
  title = {On the Quantal Nature of Speech},
  author = {Stevens, Kenneth N.},
  year = {1989},
  month = jan,
  volume = {17},
  pages = {3--45},
  issn = {00954470},
  doi = {10.1016/S0095-4470(19)31520-7},
  file = {/Users/megcychosz/Zotero/storage/NG9LZAEQ/Stevens - 1989 - On the quantal nature of speech.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {1-2}
}

@article{stoehrBilingualPreschoolersSpeech2019,
  title = {Bilingual {{Preschoolers}}' {{Speech}} Is {{Associated}} with {{Non}}-{{Native Maternal Language Input}}},
  author = {Stoehr, Antje and Benders, Titia and {van Hell}, Janet G. and Fikkert, Paula},
  year = {2019},
  month = jan,
  volume = {15},
  pages = {75--100},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2018.1533473},
  abstract = {Bilingual children are often exposed to non-native speech through their parents. Yet, little is known about the relation between bilingual preschoolers' speech production and their speech input. The present study investigated the production of voice onset time (VOT) by Dutch-German bilingual preschoolers and their sequential bilingual mothers. The findings reveal an association between maternal VOT and bilingual children's VOT in the heritage language German as well as in the majority language Dutch. By contrast, no input-production association was observed in the VOT production of monolingual German-speaking children and monolingual Dutchspeaking children. The results of this study provide the first empirical evidence that non-native and attrited maternal speech contributes to the often-observed linguistic differences between bilingual children and their monolingual peers.},
  file = {/Users/megcychosz/Zotero/storage/SI6XYCFR/Stoehr et al. - 2019 - Bilingual Preschoolers’ Speech is Associated with .pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {1}
}

@article{stoehrHeritageLanguageExposure2018,
  title = {Heritage Language Exposure Impacts Voice Onset Time of {{Dutch}}\textendash{{German}} Simultaneous Bilingual Preschoolers},
  author = {Stoehr, Antje and Benders, Titia and Van Hell, Janet G. and Fikkert, Paula},
  year = {2018},
  month = may,
  volume = {21},
  pages = {598--617},
  issn = {1366-7289, 1469-1841},
  doi = {10.1017/S1366728917000116},
  abstract = {This study assesses the effects of age and language exposure on VOT production in 29 simultaneous bilingual children aged 3;7 to 5;11 who speak German as a heritage language in the Netherlands. Dutch and German have a binary voicing contrast, but the contrast is implemented with different VOT values in the two languages. The results suggest that bilingual children produce `voiced' plosives similarly in their two languages, and these productions are not monolingual-like in either language. Bidirectional cross-linguistic influence between Dutch and German can explain these results. Yet, the bilinguals seemingly have two autonomous categories for Dutch and German `voiceless' plosives. In German, the bilinguals' aspiration is not monolingual-like, but bilinguals with more heritage language exposure produce more target-like aspiration. Importantly, the amount of exposure to German has no effect on the majority language's `voiceless' category. This implies that more heritage language exposure is associated with more language-specific voicing systems.},
  file = {/Users/megcychosz/Zotero/storage/2KVVMTXK/Stoehr et al. - 2018 - Heritage language exposure impacts voice onset tim.pdf},
  journal = {Bilingualism: Language and Cognition},
  language = {en},
  number = {3}
}

@article{stoel-gammonBabblingDevelopmentHearingimpaired1986,
  title = {Babbling Development of Hearing-Impaired and Normally Hearing Subjects},
  author = {{Stoel-Gammon}, Carol and Otomo, Kioyoshi},
  year = {1986},
  volume = {51},
  pages = {33--41},
  journal = {Journal of Speech and Hearing Disorders},
  number = {1}
}

@article{stoel-gammonRelationshipsLexicalPhonological2011,
  title = {Relationships between Lexical and Phonological Development in Young Children*},
  author = {{Stoel-Gammon}, Carol},
  year = {2011},
  month = jan,
  volume = {38},
  pages = {1--34},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000910000425},
  abstract = {Our understanding of the relationships between lexical and phonological development has been enhanced in recent years by increased interest in this area from language scientists, psychologists and phonologists. This review article provides a summary of research, highlighting similarities and differences across studies. It is suggested that the research falls into two categories with different goals and different methodological approaches : (1) child-centered studies that examine the influences active in the prelinguistic and early-word period, emphasizing individual developmental patterns and the active role played by the child ; and (2) studies inspired by research on word processing in adults ; these focus on the effects of the phonological and lexical characteristics of the ambient language on underlying representations and word learning in children. The article concludes with suggestions for integrating the findings from the two approaches and for future research.},
  file = {/Users/megcychosz/Zotero/storage/AIVUIQQD/Stoel-Gammon - 2011 - Relationships between lexical and phonological dev.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {01}
}

@article{stoel-gammonVowelSystemsNormally1990,
  title = {Vowel Systems of Normally Developing and Phonologically Disordered Children},
  author = {{Stoel-gammon}, Carol and Herrington, Paula Beckett},
  year = {1990},
  month = jan,
  volume = {4},
  pages = {145--160},
  issn = {0269-9206, 1464-5076},
  doi = {10.3109/02699209008985478},
  abstract = {Available literature on the acquisition of vowels in normally developing and phonologically disordered subjects is reviewed and detailed case studies of the vowel productions of two phonologically disordered subjects are presented. The findings reveal parallels between the accuracy levels for disordered subjects and order of mastery in younger normal children. In both populations, corner vowels are produced accurately before non-corner vowels. Unstressed vowels were found to be problematic for children with phonological disorders.},
  file = {/Users/megcychosz/Zotero/storage/UBMKUS7U/Stoel-gammon and Herrington - 1990 - Vowel systems of normally developing and phonologi.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {2}
}

@article{stokesArticulatoryComplexityAmbient2005,
  title = {Articulatory {{Complexity}}, {{Ambient Frequency}}, and {{Functional Load}} as {{Predictors}} of {{Consonant Development}} in {{Children}}},
  author = {Stokes, Stephanie F. and Surendran, Dinoj},
  year = {2005},
  month = jun,
  volume = {48},
  pages = {577--591},
  issn = {1092-4388},
  doi = {10.1044/1092-4388(2005/040)},
  abstract = {University of Chicago The notion of a universal pattern of phonological development, rooted in basic physiological constraints, is controversial, with some researchers arguing for a strong environmental (ambient language) influence on phonological development or an interaction of both physiological constraints and ambient language effects. This research examines the relative value of articulatory complexity, ambient frequency, and functional load as predictors of consonant development in children. Three languages are investigated: Cantonese, American English, and Dutch. Regression analyses revealed that functional load accounted for 55\% of the variance in age of emergence of consonants in 7 English-speaking children (8\textendash 25 months), while frequency of consonants in the ambient language accounted for 63\% of the variance in age of emergence of consonants in 51 Cantonesespeaking children (15\textendash 30 months). Articulatory complexity accounted for 40\% of the accuracy of production of consonants in 40 English-speaking children (25 months), and frequency accounted for 43\% of the variance in accuracy of production of consonants in 5 Dutch-speaking children (24 months). Given cross-linguistic differences, further research is required.},
  file = {/Users/megcychosz/Zotero/storage/EIVWUHL3/Stokes and Surendran - 2005 - Articulatory Complexity, Ambient Frequency, and Fu.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {3}
}

@article{stokesFactorsThatInfluence2009,
  title = {Factors That Influence Vocabulary Development in Two-Year-Old Children},
  author = {Stokes, Stephanie F. and Klee, Thomas},
  year = {2009},
  month = apr,
  volume = {50},
  pages = {498--505},
  issn = {00219630, 14697610},
  doi = {10.1111/j.1469-7610.2008.01991.x},
  file = {/Users/megcychosz/Zotero/storage/5MNHHZ59/Stokes and Klee - 2009 - Factors that influence vocabulary development in t.pdf},
  journal = {Journal of Child Psychology and Psychiatry},
  language = {en},
  number = {4}
}

@article{stokesNeighborhoodDensityWord2010,
  title = {Neighborhood {{Density}} and {{Word Frequency Predict Vocabulary Size}} in {{Toddlers}}},
  author = {Stokes, Stephanie F.},
  year = {2010},
  month = jun,
  volume = {53},
  pages = {670--683},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2009/08-0254)},
  abstract = {Purpose: To document the lexical characteristics of neighborhood density (ND) and word frequency (WF) in the lexicons of a large sample of English-speaking toddlers. Method: Parents of 222 British-English\textendash speaking children aged 27({$\pm$}3) months completed a British adaptation of the MacArthur\textendash Bates Communicative Development Inventory: Words and Sentences (MCDI; Klee \& Harrison, 2001). Child words were coded for ND and WF, and the relationships among vocabulary, ND, and WF were examined. A cut-point of \textendash 1 SD below the mean on the MCDI classified children into one of two groups: low or high vocabulary size. Group differences on ND and WF were examined using nonparametric statistics. Results: In a hierarchical regression, ND and WF accounted for 47\% and 14\% of unique variance in MCDI scores, respectively. Low-vocabulary children scored significantly higher on ND and significantly lower on WF than did high-vocabulary children, but there was more variability in ND and WF for children at the lowest points of the vocabulary continuum. Conclusion: Children at the lowest points of a continuum of vocabulary size may be extracting statistical properties of the input language in a manner quite different from their more able age peers.},
  file = {/Users/megcychosz/Zotero/storage/KLKWIEGK/Stokes - 2010 - Neighborhood Density and Word Frequency Predict Vo.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {3}
}

@article{stollNounsVerbsChintang2012,
  title = {Nouns and Verbs in {{Chintang}}: Children's Usage and Surrounding Adult Speech},
  shorttitle = {Nouns and Verbs in {{Chintang}}},
  author = {Stoll, Sabine and Bickel, Balthasar and Lieven, Elena and Paudyal, Netra P. and Banjade, Goma and Bhatta, Toya N. and Gaenszle, Martin and Pettigrew, Judith and Rai, Ichchha Purna and Rai, Manoj and Rai, Novel Kishore},
  year = {2012},
  month = mar,
  volume = {39},
  pages = {284--321},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000911000080},
  abstract = {ABSTRACT             Analyzing the development of the noun-to-verb ratio in a longitudinal corpus of four Chintang (Sino-Tibetan) children, we find that up to about age four, children have a significantly higher ratio than adults. Previous cross-linguistic research rules out an explanation of this in terms of a universal noun bias; instead, a likely cause is that Chintang verb morphology is polysynthetic and difficult to learn. This hypothesis is supported by the fact that the development of Chintang children's noun-to-verb ratio correlates significantly with the extent to which they show a similar flexibility with verbal morphology to that of the surrounding adults, as measured by morphological paradigm entropy. While this development levels off around age three, children continue to have a higher overall noun-to-verb ratio than adults. A likely explanation lies in the kinds of activities that children are engaged in and that are almost completely separate from adults' activities in this culture.},
  file = {/Users/megcychosz/Zotero/storage/35LWGWLQ/Stoll et al. - 2012 - Nouns and verbs in Chintang children's usage and .pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {2}
}

@article{storkelChildrenAcquireDense2004,
  title = {Do Children Acquire Dense Neighborhoods? {{An}} Investigation of Similarity Neighborhoods in Lexical Acquisition},
  shorttitle = {Do Children Acquire Dense Neighborhoods?},
  author = {Storkel, Holly L.},
  year = {2004},
  month = apr,
  volume = {25},
  pages = {201--221},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716404001109},
  abstract = {This study tests the claim that children acquire collections of phonologically similar word forms, namely, dense neighborhoods. Age of acquisition (AoA) norms were obtained from two databases: parent report of infant and toddler production and adult self-ratings of AoA. Neighborhood density, word frequency, word length, Density \texttimes{} Frequency and Density \texttimes{} Length were analyzed as potential predictors of AoA using linear regression. Early acquired words were higher in density, higher in word frequency, and shorter in length than late acquired words. Significant interactions provided evidence that the lexical factors predicting AoA varied, depending on the type of word being learned. The implication of these findings for lexical acquisition and language learning are discussed.},
  file = {/Users/megcychosz/Zotero/storage/QRNQSD8H/Storkel - 2004 - Do children acquire dense neighborhoods An invest.pdf},
  journal = {Applied Psycholinguistics},
  language = {en}
}

@article{storkelComparisonHomonymNovel2005,
  title = {A Comparison of Homonym and Novel Word Learning: The Role of Phonotactic Probability and Word Frequency},
  shorttitle = {A Comparison of Homonym and Novel Word Learning},
  author = {Storkel, Holly L. and Maekawa, Junko},
  year = {2005},
  month = nov,
  volume = {32},
  pages = {827--853},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000905007099},
  abstract = {This study compares homonym learning to novel word learning by three- to four-year-old children to determine whether homonyms are learned more rapidly or more slowly than novel words. In addition, the role of form characteristics in homonym learning is examined by manipulating phonotactic probability and word frequency. Thirty-two children were exposed to homonyms and novel words in a story with visual support and learning was measured in two tasks: referent identification; picture naming. Results showed that responses to homonyms were as accurate as responses to novel words in the referent identification task. In contrast, responses to homonyms were more accurate than responses to novel words in the picture-naming task. Furthermore, homonyms composed of common sound sequences were named more accurately than those composed of rare sound sequences. The influence of word frequency was less straightforward. These results may be inconsistent with a one-to-one form-referent bias in word learning.},
  file = {/Users/megcychosz/Zotero/storage/52FA2ECZ/Storkel and Maekawa - 2005 - A comparison of homonym and novel word learning t.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {4}
}

@article{storkelImplementingEvidenceBasedPractice2018,
  title = {Implementing {{Evidence}}-{{Based Practice}}: {{Selecting Treatment Words}} to {{Boost Phonological Learning}}},
  shorttitle = {Implementing {{Evidence}}-{{Based Practice}}},
  author = {Storkel, Holly L.},
  year = {2018},
  month = jul,
  volume = {49},
  pages = {482--496},
  issn = {0161-1461, 1558-9129},
  doi = {10.1044/2017_LSHSS-17-0080},
  abstract = {Purpose               Word selection has typically been thought of as an inactive ingredient in phonological treatment, but emerging evidence suggests that word selection is an active ingredient that can impact phonological learning. The goals of this tutorial are to (a) review the emerging single-subject evidence on the influence of word characteristics on phonological learning in clinical treatment, (b) outline hypotheses regarding the mechanism of action of word characteristics, and (c) provide resources to support clinicians incorporating word selection as an active ingredient in their approach to phonological treatment.                                         Method               Research demonstrating the influence of the word frequency, neighborhood density, age of acquisition, and lexicality of treatment stimuli on phonological learning is summarized. The mechanism of action for each characteristic is hypothesized. Methods from the research studies are used to create a free set of evidence-based treatment materials targeting most of the mid-8 and late-8 consonants.                                         Results               Clinicians have numerous evidence-based options to consider when selecting stimuli for phonological treatment including (a) high-frequency and high-density words, (b) low-frequency and high-density words, (c) high-frequency and mixed-density words, (d) low-frequency and late-acquired words, and (e) nonwords.                                         Conclusion               Incorporating word characteristics into phonological treatment may boost phonological learning.                                         KU ScholarWorks Supplemental Material                                http://hdl.handle.net/1808/24768},
  file = {/Users/megcychosz/Zotero/storage/CA4XK8MD/Storkel - 2018 - Implementing Evidence-Based Practice Selecting Tr.pdf},
  journal = {Language, Speech, and Hearing Services in Schools},
  language = {en},
  number = {3}
}

@article{storkelInfluencePartwordPhonotactic2011,
  title = {The Influence of Part-Word Phonotactic Probability/Neighborhood Density on Word Learning by Preschool Children Varying in Expressive Vocabulary},
  author = {Storkel, Holly L. and Hoover, Jill R.},
  year = {2011},
  month = jun,
  volume = {38},
  pages = {628--643},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000910000176},
  abstract = {The goal of this study was to examine the influence of part-word phonotactic probability/ neighborhood density on word learning by preschool children with normal vocabularies that varied in size. Ninety-eight children (age 2;11 \textendash{} 6;0) were taught consonant-vowel-consonant (CVC) nonwords orthogonally varying in the probability/density of the CV (i.e., body) and VC (i.e., rhyme). Learning was measured via picture naming. Children with the lowest expressive vocabulary scores showed no effect of either CV or VC probability/density, although floor effects could not be ruled out. In contrast, children with low or high expressive vocabulary scores demonstrated sensitivity to part-word probability/density with the nature of the effect varying by group. Children with the highest expressive vocabulary scores displayed yet a third pattern of partword probability/density effects. Taken together, word learning by preschool children was influenced by part-word probability/density but the nature of this influence appeared to depend on the size of the lexicon.},
  file = {/Users/megcychosz/Zotero/storage/2JWYQ583/Storkel and Hoover - 2011 - The influence of part-word phonotactic probability.pdf;/Users/megcychosz/Zotero/storage/68TPQDAU/Storkel and Hoover - 2011 - The influence of part-word phonotactic probability.pdf;/Users/megcychosz/Zotero/storage/RPFQLQVA/Storkel and Hoover - 2011 - The influence of part-word phonotactic probability.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {03}
}

@article{storkelLexiconPhonologyInteractions2002,
  title = {The {{Lexicon}} and {{Phonology}}: {{Interactions}} in {{Language Acquisition}}},
  shorttitle = {The {{Lexicon}} and {{Phonology}}},
  author = {Storkel, Holly L. and Morrisette, Michele L.},
  year = {2002},
  month = jan,
  volume = {33},
  pages = {24--37},
  issn = {0161-1461, 1558-9129},
  doi = {10.1044/0161-1461(2002/003)},
  abstract = {The purpose of this paper is to underscore the importance of the link between lexical and phonological acquisition by considering learning by children beyond the 50-word stage and by applying cognitive models of spoken word processing to development. Lexical and phonological variables that have been shown to influence perception and production across the lifespan are considered relative to their potential role in learning by preschool children. The effect of these lexical and phonological variables on perception, production, and learning are discussed in the context of a two-representation connectionist model of spoken word processing. The model appears to offer insights into the complex interaction between the lexicon and phonology and may be useful for clinical diagnosis and treatment of children with language delays.},
  file = {/Users/megcychosz/Zotero/storage/KJID5J2Y/Storkel and Morrisette - 2002 - The Lexicon and Phonology Interactions in Languag.pdf},
  journal = {Language, Speech, and Hearing Services in Schools},
  language = {en},
  number = {1}
}

@article{storkelMethodsMinimizingConfounding2004,
  title = {Methods for {{Minimizing}} the {{Confounding Effects}} of {{Word Length}} in the {{Analysis}} of {{Phonotactic Probability}} and {{Neighborhood Density}}},
  author = {Storkel, Holly L.},
  year = {2004},
  month = dec,
  volume = {47},
  pages = {1454--1468},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2004/108)},
  abstract = {Recent research suggests that phonotactic probability (the likelihood of occurrence of a sound sequence) and neighborhood density (the number of words phonologically similar to a given word) influence spoken language processing and acquisition across the lifespan in both normal and clinical populations. The majority of research in this area has tended to focus on controlled laboratory studies rather than naturalistic data such as spontaneous speech samples or elicited probes. One difficulty in applying current measures of phonotactic probability and neighborhood density to more naturalistic samples is the significant correlation between these variables and word length. This study examines several alternative transformations of phonotactic probability and neighborhood density as a means of reducing or eliminating this correlation with word length. Computational analyses of the words in a large database and reanalysis of archival data supported the use of z scores for the analysis of phonotactic probability as a continuous variable and the use of median transformation scores for the analysis of phonotactic probability as a dichotomous variable. Neighborhood density results were less clear with the conclusion that analysis of neighborhood density as a continuous variable warrants further investigation to differentiate the utility of z scores in comparison to median transformation scores. Furthermore, balanced dichotomous coding of neighborhood density was difficult to achieve, suggesting that analysis of neighborhood density as a dichotomous variable should be approached with caution. Recommendations for future application and analyses are discussed.},
  file = {/Users/megcychosz/Zotero/storage/SCAZIVD7/Storkel - 2004 - Methods for Minimizing the Confounding Effects of .pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {6}
}

@article{storkelRestructuringSimilarityNeighbourhoods2002,
  title = {Restructuring of Similarity Neighbourhoods in the Developing Mental Lexicon},
  author = {Storkel, Holly L.},
  year = {2002},
  month = may,
  volume = {29},
  pages = {251--274},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000902005032},
  abstract = {Previous evidence suggests that the structure of similarity neighbourhoods in the developing mental lexicon may differ from that of the fully developed lexicon. The similarity relationships used to organize words into neighbourhoods was investigated in 20 pre-school children (age 3;7 to 5;11) using a two alternative forced-choice classification task. Children classified the similarity of test words relative to a standard word to determine neighbourhood membership. The similarity relationship between the test and standard words varied orthogonally in terms of type of similarity and position of overlap. Standard words were drawn from neighbourhoods differing in density. Results showed that dense neighbourhoods were organized by phoneme similarity in the onset+nucleus or rhyme positions of overlap. In contrast, sparse neighbourhoods appeared to be organized by phoneme similarity in the onset+nucleus, but manner similarity in the rhyme. These results are integrated with previous findings from infants and adults to propose a developmental course of change in the mental lexicon.},
  file = {/Users/megcychosz/Zotero/storage/4TGHYGED/Storkel - 2002 - Restructuring of similarity neighbourhoods in the .pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {2}
}

@article{storyAgedependentVocalTract2018,
  title = {An Age-Dependent Vocal Tract Model for Males and Females Based on Anatomic Measurements},
  author = {Story, Brad H. and Vorperian, Houri K. and Bunton, Kate and Durtschi, Reid B.},
  year = {2018},
  month = may,
  volume = {143},
  pages = {3079--3102},
  issn = {0001-4966},
  doi = {10.1121/1.5038264},
  file = {/Users/megcychosz/Zotero/storage/PRZJNV6X/Story et al. - 2018 - An age-dependent vocal tract model for males and f.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{storyFormantMeasurementChildren2015,
  title = {Formant Measurement in Children's Speech Based on Spectral Filtering},
  author = {Story, Brad H. and Bunton, Kate},
  year = {2015},
  volume = {76},
  pages = {93--111},
  issn = {0167-6393},
  doi = {10.1016/j.specom.2015.11.001},
  abstract = {Children's speech presents a challenging problem for formant frequency measurement. In part, this is because high fundamental frequencies, typical of a children's speech production, generate widely spaced harmonic components that may undersample the spectral shape of the vocal tract transfer function. In addition, there is often a weakening of upper harmonic energy and a noise component due to glottal turbulence. The purpose of this study was to develop a formant measurement technique based on cepstral analysis that does not require modification of the cepstrum itself or transformation back to the spectral domain. Instead, a narrow-band spectrum is low-pass filtered with a cutoff point (i.e., cutoff ``quefrency'' in the terminology of cepstral analysis) to preserve only the spectral envelope. To test the method, speech representative of a 2\textendash 3 year-old child was simulated with an airway modulation model of speech production. The model, which includes physiologically-scaled vocal folds and vocal tract, generates sound output analogous to a microphone signal. The vocal tract resonance frequencies can be calculated independently of the output signal and thus provide test cases that allow for assessing the accuracy of the formant tracking algorithm. When applied to the simulated child-like speech, the spectral filtering approach was shown to provide a clear spectrographic representation of formant change over the time course of the signal, and facilitates tracking formant frequencies for further analysis.},
  file = {/Users/megcychosz/Zotero/storage/6Z8NZKM5/Story and Bunton - 2015 - Formant measurement in children’s speech based on .pdf},
  journal = {Speech communication},
  pmcid = {PMC4743040},
  pmid = {26855461}
}

@article{strycharczukGradualAbruptPhonetic2016,
  title = {Gradual or Abrupt? {{The}} Phonetic Path to Morphologisation},
  shorttitle = {Gradual or Abrupt?},
  author = {Strycharczuk, Patrycja and Scobbie, James M.},
  year = {2016},
  month = nov,
  volume = {59},
  pages = {76--91},
  issn = {00954470},
  doi = {10.1016/j.wocn.2016.09.003},
  abstract = {While some sound changes occur in environments defined in purely phonological terms, others may become sensitive to morphological boundaries. In this paper, we investigate the phonetic nature of this latter diachronic development: does it happen through small gradient increments, or is there a categorical shift from one allophone to another? We focus on goose-fronting and /l/-darkening in Southern British English, the interaction of which is sensitive to morphological boundaries. Relatively retracted realisations of the vowel and dark realisations of the /l/ appear before a morpheme boundary, even when a vowel follows (e.g. fool-ing), whereas in monomorphemic words (e.g. hula), there is more /u:/-fronting, and the /l/ is relatively lighter. We analyse the phonetic realisation of such pairs as hula vs. fool-ing in 20 speakers of Southern British English using both acoustic and articulatory (ultrasound) instrumental methods. All the speakers express the morphological contrast in some way, although effect sizes vary dramatically. For some speakers, the contrast involves subtle articulatory differences without any clear acoustic consequences, whereas other speakers show robust differences employing multiple phonetic correlates. We therefore argue that the hula{$\sim$}fool-ing contrast would be misrepresented if analysed in terms of a small number of either /u:/ or /l/ allophonic categories. Instead, we interpret the results as supporting the predictions of phonological frameworks that incorporate phonetically-gradient morphologisation.},
  file = {/Users/megcychosz/Zotero/storage/JV7L9W93/Strycharczuk and Scobbie - 2016 - Gradual or abrupt The phonetic path to morphologi.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@inbook{strycharczukPhoneticDetailPhonetic2019,
  title = {Phonetic {{Detail}} and {{Phonetic Gradience}} in {{Morphological Processes}}},
  booktitle = {Oxford {{Research Encyclopedia}} of {{Linguistics}}},
  author = {Strycharczuk, Patrycja},
  year = {2019},
  pages = {1--25},
  publisher = {{Oxford University Press}},
  doi = {10.1093/acrefore/9780199384655.013.616},
  abstract = {It is uncontroversial that morphological processes can change phonological surface representations. However, some empirical evidence also suggests that morphological processes may trigger phonetically gradient processes, that is, processes that involve fine phonetic differences, but involve no change in phonological categories. Such findings challenge modular or discrete feedforward theories of grammatical architecture, which counterpredict direct interactions between morphology and phonetics. This article reviews some of the findings in this area, pointing to two types of difficulty in interpreting evidence of morphologically-conditioned phonetic gradience. The first one involves significance and replicability in experimental sciences, which become especially problematic when fine phonetic detail is examined and the magnitude of differences involved is very small. The second one concerns identifying what is causing the phonetic effects among a wealth of possibilities, including paradigmatic relationships, morphological structure, prosody, and informativity.},
  collaborator = {Strycharczuk, Patrycja},
  file = {/Users/megcychosz/Zotero/storage/4VKMPQDF/Strycharczuk - 2019 - Phonetic Detail and Phonetic Gradience in Morpholo.pdf},
  isbn = {978-0-19-938465-5},
  language = {en}
}

@book{studdert-kennedyReportStatusProgress,
  title = {A Report on the Status and Progress of Studies on the Nature of Speech, Instrumentation for Its Investigation, and Practical Applications},
  author = {{Studdert-Kennedy}, M.}
}

@misc{SubglottalResonancesDistinctive,
  title = {Subglottal Resonances and Distinctive Features | {{Elsevier Enhanced Reader}}},
  doi = {10.1016/j.wocn.2008.10.006},
  file = {/Users/megcychosz/Zotero/storage/2MCLS5GQ/S0095447008000594.html},
  howpublished = {https://reader.elsevier.com/reader/sd/pii/S0095447008000594?token=9E8BEEDA0ACDADE9FAD2F444E9AE58310A904CEF5DD50B3F86457417789027782EDF01D8AB612D84A47FCA5513639815},
  language = {en}
}

@article{sugaharaDurationalCorrelatesEnglish2009,
  title = {Durational Correlates of {{English}} Sublexical Constituent Structure},
  author = {Sugahara, Mariko and Turk, Alice},
  year = {2009},
  volume = {26},
  pages = {477--524},
  issn = {0952-6757, 1469-8188},
  doi = {10.1017/S0952675709990248},
  file = {/Users/megcychosz/Zotero/storage/QPRXIG94/Sugahara and Turk - 2009 - Durational correlates of English sublexical consti.pdf},
  journal = {Phonology},
  language = {en},
  number = {03}
}

@article{summerfieldArticulatoryRatePerceptual1981,
  title = {Articulatory Rate and Perceptual Constancy in Phonetic Perception},
  author = {Summerfield, Quentin},
  year = {1981},
  volume = {7},
  pages = {1074--1095},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1277(Electronic),0096-1523(Print)},
  doi = {10.1037/0096-1523.7.5.1074},
  file = {/Users/megcychosz/Zotero/storage/M7BDAF9Z/Summerfield - Articulatory Rate and Perceptual Constancy in Phon.pdf;/Users/megcychosz/Zotero/storage/3WA4VAR9/1982-07509-001.html},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  keywords = {Articulation (Speech),Consonants,Speech Perception,Speech Rate},
  number = {5}
}

@article{summersBilingualPerformanceNonword2010,
  title = {Bilingual Performance on Nonword Repetition in {{Spanish}} and {{English}}},
  author = {Summers, Connie and Bohman, Thomas M. and Gillam, Ronald B. and Pe{\~n}a, Elizabeth D. and Bedore, Lisa M.},
  year = {2010},
  month = jul,
  volume = {45},
  pages = {480--493},
  issn = {1368-2822, 1460-6984},
  doi = {10.3109/13682820903198058},
  abstract = {Background: Nonword repetition (NWR) involves the ability to perceive, store, recall and reproduce phonological sequences. These same abilities play a role in word and morpheme learning. Cross-linguistic studies of performance on NWR tasks, word learning, and morpheme learning yield patterns of increased performance on all three tasks as a function of age and language experience. These results are consistent with the idea that there may be universal information-processing mechanisms supporting language learning. Because bilingual children's language experience is divided across two languages, studying performance in two languages on NWR could inform one's understanding of the relationship between information processing and language learning. Aims: The primary aims of this study were to compare bilingual language learners' recall of Spanish-like and English-like items on NWR tasks and to assess the relationships between performance on NWR, semantics, and morphology tasks. Methods \& Procedures: Sixty-two Hispanic children exposed to English and Spanish were recruited from schools in central Texas, USA. Their parents reported on the children's input and output in both languages. The children completed NWR tasks and short tests of semantics and morphosyntax in both languages. Mixed-model analysis of variance was used to explore direct effects and interactions between the variables of nonword length, language experience, language outcome measures, and cumulative exposure on NWR performance. Outcomes \& Results: Children produced the Spanish-like nonwords more accurately than the English-like nonwords. NWR performance was significantly correlated to cumulative language experience in both English and Spanish. There were also significant correlations between NWR and morphosyntax but not semantics. Conclusions \& Implications: Language knowledge appears to play a role in the task of NWR. The relationship between performance on morphosyntax and NWR tasks indicates children rely on similar language-learning mechanisms to mediate these tasks. More exposure to Spanish may increase abilities to repeat longer nonwords. This knowledge may shift across levels of bilingualism. Further research is needed to understand this relationship, as it is likely to have implications for language teaching or intervention for children with language impairments.},
  file = {/Users/megcychosz/Zotero/storage/AHVMZB2C/Summers et al. - 2010 - Bilingual performance on nonword repetition in Spa.pdf},
  journal = {International Journal of Language \& Communication Disorders},
  language = {en},
  number = {4}
}

@article{sundaraDevelopmentCoronalStop2008,
  title = {Development of Coronal Stop Perception: {{Bilingual}} Infants Keep Pace with Their Monolingual Peers},
  shorttitle = {Development of Coronal Stop Perception},
  author = {Sundara, Megha and Polka, Linda and Molnar, Monika},
  year = {2008},
  month = jul,
  volume = {108},
  pages = {232--242},
  issn = {00100277},
  doi = {10.1016/j.cognition.2007.12.013},
  abstract = {Previous studies indicate that the discrimination of native phonetic contrasts in infants exposed to two languages from birth follows a different developmental time course from that observed in monolingual infants. We compared infant discrimination of dental (French) and alveolar (English) place variants of /d/ in three groups differing in language experience. At 6\textendash 8 months, infants in all three language groups succeeded; at 10\textendash 12 months, monolingual English and bilingual but not monolingual French infants distinguished this contrast. Thus, for highly frequent, similar phones, despite overlap in cross-linguistic distributions, bilingual infants performed on par with their English monolingual peers and better than their French monolingual peers.},
  file = {/Users/megcychosz/Zotero/storage/F9RHLB42/Sundara et al. - 2008 - Development of coronal stop perception Bilingual .pdf},
  journal = {Cognition},
  language = {en},
  number = {1}
}

@article{sundaraExposureSecondLanguage2020,
  title = {Exposure to a Second Language in Infancy Alters Speech Production},
  author = {Sundara, Megha and Ward, Nancy and Conboy, Barbara and Kuhl, Patricia K.},
  year = {2020},
  month = jan,
  pages = {1--14},
  issn = {1366-7289, 1469-1841},
  doi = {10.1017/S1366728919000853},
  abstract = {We evaluated the impact of exposure to a second language on infants' emerging speech production skills. We compared speech produced by three groups of 12-month-old infants while they interacted with interlocutors who spoke to them in Spanish and English: monolingual English-learning infants who had previously received 5 hours of exposure to a second language (Spanish), English- and Spanish-learning simultaneous bilinguals, and monolingual English-learning infants without any exposure to Spanish. Our results showed that the monolingual English-learning infants with short-term exposure to Spanish and the bilingual infants, but not the monolingual English-learning infants without exposure to Spanish, flexibly matched the prosody of their babbling to that of a Spanish- or English-speaking interlocutor. Our findings demonstrate the nature and extent of benefits for language learning from early exposure to two languages. We discuss the implications of these findings for language organization in infants learning two languages.},
  file = {/Users/megcychosz/Zotero/storage/446AGI6J/Sundara et al. - 2020 - Exposure to a second language in infancy alters sp.pdf},
  journal = {Bilingualism: Language and Cognition},
  language = {en}
}

@article{sundaraLanguageexperienceFacilitatesDiscrimination2006,
  title = {Language-Experience Facilitates Discrimination of /d-/ in Monolingual and Bilingual Acquisition of {{English}}},
  author = {Sundara, Megha and Polka, Linda and Genesee, Fred},
  year = {2006},
  month = jun,
  volume = {100},
  pages = {369--388},
  issn = {00100277},
  doi = {10.1016/j.cognition.2005.04.007},
  abstract = {To trace how age and language experience shape the discrimination of native and non-native phonetic contrasts, we compared 4-year-olds learning either English or French or both and simultaneous bilingual adults on their ability to discriminate the English /d- / contrast. Findings show that the ability to discriminate the native English contrast improved with age. However, in the absence of experience with this contrast, discrimination of French children and adults remained unchanged during development. Furthermore, although simultaneous bilingual and monolingual English adults were comparable, children exposed to both English and French were poorer at discriminating this contrast when compared to monolingual English-learning 4-year-olds. Thus, language experience facilitates perception of the English /d- / contrast and this facilitation occurs later in development when English and French are acquired simultaneously. The difference between bilingual and monolingual acquisition has implications for language organization in children with simultaneous exposure.},
  file = {/Users/megcychosz/Zotero/storage/CU2N5236/Sundara et al. - 2006 - Language-experience facilitates discrimination of .pdf},
  journal = {Cognition},
  language = {en},
  number = {2}
}

@article{sungDynamicsAgeSex2013a,
  title = {The {{Dynamics}} of {{Age}} and {{Sex}} in the {{Development}} of {{Mother}}-{{Infant Vocal Communication Between}} 3 and 11 {{Months}}},
  author = {Sung, Jihyun and {Fausto-Sterling}, Anne and Garcia Coll, Cynthia and Seifer, Ronald},
  year = {2013},
  month = nov,
  volume = {18},
  pages = {1135--1158},
  issn = {15250008},
  doi = {10.1111/infa.12019},
  file = {/Users/megcychosz/Zotero/storage/6YJWCKA6/Sung et al. - 2013 - The Dynamics of Age and Sex in the Development of .pdf},
  journal = {Infancy},
  language = {en},
  number = {6}
}

@article{superEnvironmentalEffectsMotor1976,
  title = {Environmental Effects on Motor Development: {{The}} Case of '{{African}} Infant Precocity'},
  author = {Super, C.M.},
  year = {1976},
  volume = {18},
  pages = {561--567},
  journal = {Developmental Medicine \& Child Neurology}
}

@article{suskindProjectASPIRESpoken2016,
  title = {Project {{ASPIRE}}: {{Spoken Language Intervention Curriculum}} for {{Parents}} of {{Low}}-Socioeconomic {{Status}} and {{Their Deaf}} and {{Hard}}-of-{{Hearing Children}}},
  shorttitle = {Project {{ASPIRE}}},
  author = {Suskind, Dana L. and Graf, Eileen and Leffel, Kristin R. and Hernandez, Marc W. and Suskind, Elizabeth and Webber, Robert and Tannenbaum, Sally and Nevins, Mary Ellen},
  year = {2016},
  month = feb,
  volume = {37},
  pages = {e110-e117},
  issn = {1531-7129},
  doi = {10.1097/MAO.0000000000000931},
  file = {/Users/megcychosz/Zotero/storage/6FJ4NP3Z/Suskind et al. - 2016 - Project ASPIRE Spoken Language Intervention Curri.pdf;/Users/megcychosz/Zotero/storage/R8AYG2U4/Suskind et al. notes.rtf},
  journal = {Otology \& Neurotology},
  language = {en},
  number = {2}
}

@article{sussmanConsonantVowelInterdependenciesBabbling1996,
  title = {Consonant-{{Vowel Interdependencies}} in {{Babbling}} and {{Early Words}}: {{Preliminary Examination}} of a {{Locus Equation Approach}}},
  shorttitle = {Consonant-{{Vowel Interdependencies}} in {{Babbling}} and {{Early Words}}},
  author = {Sussman, Harvey M. and Minifie, Fred D. and Buder, Eugene H. and {Stoel-Gammon}, Carol and Smith, Jason},
  year = {1996},
  month = apr,
  volume = {39},
  pages = {424--433},
  issn = {1092-4388},
  doi = {10.1044/jshr.3902.424},
  abstract = {Consonant-vowel productions at two distinct stages of language development were studied in a single female child. At 12 months canonical babbling syllables (N= 144) identified by a panel of listeners as comprising [bV], [dV], and [gv] tokens were acoustically analyzed by measuring F2 transition onset and F2 midvowel frequencies and plotting their relationship as locus equations for each stop category. Aregression analysis performed on these scatterplots revealed differential slopes and y-intercepts as afunction of stop place. The same analysis was performed 9 months later on CV utterances (N= 243) produced as syllable-initial segments of real words by the same child. Whereas labial and velar locus equation parameters moved toward more adult-like values, alveolar slope and y-intercept moved away from adult values and more inthe direction of decreased coarticulation between vowel and consonant. There was greater scatter of data points around the regression line for production of words compared to babbling. These results are compared to locus equations obtained from 3-5-year-olds and adults. Locus equations appear to be useful as an empirical developmental probe to document how CV productions gradually approach adult categorical standards.},
  file = {/Users/megcychosz/Zotero/storage/NU4Y3VK5/Sussman et al. - 1996 - Consonant-Vowel Interdependencies in Babbling and .pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en}
}

@article{svirskyDevelopmentLanguageSpeech2004,
  title = {Development of {{Language}} and {{Speech Perception}} in {{Congenitally}}, {{Profoundly Deaf Children}} as a {{Function}} of {{Age}} at {{Cochlear Implantation}}},
  author = {Svirsky, Mario A. and Teoh, Su-Wooi and Neuburger, Heidi},
  year = {2004},
  volume = {9},
  pages = {224--233},
  issn = {14219700, 14203030},
  doi = {10.1159/000078392},
  abstract = {Like any other surgery requiring anesthesia, cochlear implantation in the first few years of life carries potential risks, which makes it important to assess the potential benefits. This study introduces a new method to assess the effect of age at implantation on cochlear implant outcomes: developmental trajectory analysis (DTA). DTA compares curves representing change in an outcome measure over time (i.e. developmental trajectories) for two groups of children that differ along a potentially important independent variable (e.g. age at intervention). This method was used to compare language development and speech perception outcomes in children who received cochlear implants in the second, third or fourth year of life. Within this range of age at implantation, it was found that implantation before the age of 2 resulted in speech perception and language advantages that were significant both from a statistical and a practical point of view. Additionally, the present results are consistent with the existence of a `sensitive period' for language development, a gradual decline in language acquisition skills as a function of age.},
  file = {/Users/megcychosz/Zotero/storage/HQSZMWN3/Svirsky et al. - 2004 - Development of Language and Speech Perception in C.pdf},
  journal = {Audiology and Neuro-Otology},
  language = {en},
  number = {4}
}

@article{swingleyContributionsInfantWord2009,
  title = {Contributions of Infant Word Learning to Language Development},
  author = {Swingley, D.},
  year = {2009},
  month = dec,
  volume = {364},
  pages = {3617--3632},
  issn = {0962-8436, 1471-2970},
  doi = {10.1098/rstb.2009.0107},
  file = {/Users/megcychosz/Zotero/storage/X3IKV869/Swingley - 2009 - Contributions of infant word learning to language .pdf},
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  language = {en},
  number = {1536}
}

@article{swingleyLexicalCompetitionYoung2007,
  title = {Lexical Competition in Young Children's Word Learning},
  author = {Swingley, Daniel and Aslin, Richard N.},
  year = {2007},
  month = mar,
  volume = {54},
  pages = {99--132},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2006.05.001},
  abstract = {In two experiments, 1.5 year olds were taught novel words whose sound patterns were phonologically similar to familiar words (novel neighbors) or were not (novel nonneighbors). Learning was tested using a picture fixation task. In both experiments, children learned the novel nonneighbors but not the novel neighbors. In addition, exposure to the novel neighbors impaired recognition performance on familiar neighbors. Finally, children did not spontaneously use phonological differences to infer that a novel word referred to a novel object. Thus, lexical competition\textemdash inhibitory interaction among words in speech comprehension\textemdash can prevent children from using their full phonological sensitivity in judging words as novel. These results suggest that word learning in young children, as in adults, relies not only on the discrimination and identification of phonetic categories, but also on evaluating the likelihood that an utterance conveys a new word.},
  file = {/Users/megcychosz/Zotero/storage/DRC3NSGA/Swingley and Aslin - 2007 - Lexical competition in young children’s word learn.pdf},
  journal = {Cognitive Psychology},
  language = {en},
  number = {2}
}

@article{swingleyLexicalLearningMay2018,
  title = {Lexical {{Learning May Contribute}} to {{Phonetic Learning}} in {{Infants}}: {{A Corpus Analysis}} of {{Maternal Spanish}}},
  shorttitle = {Lexical {{Learning May Contribute}} to {{Phonetic Learning}} in {{Infants}}},
  author = {Swingley, Daniel and Alarcon, Claudia},
  year = {2018},
  month = jul,
  volume = {42},
  pages = {1618--1641},
  issn = {03640213},
  doi = {10.1111/cogs.12620},
  abstract = {In their first year, infants begin to learn the speech sounds of their language. This process is typically modeled as an unsupervised clustering problem in which phonetically similar speechsound tokens are grouped into phonetic categories by infants using their domain-general inference abilities. We argue here that maternal speech is too phonetically variable for this account to be plausible, and we provide phonetic evidence from Spanish showing that infant-directed Spanish vowels are more readily clustered over word types than over vowel tokens. The results suggest that infants' early adaptation to native-language phonetics depends on their word-form lexicon, implicating a much wider range of potential sources of influence on infants' developmental trajectories in language learning.},
  file = {/Users/megcychosz/Zotero/storage/DLMVI2GW/Swingley and Alarcon - 2018 - Lexical Learning May Contribute to Phonetic Learni.pdf;/Users/megcychosz/Zotero/storage/LAKHMYA9/cogs.12620.pdf},
  journal = {Cognitive Science},
  language = {en},
  number = {5}
}

@article{swingleyLexicalNeighborhoodsWordForm2002,
  title = {Lexical {{Neighborhoods}} and the {{Word}}-{{Form Representations}} of 14-{{Month}}-{{Olds}}},
  author = {Swingley, Daniel and Aslin, Richard N.},
  year = {2002},
  month = sep,
  volume = {13},
  pages = {480--484},
  issn = {0956-7976, 1467-9280},
  doi = {10.1111/1467-9280.00485},
  abstract = {The degree to which infants represent phonetic detail in words has been a source of controversy in phonology and developmental psychology. One prominent hypothesis holds that infants store words in a vague or inaccurate form until the learning of similar-sounding neighbors forces attention to subtle phonetic distinctions. In the experiment reported here, we used a visual fixation task to assess word recognition. We present the first evidence indicating that, in fact, the lexical representations of 14- and 15-month-olds are encoded in fine detail, even when this detail is not functionally necessary for distinguishing similar words in the infant's vocabulary. Exposure to words is sufficient for well-specified lexical representations, even well before the vocabulary spurt. These results suggest developmental continuity in infants' representations of speech: As infants begin to build a vocabulary and learn word meanings, they use the perceptual abilities previously demonstrated in tasks testing the discrimination and categorization of meaningless syllables.},
  file = {/Users/megcychosz/Zotero/storage/Z5WXTUAQ/Swingley and Aslin - 2002 - Lexical Neighborhoods and the Word-Form Representa.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {5}
}

@article{swingleyQuantitativeLinguisticPredictors2018,
  title = {Quantitative {{Linguistic Predictors}} of {{Infants}}' {{Learning}} of {{Specific English Words}}},
  author = {Swingley, Daniel and Humphrey, Colman},
  year = {2018},
  month = jul,
  volume = {89},
  pages = {1247--1267},
  issn = {00093920},
  doi = {10.1111/cdev.12731},
  file = {/Users/megcychosz/Zotero/storage/AIUJHBG9/Swingley and Humphrey - 2018 - Quantitative Linguistic Predictors of Infants’ Lea.pdf},
  journal = {Child Development},
  language = {en},
  number = {4}
}

@article{swingleyTwoyearoldsInterpretNovel2016,
  title = {Two-Year-Olds Interpret Novel Phonological Neighbors as Familiar Words.},
  author = {Swingley, Daniel},
  year = {2016},
  volume = {52},
  pages = {1011--1023},
  issn = {1939-0599, 0012-1649},
  doi = {10.1037/dev0000114},
  abstract = {When children hear a novel word in a context presenting a novel object and a familiar one, they usually assume that the novel word refers to the novel object. In a series of experiments, we tested whether this behavior would be found when 2-year-olds interpreted novel words that differed phonologically from familiar words in only 1 sound, either a vowel or consonant. Under these conditions children almost always chose the familiar object, though examination of eye movements showed that children did detect the tested phonological distinctions. Thus, children discounted perceptible phonological variations when doing so permitted a resolution of the speaker's meaning without postulating a new word. Children with larger vocabularies made novel-word interpretations more often than children with smaller vocabularies did. The results suggest that although young children do interpret speech in terms of a learned phonological system, this does not mean that children assume that phonological distinctions imply lexical distinctions.},
  file = {/Users/megcychosz/Zotero/storage/PSDBBDYL/Swingley - 2016 - Two-year-olds interpret novel phonological neighbo.pdf},
  journal = {Developmental Psychology},
  language = {en},
  number = {7}
}

@article{szagunAgeExperienceInfluence2012a,
  title = {Age or {{Experience}}? {{The Influence}} of {{Age}} at {{Implantation}} and {{Social}} and {{Linguistic Environment}} on {{Language Development}} in {{Children With Cochlear Implants}}},
  shorttitle = {Age or {{Experience}}?},
  author = {Szagun, Gisela and Stumper, Barbara},
  year = {2012},
  month = dec,
  volume = {55},
  pages = {1640--1654},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2012/11-0119)},
  abstract = {Purpose: The authors investigated the influence of social environmental variables and age at implantation on language development in children with cochlear implants. Method: Participants were 25 children with cochlear implants and their parents. Age at implantation ranged from 6 months to 42 months (Mage = 20.4 months, SD = 22.0 months). Linguistic progress was assessed at 12, 18, 24, and 30 months after implantation. At each data point, language measures were based on parental questionnaire and 45-min spontaneous speech samples. Children's language and parents' child-directed language were analyzed. Results: On all language measures, children displayed considerable vocabulary and grammatical growth over time. Although there was no overall effect of age at implantation, younger and older children had different growth patterns. Children implanted by age 24 months made the most marked progress earlier on, whereas children implanted thereafter did so later on. Higher levels of maternal education were associated with faster linguistic progress; age at implantation was not. Properties of maternal language input, mean length of utterance, and expansions were associated with children's linguistic progress independently of age at implantation. Conclusions: In children implanted within the sensitive period for language learning, children's home language environment contributes more crucially to their linguistic progress than does age at implantation.},
  file = {/Users/megcychosz/Zotero/storage/MPPGQRF5/Szagun and Stumper - 2012 - Age or Experience The Influence of Age at Implant.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {6}
}

@article{szewczykNonwordRepetitionDepends2018,
  title = {Nonword Repetition Depends on the Frequency of Sublexical Representations at Different Grain Sizes: {{Evidence}} from a Multi-Factorial Analysis},
  shorttitle = {Nonword Repetition Depends on the Frequency of Sublexical Representations at Different Grain Sizes},
  author = {Szewczyk, Jakub M. and Marecka, Marta and Chiat, Shula and Wodniecka, Zofia},
  year = {2018},
  month = oct,
  volume = {179},
  pages = {23--36},
  issn = {00100277},
  doi = {10.1016/j.cognition.2018.06.002},
  abstract = {The nonword repetition task (NWR) has been widely used in basic cognitive and clinical research, as well as in clinical assessment, and has been proposed as a clinical marker for Specific Language Impairment (SLI). Yet the mechanisms underlying performance on this task are not clear. This study offers insights into these mechanisms through a comprehensive examination of item-related variables identified in previous research as possibly contributing to NWR scores and through testing the predictive power of each in relation to the others. A unique feature of the study is that all factors are considered simultaneously. Fifty-seven typically developing children were tested with a NWR task containing 150 nonwords differing in length, phonotactic probability, lexical neighbourhood and phonological complexity. The results indicate that phonological processing of novel words draws on sublexical representations at all grain sizes and that these representations are phonological, unstructured and insensitive to morphemehood. We propose a novel index \textendash{} mean ngram frequency of all phonemes \textendash{} that best captures the extent to which a nonword draws on sublexical representations. The study demonstrates the primacy of sublexical representations in NWR performance with implications for the nature of the deficit in SLI.},
  file = {/Users/megcychosz/Zotero/storage/MD7696FE/Szewczyk et al. - 2018 - Nonword repetition depends on the frequency of sub.pdf},
  journal = {Cognition},
  language = {en}
}

@article{taftLexicalStorageRetrieval1975,
  title = {Lexical Storage and Retrieval of Prefixed Words},
  author = {Taft, Marcus and Forster, Kenneth I.},
  year = {1975},
  volume = {14},
  pages = {638--647},
  journal = {Journal of Verbal Learning and Verbal Behavior}
}

@article{taftLexicalStorageRetrieval1976,
  title = {Lexical Storage and Retrieval of Polymorphemic and Polysyllabic Words},
  author = {Taft, Marcus and Forster, Kenneth I.},
  year = {1976},
  volume = {15},
  pages = {607--620},
  file = {/Users/megcychosz/Zotero/storage/F4FHUU7C/Lexical_Storage_and_Retrieval_.pdf},
  journal = {Journal of Verbal Learning and Verbal Behavior},
  number = {6}
}

@article{takagiLimitsExtendedNaturalistic1995,
  title = {The Limits of Extended Naturalistic Exposure on the Perceptual Mastery of {{English}} /r/ and /l/ by Adult {{Japanese}} Learners of {{English}}},
  author = {Takagi, Naoyuki and Mann, Virginia},
  year = {1995},
  volume = {16},
  pages = {380--406},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716400066005},
  abstract = {To evaluate the effect of extended adult exposure to authentic spoken English on the perceptual mastery of English /r/ and /l/, we tested 12 native speakers of English (A), 12 experienced Japanese (EJ) who had spent 12 or more years in the United States, and 12 less experienced Japanese (LJ) who had spent less than one year in the United States. The tests included the forced-choice identification of naturally produced /r/s and /1/s and the labeling of wordinitial synthetic tokens that varied F2 and F3 to form an /r/-/l/-/w/ continuum. The EJs' mean performance in both tasks was closer to that of the As than the LJs, but nonetheless fell short. Extended exposure may improve /r/-/l/ identification accuracy; it does not ensure perfect perceptual mastery.},
  file = {/Users/megcychosz/Zotero/storage/4BDKA57T/Takagi and Mann - 1995 - The limits of extended naturalistic exposure on th.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {4}
}

@incollection{tamis-lemondaParentInfantCommunicative2012,
  title = {Parent\textendash{{Infant Communicative Interactions}} in {{Cultural Context}}},
  booktitle = {Handbook of Psychology: {{Developmental}} Psychology},
  author = {{Tamis-LeMonda}, C. S. and Song, L.},
  year = {2012},
  edition = {Second},
  volume = {6},
  pages = {143--170},
  publisher = {{Wiley}},
  address = {{New York, NY}}
}

@article{tangAcquisitionMandarinTonal2019a,
  title = {The {{Acquisition}} of {{Mandarin Tonal Processes}} by {{Children With Cochlear Implants}}},
  author = {Tang, Ping and Yuen, Ivan and Xu Rattanasone, Nan and Gao, Liqun and Demuth, Katherine},
  year = {2019},
  month = may,
  volume = {62},
  pages = {1309--1325},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2018_JSLHR-S-18-0304},
  abstract = {Purpose               Children with cochlear implants (CIs) face challenges in acquiring tonal languages, as CIs do not efficiently code pitch information. Mandarin is a tonal language with lexical tones and tonal processes such as neutral tone and tone sandhi, exhibiting contextually conditioned tonal realizations. Previous studies suggest that early implantation and long CI experience facilitate the acquisition of lexical tones by children with CIs. However, there is lack of acoustic evidence on children's tonal productions demonstrating that this is the case, and it is unclear whether and how children with CIs are able to acquire contextual tones. This study therefore examined the acoustic realization of both lexical tones and contextual tones as produced by children fitted with CIs, exploring the potential effects of age at implantation and length of CI experience on their acquisition of the Mandarin tonal system.                                         Method               Seventy-two Mandarin-learning preschoolers with CIs, varying in age at implantation (13\textendash 42 months) and length of CI experience (2\textendash 49 months), and 44 normal hearing 3-year-old controls were recruited. Tonal productions were elicited from both groups using picture-naming tasks and acoustically compared.                                         Results               Only the early implanted group (i.e., implanted before the age of 2 years) produced normal-like lexical tones and generally had contextual tones approximating those of the normal-hearing children. The other children, including those with longer CI experience, did not have typical tonal productions; their pitch patterns for lexical tones tended to be flatter, and contextual tone productions were unchanged across tonal contexts.                                         Conclusion               Children with CIs face challenges in acquiring Mandarin tones, but early implantation may help them to develop normal-like lexical tone categories, which further facilitates their implementation of contextual tones.                                         Supplemental Material                                https://doi.org/10.23641/asha.8038889},
  file = {/Users/megcychosz/Zotero/storage/L5CX4RSR/Tang et al. - 2019 - The Acquisition of Mandarin Tonal Processes by Chi.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {5}
}

@article{teaglePediatricCochlearImplantation2019,
  title = {Pediatric Cochlear Implantation: {{A}} Quarter Century in Review},
  shorttitle = {Pediatric Cochlear Implantation},
  author = {Teagle, Holly F.B. and Park, Lisa R. and Brown, Kevin D. and Zdanski, Carlton and Pillsbury, Harold C.},
  year = {2019},
  month = nov,
  volume = {20},
  pages = {288--298},
  issn = {1467-0100, 1754-7628},
  doi = {10.1080/14670100.2019.1655868},
  abstract = {Objective: To review the growth of a pediatric cochlear implant (CI) program at one large tertiary care medical center over a 25-year period in order to (1) describe the population of pediatric cochlear implant recipients, (2) document word recognition outcomes, and (3) describe changes in candidacy criteria over time. Design: A retrospective review of population demographics and trends included etiology of hearing loss, device use and type, expansion of inclusion criteria, and word recognition outcomes. Results: Ninety-one percent of the children studied were from North Carolina and reflect the ethnic distribution of the state. The population is heterogeneous for etiology and the presence of syndromes and/or comorbidities. A trend of lower age of implant and greater residual hearing was documented overtime. As a single metric, monosyllable word recognition for the children assessed is good with the mean CNC test word score of 76.13\% (range 0\textendash 100, S.D = 19.94). Conclusions: Pediatric cochlear implant candidacy criteria have evolved despite no change in FDAapproved regulations since 2000. There is great diversity among recipients but word recognition outcomes are generally good in this population and have improved over time. Professionals who may refer children for cochlear implantation should be aware of current clinical practices and general outcomes.},
  file = {/Users/megcychosz/Zotero/storage/7SDVVLA7/Teagle et al. - 2019 - Pediatric cochlear implantation A quarter century.pdf},
  journal = {Cochlear Implants International},
  language = {en},
  number = {6}
}

@article{terbandAuditoryFeedbackPerturbation2014,
  title = {Auditory Feedback Perturbation in Children with Developmental Speech Sound Disorders},
  author = {Terband, Hayo and {van Brenk}, Frits and {van Doornik-van der Zee}, Anniek},
  year = {2014},
  month = sep,
  volume = {51},
  pages = {64--77},
  issn = {00219924},
  doi = {10.1016/j.jcomdis.2014.06.009},
  abstract = {Background/purpose: Several studies indicate a close relation between auditory and speech motor functions in children with speech sound disorders (SSD). The aim of this study was to investigate the ability to compensate and adapt for perturbed auditory feedback in children with SSD compared to age-matched normally developing children. Method: 17 normally developing children aged 4.1\textendash 8.7 years (mean = 5.5, SD = 1.4), and 11 children with SSD aged 3.9\textendash 7.5 years (mean = 5.1, SD = 1.0) participated in the study. Auditory feedback was perturbed by real-time shifting the first and second formant of the vowel /e/ during the production of CVC words in a five-step paradigm (practice/ familiarization; start/baseline; ramp; hold; end/release). Results: At the group level, the normally developing children were better able to compensate and adapt, adjusting their formant frequencies in the direction opposite to the perturbation, while the group of children with SSD followed (amplifying) the perturbation. However, large individual differences lie underneath. Furthermore, strong correlations were found between the amount of compensation and performance on oral motor movement non-word repetition tasks. Conclusions: Results suggested that while most children with SSD can detect incongruencies in auditory feedback and can adapt their target representations, they are unable to compensate for perturbed auditory feedback. These findings suggest that impaired auditory\textendash motor integration may play a key role in SSD.},
  file = {/Users/megcychosz/Zotero/storage/SRZTQ4PR/Terband et al. - 2014 - Auditory feedback perturbation in children with de.pdf},
  journal = {Journal of Communication Disorders},
  language = {en}
}

@article{terbandSpeechMotorDevelopment2010,
  title = {Speech Motor Development in Chldhood Apraxia of Speech: {{Generating}} Testable Hypotheses by Neurocomputational Modeling},
  author = {Terband, H. and Maassen, B.},
  year = {2010},
  volume = {62},
  pages = {134--142},
  journal = {Folia Phoniatrica et Logopaedica},
  number = {3}
}

@article{tesarLearnabilityOptimalityTheory,
  title = {Learnability in {{Optimality Theory}}},
  author = {Tesar, Bruce and Smolensky, Paul},
  pages = {40},
  abstract = {In this article we show how Optimality Theory yields a highly general Constraint Demotion principle for grammar learning. The resulting learning procedure specifically exploits the grammatical structure of Optimality Theory, independent of the content of substantive constraints defining any given grammatical module. We decompose the learning problem and present formal results for a central subproblem, deducing the constraint ranking particular to a target language, given structural descriptions of positive examples. The structure imposed on the space of possible grammars by Optimality Theory allows efficient convergence to a correct grammar. We discuss implications for learning from overt data only, as well as other learning issues. We argue that Optimality Theory promotes confluence of the demands of more effective learnability and deeper linguistic explanation.},
  file = {/Users/megcychosz/Zotero/storage/Z59YY2LR/Tesar and Smolensky - Learnability in Optimality Theory.pdf},
  language = {en}
}

@book{thelenDynamicSystemsApproach1996,
  title = {A Dynamic Systems Approach to the Development of Cognition and Action},
  author = {Thelen, Esther and Smith, Linda B.},
  year = {1996},
  publisher = {{Massachusetts Institute of Technology}},
  address = {{Cambridge, MA}}
}

@article{themanybabiesconsortiumQuantifyingSourcesVariability2020,
  title = {Quantifying Sources of Variability in Infancy Research Using the Infant-Directed Speech Preference.},
  author = {The Many Babies Consortium},
  year = {2020},
  volume = {3},
  pages = {24--52},
  journal = {Advances in Methods and Practices in Psychological Science},
  number = {1}
}

@article{theodoreExaminationLocusPositional2015,
  title = {Examination of the {{Locus}} of {{Positional Effects}} on {{Children}}'s {{Production}} of {{Plural}} \textendash s: {{Considerations From Local}} and {{Global Speech Planning}}},
  shorttitle = {Examination of the {{Locus}} of {{Positional Effects}} on {{Children}}'s {{Production}} of {{Plural}} \textendash s},
  author = {Theodore, Rachel M. and Demuth, Katherine and {Shattuck-Hufnagel}, Stefanie},
  year = {2015},
  month = jun,
  volume = {58},
  pages = {946--953},
  issn = {1092-4388},
  doi = {10.1044/2015_JSLHR-L-14-0208},
  abstract = {Purpose Prosodic and articulatory factors influence children's production of inflectional morphemes. For example, plural \textendash s is produced more reliably in utterance-final compared to utterance-medial position (i.e., the positional effect), which has been attributed to the increased planning time in utterance-final position. In previous investigations of plural \textendash s, utterance-medial plurals were followed by a stop consonant (e.g., dogs bark), inducing high articulatory complexity. We examined whether the positional effect would be observed if the utterance-medial context were simplified to a following vowel. Method An elicited imitation task was used to collect productions of plural nouns from 2-year-old children. Nouns were elicited utterance-medially and utterance-finally, with the medial plural followed by either a stressed or an unstressed vowel. Acoustic analysis was used to identify evidence of morpheme production. Results The positional effect was absent when the morpheme was followed by a vowel (e.g., dogs eat). However, it returned when the vowel-initial word contained 2 syllables (e.g., dogs arrive), suggesting that the increased processing load in the latter condition negated the facilitative effect of the easy articulatory context. Conclusions Children's productions of grammatical morphemes reflect a rich interaction between emerging levels of linguistic competence, raising considerations for diagnosis and rehabilitation of language disorders.},
  file = {/Users/megcychosz/Zotero/storage/6FBEZ4PE/Theodore et al. - 2015 - Examination of the Locus of Positional Effects on .pdf},
  journal = {Journal of Speech, Language, and Hearing Research : JSLHR},
  number = {3},
  pmcid = {PMC4610282},
  pmid = {25682582}
}

@article{thibautDevelopingMotorPlanning2010,
  title = {Developing Motor Planning over Ages},
  author = {Thibaut, Jean-Pierre and Toussaint, Lucette},
  year = {2010},
  pages = {15},
  abstract = {Few studies have explored the development of response selection processes in children in the case of object manipulation. In the current research, we studied the end-state comfort effect, the tendency to ensure a comfortable position at the end rather than at the beginning of simple object manipulation tasks. We used two versions of the unimanual bar transport task. In Experiment 1, only 10-year-olds reached the same level of sensitivity to end-state comfort as adults, and 8-year-olds were less efficient than 6year-olds. In each age group, children's sensitivity did not increase during a session: i.e., either clearly showed the sensitivity or showed no sensitivity at all. Experiment 2 replicated these results when the bar was replaced by a pencil and when the task did not require much precision. However, when the task required more precision, 8-year-olds increased their level of sensitivity to the end-state comfort effect, whereas this was not the case for younger children. These results describe the development of advanced planning processes from 4 to 10 years of age as well as the positive effect of task constraints on the end-state comfort effect for 8year-olds.},
  file = {/Users/megcychosz/Zotero/storage/53D3Q947/Thibaut and Toussaint - 2010 - Developing motor planning over ages.pdf},
  journal = {Journal of Experimental Child Psychology},
  language = {en}
}

@article{thiessenInfantDirectedSpeechFacilitates2005,
  title = {Infant-{{Directed Speech Facilitates Word Segmentation}}},
  author = {Thiessen, Erik D and Hill, Emily A and Saffran, Jenny R},
  year = {2005},
  volume = {7},
  pages = {53--71},
  file = {/Users/megcychosz/Zotero/storage/C68JHJCM/Thiessen et al. - Infant-Directed Speech Facilitates Word Segmentati.pdf},
  journal = {Infancy},
  language = {en},
  number = {1}
}

@article{thordardottirRelationshipBilingualExposure2011,
  title = {The Relationship between Bilingual Exposure and Vocabulary Development},
  author = {Thordardottir, Elin},
  year = {2011},
  month = dec,
  volume = {15},
  pages = {426--445},
  issn = {1367-0069, 1756-6878},
  doi = {10.1177/1367006911403202},
  abstract = {The relationship between amount of bilingual exposure and performance in receptive and expressive vocabulary in French and English was examined in 5-year-old Montreal children acquiring French and English simultaneously as well as in monolingual children. The children were equated on age, socio-economic status, nonverbal cognition, and on minority/majority language status (both languages have equal status), but differed in the amount of exposure they had received to each language spanning the continuum of bilingual exposure levels. A strong relationship was found between amount of exposure to a language and performance in that language. This relationship was different for receptive and expressive vocabulary. Children having been exposed to both languages equally scored comparably to monolingual children in receptive vocabulary, but greater exposure was required to match monolingual standards in expressive vocabulary. Contrary to many previous studies, the bilingual children were not found to exhibit a significant gap relative to monolingual children in receptive vocabulary. This was attributed to the favorable languagelearning environment for French and English in Montreal and might also be related to the fact the two languages are fairly closely related. Children with early and late onset (before 6 months and after 20 months) of bilingual exposure who were equated on overall amount of exposure to each language did not differ significantly on any vocabulary measure.},
  file = {/Users/megcychosz/Zotero/storage/C9XBVQJA/Thordardottir - 2011 - The relationship between bilingual exposure and vo.pdf},
  journal = {International Journal of Bilingualism},
  language = {en},
  number = {4}
}

@article{tilsenSelectionCoordinationArticulatory2016,
  title = {Selection and Coordination: {{The}} Articulatory Basis for the Emergence of Phonological Structure},
  shorttitle = {Selection and Coordination},
  author = {Tilsen, Sam},
  year = {2016},
  month = mar,
  volume = {55},
  pages = {53--77},
  issn = {00954470},
  doi = {10.1016/j.wocn.2015.11.005},
  abstract = {Phonological theories commonly analyze speech utterances as composed of hierarchically organized units, such as features/gestures, segments, moras, and syllables, but it is not well understood why this hierarchical organization is observed. Moreover, current phonological theories and speech production models fail to explain cross-linguistic and developmental variation in the organization of units. This paper presents the selectioncoordination theory of speech production, which attempts to unify our understanding of developmental and crosslinguistic variation in phonological structure. The theory holds that hierarchical organization emerges from a recurring trend in speech development whereby children acquire coordinative regimes of control over articulatory gestures that were previously competitively selected. In this framework, segments, moras, and syllables are understood as differently-sized instantiations of the same type of motor planning unit, and cross-linguistic and developmental phonological patterns are derived from distinguishing competitive and coordinative regimes of articulatory control. Evidence for the theory is drawn from research in motor control, speech development, and phonological and phonetic patterns in speech.},
  file = {/Users/megcychosz/Zotero/storage/24YIWB6Q/Tilsen 2016 notes.docx;/Users/megcychosz/Zotero/storage/GNJXY79V/Tilsen - 2016 - Selection and coordination The articulatory basis.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{tingleyDevelopmentSpeechTiming1975,
  title = {Development of Speech Timing Control in Children},
  author = {Tingley, B.M. and Allen, G.D.},
  year = {1975},
  volume = {46},
  pages = {186--194},
  journal = {Child Development},
  number = {1}
}

@article{titzeConsensusSymbolicNotation2015,
  title = {Toward a Consensus on Symbolic Notation of Harmonics, Resonances, and Formants in Vocalization},
  author = {Titze, Ingo R. and Baken, Ronald J. and Bozeman, Kenneth W. and Granqvist, Svante and Henrich, Nathalie and Herbst, Christian T. and Howard, David M. and Hunter, Eric J. and Kaelin, Dean and Kent, Raymond D. and Kreiman, Jody and Kob, Malte and L{\"o}fqvist, Anders and McCoy, Scott and Miller, Donald G. and No{\'e}, Hubert and Scherer, Ronald C. and Smith, John R. and Story, Brad H. and {\v S}vec, Jan G. and Ternstr{\"o}m, Sten and Wolfe, Joe},
  year = {2015},
  month = may,
  volume = {137},
  pages = {3005--3007},
  issn = {0001-4966},
  doi = {10.1121/1.4919349},
  file = {/Users/megcychosz/Zotero/storage/6NFW6VIS/Titze et al. - 2015 - Toward a consensus on symbolic notation of harmoni.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{tobeyFactorsAssociatedDevelopment2003,
  title = {Factors {{Associated}} with {{Development}} of {{Speech Production Skills}} in {{Children Implanted}} by {{Age Five}}:},
  shorttitle = {Factors {{Associated}} with {{Development}} of {{Speech Production Skills}} in {{Children Implanted}} by {{Age Five}}},
  author = {Tobey, Emily A. and Geers, Ann E. and Brenner, Chris and Altuna, Dianne and Gabbert, Gretchen},
  year = {2003},
  month = feb,
  volume = {24},
  pages = {36S-45S},
  issn = {0196-0202},
  doi = {10.1097/01.AUD.0000051688.48224.A6},
  abstract = {Objective: This study investigated speech production outcomes and the factors influencing the outcomes in children who had 4 to 6 yr of experience with a multichannel cochlear implant. Production variables examined included speech intelligibility, accuracy of consonant and vowel production, percentage of plosives and fricatives produced, duration of sentences, percentage of time involved in communication breakdowns during a communication sample, and responses to a speech usage questionnaire. Design: 181 children between the ages of 8 and 9 yr who received a multichannel cochlear implant before age 5 yr participated as subjects. Independent variables were the amount and type of educational intervention and intervening variables were distributed across child, family and implant characteristics. Multiple regression analyses provided a measure of the amount of variance associated with speech production skills accounted for by the intervening and independent variables. Results: Performance for the key words in the speech intelligibility measured averaged 63.5\% for the group of children. Accuracy of phoneme production was higher for consonants (68.0\%) than for vowels (61.6\%) for the group. More plosives were present for acoustic analyses (91.6\%) than were fricatives (78.4\%). Duration for the speech intelligibility sentences averaged 2572.3 msec. Communication breakdowns occurred on average 14.5\% of the time involved in a language sample. Significant predictors of high levels of oral communication skills included higher nonverbal intelligence, gender, longer use of SPEAK processing strategy, a fully active electrode array, greater dynamic range, and greater growth of loudness. The primary rehabilitative factors contributing to high levels of oral communication were an emphasis on oral-aural communication and classrooms that emphasized dependence on speech and listening. Conclusions: Speech production performance in children with cochlear implants is influenced by nonverbal intelligence, gender, implant characteristics including the length of time using the newest},
  file = {/Users/megcychosz/Zotero/storage/V6JGEGM5/Tobey et al. - 2003 - Factors Associated with Development of Speech Prod.pdf},
  journal = {Ear and Hearing},
  language = {en},
  number = {Supplement}
}

@article{toddProductionContrastSibilant2011,
  title = {Production of Contrast between Sibilant Fricatives by Children with Cochlear Implants},
  author = {Todd, Ann E. and Edwards, Jan R. and Litovsky, Ruth Y.},
  year = {2011},
  month = dec,
  volume = {130},
  pages = {3969--3979},
  issn = {0001-4966},
  doi = {10.1121/1.3652852},
  file = {/Users/megcychosz/Zotero/storage/8I5YVHBV/Todd et al. - 2011 - Production of contrast between sibilant fricatives.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {6}
}

@techreport{tomaschekHowAnticipatoryCoarticulation2019,
  title = {How Is Anticipatory Coarticulation of Suffixes Affected by Lexical Proficiency?},
  author = {Tomaschek, Fabian and Tucker, Benjamin V. and Ramscar, Michael and Baayen, R. H.},
  year = {2019},
  month = jul,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/gv89j},
  abstract = {More and more studies find differences in fine phonetic detail related to the morphological function of words and segments. In the present study, we investigated to what extent these differences arise due to anticipatory coarticulation of inflectional exponents and the amount of long-term practice with individual verbs such as American English ''clean'', ''cleaned'', ''cleans'', ''cleaning''. Kinematic studies of hand movements show that with greater practice, i.e. regular repetition of a sequence of gestures, upcoming gestures are stronger and smoother anticipated. Consequently, we hypothesized to find stronger anticipatory coarticulation of inflectional exponents during the articulation of the stem vowel in verbs for which speakers acquired a greater lexical proficiency, as their articulatory gestures were better practiced. We observed both, stronger anticipatory coarticulation towards the offset of the gesture and less coarticulation concomittant with more hyperarticulation towards the onset of the gesture. We link these results to findings that morphological function is reflected in fine phonetic detail, challenging traditional models of speech production, which assume a separation of lexical information and the phonetic detail.},
  file = {/Users/megcychosz/Zotero/storage/BY59CUAS/Tomaschek et al. - 2019 - How is anticipatory coarticulation of suffixes aff.pdf},
  language = {en},
  type = {Preprint}
}

@article{tomaschekPracticeMakesPerfect2018,
  title = {Practice Makes Perfect: The Consequences of Lexical Proficiency for Articulation},
  shorttitle = {Practice Makes Perfect},
  author = {Tomaschek, Fabian and Tucker, Benjamin V. and Fasiolo, Matteo and Baayen, R. Harald},
  year = {2018},
  month = sep,
  volume = {4},
  issn = {2199-174X},
  doi = {10.1515/lingvan-2017-0018},
  file = {/Users/megcychosz/Zotero/storage/SQPPW4GJ/Tomaschek et al. - 2018 - Practice makes perfect the consequences of lexica.pdf},
  journal = {Linguistics Vanguard},
  language = {en},
  number = {s2}
}

@article{tomaschekStrategiesAddressingCollinearity2018,
  title = {Strategies for Addressing Collinearity in Multivariate Linguistic Data},
  author = {Tomaschek, Fabian and Hendrix, Peter and Baayen, R. Harald},
  year = {2018},
  month = nov,
  volume = {71},
  pages = {249--267},
  issn = {00954470},
  doi = {10.1016/j.wocn.2018.09.004},
  abstract = {When multiple correlated predictors are considered jointly in regression modeling, estimated coefficients may assume counterintuitive and theoretically uninterpretable values. We survey several statistical methods that implement strategies for the analysis of collinear data: regression with regularization (the elastic net), supervised component generalized linear regression, and random forests. Methods are illustrated for a data set with a wide range of predictors for segment duration in a German speech corpus. Results broadly converge, but each method has its own strengths and weaknesses. Jointly, they provide the analyst with somewhat different but complementary perspectives on the structure of collinear data.},
  file = {/Users/megcychosz/Zotero/storage/43MZTF2A/Tomaschek et al. - 2018 - Strategies for addressing collinearity in multivar.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@book{tomaselloConstructingLanguageUsagebased2003,
  title = {Constructing a Language: {{A}} Usage-Based Approach to Child Language Acquisition},
  author = {Tomasello, Michael},
  year = {2003},
  publisher = {{Harvard University Press}},
  address = {{Cambridge, MA}}
}

@article{topbasPhonologicalAcquisitionTurkish1997,
  title = {Phonological Acquisition of {{Turkish}} Children: Implications for Phonological Disorders},
  shorttitle = {Phonological Acquisition of {{Turkish}} Children},
  author = {Topbas, Seyhun},
  year = {1997},
  month = jan,
  volume = {32},
  pages = {377--396},
  issn = {1368-2822, 1460-6984},
  doi = {10.3109/13682829709082255},
  abstract = {S The study reported describes the phonological rules typical of normal development of Turkish-speaking children. The processes identifed include: reduplication, syllable deletion, consonant deletion, assimilation, cluster reduction, liquid deviation, stopping, fronting. affrication, and backing. From a crosslinguistic perspective, the phonological process patterns exhibited coincide broadly with universal tendencies, although some language specific patterns were also evident. In contrast, a case study of a phonologically disordered child indicated that her system was characterised by the use of idiosyncratic phonological rules as well as delayed acquisition of some aspects of the system. This atypical pattern reflects reports of phonologically disordered children learning other languages. Thefindings indicate that the deficit underlying this type of phonological disorder leads to similar phonological behaviour irrespective of the language being acquired.},
  file = {/Users/megcychosz/Zotero/storage/FLQ394NH/Topbas - 1997 - Phonological acquisition of Turkish children impl.pdf},
  journal = {International Journal of Language \& Communication Disorders},
  language = {en},
  number = {4}
}

@incollection{toreroDialectosQuechuas1964,
  title = {Los Dialectos {{Quechuas}}},
  booktitle = {Anales {{Cient\'ificos}} de La {{Universidad Agraria}}},
  author = {Torero, O},
  year = {1964},
  volume = {2},
  pages = {446--478},
  address = {{Lima, Peru}}
}

@article{torringtoneatonNonwordRepetition2yearolds2015,
  title = {Non-Word Repetition in 2-Year-Olds: {{Replication}} of an Adapted Paradigm and a Useful Methodological Extension},
  shorttitle = {Non-Word Repetition in 2-Year-Olds},
  author = {Torrington Eaton, Catherine and Newman, Rochelle S. and Ratner, Nan Bernstein and Rowe, Meredith L.},
  year = {2015},
  month = jul,
  volume = {29},
  pages = {523--535},
  issn = {0269-9206, 1464-5076},
  doi = {10.3109/02699206.2015.1029594},
  abstract = {Accurate non-word repetition (NWR) has been largely attributed to phonological memory, although the task involves other processes including speech production, which may confound results in toddlers with developing speech production abilities. This study is based on Hoff, Core and Bridges' adapted NWR task, which includes a real-word repetition (RWR) condition. We tested 86 typically developing 2-year-olds and found relationships between NWR and both receptive and expressive vocabulary using a novel measure that controls for speech production by comparing contextually matched targets in RWR. Post hoc analyses demonstrated the influence of lexical and sublexical factors in repetition tasks. Overall, results illustrate the importance of controlling for speech production differences in young children and support a useful methodological approach for testing NWR.},
  file = {/Users/megcychosz/Zotero/storage/RCDHGB9L/Torrington Eaton et al. - 2015 - Non-word repetition in 2-year-olds Replication of.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {7}
}

@article{toscanoCueIntegrationCategories2010,
  title = {Cue {{Integration With Categories}}: {{Weighting Acoustic Cues}} in {{Speech Using Unsupervised Learning}} and {{Distributional Statistics}}},
  shorttitle = {Cue {{Integration With Categories}}},
  author = {Toscano, Joseph C. and McMurray, Bob},
  year = {2010},
  volume = {34},
  pages = {434--464},
  issn = {1551-6709},
  doi = {10.1111/j.1551-6709.2009.01077.x},
  abstract = {During speech perception, listeners make judgments about the phonological category of sounds by taking advantage of multiple acoustic cues for each phonological contrast. Perceptual experiments have shown that listeners weight these cues differently. How do listeners weight and combine acoustic cues to arrive at an overall estimate of the category for a speech sound? Here, we present several simulations using a mixture of Gaussians models that learn cue weights and combine cues on the basis of their distributional statistics. We show that a cue-weighting metric in which cues receive weight as a function of their reliability at distinguishing phonological categories provides a good fit to the perceptual data obtained from human listeners, but only when these weights emerge through the dynamics of learning. These results suggest that cue weights can be readily extracted from the speech signal through unsupervised learning processes.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1551-6709.2009.01077.x},
  file = {/Users/megcychosz/Zotero/storage/2NJBAPU2/Toscano and McMurray - 2010 - Cue Integration With Categories Weighting Acousti.pdf;/Users/megcychosz/Zotero/storage/XZJVR6AK/j.1551-6709.2009.01077.html},
  journal = {Cognitive Science},
  keywords = {Categorization,Cue weighting,Mixture of Gaussians,Reliability,Speech development,Speech perception,Statistical learning,Unsupervised learning},
  language = {en},
  number = {3}
}

@article{toscanoCueintegrationContextEffects2012,
  title = {Cue-Integration and Context Effects in Speech: {{Evidence}} against Speaking-Rate Normalization},
  shorttitle = {Cue-Integration and Context Effects in Speech},
  author = {Toscano, Joseph C. and McMurray, Bob},
  year = {2012},
  month = aug,
  volume = {74},
  pages = {1284--1301},
  issn = {1943-3921, 1943-393X},
  doi = {10.3758/s13414-012-0306-z},
  abstract = {Listeners are able to accurately recognize speech despite variation in acoustic cues across contexts, such as different speaking rates. Previous work has suggested that listeners use rate information (indicated by vowel length; VL) to modify their use of context-dependent acoustic cues, like voice-onset time (VOT), a primary cue to voicing. We present several experiments and simulations that offer an alternative explanation: that listeners treat VL as a phonetic cue rather than as an indicator of speaking rate, and that they rely on general cue-integration principles to combine information from VOT and VL. We demonstrate that listeners use the two cues independently, that VL is used in both naturally produced and synthetic speech, and that the effects of stimulus naturalness can be explained by a cue-integration model. Together, these results suggest that listeners do not interpret VOT relative to rate information provided by VL and that the effects of speaking rate can be explained by more general cue-integration principles.},
  file = {/Users/megcychosz/Zotero/storage/WQ8LNL7Z/Toscano and McMurray - 2012 - Cue-integration and context effects in speech Evi.pdf},
  journal = {Attention, Perception, \& Psychophysics},
  language = {en},
  number = {6}
}

@article{treatImpactPositiveParenting2019,
  title = {The Impact of Positive Parenting Behaviors and Maternal Depression on the Features of Young Children's Home Language Environments},
  author = {Treat, Amy E. and Sheffield Morris, Amanda and {Hays-Grudo}, Jennifer and Williamson, Amy C.},
  year = {2019},
  month = nov,
  pages = {1--19},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S030500091900062X},
  abstract = {This study investigated the associations between maternal depression when infants were 3 to 11 months old (M = 6 months), and positive parenting behaviors when children were between 12 and 22 months (M = 17 months) and the home language environment assessed when children were 18 to 28 months old (M = 23.5 months) in a sample of 29 low-income mother\textendash child dyads. After controlling for maternal education, only teaching behaviors remained a moderate and significant predictor of adult word counts. Observed teaching behaviors significantly predicted conversational turns and marginally predicted child vocalizations; effects sizes were small. Encouraging behaviors were a small and significant predictor of conversational turns and a marginally significant predictor of adult word counts. Maternal depression was a moderate and significant predictor of children's vocal productivity scores and a small, marginal predictor of conversational turns. These findings have important implications for parenting and children's language outcomes.},
  file = {/Users/megcychosz/Zotero/storage/RYYSNEWY/Treat et al. - 2019 - The impact of positive parenting behaviors and mat.pdf},
  journal = {Journal of Child Language},
  language = {en}
}

@article{tremblaySomatosensoryBasisSpeech2003,
  title = {Somatosensory Basis of Speech Production},
  author = {Tremblay, St{\'e}phanie and Shiller, Douglas M. and Ostry, David J.},
  year = {2003},
  month = jun,
  volume = {423},
  pages = {866--869},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature01710},
  file = {/Users/megcychosz/Zotero/storage/QIBBLX8C/Tremblay et al. - 2003 - Somatosensory basis of speech production.pdf},
  journal = {Nature},
  language = {en},
  number = {6942}
}

@incollection{trilsbeekArchivingChallenges2006,
  title = {Archiving Challenges},
  booktitle = {Essentials of {{Language Documentation}}},
  author = {Trilsbeek, Paul and Wittenburg, Peter},
  year = {2006},
  pages = {311--335},
  publisher = {{Mouton de Gruyter}},
  address = {{Berlin and New York}},
  file = {/Users/megcychosz/Zotero/storage/ER7ED6IB/Trilsbeek and Wittenburg - 2006 - Archiving challenges.pdf},
  series = {Trends in {{Linguistics}}: {{Studies}} and {{Monographs}} 178}
}

@article{trudgillLinguisticSocialTypology2004,
  title = {Linguistic and Social Typology: {{The Austronesian}} Migrations and Phoneme Inventories},
  shorttitle = {Linguistic and Social Typology},
  author = {Trudgill, Peter},
  year = {2004},
  month = jan,
  volume = {8},
  issn = {1430-0532, 1613-415X},
  doi = {10.1515/lity.2004.8.3.305},
  abstract = {There is a challenging issue for linguistic typology which involves the relationships which might exist between societal type and aspects of linguistic structure. Linguistic-typological studies have provided us with insights into the range of structures available in human languages, but we do not yet have explanations for why, of all the possible structures available, particular languages select particular structures and not others. A legitimate sociolinguistic viewpoint would be that some social explanations may be available. The sociolinguistic factors suggested as being relevant are language contact versus isolation, and community size and network structure. This paper deals with this thesis from the point of view of Austronesian phonology, with particular reference to Polynesian phoneme inventories.},
  file = {/Users/megcychosz/Zotero/storage/I5MLNBHC/Trudgill - 2004 - Linguistic and social typology The Austronesian m.pdf},
  journal = {Linguistic Typology},
  language = {en},
  number = {3}
}

@article{tsaoEffectIntertalkerSpeech2006,
  title = {The Effect of Intertalker Speech Rate Variation on Acoustic Vowel Space},
  author = {Tsao, Ying-Chiao and Weismer, Gary and Iqbal, Kamran},
  year = {2006},
  volume = {119},
  pages = {1074--1082},
  file = {/Users/megcychosz/Zotero/storage/IFF3AE96/Tsao et al. - 2006 - The effect of intertalker speech rate variation on.pdf},
  journal = {Journal of the Acoustical Society of America},
  language = {en},
  number = {2}
}

@article{tsujiMoreBetterBehavioral2017,
  title = {The More, the Better? {{Behavioral}} and Neural Correlates of Frequent and Infrequent Vowel Exposure},
  shorttitle = {The More, the Better?},
  author = {Tsuji, Sho and Fikkert, Paula and Minagawa, Yasuyo and Dupoux, Emmanuel and Filippin, Luca and Versteegh, Maarten and Hagoort, Peter and Cristia, Alejandrina},
  year = {2017},
  volume = {59},
  pages = {603--612},
  issn = {1098-2302},
  doi = {10.1002/dev.21534},
  abstract = {A central assumption in the perceptual attunement literature holds that exposure to a speech sound contrast leads to improvement in native speech sound processing. However, whether the amount of exposure matters for this process has not been put to a direct test. We elucidated indicators of frequency-dependent perceptual attunement by comparing 5\textendash 8-month-old Dutch infants' discrimination of tokens containing a highly frequent [hɪt-he:t] and a highly infrequent [hʏt-h\o :t] native vowel contrast as well as a non-native [h{$\varepsilon$}t-h\ae t] vowel contrast in a behavioral visual habituation paradigm (Experiment 1). Infants discriminated both native contrasts similarly well, but did not discriminate the non-native contrast. We sought further evidence for subtle differences in the processing of the two native contrasts using near-infrared spectroscopy and a within-participant design (Experiment 2). The neuroimaging data did not provide additional evidence that responses to native contrasts are modulated by frequency of exposure. These results suggest that even large differences in exposure to a native contrast may not directly translate to behavioral and neural indicators of perceptual attunement, raising the possibility that frequency of exposure does not influence improvements in discriminating native contrasts.},
  file = {/Users/megcychosz/Zotero/storage/BJXZWY76/Tsuji et al. - 2017 - The more, the better Behavioral and neural correl.pdf;/Users/megcychosz/Zotero/storage/MWKYPCPD/dev.html},
  journal = {Developmental Psychobiology},
  keywords = {human infants,language experience,near-infrared spectroscopy,vowel discrimination},
  language = {en},
  number = {5}
}

@article{tuckerIntroductionSpecialIssue2020,
  title = {Introduction to the Special Issue on the Phonetics of Under-Documented Languages},
  author = {Tucker, Benjamin V. and Wright, Richard},
  year = {2020},
  month = apr,
  volume = {147},
  pages = {2741--2744},
  issn = {0001-4966},
  doi = {10.1121/10.0001107},
  file = {/Users/megcychosz/Zotero/storage/TIMDRQ8Z/Tucker and Wright - 2020 - Introduction to the special issue on the phonetics.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@article{tuckerSpeechAcousticsWorld2020,
  title = {Speech {{Acoustics}} of the {{World}}'s {{Languages}}},
  author = {Tucker, Benjamin V.},
  year = {2020},
  volume = {16},
  pages = {56},
  issn = {15570215},
  doi = {10.1121/AT.2020.16.2.56},
  file = {/Users/megcychosz/Zotero/storage/9KVKBBB6/Tucker - 2020 - Speech Acoustics of the World’s Languages.pdf},
  journal = {Acoustics Today},
  language = {en},
  number = {2}
}

@article{turnerStatisticalFormantpatternModel2009,
  title = {A Statistical, Formant-Pattern Model for Segregating Vowel Type and Vocal-Tract Length in Developmental Formant Data},
  author = {Turner, Richard E. and Walters, Thomas C. and Monaghan, Jessica J. M. and Patterson, Roy D.},
  year = {2009},
  month = apr,
  volume = {125},
  pages = {2374--2386},
  issn = {0001-4966},
  doi = {10.1121/1.3079772},
  file = {/Users/megcychosz/Zotero/storage/N3ZR9722/Turner et al. - 2009 - A statistical, formant-pattern model for segregati.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {4}
}

@article{tye-murrayAcquisitionSpeechChildren1995,
  title = {Acquisition of {{Speech}} by {{Children Who Have Prolonged Cochlear Implant Experience}}},
  author = {{Tye-Murray}, Nancy and Spencer, Linda and Woodworth, George G.},
  year = {1995},
  month = apr,
  volume = {38},
  pages = {327--337},
  issn = {0022-4685},
  abstract = {The four purposes of this investigation were to assess whether children acquire intelligible speech following prolonged cochlear-implant experience and examine their speech error patterns, to examine how age at implantation influences speech acquisition, to assess how speech production and speech perception skills relate, and to determine whether cochlear implant recipients who formerly used simultaneous communication (speech and manually coded English) begin to use speech without sign to communicate. Twenty-eight prelinguistically deafened children who use a Nucleus cochlear implant were assigned to one of three age groups, according to age at implantation: 2\textendash 5 yrs (N = 12), 5\textendash 8 yrs (N = 9), and 8\textendash 15 yrs (N = 7). All subjects had worn a cochlear implant for at least 24 mos, and an average of 36 mos. All subjects used simultaneous communication at the time of implantation. Subjects performed both imitative and structured spontaneous sampling speech tasks. The results permit the following conclusions: (a) children who have used a cochlear implant for at least 2 yrs acquire some intelligible speech; (b) children who receive a cochlear implant before the age of 5 yrs appear to show greater benefit in their speech production skills than children who are older, at least after a minimum of 2 yrs of use; (c) children who recognize more speech while wearing their cochlear implants are likely to speak more intelligibly; and, (d) signing does not disappear from a child's communication mode following implantation.},
  file = {/Users/megcychosz/Zotero/storage/TKPSMCKP/Tye-Murray et al. - 1995 - Acquisition of Speech by Children Who Have Prolong.pdf},
  journal = {Journal of speech and hearing research},
  number = {2},
  pmcid = {PMC3209957},
  pmid = {7596098}
}

@techreport{u.s.censusbureauQuickFactsMaryland2010,
  title = {{{QuickFacts}}: {{Maryland}}},
  author = {U.S. Census Bureau},
  year = {2010}
}

@inproceedings{umeshSimpleApproachNonuniform2002,
  title = {A Simple Approach to Non-Uniform Vowel Normalization},
  booktitle = {Proceedings of the {{International Conference}} on {{Acoustics}}, {{Speech}}, and {{Signal Processing}}},
  author = {Umesh, S and Kumar, S V Bharath and Vinay, M K and Sharma, Rajesh and Sinha, Rohit},
  year = {2002},
  volume = {1},
  pages = {I-517-I-520},
  address = {{Orlando, USA}},
  abstract = {In this paper, we present results of non-uniform vowel normalization and show that the frequency-warping necessary to do nonuniform vowel normalization is similar to the mel-scale. We compare our methods to Fant's non-uniform vowel normalization method and show that with proposed frequency warping approach we can achieve similar performance without any knowledge of the spoken vowel and the formant number. The proposed approach is motivated by a desire to perform non-uniform speaker normalization in automatic speech recognition systems. We also present results of a more comprehensive study of our earlier work on nonuniform scaling which again shows that mel-scale is the appropriate warping function. All the results in this paper are based on data from Peterson \& Barney and Hillenbrand et al. vowel databases.},
  file = {/Users/megcychosz/Zotero/storage/P74CTJM3/Umesh et al. - A SIMPLE APPROACH TO NON-UNIFORM VOWEL NORMALIZATI.pdf},
  language = {en}
}

@techreport{universiteparis1-pantheonsorbonneTableauConversionNotes2015,
  title = {{Tableau de conversion des notes}},
  author = {{Universit{\'e} Paris 1-Panth{\'e}on Sorbonne}},
  year = {2015},
  address = {{Paris, France}},
  institution = {{Universit\'e Paris 1-Panth\'eon Sorbonne}},
  language = {French}
}

@incollection{unsworthAmountExposureProxy2016,
  title = {Amount of Exposure as a Proxy for Dominance in Bilingual Language Acquisition},
  booktitle = {Language {{Dominance}} in {{Bilinguals}}},
  author = {Unsworth, Sharon},
  editor = {{Silva-Corvalan}, Carmen and {Treffers-Daller}, Jeanine},
  year = {2016},
  pages = {156--173},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9781107375345.008},
  file = {/Users/megcychosz/Zotero/storage/ZDSB4X4T/Unsworth - 2016 - Amount of exposure as a proxy for dominance in bil.pdf},
  isbn = {978-1-107-37534-5},
  language = {en}
}

@article{unsworthExperientialMeasuresCan2018,
  title = {Experiential {{Measures Can Be Used}} as a {{Proxy}} for {{Language Dominance}} in {{Bilingual Language Acquisition Research}}},
  author = {Unsworth, Sharon and Chondrogianni, Vicky and Skarabela, Barbora},
  year = {2018},
  month = oct,
  volume = {9},
  pages = {1--15},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2018.01809},
  abstract = {Language dominance is a multidimensional construct comprising several distinct yet interrelated components, including language proficiency, exposure and use. The exact relation between these components remains unclear. Several studies have observed a (non-linear) relationship between bilingual children's amount of exposure and absolute proficiency in each language, but our understanding of the relationship between language exposure and use and relative proficiency is limited. To address this question, we examined whether experiential-based measures of language dominance, operationalised here in the narrow sense of relative language proficiency, can provide an efficient alternative to the more labor-intensive performance-based measures often used in the literature. In earlier work, Unsworth (2016a) examined the relationship between relative proficiency and language exposure and use in a group of English\textendash Dutch bilingual preschool children residing in the Netherlands. This study expands these findings by examining Dutch\textendash English preschool children of the same age residing in the United Kingdom in order to cover the full dominance continuum. Participants were 35 simultaneous bilingual children (2;0\textendash 5;0) exposed to English and Dutch, 20 resident in the Netherlands and 15 in the United Kingdom. Relative amount of language exposure and use were estimated using a parental questionnaire. To obtain performance-based measures of language proficiency, children's spontaneous speech was recorded during a half-hour play session in each language. The transcribed data were used to derive MLU (words), average length of the longest five utterances, the number of different verb and noun types. Single word vocabulary comprehension was assessed using standardized tests in both languages. Following Yip and Matthews (2006), relative proficiency was operationalised using differentials. In line with Unsworth (2016a), English-dominant children typically had less than approx. 35\% exposure to Dutch and used Dutch less than approximately 30\% of the time. Curve-fitting analyses revealed that non-linear models best fit the data. Logistic regression analyses showed that both exposure and use were good predictors of dominance group membership assigned using the same approach as Unsworth (2016a), that is, using SDs. Dominance groups derived independently using cluster analyses overlapped with the groups derived using SDs, confirming that relative amount of exposure and use can be used as a proxy for language dominance.},
  file = {/Users/megcychosz/Zotero/storage/KK45I8PK/Unsworth et al. - 2018 - Experiential Measures Can Be Used as a Proxy for L.pdf},
  journal = {Frontiers in Psychology},
  language = {en},
  number = {1809}
}

@book{usoltsevVoiceActivityDetectorPython,
  title = {Voice {{Activity Detector}}-{{Python}}},
  author = {Usoltsev, A.},
  series = {{{GitHub}} Repository}
}

@book{vadenIrvinePhonotacticOnline,
  title = {The {{Irvine Phonotactic Online Dictionary}}},
  author = {Vaden, K. I. and Halpin, H.R. and Hickock, G.S.},
  edition = {Version 2.0}
}

@article{vallabhaUnsupervisedLearningVowel2007,
  title = {Unsupervised Learning of Vowel Categories from Infant-Directed Speech},
  author = {Vallabha, G. K. and McClelland, J. L. and Pons, F. and Werker, J. F. and Amano, S.},
  year = {2007},
  month = aug,
  volume = {104},
  pages = {13273--13278},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0705369104},
  file = {/Users/megcychosz/Zotero/storage/4Q4KI8QB/Vallabha et al. - 2007 - Unsupervised learning of vowel categories from inf.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {33}
}

@article{vandamAutomatedVocalAnalysis2015,
  title = {Automated {{Vocal Analysis}} of {{Children With Hearing Loss}} and {{Their Typical}} and {{Atypical Peers}}:},
  shorttitle = {Automated {{Vocal Analysis}} of {{Children With Hearing Loss}} and {{Their Typical}} and {{Atypical Peers}}},
  author = {VanDam, Mark and Oller, D. Kimbrough and Ambrose, Sophie E. and Gray, Sharmistha and Richards, Jeffrey A. and Xu, Dongxin and Gilkerson, Jill and Silbert, Noah H. and Moeller, Mary Pat},
  year = {2015},
  volume = {36},
  pages = {e146-e152},
  issn = {0196-0202},
  doi = {10.1097/AUD.0000000000000138},
  abstract = {Objectives\textemdash This study investigated automatic assessment of vocal development in children with hearing loss as compared with children who are typically developing, have language delays, and autism spectrum disorder. Statistical models are examined for performance in a classification model and to predict age within the four groups of children. Design\textemdash The vocal analysis system analyzed over 1900 whole-day, naturalistic acoustic recordings from 273 toddlers and preschoolers comprising children who were typically developing, hard of hearing, language delayed, or autistic. Results\textemdash Samples from children who were hard-of-hearing patterned more similarly to those of typically-developing children than to the language-delayed or autistic samples. The statistical models were able to classify children from the four groups examined and estimate developmental age based on automated vocal analysis. Conclusions\textemdash This work shows a broad similarity between children with hearing loss and typically developing children, although children with hearing loss show some delay in their production of speech. Automatic acoustic analysis can now be used to quantitatively compare vocal development in children with and without speech-related disorders. The work may serve to better distinguish among various developmental disorders and ultimately contribute to improved intervention.},
  file = {/Users/megcychosz/Zotero/storage/MFYTMH9P/VanDam et al. - 2015 - Automated Vocal Analysis of Children With Hearing .pdf},
  journal = {Ear and Hearing},
  language = {en},
  number = {4}
}

@article{vandamHomeBankOnlineRepository2016,
  title = {{{HomeBank}}, an Online Repository of Daylong Child-Centered Audio Recordings},
  author = {VanDam, M. and Warlaumont, Anne S and Bergelson, Elika and Cristi{\`a}, Alejandrina and Soderstrom, Melanie and De Palma, P. and MacWhinney, B.},
  year = {2016},
  volume = {37},
  pages = {128--142},
  journal = {Seminars in Speech and Language}
}

@article{vandamQuantityParentalLanguage2012,
  title = {Quantity of {{Parental Language}} in the {{Home Environments}} of {{Hard}}-of-{{Hearing}} 2-{{Year}}-{{Olds}}},
  author = {VanDam, M. and Ambrose, S. E. and Moeller, M. P.},
  year = {2012},
  month = oct,
  volume = {17},
  pages = {402--420},
  issn = {1081-4159, 1465-7325},
  doi = {10.1093/deafed/ens025},
  file = {/Users/megcychosz/Zotero/storage/AHMC852M/VanDam et al. - 2012 - Quantity of Parental Language in the Home Environm.pdf},
  journal = {Journal of Deaf Studies and Deaf Education},
  language = {en},
  number = {4}
}

@article{vandenbuntSensorimotorControlSpeech2018,
  title = {Sensorimotor {{Control}} of {{Speech}} and {{Children}}'s {{Reading Ability}}},
  author = {{van den Bunt}, Mark R. and Groen, Margriet A. and Frost, Steve and Lau, Airey and Preston, Jonathan L. and Gracco, Vincent L. and Pugh, Kenneth R. and Verhoeven, Ludo T. W.},
  year = {2018},
  month = nov,
  volume = {22},
  pages = {503--516},
  issn = {1088-8438, 1532-799X},
  doi = {10.1080/10888438.2018.1491583},
  abstract = {Studies of the role of phonological representations in learning to read have almost exclusively focused on speech perception. In the current study, we examined links between sensorimotor control of speech, reading, and reading-related abilities. We studied two languages, English and Dutch, which vary in the regularity of their spelling-to-sound mappings. There were 236 American and Dutch children, 4 to 8 years old, who performed an altered auditory feedback task in which the first formant of the /{$\varepsilon$}/ vowel was altered. A stronger response to altered feedback for literate relative to preliterate children was observed, and this was particularly the case for the Dutch children. Moreover, the magnitude of the responses was related to precursors of reading in preliterate children and to reading skill in literate children. We propose that these findings could be related to changes in children's speech production skills that facilitate the integration of orthographic and phonemic information.},
  file = {/Users/megcychosz/Zotero/storage/CBCGB5IQ/van den Bunt et al. - 2018 - Sensorimotor Control of Speech and Children’s Read.pdf},
  journal = {Scientific Studies of Reading},
  language = {en},
  number = {6}
}

@book{vangelderenGrammaticalizationEconomy2004,
  title = {Grammaticalization as Economy},
  author = {{van Gelderen}, E},
  year = {2004},
  publisher = {{John Benjamins}},
  address = {{Amsterdam}}
}

@article{vanormelingenLanguageDevelopmentChildren2020,
  title = {Language Development in Children from Different {{SES}} Backgrounds: {{Babbling}} Onset and Consonant Characteristics},
  shorttitle = {Language Development in Children from Different {{SES}} Backgrounds},
  author = {Vanormelingen, Liesbeth and Faes, Jolien and Gillis, Steven},
  year = {2020},
  month = oct,
  issn = {2211-7245, 2211-7253},
  doi = {10.1075/dujal.19032.van},
  abstract = {The aim of the study is to analyze prelexical speech development in young children with a different socio-economic status (SES): children from low SES backgrounds (lowSES) are compared with mid-to-high SES (mhSES) children. Timing of the onset of babbling and the consonantal development in consonant-vowel (cv) syllables are investigated. Result show that lowSES children reach the babbling onset milestone significantly later than mhSES children. In addition, they use different consonant types in their cvsyllables: they use more glides, but fewer stops, nasals, fricatives, and liquids. These early differences between children of different backgrounds seem to be in line with the literature on SES differences later on in life.},
  file = {/Users/megcychosz/Zotero/storage/NQCYQMQH/Vanormelingen et al. - 2020 - Language development in children from different SE.pdf},
  journal = {Dutch Journal of Applied Linguistics},
  language = {en}
}

@article{vanseverenConsonantInventoriesSpontaneous2012,
  title = {Consonant Inventories in the Spontaneous Speech of Young Children: {{A}} Bootstrapping Procedure},
  shorttitle = {Consonant Inventories in the Spontaneous Speech of Young Children},
  author = {Van Severen, Lieve and Van Den Berg, Renate and Molemans, Inge and Gillis, Steven},
  year = {2012},
  month = feb,
  volume = {26},
  pages = {164--187},
  issn = {0269-9206, 1464-5076},
  doi = {10.3109/02699206.2011.595527},
  abstract = {Consonant inventories are commonly drawn to assess the phonological acquisition of toddlers. However, the spontaneous speech data that are analysed often vary substantially in size and composition. Consequently, comparisons between children and across studies are fundamentally hampered. This study aims to examine the effect of sample size on the resulting consonant inventories. A spontaneous speech corpus of 30 Dutch-speaking 2-year-olds was used. The results indicate that in order to construct and compare inventories reliably, they should be drawn from speech samples that are equally large. A new consonant inventory procedure is introduced. The implementation of this procedure demonstrates considerably less variation in inventory size across children and word positions than reported previously. This finding has important implications for clinical studies that constructed and compared inventories of typically and atypically developing children without normalizing the sample size.},
  file = {/Users/megcychosz/Zotero/storage/9TZG8A45/Van Severen et al. - 2012 - Consonant inventories in the spontaneous speech of.pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {2}
}

@article{Variable,
  title = {Variable}
}

@article{vasishthBayesianDataAnalysis2018,
  title = {Bayesian Data Analysis in the Phonetic Sciences: {{A}} Tutorial Introduction},
  shorttitle = {Bayesian Data Analysis in the Phonetic Sciences},
  author = {Vasishth, Shravan and Nicenboim, Bruno and Beckman, Mary E. and Li, Fangfang and Kong, Eun Jong},
  year = {2018},
  month = nov,
  volume = {71},
  pages = {147--161},
  issn = {00954470},
  doi = {10.1016/j.wocn.2018.07.008},
  abstract = {This tutorial analyzes voice onset time (VOT) data from Dongbei (Northeastern) Mandarin Chinese and North American English to demonstrate how Bayesian linear mixed models can be fit using the programming language Stan via the R package brms. Through this case study, we demonstrate some of the advantages of the Bayesian framework: researchers can (i) flexibly define the underlying process that they believe to have generated the data; (ii) obtain direct information regarding the uncertainty about the parameter that relates the data to the theoretical question being studied; and (iii) incorporate prior knowledge into the analysis. Getting started with Bayesian modeling can be challenging, especially when one is trying to model one's own (often unique) data. It is difficult to see how one can apply general principles described in textbooks to one's own specific research problem. We address this barrier to using Bayesian methods by providing three detailed examples, with source code to allow easy reproducibility. The examples presented are intended to give the reader a flavor of the process of model-fitting; suggestions for further study are also provided. All data and code are available from: https://osf.io/g4zpv.},
  file = {/Users/megcychosz/Zotero/storage/GEIAXWE4/Vasishth et al. - 2018 - Bayesian data analysis in the phonetic sciences A.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{vihmanAcquisitionMorphologyBilingual1982,
  title = {The Acquisition of Morphology by a Bilingual Child: {{A}} Whole-Word Approach},
  shorttitle = {The Acquisition of Morphology by a Bilingual Child},
  author = {Vihman, Marilyn May},
  year = {1982},
  month = jun,
  volume = {3},
  pages = {141},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716400006676},
  abstract = {The avoidance of inflectional markers, a kind of "macrodevelopment'' in the acquisition of morphology, is described in this analysis bf the strategies displayed by a bilingual child simultaneously exposed to Estonian and to English. A whole-word approach was manifested in: the acquisition of postpositions before case endings; the learning of pronominal case and other suppletive or irregular forms before regular markers were used; the borrowing of the analytic English construction with have into Estonian; and the preference for did + verb for the expression of the English past tense. In interpreting these data the factor of bilingualism per se is weighed against the possible existence of a whole-word approach to language in general as a manifestation of a particular cognitive style.},
  file = {/Users/megcychosz/Zotero/storage/5IFD3Y95/Vihman - 1982 - The acquisition of morphology by a bilingual child.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {02}
}

@article{vihmanBabblingSpeechReAssessment1985,
  title = {From {{Babbling}} to {{Speech}}: {{A Re}}-{{Assessment}} of the {{Continuity Issue}}},
  shorttitle = {From {{Babbling}} to {{Speech}}},
  author = {Vihman, Marilyn May and Macken, Marlys A. and Miller, Ruth and Simmons, Hazel and Miller, Jim},
  year = {1985},
  month = jun,
  volume = {61},
  pages = {397},
  issn = {00978507},
  doi = {10.2307/414151},
  file = {/Users/megcychosz/Zotero/storage/FZQM5JDR/Vihman et al. - 1985 - From Babbling to Speech A Re-Assessment of the Co.pdf},
  journal = {Language},
  language = {en},
  number = {2}
}

@book{vihmanEmergencePhonologyWholeword2013,
  title = {The Emergence of Phonology: {{Whole}}-Word Approaches and Cross-Linguistic Evidence},
  author = {Vihman, Marilyn M. and {Keren-Portnoy}, Tamar},
  year = {2013},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge, MA}}
}

@incollection{vihmanGettingRhythmRight2006,
  title = {Getting the Rhythm Right : {{A}} Cross-Linguistic Study of Segmental Duration in Babbling and First Words},
  booktitle = {Papers in {{Laboratory Phonology VIII}}: {{Varieties}} of {{Phonological Competence}},},
  author = {Vihman, M M and Nakai, S and DePaolis, R A},
  editor = {Goldstein, L. and Best, K. and Whalen, D. H. and Anderson, Steve},
  year = {2006},
  pages = {341--366},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  file = {/Users/megcychosz/Zotero/storage/JZ7J3NK3/Vihman et al. - Getting the rhythm right  A cross-linguistic stud.pdf},
  language = {en}
}

@article{vihmanGettingStartedSystem2002,
  title = {Getting Started without a System: {{From}} Phonetics to Phonology in Bilingual Development},
  shorttitle = {Getting Started without a System},
  author = {Vihman, Marilyn May},
  year = {2002},
  month = sep,
  volume = {6},
  pages = {239--254},
  issn = {1367-0069, 1756-6878},
  doi = {10.1177/13670069020060030201},
  file = {/Users/megcychosz/Zotero/storage/UQYM394P/Vihman - 2002 - Getting started without a system From phonetics t.pdf},
  journal = {International Journal of Bilingualism},
  language = {en},
  number = {3}
}

@article{vihmanLanguageDifferentiationBilingual1985,
  title = {Language Differentiation by the Bilingual Infant},
  author = {Vihman, Marilyn May},
  year = {1985},
  month = jun,
  volume = {12},
  pages = {297--324},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000900006450},
  abstract = {This paper traces the process involved in the bilingual infant's gradual differentiation of his two languages, beginning with the acquisition of a dual lexicon. Word combination is at first based indiscriminately on this dual language source; function words account for a disproportionately large number of tokens used in mixed-language utterances. Universal principles of child syntax are at first applied; later, rules specific to each of the languages are developed separately. The development of selfawareness and sensitivity to standards in the second year provides the essential cognitive underpinning for the child to begin to avoid mixedlanguage utterances and to choose his language according to his interlocutor. At a still later point the bilingual older child may begin to make use of code-switching strategies appropriate to his or her bilingual community.},
  file = {/Users/megcychosz/Zotero/storage/GXLLDYA5/Vihman - 1985 - Language differentiation by the bilingual infant.pdf},
  journal = {Journal of Child Language},
  language = {en},
  number = {2}
}

@article{vihmanLearningWordsLearning2017,
  title = {Learning Words and Learning Sounds: {{Advances}} in Language Development},
  shorttitle = {Learning Words and Learning Sounds},
  author = {Vihman, Marilyn M.},
  year = {2017},
  volume = {108},
  pages = {1--27},
  issn = {2044-8295},
  doi = {10.1111/bjop.12207},
  abstract = {Phonological development is sometimes seen as a process of learning sounds, or forming phonological categories, and then combining sounds to build words, with the evidence taken largely from studies demonstrating `perceptual narrowing' in infant speech perception over the first year of life. In contrast, studies of early word production have long provided evidence that holistic word learning may precede the formation of phonological categories. In that account, children begin by matching their existing vocal patterns to adult words, with knowledge of the phonological system emerging from the network of related word forms. Here I review evidence from production and then consider how the implicit and explicit learning mechanisms assumed by the complementary memory systems model might be understood as reconciling the two approaches.},
  file = {/Users/megcychosz/Zotero/storage/9TP9UHRX/Vihman - 2017 - Learning words and learning sounds Advances in la.pdf;/Users/megcychosz/Zotero/storage/7Y3IKDZV/bjop.html},
  journal = {British Journal of Psychology},
  keywords = {complementary systems model,exemplars,perceptual narrowing,phonological development,phonological template,speech sounds,vocal motor scheme,word learning},
  language = {en},
  number = {1}
}

@article{vihmanPhonologicalDevelopmentBabbling1986,
  title = {Phonological Development from Babbling to Speech: {{Common}} Tendencies and Individual Differences},
  shorttitle = {Phonological Development from Babbling to Speech},
  author = {Vihman, Marilyn May and Ferguson, Charles A. and Elbert, Mary},
  year = {1986},
  month = mar,
  volume = {7},
  pages = {3--40},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716400007165},
  abstract = {Taking as a point of departure Locke's biological model for the origins of phonological development, this study encompasses analyses of phonetic tendencies, consonant use in babbling and early words, and phonological word-selection patterns. Data from 10 children aged 9 to 16 months are drawn from four lexically defined points covering the period from no word use to a cumulative vocabulary of 50 words. Individual differences are found to prevail from the start in all three domains analyzed, with some increase in uniformity across subjects with increasing knowledge of language. Furthermore, the phonological processes typical of development from age 1 to 3 or 4 years are found to be rooted in the phonetic tendencies of the prelinguistic period.},
  file = {/Users/megcychosz/Zotero/storage/BB53R32T/Vihman et al. - 1986 - Phonological development from babbling to speech .pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {1}
}

@incollection{vihmanPhonologicalDevelopmentBilingual2014,
  title = {Phonological {{Development}} in the {{Bilingual Child}}},
  booktitle = {Phonological {{Development}}: {{The First Two Years}}},
  author = {Vihman, Marilyn},
  year = {2014},
  file = {/Users/megcychosz/Zotero/storage/74J6WKR9/Phonological_Development_The_First_Two_Years_----_(Chapter_8_Phonological_Development_in_the_Bilingual_Child_).pdf}
}

@book{vihmanPhonologicalDevelopmentFirst2014,
  title = {Phonological Development: {{The}} First Two Years},
  author = {Vihman, Marilyn M.},
  year = {2014},
  edition = {Second},
  publisher = {{Wiley-Blackwell}},
  address = {{Boston, MA}},
  file = {/Users/megcychosz/Zotero/storage/6C45GCZA/Vihman_2014_ch10_emergentist models.pdf;/Users/megcychosz/Zotero/storage/ESMSQBUE/Vihman_2014_ch9_formalist models.pdf;/Users/megcychosz/Zotero/storage/LVAIYTSH/Phonological_Development_The_First_Two_Years_2_.pdf;/Users/megcychosz/Zotero/storage/RCGNP7JA/Vihman_template_talk.txt}
}

@article{vihmanPhonologicalDevelopmentRadical2007,
  title = {Phonological Development: Toward a ``Radical'' Templatic Phonology},
  shorttitle = {Phonological Development},
  author = {Vihman, Marilyn and Croft, William},
  year = {2007},
  month = jan,
  volume = {45},
  pages = {683--725},
  issn = {0024-3949, 1613-396X},
  doi = {10.1515/LING.2007.021},
  abstract = {Radical'' templatic phonology is a template-based approach to segmental phonological representation. The central hypothesis is that the segmental phonological structure of words is represented as language-specific phonotactic templates, in the sense used in the developmental literature. Template-based organization of the early lexicon has been identified in children acquiring several di\textcurrency erent languages. It is the result of a usage-based abstracting or ``induction'' process based on both babbling practice (phonetic production) and input experience with specific adult phonological patterns. The resulting templates thus constitute patterns that reconcile (or ``adapt'') the model provided by target words with the child's own phonetic repertoire of syllables or word shapes \textemdash{} typically extending or building on the forms initially ``selected'' for first word production, in which adult and child forms show a close match. In adult phonology segment categories \textemdash natural classes, or features \textemdash{} are best defined in terms of their occurrence in positions in the templates in individual languages, not as independent universal categories. After reviewing the status of segment categories and their phonetic basis in contemporary phonological theory we present crosslinguistic evidence of pervasive variation in both phonetic realization and phonological distribution patterns, evidence that supports the template construct.},
  file = {/Users/megcychosz/Zotero/storage/P3U6WFGM/Vihman and Croft - 2007 - Phonological development toward a “radical” templ.pdf},
  journal = {Linguistics},
  language = {en},
  number = {4}
}

@article{vihmanPhonologicalReorganizationCase,
  title = {Phonological {{Reorganization}}: {{A Case Study}}},
  author = {Vihman, Marilyn M and Velleman, Shelley L},
  pages = {22},
  abstract = {Various types of phonological behavior have been identified a s evidence of the systematization which is said to occur in the course of the transition from early, `thole-word'' phonology to later, segment-based phonology. However, we have a limited understanding of the role of such early phonological behavior in facilitating - or initiating - the emergence of segmental phonology. Furthermore, there has been little acoustic verification of such changes in children's phonological systems. In this study, the lexical production of one child is analyzed in detail from the onset of word use at 10 months to 16 months, when she had a cumulative lesicon of over 70 words. A period of phonological experimentation and the emergence of productive ``word recipes'' are documented, using both perceptual and acoustic analysis. Implications of such systematization for the later development of segmental phonology are discussed.},
  file = {/Users/megcychosz/Zotero/storage/AHBHIUYY/Vihman and Velleman - Phonological Reorganization A Case Study.pdf},
  language = {en}
}

@article{vihmanRoleProductionInfant2014,
  title = {The {{Role}} of {{Production}} in {{Infant Word Learning}}: {{The Role}} of {{Production}} in {{Infant Word Learning}}},
  shorttitle = {The {{Role}} of {{Production}} in {{Infant Word Learning}}},
  author = {Vihman, Marilyn May and DePaolis, Rory A. and {Keren-Portnoy}, Tamar},
  year = {2014},
  month = sep,
  volume = {64},
  pages = {121--140},
  issn = {00238333},
  doi = {10.1111/lang.12058},
  file = {/Users/megcychosz/Zotero/storage/JY36SAH3/Vihman et al. - 2014 - The Role of Production in Infant Word Learning Th.pdf},
  journal = {Language Learning},
  language = {en},
  number = {s2}
}

@article{vihmanVariablePathsEarly1993,
  title = {Variable Paths to Early Word Production},
  author = {Vihman, Marilyn May},
  year = {1993},
  month = jan,
  volume = {21},
  pages = {61--82},
  issn = {00954470},
  doi = {10.1016/S0095-4470(19)31321-X},
  file = {/Users/megcychosz/Zotero/storage/D6GEL3N8/Vihman - 1993 - Variable paths to early word production.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {1-2}
}

@article{vitevitchPhonologicalNeighborhoodEffects2016,
  title = {Phonological {{Neighborhood Effects}} in {{Spoken Word Perception}} and {{Production}}},
  author = {Vitevitch, Michael S. and Luce, Paul A.},
  year = {2016},
  month = jan,
  volume = {2},
  pages = {75--94},
  issn = {2333-9683, 2333-9691},
  doi = {10.1146/annurev-linguistics-030514-124832},
  abstract = {Research on spoken word perception and production has identified two hallmarks of spoken word processing: multiple activation of representations of the sound patterns of words in memory and subsequent competition among these patterns. Evidence for this activation-competition process has come, in part, from experimental studies examining the effects of phonological neighborhoods, which are collections of similar-sounding words that are activated in memory during both perception and production. In this article, we review more than 20 years of research on phonological neighborhood effects in spoken word processing that has demonstrated that the speed and accuracy of spoken word perception and production are, in large part, a function of the density and frequency of neighborhoods of spoken words. We conclude our review with a discussion of new avenues of research\textemdash based on recent advances in network science\textemdash that hold the promise of deepening our understanding of the mental operations involved in our uniquely human capacity for communicating with the spoken word.},
  file = {/Users/megcychosz/Zotero/storage/NSHZTIZ8/Vitevitch and Luce - 2016 - Phonological Neighborhood Effects in Spoken Word P.pdf},
  journal = {Annual Review of Linguistics},
  language = {en},
  number = {1}
}

@article{vitevitchPhonotacticsSyllableStress1997,
  title = {Phonotactics and {{Syllable Stress}}: {{Implications}} for the {{Processing}} of {{Spoken Nonsense Words}}},
  shorttitle = {Phonotactics and {{Syllable Stress}}},
  author = {Vitevitch, Michael S. and Luce, Paul A. and {Charles-Luce}, Jan and Kemmerer, David},
  year = {1997},
  month = jan,
  volume = {40},
  pages = {47--62},
  issn = {0023-8309, 1756-6053},
  doi = {10.1177/002383099704000103},
  file = {/Users/megcychosz/Zotero/storage/C7CT67ZM/Vitevitch et al. - 1997 - Phonotactics and Syllable Stress Implications for.pdf},
  journal = {Language and Speech},
  language = {en},
  number = {1}
}

@article{vitevitchProbabilisticPhonotacticsNeighborhood1999,
  title = {Probabilistic {{Phonotactics}} and {{Neighborhood Activation}} in {{Spoken Word Recognition}}},
  author = {Vitevitch, Michael S. and Luce, Paul A.},
  year = {1999},
  month = apr,
  volume = {40},
  pages = {374--408},
  issn = {0749596X},
  doi = {10.1006/jmla.1998.2618},
  file = {/Users/megcychosz/Zotero/storage/5GJ8D3EI/Vitevitch and Luce - 1999 - Probabilistic Phonotactics and Neighborhood Activa.pdf},
  journal = {Journal of Memory and Language},
  language = {en},
  number = {3}
}

@article{vitevitchWhenWordsCompete1998,
  title = {When {{Words Compete}}: {{Levels}} of {{Processing}} in {{Perception}} of {{Spoken Words}}},
  shorttitle = {When {{Words Compete}}},
  author = {Vitevitch, Michael S. and Luce, Paul A.},
  year = {1998},
  month = jul,
  volume = {9},
  pages = {325--329},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/1467-9280.00064},
  abstract = {Current theories of spoken-word recognition posit two levels of representation and process: lexical and sublexical. By manipulating probabilistic phonotactics and similarity-neighborhood density, we attempted to determine if these two levels of representation have dissociable effects on processing. Whereas probabilistic phonotactics have been associated with facilitatory effects on recognition, increases in similarity-neighborhood density typically result in inhibitory effects on recognition arising from lexical competition. Our results demonstrated that when the lexical level is invoked using real words, competitive effects of neighborhood density are observed. However, when strong lexical effects are removed by the use of nonsense word stimuli, facilitatory effects of phonotactics emerge. These results are consistent with a two-level framework of process and representation embodied in certain current models of spoken-word recognition.},
  journal = {Psychological Science},
  number = {4}
}

@article{vogtCommunicativeIntentionsChilddirected2015,
  title = {Communicative Intentions of Child-Directed Speech in Three Different Learning Environments: {{Observations}} from the {{Netherlands}}, and Rural and Urban {{Mozambique}}},
  shorttitle = {Communicative Intentions of Child-Directed Speech in Three Different Learning Environments},
  author = {Vogt, Paul and Mastin, J. Douglas and Schots, Diede M. A.},
  year = {2015},
  month = oct,
  volume = {35},
  pages = {341--358},
  issn = {0142-7237, 1740-2344},
  doi = {10.1177/0142723715596647},
  abstract = {This article compares the communicative intentions observed in the speech addressed to children of 1;1 and 1;6 years old from three cultural communities: the Netherlands, rural Mozambique, and urban Mozambique. These communities represent two prototypical learning environments and a third hybrid: Western, urban, middle-class families; non-Western, rural, subsistence-farming families; and non-Western, urban learning environment. The results show that the Dutch CDS contains relatively more utterances with a cognitive intention than the Mozambican CDS. In Mozambique, CDS contains more imperatives, particularly in the rural environment. The CDS from urban Mozambique contains more socioemotional intentions. The findings suggest that these differences can be explained in terms of the different responsibilities and levels of autonomy expected from children of the three learning environments.},
  file = {/Users/megcychosz/Zotero/storage/2B859LGF/Vogt et al. - 2015 - Communicative intentions of child-directed speech .pdf},
  journal = {First Language},
  language = {en},
  number = {4-5}
}

@article{vonhapsburgAuditorySensitivityPrelinguistic2006,
  title = {Auditory {{Sensitivity}} and the {{Prelinguistic Vocalizations}} of {{Early}}-{{Amplified Infants}}},
  author = {{von Hapsburg}, Deborah and Davis, Barbara L.},
  year = {2006},
  month = aug,
  volume = {49},
  pages = {809--822},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2006/057)},
  abstract = {Purpose: Vocalization development has not been studied thoroughly in infants with early-identified hearing loss who receive hearing aids in the 1st year of life. This study sought to evaluate the relationship between auditory sensitivity and prelinguistic vocalization patterns in infants during the babbling stage. Method: Spontaneous vocalizations of 15 early-identified infants with varying degrees of hearing sensitivity, from normal to profound hearing loss, were audiotaped and perceptually transcribed. Associations between the infant's unaided pure-tone average and the following vocalizations were explored: canonical babbling ratio, percentage of utterances containing canonical syllables, canonical syllable shapes, number of syllable sequences, and consonant-onset patterns in canonical syllables. Results: Hearing sensitivity was significantly associated with the percentage of utterances containing canonical syllables, the vocalization types used in utterances, and canonical syllable shapes used by the infants. Conclusions: Auditory sensitivity contributes significantly to the emergence of babbling patterns. In addition, there is a need for continued study of the vocalizations of infants with milder forms of hearing loss, because in this study, their vocalizations were highly variable despite having received early amplification.},
  file = {/Users/megcychosz/Zotero/storage/XD2KJJ4L/Hapsburg and Davis - 2006 - Auditory Sensitivity and the Prelinguistic Vocaliz.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {4}
}

@article{vorperianAnatomicDevelopmentOral2009,
  title = {Anatomic Development of the Oral and Pharyngeal Portions of the Vocal Tract: {{An}} Imaging Studya)},
  author = {Vorperian, Houri K and Wang, Shubing},
  year = {2009},
  volume = {125},
  pages = {13},
  file = {/Users/megcychosz/Zotero/storage/RQLR98W5/Vorperian and Wang - 2009 - Anatomic development of the oral and pharyngeal po.pdf},
  journal = {J. Acoust. Soc. Am.},
  language = {en},
  number = {3}
}

@article{vorperianDevelopmentalSexualDimorphism2011,
  title = {Developmental {{Sexual Dimorphism}} of the {{Oral}} and {{Pharyngeal Portions}} of the {{Vocal Tract}}: {{An Imaging Study}}},
  shorttitle = {Developmental {{Sexual Dimorphism}} of the {{Oral}} and {{Pharyngeal Portions}} of the {{Vocal Tract}}},
  author = {Vorperian, Houri K. and Wang, Shubing and Schimek, E. Michael and Durtschi, Reid B. and Kent, R.D. and Gentry, Lindell R. and Chung, Moo K.},
  year = {2011},
  month = aug,
  volume = {54},
  pages = {995--1010},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2010/10-0097)},
  abstract = {Purpose\textemdash The anatomic origin for prepubertal vowel acoustic differences between males and females remains unknown. The purpose of this study is to examine developmental sex differences in vocal tract (VT) length and its oral and pharyngeal portions.},
  file = {/Users/megcychosz/Zotero/storage/KTZCWWKJ/Vorperian et al. - 2011 - Developmental Sexual Dimorphism of the Oral and Ph.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {4}
}

@article{vorperianDevelopmentVocalTract2005,
  title = {Development of Vocal Tract Length during Early Childhood: {{A}} Magnetic Resonance Imaging Study},
  shorttitle = {Development of Vocal Tract Length during Early Childhood},
  author = {Vorperian, Houri K. and Kent, R.D. and Lindstrom, Mary J. and Kalina, Cliff M. and Gentry, Lindell R. and Yandell, Brian S.},
  year = {2005},
  volume = {117},
  pages = {338--350},
  issn = {0001-4966},
  doi = {10.1121/1.1835958},
  file = {/Users/megcychosz/Zotero/storage/5QR8E4IV/Vorperian et al. - 2005 - Development of vocal tract length during early chi.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{vorperianVowelAcousticSpace2007,
  title = {Vowel {{Acoustic Space Development}} in {{Children}}: {{A Synthesis}} of {{Acoustic}} and {{Anatomic Data}}},
  shorttitle = {Vowel {{Acoustic Space Development}} in {{Children}}},
  author = {Vorperian, Houri K. and Kent, R.D.},
  year = {2007},
  volume = {50},
  pages = {1510--1545},
  issn = {1092-4388},
  doi = {10.1044/1092-4388(2007/104)},
  abstract = {Purpose\textemdash This article integrates published acoustic data on the development of vowel production. Age specific data on formant-frequencies are considered in the light of information on the development of the vocal tract (VT) to create an anatomic-acoustic description of the maturation of the vowel acoustic space for English. Method\textemdash Literature searches identified 14 studies reporting data on vowel formant-frequencies. Data on corner vowels are summarized graphically to show age/sex related changes in the area and shape of the traditional vowel quadrilateral. Conclusions\textemdash Vowel development is expressed as: (a) establishment of a language-appropriate acoustic representation (e.g., F1-F2 quadrilateral or F1-F2-F3 space), (b) gradual reduction in formant-frequencies and F1-F2 area with age, (c) reduction in formant-frequency variability, (d) emergence of male-female differences in formant-frequency by age 4 years with more apparent differences by 8 years, (e) jumps in formant-frequency at ages corresponding to growth spurts of the VT, and (f) a decline of f0 after age 1, with the decline being more rapid during early childhood and adolescence. Questions remain about optimal procedures for VT normalization, and the exact relationship between VT growth and formant-frequencies. Comments are included on nasalization and vocal fundamental-frequency as they relate to the development of vowel production.},
  file = {/Users/megcychosz/Zotero/storage/XNG3NCAY/Vorperian and Kent - 2007 - Vowel Acoustic Space Development in Children A Sy.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {6}
}

@inproceedings{vosoughiLongitudinalStudyProsodic2012,
  title = {A Longitudinal Study of Prosodic Exaggeration in Child-Directed Speech},
  booktitle = {Proceedings of {{Speech Prosody}}},
  author = {Vosoughi, Soroush and Roy, Deb},
  year = {2012},
  pages = {194--197},
  abstract = {We investigate the role of prosody in child-directed speech of three English speaking adults using data collected for the Human Speechome Project, an ecologically valid, longitudinal corpus collected from the home of a family with a young child. We looked at differences in prosody between child-directed and adult-directed speech. We also looked at the change in prosody of child-directed speech as the child gets older. Results showed significant interactions between speech type and vowel duration, mean F0 and F0 range. We also found significant changes in prosody in child-directed speech as the child gets older.},
  file = {/Users/megcychosz/Zotero/storage/E2XAVL7D/Vosoughi and Roy - A longitudinal study of prosodic exaggeration in c.pdf},
  language = {en}
}

@article{vpsForagingApproachAnalysing2020,
  title = {A Foraging Approach to Analysing Infant and Caregiver Vocal Behaviour},
  author = {Vps, Ritwika and Pretzer, Gina M and Mendoza, Sara and Shedd, Christopher and Gopinathan, Ajay and Warlaumont, Anne S},
  year = {2020},
  pages = {1--16},
  abstract = {We explored the idea that infants search in an acoustic space for vocalisations that elicit adult utterances and vice versa, inspired by research on spatial and memory foraging. Infant-worn recorders were used to collect day-long audio recordings. Infant speech-related and adult vocalisation onsets and offsets were automatically identified. We examined vocalisation-tovocalisation steps, focusing on inter-vocalisation time intervals and distances in an acoustic space defined by mean pitch and mean amplitude. Infant inter-vocalisation intervals were shorter immediately following a vocal response from an adult. Adult intervals were shorter following an infant response and adult inter-vocalisation pitch differences were smaller following the receipt of a vocal response from the infant. These findings are consistent with the hypothesis that infants forage vocally for social input. In contrast, adult amplitude steps were larger following infant vocal response. Infant acoustic step sizes showed less clear evidence of modification following receipt of adult response. Increasing infant age was associated with changes in inter-vocalization step sizes for both infants and adults. The study represents a novel application of foraging theory to characterise infant vocal exploration and infant-caregiver vocal interactions. We also provide new data on how pitch, amplitude, and age predict whether a response will be received.},
  file = {/Users/megcychosz/Zotero/storage/K5YHWL2V/Vps et al. - A foraging approach to analysing infant and caregi.pdf},
  journal = {Scientific Reports},
  language = {en}
}

@article{vrantsidisSocioeconomicStatusExecutive2020,
  title = {Socioeconomic Status and Executive Function in Early Childhood: {{Exploring}} Proximal Mechanisms},
  shorttitle = {Socioeconomic Status and Executive Function in Early Childhood},
  author = {Vrantsidis, Daphne M. and Clark, Caron A. C. and Chevalier, Nicolas and Espy, Kimberly Andrews and Wiebe, Sandra A.},
  year = {2020},
  month = may,
  volume = {23},
  issn = {1363-755X, 1467-7687},
  doi = {10.1111/desc.12917},
  abstract = {Although there is substantial evidence that socioeconomic status (SES) predicts children's executive function (EF), the mechanisms underlying this association are poorly understood. This study tested the utility of two theories proposed to link SES to children's EF: the family stress model and the family investment model. Data came from the Midwestern Infant Development Study (N = 151). To measure SES, parental education and income were assessed during pregnancy, and income was also assessed when children were 6 and 36 months old. Children's EF, operationalized as working memory/inhibitory control (WMIC) and self-control, was assessed at 36 months of age, along with potential mediators including maternal psychological distress, harsh parenting, and cognitive stimulation. Using structural equation modeling, we tested simultaneous pathways from SES to EF: (a) via maternal psychological distress to harsh parenting (family stress model) and (b) via cognitive stimulation (family investment model). Of the SES measures, lower education predicted poorer WMIC directly and indirectly via greater maternal psychological distress. Lower education also predicted poorer self-control via greater maternal psychological distress. This effect was partially suppressed by an indirect path from lower education to better self-control via greater psychological distress and increased harsh parenting. Cognitive stimulation did not act as a mediator. Income was not directly or indirectly associated with EF. These findings provide partial support for the family stress model and suggest that family functioning is an important proximal mechanism for children's EF development. This study also highlights the importance of considering SES as a multidimensional construct.},
  file = {/Users/megcychosz/Zotero/storage/4D3IMTXJ/Vrantsidis et al. - 2020 - Socioeconomic status and executive function in ear.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {3}
}

@article{wadePerceptualEffectsPreceding2005,
  title = {Perceptual Effects of Preceding Nonspeech Rate on Temporal Properties of Speech Categories},
  author = {Wade, Travis and Holt, Lori L.},
  year = {2005},
  month = aug,
  volume = {67},
  pages = {939--950},
  issn = {0031-5117, 1532-5962},
  doi = {10.3758/BF03193621},
  file = {/Users/megcychosz/Zotero/storage/CDQ935P7/Wade and Holt - 2005 - Perceptual effects of preceding nonspeech rate on .pdf},
  journal = {Perception \& Psychophysics},
  language = {en},
  number = {6}
}

@book{wagnerComprehensiveTestPhonological,
  title = {Comprehensive {{Test}} of {{Phonological Processing}}},
  author = {Wagner, R.K. and Torgesen, J.K. and Rashotte, C.A. and Pearson, N.A.},
  edition = {Second},
  publisher = {{Pro-Ed}},
  address = {{Austin, Texas}}
}

@article{wagnerDevelopmentReadingRelatedPhonological1994,
  title = {Development of {{Reading}}-{{Related Phonological Processing Abilities}}: {{New Evidence}} of {{Bidirectional Causality From}} a {{Latent Variable Longitudinal Study}}},
  author = {Wagner, Richard K and Torgesen, Joseph K and Rashotte, Carol A},
  year = {1994},
  volume = {30},
  pages = {73--87},
  file = {/Users/megcychosz/Zotero/storage/K9934EFC/Wagner et al. - Development of Reading-Related Phonological Proces.pdf},
  journal = {Developmental Psychology},
  language = {en},
  number = {1}
}

@article{waldsteinEffectsPostlingualDeafness1990,
  title = {Effects of Postlingual Deafness on Speech Production: {{Implications}} for the Role of Auditory Feedback},
  shorttitle = {Effects of Postlingual Deafness on Speech Production},
  author = {Waldstein, Robin S.},
  year = {1990},
  month = nov,
  volume = {88},
  pages = {2099--2114},
  issn = {0001-4966},
  doi = {10.1121/1.400107},
  file = {/Users/megcychosz/Zotero/storage/PED223AG/Waldstein - 1990 - Effects of postlingual deafness on speech producti.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{wallaceBabbleGatewaySpeech1998,
  title = {Is Babble the Gateway to Speech for All Children? {{A Longitudinal}} Study of Children Who Are Deaf or Hard of Hearing},
  author = {Wallace, V. and Menn, Lise and {Yoshinaga-Itano}, Christine},
  year = {1998},
  volume = {100},
  pages = {121--148},
  file = {/Users/megcychosz/Zotero/storage/PSTMIMDF/document(2).pdf;/Users/megcychosz/Zotero/storage/R2QSNJMB/wallace_etal_1998.pdf},
  journal = {The Volta Review},
  number = {5}
}

@article{walshArticulatoryMovementsAdolescents2002,
  title = {Articulatory Movements in Adolescents: Evidence for Protracted Develop- Ment of Speech Motor Control Processes.},
  author = {Walsh, B. and Smith, A.},
  year = {2002},
  volume = {45},
  pages = {1119--1133},
  journal = {Journal of Speech Language and Hearing Research},
  number = {6}
}

@article{wangLexicalProsodicPitch2021,
  title = {Lexical and {{Prosodic Pitch Modifications}} in {{Cantonese Infant}}-Directed {{Speech}}},
  author = {Wang, Luchang and Kalashnikova, Marina and Kager, Ren{\'e} and Lai, Regine and Wong, Patrick C.M.},
  year = {2021},
  month = feb,
  pages = {1--27},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000920000707},
  abstract = {The functions of acoustic-phonetic modifications in infant-directed speech (IDS) remain a question: do they specifically serve to facilitate language learning via enhanced phonemic contrasts (the hyperarticulation hypothesis) or primarily to improve communication via prosodic exaggeration (the prosodic hypothesis)? The study of lexical tones provides a unique opportunity to shed light on this, as lexical tones are phonemically contrastive, yet their primary cue, pitch, is also a prosodic cue. This study investigated Cantonese IDS and found increased intra-talker variation of lexical tones, which more likely posed a challenge to rather than facilitated phonetic learning. Although tonal space was expanded which could facilitate phonetic learning, its expansion was a function of overall intonational modifications. Similar findings were observed in speech to pets who should not benefit from larger phonemic distinction. We conclude that lexicaltone adjustments in IDS mainly serve to broadly enhance communication rather than specifically increase phonemic contrast for learners.},
  file = {/Users/megcychosz/Zotero/storage/VPRRFCYW/Wang et al. - 2021 - Lexical and Prosodic Pitch Modifications in Canton.pdf},
  journal = {Journal of Child Language},
  language = {en}
}

@article{wangLexicalRepetitionProperties2020,
  title = {Lexical {{Repetition Properties}} of {{Caregiver Speech}} and {{Language Development}} in {{Children With Cochlear Implants}}},
  author = {Wang, Yuanyuan and Jung, Jongmin and Bergeson, Tonya R. and Houston, Derek M.},
  year = {2020},
  month = mar,
  volume = {63},
  pages = {872--884},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/2019_JSLHR-19-00227},
  abstract = {Purpose               Early language input plays an important role in child language and cognitive development (e.g., Gilkerson et al., 2018; Hart \& Risley, 1995). In this study, we examined the effects of child's hearing status on lexical repetition properties of speech produced by their caregivers with normal hearing (NH). In addition, we investigated the relationship between maternal lexical repetition properties and later language skills in English-learning infants with cochlear implants (CIs).                                         Method               In a free-play session, 17 mothers and their prelingually deaf infants who received CIs before 2 years of age (CI group) were recorded at two post-CI intervals: 3 and 6 months postactivation; 18 hearing experience\textendash matched infants with NH and their mothers and 14 chronological age\textendash matched infants with NH group and their mothers were matched to the CI group. Maternal speech was transcribed from the recordings, and measures of maternal lexical repetition were obtained. Standardized language assessments were administered on children with CIs approximately two years after CI activation.                                         Results               The findings indicated that measures of lexical repetition were similar among the three groups of mothers, regardless of the hearing status of their infants. In addition, lexical repetition measures were correlated with later language skills in infants with CIs.                                         Conclusions               Infants with CIs receive the language input that contains similar lexical repetition properties as that in the speech received by their peers with NH, which is likely to play an important role in child speech processing and language development. These findings provide the knowledge for professionals to coach parents to implement specific language intervention strategies to support language development in infants with hearing loss.                                         Supplemental Material                                https://doi.org/10.23641/asha.11936322},
  file = {/Users/megcychosz/Zotero/storage/EX8ZB9WA/Wang et al. - 2020 - Lexical Repetition Properties of Caregiver Speech .pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {3}
}

@article{wangMetaanalysisPredictabilityLENA2020,
  title = {A Meta-Analysis of the Predictability of {{LENA}}\texttrademark{} Automated Measures for Child Language Development},
  author = {Wang, Yuanyuan and Williams, Rondeline and Dilley, Laura and Houston, Derek M.},
  year = {2020},
  month = sep,
  volume = {57},
  pages = {100921},
  issn = {02732297},
  doi = {10.1016/j.dr.2020.100921},
  abstract = {Early language environment plays a critical role in child language development. The Language ENvironment Analysis (LENA\texttrademark ) system allows researchers and clinicians to collect daylong recordings and obtain automated measures to characterize a child's language environment. This meta-analysis evaluates the predictability of LENA's automated measures for language skills in young children. We systematically searched reports for associations between LENA's automated measures, specifically, adult word count (AWC), conversational turn count (CTC), and child vocalization count (CVC), and language skills in children younger than 48 months. Using robust variance estimation, we calculated weighted mean effect sizes and conducted moderator analyses exploring the factors that might affect this relationship. The results revealed an overall medium effect size for the correlation between LENA's automated measures and language skills. This relationship was largely consistent regardless of child developmental status, publication status, language assessment modality and method, or the age at which the LENA recording was taken; however, the effect was moderated by the gap between LENA recordings and language measures taken. Among the three measures, there were medium associations between CTC and CVC and language, whereas there was a small-to-medium association between AWC and language. These findings extend beyond validation work conducted by the LENA Research Foundation and suggest certain predictive strength of LENA's automated measures for child language. We discussed possible mechanisms underlying the observed associations, as well as the theoretical, methodological, and clinical implications of these findings.},
  file = {/Users/megcychosz/Zotero/storage/C4GZU7Z6/Wang et al. - 2020 - A meta-analysis of the predictability of LENA™ aut.pdf},
  journal = {Developmental Review},
  language = {en}
}

@inproceedings{warlaumontDetectionTotalSyllables2016,
  title = {Detection of {{Total Syllables}} and {{Canonical Syllables}} in {{Infant Vocalizations}}},
  booktitle = {Interspeech 2016},
  author = {Warlaumont, Anne S. and {Ramsdell-Hudock}, Heather L.},
  year = {2016},
  month = sep,
  pages = {2676--2680},
  doi = {10.21437/Interspeech.2016-1518},
  abstract = {During the first two years of life, human infants produce increasing numbers of speech-like (canonical) syllables. Both basic research on child speech development and clinical work assessing a child's pre-speech capabilities stand to benefit from efficient, accurate, and consistent methods for counting the syllables present in a given infant utterance. To date, there have been only a few attempts to perform syllable counting in infant vocalizations automatically, and thorough comparisons to human listener counts are lacking. We apply four existing, openly available systems for detecting syllabic, consonant, or vowel elements in vocalizations and apply them to a set of infant utterances individually and in combination. With the automated methods, we obtain canonical syllable counts that correlate well enough with trained human listener counts to replicate the pattern of increasing canonical syllable frequency as infants get older. However, agreement between the automated methods and human listener canonical syllable counts is considerably weaker than human listeners' agreement with each other. On the other hand, automatic identification of syllable-like units of any type (canonical and non-canonical both included) match human listeners' judgments quite well. Interestingly, these total syllable counts also increase with infant age.},
  file = {/Users/megcychosz/Zotero/storage/QB6ZPZ6F/Warlaumont and Ramsdell-Hudock - 2016 - Detection of Total Syllables and Canonical Syllabl.pdf},
  language = {en}
}

@article{warlaumontLearningProduceSyllabic2016,
  title = {Learning to {{Produce Syllabic Speech Sounds}} via {{Reward}}-{{Modulated Neural Plasticity}}},
  author = {Warlaumont, Anne S. and Finnegan, Megan K.},
  editor = {Verguts, Tom},
  year = {2016},
  month = jan,
  volume = {11},
  pages = {e0145096},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0145096},
  file = {/Users/megcychosz/Zotero/storage/HWLB2LBI/Warlaumont and Finnegan - 2016 - Learning to Produce Syllabic Speech Sounds via Rew.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {1}
}

@article{warlaumontModelingEmergenceSyllabic2015,
  title = {Modeling the Emergence of Syllabic Structure},
  author = {Warlaumont, Anne S.},
  year = {2015},
  month = nov,
  volume = {53},
  pages = {61--65},
  issn = {00954470},
  doi = {10.1016/j.wocn.2015.06.004},
  abstract = {Most computational models that have addressed the development of consonant\textendash vowel syllable systems have assumed a preexisting tendency to produce syllabically structured utterances. For instance, the COSMO model assumes a consistent base of jaw movement upon which finer-grained articulatory patterns are learned, motivated by MacNeilage and Davis's frame-then-content theory (FCT). While research operating under this assumption has provided much useful information on infant speech development, it does not address the gradual transition from non-syllabic to syllabic sounds that occurs during the first seven months of human infancy. It is important to consider the role that learning plays in this very significant transition. This paper discusses two computational models that address how infants may learn to produce syllabic utterances. Future work should develop agent-based models of sound production that show how syllabicity itself can emerge in a population of agents.},
  file = {/Users/megcychosz/Zotero/storage/6QLSPG8M/Sebastián-Gallés-2005.-Cross-language-speech-perception.pdf;/Users/megcychosz/Zotero/storage/DYNPSZLP/Warlaumont - 2015 - Modeling the emergence of syllabic structure.pdf},
  journal = {Journal of Phonetics},
  language = {en}
}

@article{warlaumontSocialFeedbackLoop2014,
  title = {A {{Social Feedback Loop}} for {{Speech Development}} and {{Its Reduction}} in {{Autism}}},
  author = {Warlaumont, Anne S. and Richards, Jeffrey A. and Gilkerson, Jill and Oller, D. Kimbrough},
  year = {2014},
  month = jul,
  volume = {25},
  pages = {1314--1324},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797614531023},
  abstract = {We analyzed the microstructure of child-adult interaction during naturalistic, daylong, automatically labeled audio recordings (13,836 hr total) of children (8- to 48-month-olds) with and without autism. We found that an adult was more likely to respond when the child's vocalization was speech related rather than not speech related. In turn, a child's vocalization was more likely to be speech related if the child's previous speech-related vocalization had received an immediate adult response rather than no response. Taken together, these results are consistent with the idea that there is a social feedback loop between child and caregiver that promotes speech development. Although this feedback loop applies in both typical development and autism, children with autism produced proportionally fewer speech-related vocalizations, and the responses they received were less contingent on whether their vocalizations were speech related. We argue that such differences will diminish the strength of the social feedback loop and have cascading effects on speech development over time. Differences related to socioeconomic status are also reported.},
  file = {/Users/megcychosz/Zotero/storage/QKHYMBGF/Warlaumont et al. - 2014 - A Social Feedback Loop for Speech Development and .pdf},
  journal = {Psychological Science},
  language = {en},
  number = {7}
}

@book{warlaumontWarlaumontHomeBankCorpus2016,
  title = {Warlaumont {{HomeBank Corpus}}},
  author = {Warlaumont, A. and Pretzer, G.M. and Mendoza, S. and Walle, E.A.},
  year = {2016}
}

@article{warnerOrthographicVsMorphological2006,
  title = {Orthographic vs. Morphological Incomplete Neutralization Effects},
  author = {Warner, Natasha and Good, Erin and Jongman, Allard and Sereno, Joan},
  year = {2006},
  month = apr,
  volume = {34},
  pages = {285--293},
  issn = {00954470},
  doi = {10.1016/j.wocn.2004.11.003},
  abstract = {This study, following up on work on Dutch by Warner, Jongman, Sereno, and Kemps (2004. Journal of Phonetics, 32, 251\textendash 276), investigates the influence of orthographic distinctions and underlying morphological distinctions on the small sub-phonemic durational differences that have been called incomplete neutralization. One part of the previous work indicated that an orthographic geminate/ singleton distinction could cause speakers to produce an incomplete neutralization effect. However, one interpretation of the materials in that experiment is that they contain an underlying difference in the phoneme string at the level of concatenation of morphemes, rather than just an orthographic difference. Thus, the previous effect might simply be another example of incomplete neutralization of a phonemic distinction. The current experiment, also on Dutch, uses word pairs which have the same underlying morphological contrast, but do not differ in orthography. These new materials show no incomplete neutralization, and thus support the hypothesis that orthography, but not underlying morphological differences, can cause incomplete neutralization effects.},
  file = {/Users/megcychosz/Zotero/storage/SITT2VXE/Warner et al. - 2006 - Orthographic vs. morphological incomplete neutrali.pdf},
  journal = {Journal of Phonetics},
  language = {en},
  number = {2}
}

@article{watanabeFormantEstimationMethod2001,
  title = {Formant Estimation Method Using Inverse-Filter Control},
  author = {Watanabe, A.},
  year = {2001},
  volume = {9},
  pages = {317--326},
  journal = {IEEE Transactions on Speech and Audio Processing},
  number = {4}
}

@article{weberWhenCulturalNorms2017,
  title = {When {{Cultural Norms Discourage Talking}} to {{Babies}}: {{Effectiveness}} of a {{Parenting Program}} in {{Rural Senegal}}},
  shorttitle = {When {{Cultural Norms Discourage Talking}} to {{Babies}}},
  author = {Weber, Ann and Fernald, Anne and Diop, Yatma},
  year = {2017},
  month = sep,
  volume = {88},
  pages = {1513--1526},
  issn = {00093920},
  doi = {10.1111/cdev.12882},
  file = {/Users/megcychosz/Zotero/storage/2ZRATY3U/Weber et al. summary.rtf;/Users/megcychosz/Zotero/storage/56XU4HEB/Weber et al. - 2017 - When Cultural Norms Discourage Talking to Babies .pdf;/Users/megcychosz/Zotero/storage/JYNQJYN4/criticism of Weber et al..rtf},
  journal = {Child Development},
  language = {en},
  number = {5}
}

@article{wedelHighFunctionalLoad2013,
  title = {High Functional Load Inhibits Phonological Contrast Loss: {{A}} Corpus Study},
  shorttitle = {High Functional Load Inhibits Phonological Contrast Loss},
  author = {Wedel, Andrew and Kaplan, Abby and Jackson, Scott},
  year = {2013},
  month = aug,
  volume = {128},
  pages = {179--186},
  issn = {00100277},
  doi = {10.1016/j.cognition.2013.03.002},
  abstract = {For nearly a century, linguists have suggested that diachronic merger is less likely between phonemes with a high functional load \textendash{} that is, phonemes that distinguish many words in the language in question. However, limitations in data and computational power have made assessing this hypothesis difficult. Here we present the first larger-scale study of the functional load hypothesis, using data from sound changes in a diverse set of languages. Our results support the functional load hypothesis: phoneme pairs undergoing merger distinguish significantly fewer minimal pairs in the lexicon than unmerged phoneme pairs. Furthermore, we show that higher phoneme probability is positively correlated with merger, but that this effect is stronger for phonemes that distinguish no minimal pairs. Finally, within our dataset we find that minimal pair count and phoneme probability better predict merger than change in system entropy at the lexical or phoneme level.},
  file = {/Users/megcychosz/Zotero/storage/RG8LNEVL/Wedel et al. - 2013 - High functional load inhibits phonological contras.pdf},
  journal = {Cognition},
  language = {en},
  number = {2}
}

@book{weislederDaylongRecordings2122019,
  title = {Daylong Recordings of 2-12 Month-Old Infants from {{Spanish}}-Speaking Homes in the {{U}}.{{S}}.},
  author = {Weisleder, Adriana and Mendelsohn, A.},
  year = {2019}
}

@article{weislederTalkingChildrenMatters2013,
  title = {Talking to {{Children Matters}}: {{Early Language Experience Strengthens Processing}} and {{Builds Vocabulary}}},
  shorttitle = {Talking to {{Children Matters}}},
  author = {Weisleder, Adriana and Fernald, Anne},
  year = {2013},
  month = nov,
  volume = {24},
  pages = {2143--2152},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797613488145},
  abstract = {Infants differ substantially in their rates of language growth, and slow growth predicts later academic difficulties. In this study, we explored how the amount of speech directed to infants in Spanish-speaking families low in socioeconomic status influenced the development of children's skill in real-time language processing and vocabulary learning. Allday recordings of parent-infant interactions at home revealed striking variability among families in how much speech caregivers addressed to their child. Infants who experienced more child-directed speech became more efficient in processing familiar words in real time and had larger expressive vocabularies by the age of 24 months, although speech simply overheard by the child was unrelated to vocabulary outcomes. Mediation analyses showed that the effect of child-directed speech on expressive vocabulary was explained by infants' language-processing efficiency, which suggests that richer language experience strengthens processing skills that facilitate language growth.},
  file = {/Users/megcychosz/Zotero/storage/TI2A2QVN/Weisleder 2013 supporting methods.pdf;/Users/megcychosz/Zotero/storage/XRS37EFS/Weisleder and Fernald - 2013 - Talking to Children Matters Early Language Experi.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {11}
}

@article{welchEffectsSyllablefinalSegment2009,
  title = {Effects of Syllable-Final Segment Duration on the Identification of Synthetic Speech Continua by Birds and Humans},
  author = {Welch, Thomas E. and Sawusch, James R. and Dent, Micheal L.},
  year = {2009},
  volume = {126},
  pages = {2779--2787},
  issn = {0001-4966},
  doi = {10.1121/1.3212923},
  file = {/Users/megcychosz/Zotero/storage/G7NMDQGR/Welch et al. - 2009 - Effects of syllable-final segment duration on the .pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{werkerBilingualismInfancyFirst2008,
  title = {Bilingualism in Infancy: First Steps in Perception and Comprehension},
  shorttitle = {Bilingualism in Infancy},
  author = {Werker, Janet F. and {Byers-Heinlein}, Krista},
  year = {2008},
  month = apr,
  volume = {12},
  pages = {144--151},
  issn = {13646613},
  doi = {10.1016/j.tics.2008.01.008},
  file = {/Users/megcychosz/Zotero/storage/GRXHMAFC/Werker and Byers-Heinlein - 2008 - Bilingualism in infancy first steps in perception.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {4}
}

@article{werkerCrosslanguageSpeechPerception1984,
  title = {Cross-Language Speech Perception: {{Evidence}} for Perceptual Reorganization during the First Year of Life},
  author = {Werker, J. F. and Tees, R.C.},
  year = {1984},
  volume = {7},
  pages = {49--63},
  journal = {Infant Behavior and Development},
  number = {1}
}

@article{werkerPerceptualBeginningsLanguage2018,
  title = {Perceptual Beginnings to Language Acquisition},
  author = {Werker, Janet F.},
  year = {2018},
  month = jul,
  volume = {39},
  pages = {703--728},
  issn = {0142-7164, 1469-1817},
  doi = {10.1017/S0142716418000152},
  abstract = {In this article, I present a selective review of research on speech perception development and its relation to reference, word learning, and other aspects of language acquisition, focusing on the empirical and theoretical contributions that have come from my laboratory over the years. Discussed are the biases infants have at birth for processing speech, the mechanisms by which universal speech perception becomes attuned to the properties of the native language, and the extent to which changing speech perception sensitivities contribute to language learning. These issues are reviewed from the perspective of both monolingual and bilingual learning infants. Two foci will distinguish this from my previous reviews: first and foremost is the extent to which contrastive meaning and referential intent are not just shaped by, but also shape, changing speech perception sensitivities, and second is the extent to which infant speech perception is multisensory and its implications for both theory and methodology.},
  file = {/Users/megcychosz/Zotero/storage/XGTB4WVP/Werker - 2018 - Perceptual beginnings to language acquisition.pdf},
  journal = {Applied Psycholinguistics},
  language = {en},
  number = {04}
}

@article{werkerPRIMIRDevelopmentalFramework2005,
  title = {{{PRIMIR}}: {{A Developmental Framework}} of {{Infant Speech Processing}}},
  shorttitle = {{{PRIMIR}}},
  author = {Werker, Janet F. and Curtin, Suzanne},
  year = {2005},
  month = apr,
  volume = {1},
  pages = {197--234},
  issn = {1547-5441, 1547-3341},
  doi = {10.1080/15475441.2005.9684216},
  file = {/Users/megcychosz/Zotero/storage/DQKQBPBA/Werker and Curtin - 2005 - PRIMIR A Developmental Framework of Infant Speech.pdf},
  journal = {Language Learning and Development},
  language = {en},
  number = {2}
}

@article{westfallStatisticalPowerOptimal2014,
  title = {Statistical Power and Optimal Design in Experiments in Which Samples of Participants Respond to Samples of Stimuli.},
  author = {Westfall, Jacob and Kenny, David A. and Judd, Charles M.},
  year = {2014},
  volume = {143},
  pages = {2020--2045},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/xge0000014},
  abstract = {Researchers designing experiments in which a sample of participants responds to a sample of stimuli are faced with difficult questions about optimal study design. The conventional procedures of statistical power analysis fail to provide appropriate answers to these questions because they are based on statistical models in which stimuli are not assumed to be a source of random variation in the data, models that are inappropriate for experiments involving crossed random factors of participants and stimuli. In this article, we present new methods of power analysis for designs with crossed random factors, and we give detailed, practical guidance to psychology researchers planning experiments in which a sample of participants responds to a sample of stimuli. We extensively examine 5 commonly used experimental designs, describe how to estimate statistical power in each, and provide power analysis results based on a reasonable set of default parameter values. We then develop general conclusions and formulate rules of thumb concerning the optimal design of experiments in which a sample of participants responds to a sample of stimuli. We show that in crossed designs, statistical power typically does not approach unity as the number of participants goes to infinity but instead approaches a maximum attainable power value that is possibly small, depending on the stimulus sample. We also consider the statistical merits of designs involving multiple stimulus blocks. Finally, we provide a simple and flexible Web-based power application to aid researchers in planning studies with samples of stimuli.},
  file = {/Users/megcychosz/Zotero/storage/FFX75EKQ/Westfall et al. - 2014 - Statistical power and optimal design in experiment.pdf},
  journal = {Journal of Experimental Psychology: General},
  language = {en},
  number = {5}
}

@article{wexlerVeryEarlyParameter1998,
  title = {Very Early Parameter Setting and the Unique Checking Constraint: {{A}} New Explanation of the Optional Infinitive Stage},
  shorttitle = {Very Early Parameter Setting and the Unique Checking Constraint},
  author = {Wexler, Ken},
  year = {1998},
  month = dec,
  volume = {106},
  pages = {23--79},
  issn = {00243841},
  doi = {10.1016/S0024-3841(98)00029-1},
  abstract = {This paper argues that the traditional view of experience-dependent properties (learned properties) of language as developing late and non-experience-dependent properties as developing early is in fact often wrong. Parameters are set correctly very early (Very Early Parameter-setting) and properties of inflectional items are also learned very early. On the other hand, some universal properties of language emerge later, presumably under a genetically-driven maturational program. The Optional Infinitive(OI) Stage (Wexler, 1990, 1992, 1994) of grammatical development is explained by the AGR/TNS Omission Model (ATOM) of Schiitze and Wexler, (1996). This paper derives this model via a new proposal for a developmental constraint: the Unique Checking Constraint (UCC), which prevents a D-feature on DP from checking more than one D-feature on functional categories, thus forcing either AGR or TNS to be omitted. The Minimalist framework of Chomsky 1995 is assumed - in particular the assumption that a D-feature and not a case feature is the driving force for the Extended Projection Principle. With AGR and TNS both having a D-feature, UCC predicts that finite sentences will not converge. The mode1 also predicts that subjects of 01's will raise to a higher functional projection, even when case is not assigned by INFL, thus solving a traditional problem in the theory of 01's. With natural assumptions on the nature of null-subject languages, the Null-Subjection/Optional Infinitive Correlation of Wexler (1996) is derived from the UCC - that 01's exist in early child language if and only if the adult grammar is not an INFL-licensed null-subject language. Thus the UCC is seen as a fundamental explanatory force for a range of phenomena in early child grammar. Moreover the child data provide strong evidence for the claim that a D-feature motivates the raising of the subject in UG, thus unifying child and adult grammar and demonstrating the usefulness of the investigation of child grammar in the study of UG.},
  file = {/Users/megcychosz/Zotero/storage/EQTE2NCN/Wexler - 1998 - Very early parameter setting and the unique checki.pdf},
  journal = {Lingua},
  language = {en}
}

@article{whalenCoarticulationLargelyPlanned1990,
  title = {Coarticulation Is Largely Planned},
  author = {Whalen, D. H.},
  year = {1990},
  volume = {18},
  pages = {3--35},
  file = {/Users/megcychosz/Zotero/storage/39297NX4/Whalen_1990.pdf},
  journal = {Journal of Phonetics}
}

@article{whalenEffectsVocalicFormant1981,
  title = {Effects of Vocalic Formant Transitions and Vowel Quality on the {{English}} [s]-[{{S}}] Boundary},
  author = {Whalen, D.},
  year = {1981},
  volume = {69},
  pages = {275--282},
  journal = {The Journal of the Acoustical Society of America},
  number = {1}
}

@article{whalenVariabilityCentralTendencies2019,
  title = {Variability and {{Central Tendencies}} in {{Speech Production}}},
  author = {Whalen, D. H. and Chen, Wei-Rong},
  year = {2019},
  month = sep,
  volume = {4},
  pages = {49},
  issn = {2297-900X},
  doi = {10.3389/fcomm.2019.00049},
  abstract = {Speech is notoriously variable, but our understanding of this variability continues to evolve. Variability has typically been taken as an indication of failure to reach a desired target due to physical or neurological limits. However, it is likely that some variability is beneficial, an effect that has been found in other domains. Part of the effort to separate beneficial from destructive variability must be to understand the distribution of values around a speech target. One aspect that is commonly measured is the standard deviation of some objective aspect of speech. The standard deviation is most meaningful for normal distributions, and the assumption in speech research has been that values are indeed normally distributed. This has not been rigorously tested, however, as the test of normality requires a large number of samples (some studies suggest a minimum of 200) to determine whether the data is normally distributed or not. Speech research (and, indeed, most research with humans) seldom reaches such numbers for a consistent environment. Here, an initial estimate for 300 repetitions of English words by a single speaker are presented. The words were pseudo-randomized with an equal number of filler items, so that immediate repetitions (and the neural and physical fatigue repetition can cause) were avoided. One hundred trials were collected on each of 3 days. Words were chosen to have very little coarticulatory influence (``heed,'' ``ode''/``owed'') or sizable coarticulatory influence (``geek,'' ``dote''). Measurements of vowel formants at acoustic midpoints indicated that the distributions were indeed normal. This was true even of the high coarticulatory environment, which some theories would predict would be skewed by the vowel's reaching the edge of an acceptable region. The current results indicate that vowel targets are consistent for different environments. Further, the range of the distributions was quite similar across the two types of environment, being, for example, about 100 Hz for F1. The amount of variability is fairly substantial but can be presumed to be beneficial, as all items were heard correctly. The normality of the distribution nonetheless indicates a control structure that accommodates the coarticulatory environment at the level of planning.},
  file = {/Users/megcychosz/Zotero/storage/KLEHSDBK/Whalen and Chen - 2019 - Variability and Central Tendencies in Speech Produ.pdf},
  journal = {Frontiers in Communication},
  language = {en}
}

@article{whitehurstOutcomesEmergentLiteracy1994,
  title = {Outcomes of an Emergent Literacy Intervention in {{Head Start}}},
  author = {Whitehurst, G.J. and Epstein, J.N. and Angel, A.L. and Payne, A.C. and Crone, D.A. and Fischel, J.E.},
  year = {1994},
  volume = {86},
  pages = {542--555},
  journal = {Journal of Educational Psychology},
  number = {4}
}

@article{whitesideSpeechPatternsChildren2000,
  title = {Speech Patterns of Children and Adults Elicited via a Picture-Naming Task: {{An}} Acoustic Study},
  shorttitle = {Speech Patterns of Children and Adults Elicited via a Picture-Naming Task},
  author = {Whiteside, S.P. and Hodgson, C.},
  year = {2000},
  month = nov,
  volume = {32},
  pages = {267--285},
  issn = {01676393},
  doi = {10.1016/S0167-6393(00)00013-3},
  abstract = {This brief study presents some acoustic phonetic characteristics that re\textasciimacron ect both the voice characteristics and motor speech behaviour of 20 pre-adolescent (6-, 8- and 10-year olds) boys and girls, and 9 adults in speech data that were elicited via a picture-naming task. The acoustic phonetic characteristics that were investigated included formant frequency values, coarticulation (or gestural overlap) and temporal patterns. Both voice characteristics and motor speech behaviour presented evidence of age and sex dierences, and age by sex interactions. In addition there were signi\textregistered cant correlations between formant frequencies and their associated formant frequency changes (or excursions). There was also evidence of individual dierences in the patterns of maturation, which did not conform to chronological age. These data are presented and discussed with reference to the sexual dimorphism of the vocal apparatus, the development of vocal characteristics, and motor speech development and behaviour. \'O 2000 Elsevier Science B.V. All rights reserved.},
  file = {/Users/megcychosz/Zotero/storage/RE8ITBRL/Whiteside and Hodgson - 2000 - Speech patterns of children and adults elicited vi.pdf},
  journal = {Speech Communication},
  language = {en},
  number = {4}
}

@book{wickhamGgplot2ElegantGraphics2016,
  title = {Ggplot2: {{Elegant Graphics}} for {{Data Analysis}}},
  author = {Wickham, Hadley},
  year = {2016},
  publisher = {{Springer-Verlag New York}},
  address = {{New York}}
}

@article{wileyAccessCochlearImplant2009,
  title = {Access to Cochlear Implant Candidacy Evaluations: {{Who}} Is {\emph{Not}} Making It to the Team Evaluations?},
  shorttitle = {Access to Cochlear Implant Candidacy Evaluations},
  author = {Wiley, Susan and {Meinzen-Derr}, Jareen},
  year = {2009},
  month = jan,
  volume = {48},
  pages = {74--79},
  issn = {1499-2027, 1708-8186},
  doi = {10.1080/14992020802475227},
  abstract = {The objective of this study was to investigate trends in the referral process among pediatric cochlear implant candidates. Medical and audiologic charts between 2003 and 2005 were reviewed, and children five years and younger with moderately-severe or worse sensorineural hearing loss were included. Of the 105 audiograms meeting the inclusion criteria, 69\% were referred for a cochlear implant, and 52\% were considered as definite candidates for an implant by audiologists with expertise in cochlear implant technology. Children referred for an implant, compared to children who were not referred, were more likely to have married parents (91\% vs. 70\%, p00.02) and more likely to have private insurance (56\% vs. 29\%, p0 0.02). Multivariable regression results were consistent with the unadjusted findings regarding marital status, but not insurance status. Children with sensorineural hearing loss are inconsistently referred to cochlear implant teams despite similar audiologic findings. To reach the Healthy People 2010 goals, this disparity should be addressed. A further understanding of the population of children not referred is important in diminishing inconsistencies and understanding barriers to care.},
  file = {/Users/megcychosz/Zotero/storage/82ZCA8WX/Wiley and Meinzen-Derr - 2009 - Access to cochlear implant candidacy evaluations .pdf},
  journal = {International Journal of Audiology},
  language = {en},
  number = {2}
}

@article{willadsenAssessmentPrelinguisticVocalizations2020,
  title = {Assessment of Prelinguistic Vocalizations in Real Time: A Comparison with Phonetic Transcription and Assessment of Inter-Coder-Reliability},
  shorttitle = {Assessment of Prelinguistic Vocalizations in Real Time},
  author = {Willadsen, Elisabeth and Persson, Christina and Patrick, Kathryn and Lohmander, Anette and Oller, D. Kimbrough},
  year = {2020},
  month = jul,
  volume = {34},
  pages = {593--616},
  issn = {0269-9206, 1464-5076},
  doi = {10.1080/02699206.2019.1681516},
  abstract = {This study iinnvveessttiiggaatted reliability of naturaallistic lliisstteening in real time (NLRT) compared to phonetic transcription. SSppeech pathology stu-\- dents with brief training in NLRT assessed prelinguistic sylllaable iinnvveen-\- tory size and speecciiffiic sylllaable types in typically developing iinnfants. A second study also examined iinnter-ccooder reliability for canonniicaall babbling, canonniical babbling ratio and presence of oral stops in sylllaable iinnvveentory of inffaants with cleft palate, by means of NLRT.},
  file = {/Users/megcychosz/Zotero/storage/MKX83MAI/Willadsen et al. - 2020 - Assessment of prelinguistic vocalizations in real .pdf},
  journal = {Clinical Linguistics \& Phonetics},
  language = {en},
  number = {7}
}

@book{williamsExpressiveVocabularyTest2007,
  title = {Expressive {{Vocabulary Test}}, {{Second Edition}}},
  author = {Williams, K.T.},
  year = {2007},
  edition = {Second},
  publisher = {{Pearson Education}},
  address = {{San Antonio, TX}}
}

@article{wilsenachPhonologicalSkillsPredictor2013,
  title = {Phonological Skills as Predictor of Reading Success: {{An}} Investigation of Emergent Bilingual {{Northern Sotho}}/{{English}} Learners},
  shorttitle = {Phonological Skills as Predictor of Reading Success},
  author = {Wilsenach, Carien},
  year = {2013},
  month = dec,
  volume = {29},
  issn = {2224-0012, 0259-2312},
  doi = {10.5785/29-2-554},
  file = {/Users/megcychosz/Zotero/storage/6MYYT4S2/Wilsenach - 2013 - Phonological skills as predictor of reading succes.pdf},
  journal = {Per Linguam},
  language = {en},
  number = {2}
}

@techreport{xuReliabilityLENALanguage2009,
  title = {Reliability of the {{LENA Language Environment Analysis System}} in Young Children's Natural Home Environment},
  author = {Xu, D. and Yapanel, U. and Gray, S.},
  year = {2009},
  address = {{Boulder, CO}},
  institution = {{LENA Research Foundation}},
  type = {Technical {{Report lTR}}-05-2}
}

@article{yangFormalistPerspectiveLanguage2018,
  title = {A Formalist Perspective on Language Acquisition},
  author = {Yang, Charles},
  year = {2018},
  month = nov,
  volume = {8},
  pages = {665--706},
  issn = {1879-9264, 1879-9272},
  doi = {10.1075/lab.18014.yan},
  abstract = {Language acquisition is a computational process by which linguistic experience is integrated into the learner's initial stage of knowledge. To understand language acquisition thus requires precise statements about these components and their interplay, stepping beyond the philosophical and methodological disputes such as the generative vs. usage-based approaches. I review several mathematical models that have guided the study of child language acquisition: How learners integrate experience with their prior knowledge of linguistic structures, How researchers assess the progress of language acquisition with rigor and clarity, and How children form the rules of language even in the face of exceptions. I also suggest that these models are applicable to second language acquisition (L2), yielding potentially important insights on the continuities and di erences between child and adult language.},
  file = {/Users/megcychosz/Zotero/storage/HE2GVYXP/Yang - 2018 - A formalist perspective on language acquisition.pdf},
  journal = {Linguistic Approaches to Bilingualism},
  language = {en},
  number = {6}
}

@article{yangGrowthLanguageUniversal2017,
  title = {The Growth of Language: {{Universal Grammar}}, Experience, and Principles of Computation},
  shorttitle = {The Growth of Language},
  author = {Yang, Charles and Crain, Stephen and Berwick, Robert C. and Chomsky, Noam and Bolhuis, Johan J.},
  year = {2017},
  month = oct,
  volume = {81},
  pages = {103--119},
  issn = {01497634},
  doi = {10.1016/j.neubiorev.2016.12.023},
  abstract = {Human infants develop language remarkably rapidly and without overt instruction. We argue that the distinctive ontogenesis of child language arises from the interplay of three factors: domain-specific principles of language (Universal Grammar), external experience, and properties of non-linguistic domains of cognition including general learning mechanisms and principles of efficient computation. We review developmental evidence that children make use of hierarchically composed structures (`Merge') from the earliest stages and at all levels of linguistic organization. At the same time, longitudinal trajectories of development show sensitivity to the quantity of specific patterns in the input, which suggests the use of probabilistic processes as well as inductive learning mechanisms that are suitable for the psychological constraints on language acquisition. By considering the place of language in human biology and evolution, we propose an approach that integrates principles from Universal Grammar and constraints from other domains of cognition. We outline some initial results of this approach as well as challenges for future research.},
  file = {/Users/megcychosz/Zotero/storage/JUFWHM6V/Yang et al. - 2017 - The growth of language Universal Grammar, experie.pdf},
  journal = {Neuroscience \& Biobehavioral Reviews},
  language = {en}
}

@article{yangUniversalGrammarStatistics2004,
  title = {Universal {{Grammar}}, Statistics or Both?},
  author = {Yang, Charles D.},
  year = {2004},
  month = oct,
  volume = {8},
  pages = {451--456},
  issn = {13646613},
  doi = {10.1016/j.tics.2004.08.006},
  file = {/Users/megcychosz/Zotero/storage/2WYRANCH/Yang - 2004 - Universal Grammar, statistics or both.pdf},
  journal = {Trends in Cognitive Sciences},
  language = {en},
  number = {10}
}

@article{yaoCognitiveBasisContactinduced2016,
  title = {On the Cognitive Basis of Contact-Induced Sound Change: {{Vowel}} Merger Reversal in {{Shanghainese}}},
  shorttitle = {On the Cognitive Basis of Contact-Induced Sound Change},
  author = {Yao, Yao and Chang, Charles B.},
  year = {2016},
  volume = {92},
  pages = {433--467},
  issn = {1535-0665},
  doi = {10.1353/lan.2016.0031},
  file = {/Users/megcychosz/Zotero/storage/BEV6QQ7A/Yao and Chang - 2016 - On the cognitive basis of contact-induced sound ch.pdf},
  journal = {Language},
  language = {en},
  number = {2}
}

@article{yeungLipMovementsAffect2013,
  title = {Lip {{Movements Affect Infants}}' {{Audiovisual Speech Perception}}},
  author = {Yeung, H. Henny and Werker, Janet F.},
  year = {2013},
  month = may,
  volume = {24},
  pages = {603--612},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797612458802},
  abstract = {Speech is robustly audiovisual from early in infancy. Here we show that audiovisual speech perception in 4.5-monthold infants is influenced by sensorimotor information related to the lip movements they make while chewing or sucking. Experiment 1 consisted of a classic audiovisual matching procedure, in which two simultaneously displayed talking faces (visual [i] and [u]) were presented with a synchronous vowel sound (audio /i/ or /u/). Infants' looking patterns were selectively biased away from the audiovisual matching face when the infants were producing lip movements similar to those needed to produce the heard vowel. Infants' looking patterns returned to those of a baseline condition (no lip movements, looking longer at the audiovisual matching face) when they were producing lip movements that did not match the heard vowel. Experiment 2 confirmed that these sensorimotor effects interacted with the heard vowel, as looking patterns differed when infants produced these same lip movements while seeing and hearing a talking face producing an unrelated vowel (audio /a/). These findings suggest that the development of speech perception and speech production may be mutually informative.},
  file = {/Users/megcychosz/Zotero/storage/62G2MJKN/Yeung and Werker - 2013 - Lip Movements Affect Infants’ Audiovisual Speech P.pdf},
  journal = {Psychological Science},
  language = {en},
  number = {5}
}

@article{yuenFiveyearoldsProduceProsodic2020,
  title = {Five-Year-Olds Produce Prosodic Cues to Distinguish Compounds from Lists in {{Australian English}}},
  author = {Yuen, Ivan and Xu Rattanasone, Nan and Schmidt, Elaine and Macdonald, Gretel and Holt, Rebecca and Demuth, Katherine},
  year = {2020},
  month = may,
  pages = {1--19},
  issn = {0305-0009, 1469-7602},
  doi = {10.1017/S0305000920000227},
  abstract = {Although previous research has indicated that five-year-olds can use acoustic cues to disambiguate compounds (N1 + N2) from lists (N1, N2) (e.g., `ice-cream' vs. `ice, cream') (Yoshida \& Katz, 2004, 2006), their productions are not yet fully adult-like (Wells, Pepp\'e \& Goulandris, 2004). The goal of this study was to examine this issue in Australian English-speaking children, with a focus on their use of F0, word duration, and pauses. Twenty-four five-year-olds and 20 adults participated in an elicited production experiment. Like adults, children produced distinct F0 patterns for the two structures. They also used longer word durations and more pauses in lists compared to compounds, indicating the presence of a boundary in lists. However, unlike adults, they also inappropriately inserted more pauses within the compound, suggesting the presence of a boundary in compounds as well. The implications for understanding children's developing knowledge of how to map acoustic cues to prosodic structures are discussed.},
  file = {/Users/megcychosz/Zotero/storage/S5PHA28J/Yuen et al. - 2020 - Five-year-olds produce prosodic cues to distinguis.pdf},
  journal = {Journal of Child Language},
  language = {en}
}

@article{yuNaturePerceptionproductionLink2019,
  title = {On the Nature of the Perception-Production Link: {{Individual}} Variability in {{English}} Sibilant-Vowel Coarticulation},
  shorttitle = {On the Nature of the Perception-Production Link},
  author = {Yu, Alan C. L.},
  year = {2019},
  month = feb,
  volume = {10},
  pages = {2},
  issn = {1868-6354},
  doi = {10.5334/labphon.97},
  file = {/Users/megcychosz/Zotero/storage/QHQGHATV/Yu - 2019 - On the nature of the perception-production link I.pdf},
  journal = {Laboratory Phonology: Journal of the Association for Laboratory Phonology},
  language = {en},
  number = {1}
}

@article{yuStabilityPerceptualCompensation2014,
  title = {The Stability of Perceptual Compensation for Coarticulation within and across Individuals: {{A}} Cross-Validation Study},
  shorttitle = {The Stability of Perceptual Compensation for Coarticulation within and across Individuals},
  author = {Yu, Alan C. L. and Lee, Hyunjung},
  year = {2014},
  month = jul,
  volume = {136},
  pages = {382--388},
  issn = {0001-4966},
  doi = {10.1121/1.4883380},
  file = {/Users/megcychosz/Zotero/storage/PN83R4YP/Yu and Lee - 2014 - The stability of perceptual compensation for coart.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {1}
}

@article{zamunerAcquisitionPhonologyBased2005,
  title = {The Acquisition of Phonology Based on Input: A Closer Look at the Relation of Cross-Linguistic and Child Language Data},
  shorttitle = {The Acquisition of Phonology Based on Input},
  author = {Zamuner, Tania S. and Gerken, LouAnn and Hammond, Michael},
  year = {2005},
  month = oct,
  volume = {115},
  pages = {1403--1426},
  issn = {00243841},
  doi = {10.1016/j.lingua.2004.06.005},
  abstract = {Parallels between cross-linguistic and child language data have been used to support a theory of language development in which acquisition is mediated by universal grammar (Universal Grammar Hypothesis\textemdash UGH). However, structures that are frequent across languages are also typically the most frequent within a specific language. This confounding of cross-linguistic and language-specific data is consistent with the hypothesis that children acquire the grammar of the specific languages to which they are exposed, based on a less constrained acquisition mechanism (Specific Language Grammar Hypothesis\textemdash SLGH). These two theories of acquisition are contrasted in an examination of English-speaking children's acquisition of codas. Predictions for the UGH were based on crosslinguistic patterns and on frequency analyses of codas from 35 languages. Results showed that languages prefer coronal and sonorant codas; however, children's productions did not favor these codas. Predictions for the SLGH were established on the frequency of English codas, and significant correlations were found between children's coda productions and the frequency of English codas.},
  file = {/Users/megcychosz/Zotero/storage/N7BGZD57/Zamuner et al. - 2005 - The acquisition of phonology based on input a clo.pdf},
  journal = {Lingua},
  language = {en},
  number = {10}
}

@article{zamunerManyFacetsSpeech2017,
  title = {The Many Facets of Speech Production and Its Complex Effects on Phonological Processing},
  author = {Zamuner, Tania S. and Yeung, H. Henny and Ducos, Myriam},
  year = {2017},
  month = feb,
  volume = {108},
  pages = {37--39},
  issn = {00071269},
  doi = {10.1111/bjop.12220},
  file = {/Users/megcychosz/Zotero/storage/AEH533SA/Zamuner et al. - 2017 - The many facets of speech production and its compl.pdf;/Users/megcychosz/Zotero/storage/B5FEH7LP/4177625.pdf},
  journal = {British Journal of Psychology},
  language = {en},
  number = {1}
}

@article{zamunerPhonologicalLexicalPhonetic2018,
  title = {A Phonological, Lexical, and Phonetic Analysis of the New Words That Young Children Imitate},
  author = {Zamuner, Tania S. and Thiessen, Andrea},
  year = {2018},
  month = dec,
  volume = {63},
  pages = {609--632},
  issn = {0008-4131, 1710-1115},
  doi = {10.1017/cnj.2018.10},
  abstract = {As children learn language, they spontaneously imitate the speech of those around them. This article investigates the new words that five children imitated between 1 and 2 years of age. Children were more likely to imitate new words as they aged and as their productive language developed. After controlling for age, children also were more likely to imitate new words that were shorter and with high neighborhood densities, and that contained sounds the children had previously produced accurately. Together, the findings demonstrate that both the patterns of the target words and children's productive abilities are predictors of children's imitative speech. This supports models of language development where there are influences stemming not only from phonological and lexical representations, but also from phonetic representations.},
  file = {/Users/megcychosz/Zotero/storage/GTMV2824/Zamuner and Thiessen - 2018 - A phonological, lexical, and phonetic analysis of .pdf},
  journal = {Canadian Journal of Linguistics/Revue canadienne de linguistique},
  language = {en},
  number = {4}
}

@article{zamunerPhonotacticProbabilitiesOnset2009,
  title = {Phonotactic {{Probabilities}} at the {{Onset}} of {{Language Development}}: {{Speech Production}} and {{Word Position}}},
  shorttitle = {Phonotactic {{Probabilities}} at the {{Onset}} of {{Language Development}}},
  author = {Zamuner, Tania S.},
  year = {2009},
  month = feb,
  volume = {52},
  pages = {49--60},
  issn = {1092-4388, 1558-9102},
  doi = {10.1044/1092-4388(2008/07-0138)},
  abstract = {Purpose: To examine the role of phonotactic probabilities at the onset of language development, in a new language (Dutch), while controlling for word position. Method: Using a nonword imitation task, 64 Dutch-learning children (age 2;2\textendash 2;8 [years;months]) were tested on how they imitated segments in low- and high-phonotactic probability environments, in word-initial and word-final position. The relationship between phonological representations and vocabulary development was examined by comparing children's performance with their receptive and expressive vocabularies. Results: Segments in high-phonotactic probability environments were at an advantage in production, in both word-initial and word-final position. Significant correlations were found between vocabulary size and children's mean segment repetition accuracy for word-initial position, but not in word-final position. Conclusion: The results indicate that phonological representations are mediated not only by children's developing vocabularies but also by the structure of children's emerging lexicons.},
  file = {/Users/megcychosz/Zotero/storage/WXA8MAZL/Zamuner - 2009 - Phonotactic Probabilities at the Onset of Language.pdf},
  journal = {Journal of Speech, Language, and Hearing Research},
  language = {en},
  number = {1}
}

@article{zamunerReverseProductionEffect2018,
  title = {Reverse Production Effect: Children Recognize Novel Words Better When They Are Heard Rather than Produced},
  shorttitle = {Reverse Production Effect},
  author = {Zamuner, Tania S. and Strahm, Stephanie and {Morin-Lessard}, Elizabeth and Page, Michael P.A.},
  year = {2018},
  month = jul,
  volume = {21},
  pages = {e12636},
  issn = {1363755X},
  doi = {10.1111/desc.12636},
  abstract = {This research investigates the effect of production on 4.5- to 6-year-old children's recognition of newly learned words. In Experiment 1, children were taught four novel words in a produced or heard training condition during a brief training phase. In Experiment 2, children were taught eight novel words, and this time training condition was in a blocked design. Immediately after training, children were tested on their recognition of the trained novel words using a preferential looking paradigm. In both experiments, children recognized novel words that were produced and heard during training, but demonstrated better recognition for items that were heard. These findings are opposite to previous results reported in the literature with adults and children. Our results show that benefits of speech production for word learning are dependent on factors such as task complexity and the developmental stage of the learner.},
  file = {/Users/megcychosz/Zotero/storage/95IGMXRH/Zamuner et al. - 2018 - Reverse production effect children recognize nove.pdf},
  journal = {Developmental Science},
  language = {en},
  number = {4}
}

@article{zamunerSpokenWordRecognition2016,
  title = {Spoken Word Recognition of Novel Words, Either Produced or Only Heard during Learning},
  author = {Zamuner, Tania S. and {Morin-Lessard}, Elizabeth and Strahm, Stephanie and Page, Michael P.A.},
  year = {2016},
  month = aug,
  volume = {89},
  pages = {55--67},
  issn = {0749596X},
  doi = {10.1016/j.jml.2015.10.003},
  abstract = {Psycholinguistic models of spoken word production differ in how they conceptualize the relationship between lexical, phonological and output representations, making different predictions for the role of production in language acquisition and language processing. This work examines the impact of production on spoken word recognition of newly learned non-words. In Experiment 1, adults were trained on non-words with visual referents; during training, they produced half of the non-words, with the other half being heardonly. Using a visual world paradigm at test, eye tracking results indicated faster recognition of non-words that were produced compared with heard-only during training. In Experiment 2, non-words were correctly pronounced or mispronounced at test. Participants showed a different pattern of recognition for mispronunciation on nonwords that were produced compared with heard-only during training. Together these results indicate that production affects the representations of newly learned words.},
  file = {/Users/megcychosz/Zotero/storage/ALZ3RDMS/Zamuner et al. - 2016 - Spoken word recognition of novel words, either pro.pdf},
  journal = {Journal of Memory and Language},
  language = {en}
}

@article{zeanahCaseStudyEthics2014,
  title = {Case {{Study}} in {{Ethics}} of {{Research}}: {{The Bucharest Early Intervention Project}}},
  author = {Zeanah, Charles H and Fox, Nathan A and Nelson, Charles A},
  year = {2014},
  pages = {11},
  abstract = {The Bucharest Early Intervention Project is the first ever randomized controlled trial of foster care as an alternative to institutional care for young abandoned children. This paper examines ethical issues in the conceptualization and implementation of the study, which involved American investigators conducting research in another country, as well as vulnerable participants. We organize discussion of ethical questions about the study around several key issues. These include the nature and location of the vulnerable study population, the social value of conducting the study, risks and benefits of participating in the study to participants, and the post-trial obligations of the investigators. In discussing how these questions were addressed as the study was designed and after it was initiated, we describe our attempts to wed sound scientific practices with meaningful ethical protections for participants.},
  file = {/Users/megcychosz/Zotero/storage/3WZPZV54/Zeanah et al. - 2014 - Case Study in Ethics of Research The Bucharest Ea.pdf},
  language = {en}
}

@article{zeanahEthicalConsiderationsInternational2006,
  title = {Ethical Considerations in International Research Collaboration: {{The Bucharest}} Early Intervention Project},
  shorttitle = {Ethical Considerations in International Research Collaboration},
  author = {Zeanah, Charles H. and Koga, Sebastian F. and Simion, Bogdan and Stanescu, Alin and Tabacaru, Cristian L. and Fox, Nathan A. and Nelson, Charles A. and {BEIP CORE GROUP}},
  year = {2006},
  month = nov,
  volume = {27},
  pages = {559--576},
  issn = {01639641, 10970355},
  doi = {10.1002/imhj.20107},
  abstract = {The Bucharest Early Intervention Project ͑BEIP͒ is the first ever randomized controlled trial of foster care as an alternative to institutional care for young children. It involved a collaboration between American investigators and Romanian health and child protection professionals. We present a brief description of the Romanian context and the project itself before discussing a number of ethical issues raised by the project. Organized around a discussion of exploitation, risk/benefit ratio, and cultural sensitivity, we evaluate a number of ethical issues involved in the BEIP using the Ethical Clinical Research Framework and the Fair Benefits Framework. Based on this review, we conclude that notwithstanding challenging ethical dilemmas, the benefits of the project outweighed its risks. Throughout the planning and implementation of the project, ethical issues were a central focus of discussion among the investigators and in the collaboration between Americans and Romanians. Thoughtful discussions from multiple perspectives are necessary to conduct research that is ethically sound and scientifically meaningful.},
  file = {/Users/megcychosz/Zotero/storage/B6L6CA4F/Zeanah et al. - 2006 - Ethical considerations in international research c.pdf},
  journal = {Infant Mental Health Journal},
  language = {en},
  number = {6}
}

@incollection{zeanahOrphanagesDevelopmentalContext2006,
  title = {Orphanages as a Developmental Context for Early Childhood},
  booktitle = {Blackwell Handbook of Early Childhood Development},
  author = {Zeanah, Charles H and Smyke, Anna and Settles, Lisa},
  year = {2006},
  pages = {424--454},
  file = {/Users/megcychosz/Zotero/storage/XXMWRWLS/1425497.pdf}
}

@article{zellouLexicallyConditionedPhonetic2015,
  title = {Lexically Conditioned Phonetic Variation in Motherese: Age-of-Acquisition and Other Word-Specific Factors in Infant- and Adult-Directed Speech},
  shorttitle = {Lexically Conditioned Phonetic Variation in Motherese},
  author = {Zellou, Georgia and Scarborough, Rebecca},
  year = {2015},
  month = jan,
  volume = {6},
  issn = {1868-6346, 1868-6354},
  doi = {10.1515/lp-2015-0010},
  abstract = {Words produced to infants exhibit phonetic modifications relative to speech to adult interlocutors, such as longer, more canonical segments and prosodic enhancement. Meanwhile, within speech directed towards adults, phonetic variation is conditioned by word properties: lower word frequency and higher phonological neighborhood density (ND) correlate with increased hyperarticulation and degree of coarticulation. Both of these types of findings have interpretations that recruit listener-directed motivations, suggesting that talkers modify their speech in an effort to enhance the perceptibility of the speech signal. In that vein, the present study examines lexically-conditioned variation in infant-directed speech. Specifically, we predict that the adult-reported age at which a word was learned \textendash{} lexical age-of-acquisition (AoA) \textendash{} conditions phonetic variation in infant-directed speech. This prediction is indeed borne out in spontaneous infant-directed speech: later-acquired words are produced with more hyperarticulated vowels and a greater degree of nasal coarticulation. Meanwhile, ND predicts phonetic variation in data from spontaneous adultdirected speech, while AoA does not independently influence production. The patterns of findings in the current study support the stance that evaluation of the need for clarity is tuned to the listener. Lexical difficulty is evaluated by AoA in infant-directed speech, while ND is most relevant in adult-directed speech.},
  file = {/Users/megcychosz/Zotero/storage/KP3BH5DK/Zellou and Scarborough - 2015 - Lexically conditioned phonetic variation in mother.pdf},
  journal = {Laboratory Phonology},
  language = {en},
  number = {3-4}
}

@inproceedings{zhangAutomatedClassificationChildren2018,
  title = {Automated {{Classification}} of {{Children}}'s {{Linguistic}} versus {{Non}}-{{Linguistic Vocalisations}}},
  booktitle = {Proceedings of {{Interspeech}} 2018},
  author = {Zhang, Zixing and Cristia, Alejandrina and Warlaumont, Anne S and Schuller, Bjorn},
  year = {2018},
  address = {{Hyderabad, India}},
  abstract = {A key outstanding task for speech technology involves dealing with non-standard speakers, notably young children. Distinguishing children's linguistic from non-linguistic vocalisations is crucial for a number of applied and fundamental research goals, and yet there are few systems available for such a classification. This paper investigates two large-scale framelevel acoustic feature sets (eGeMAPS and ComParE16) followed by a dynamic model (GRU-RNN), and two kinds of derived static feature sets on the segment level (functional-based and Bag of Audio Words) combined with a static model (SVM), and automatically learnt representations directly from original raw voice signals by using an end-to-end system. These are applied to a large database of children's vocalisations (total N = 6,298) drawn from daylong recordings gathered in Namibia, Bolivia, and Vanuatu. Among these systems, the one implemented with GRU-RNN using ComParE16 features empirically performs best. We further identify promising paths of further research, including the application of a finer-grained classification of children's vocalisations onto these data, and the exploration of other feature systems.},
  file = {/Users/megcychosz/Zotero/storage/DSPHJ6MM/Zhang et al. - Automated Classiﬁcation of Children’s Linguistic v.pdf},
  language = {en}
}

@article{zharkovaCoarticulationIndicatorSpeech2011,
  title = {Coarticulation as an {{Indicator}} of {{Speech Motor Control Development}} in {{Children}}: {{An Ultrasound Study}}},
  shorttitle = {Coarticulation as an {{Indicator}} of {{Speech Motor Control Development}} in {{Children}}},
  author = {Zharkova, Natalia and Hewlett, Nigel and Hardcastle, William J.},
  year = {2011},
  month = jan,
  volume = {15},
  pages = {118--140},
  issn = {1087-1640, 1543-2696},
  doi = {10.1123/mcj.15.1.118},
  file = {/Users/megcychosz/Zotero/storage/I4S2CH8S/Zharkova et al. - 2011 - Coarticulation as an Indicator of Speech Motor Con.pdf},
  journal = {Motor Control},
  language = {en},
  number = {1}
}

@article{zharkovaDynamicsVoicelessSibilant2018,
  title = {The Dynamics of Voiceless Sibilant Fricative Production in Children between 7 and 13 Years Old: {{An}} Ultrasound and Acoustic Study},
  shorttitle = {The Dynamics of Voiceless Sibilant Fricative Production in Children between 7 and 13 Years Old},
  author = {Zharkova, Natalia and Hardcastle, William J. and Gibbon, Fiona E.},
  year = {2018},
  month = sep,
  volume = {144},
  pages = {1454--1466},
  issn = {0001-4966},
  doi = {10.1121/1.5053585},
  file = {/Users/megcychosz/Zotero/storage/PQJN9XHI/Zharkova et al. - 2018 - The dynamics of voiceless sibilant fricative produ.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {3}
}

@article{zharkovaSpatialTemporalLingual2014,
  title = {Spatial and {{Temporal Lingual Coarticulation}} and {{Motor Control}} in {{Preadolescents}}},
  author = {Zharkova, Natalia and Hewlett, Nigel and Hardcastle, William J. and Lickley, Robin J.},
  year = {2014},
  month = apr,
  volume = {57},
  pages = {374--388},
  issn = {1092-4388},
  doi = {10.1044/2014_JSLHR-S-11-0350},
  abstract = {Purpose: In this study, the authors compared coarticulation and lingual kinematics in preadolescents and adults in order to establish whether preadolescents had a greater degree of random variability in tongue posture and whether their patterns of lingual coarticulation differed from those of adults. Method: High-speed ultrasound tongue contour data synchronized with the acoustic signal were recorded from 15 children (ages 10\textendash 12 years) and 15 adults. Tongue shape contours were analyzed at 9 normalized time points during the fricative phase of schwa-fricative-/a / and schwa-fricative-/i/ sequences with the consonants /s/ and /{$\Elzesh$} /. Results: There was no significant age-related difference in random variability. Where a significant vowel effect occurred, the amount of coarticulation was similar in the 2 groups. However, the onset of the coarticulatory effect on preadolescent /{$\Elzesh$} / was significantly later than on preadolescent /s/, and also later than on adult /s/ and /{$\Elzesh$} /. Conclusions: Preadolescents have adult-like precision of tongue control and adult-like anticipatory lingual coarticulation with respect to spatial characteristics of tongue posture. However, there remains some immaturity in the motor programming of certain complex tongue movements.},
  file = {/Users/megcychosz/Zotero/storage/78LVAB7H/Zharkova et al. - 2014 - Spatial and Temporal Lingual Coarticulation and Mo.pdf},
  journal = {Journal of Speech Language and Hearing Research},
  language = {en},
  number = {2}
}

@article{zharkovaUltrasoundAcousticAnalysis2016,
  title = {Ultrasound and Acoustic Analysis of Sibilant Fricatives in Preadolescents and Adults},
  author = {Zharkova, Natalia},
  year = {2016},
  month = may,
  volume = {139},
  pages = {2342--2351},
  issn = {0001-4966},
  doi = {10.1121/1.4947046},
  file = {/Users/megcychosz/Zotero/storage/TSYEGZ5M/Zharkova - 2016 - Ultrasound and acoustic analysis of sibilant frica.pdf},
  journal = {The Journal of the Acoustical Society of America},
  language = {en},
  number = {5}
}

@article{zharkovaUltrasoundStudyDevelopment2018,
  title = {An {{Ultrasound Study}} of the {{Development}} of {{Lingual Coarticulation}} during {{Childhood}}},
  author = {Zharkova, Natalia},
  year = {2018},
  volume = {75},
  pages = {245--271},
  issn = {0031-8388, 1423-0321},
  doi = {10.1159/000485802},
  abstract = {Background/Aims: There is growing evidence that coarticulation development is protracted and segment-specific, and yet very little information is available on the changes in the extent of coarticulation across different phonemes throughout childhood. This study describes lingual coarticulatory patterns in 6 age groups of Scottish English-speaking children between 3 and 13 years old. Methods: Vowelon-consonant anticipatory coarticulation was analysed using ultrasound imaging data on tongue shape from 4 consonants that differ in the degree of constraint, i.e., the extent of articulatory demand, on the tongue. Results: Consonant-specific age-related patterns are reported, with consonants that have more demands on the tongue reaching adolescent-like levels of coarticulation in older age groups. Within-speaker variability in tongue shape decreases with increasing age. Conclusion: Reduced coarticulation in the youngest age group may be due to insufficient tongue differentiation. Immature patterns for lingual consonants in 5- to 11-year-olds are explained by the goal of producing the consonant target overriding the goal of coarticulating the consonant with the following vowel.},
  file = {/Users/megcychosz/Zotero/storage/HE5KS9HP/Zharkova - 2018 - An Ultrasound Study of the Development of Lingual .pdf},
  journal = {Phonetica},
  language = {en},
  number = {3}
}

@article{zharkovaUltrasoundStudyLingual2008,
  title = {An {{Ultrasound Study}} of {{Lingual Coarticulation}} in {{Children}} and {{Adults}}},
  author = {Zharkova, Natalia and Hewlett, Nigel and Hardcastle, William J},
  year = {2008},
  pages = {4},
  abstract = {There have been a number of studies which compared coarticulatory patterns in children and adults, but these studies have produced conflicting results, particularly with respect to anticipatory lingual coarticulation. This study used articulatory measures derived from ultrasound imaging, in order to establish any differences between child and adult coarticulatory patterns, and to quantify the degree of variability in children's and adults' productions.},
  file = {/Users/megcychosz/Zotero/storage/JKWGG8T8/Zharkova et al. - 2008 - An Ultrasound Study of Lingual Coarticulation in C.pdf},
  language = {en}
}

@article{zieglerReadingAcquisitionDevelopmental2005,
  title = {Reading {{Acquisition}}, {{Developmental Dyslexia}}, and {{Skilled Reading Across Languages}}: {{A Psycholinguistic Grain Size Theory}}.},
  shorttitle = {Reading {{Acquisition}}, {{Developmental Dyslexia}}, and {{Skilled Reading Across Languages}}},
  author = {Ziegler, Johannes C. and Goswami, Usha},
  year = {2005},
  volume = {131},
  pages = {3--29},
  issn = {1939-1455, 0033-2909},
  doi = {10.1037/0033-2909.131.1.3},
  file = {/Users/megcychosz/Zotero/storage/762VQQR8/Ziegler and Goswami - 2005 - Reading Acquisition, Developmental Dyslexia, and S.pdf},
  journal = {Psychological Bulletin},
  language = {en},
  number = {1}
}

@article{zimmanGenderStylisticBricolage2017,
  title = {Gender as Stylistic Bricolage: {{Transmasculine}} Voices and the Relationship between Fundamental Frequency and /s/},
  shorttitle = {Gender as Stylistic Bricolage},
  author = {Zimman, Lal},
  year = {2017},
  month = jun,
  volume = {46},
  pages = {339--370},
  issn = {0047-4045, 1469-8013},
  doi = {10.1017/S0047404517000070},
  abstract = {Abstract             Despite the importance of gender differences in the voice, sociolinguists have not paid sufficient attention to the sociolinguistic processes through which phonetic resources are mobilized in the construction of a gendered voice. This article argues that gender differences in the voice\textemdash including those influenced by physiology\textemdash are best understood as elements of sociolinguistic style rather than static properties. With a focus on transgender speakers in the early stages of masculinizing hormone therapy, the analysis demonstrates the complex interrelationship of the gendered meanings attributable to characteristics like fundamental frequency and /s/. Trans speakers challenge systems for categorizing voices as female or male, which assume that different aspects of the gendered voice will pattern together in normative ways. Yet a voice's gender is not a unidimensional feature, but a cluster of features that take on meaning only in context with one another, leaving them open for recombination and change through stylistic bricolage. (Transgender, style, gender, voice, pitch, sibilants)},
  file = {/Users/megcychosz/Zotero/storage/P9JPXQ7G/Zimman - 2017 - Gender as stylistic bricolage Transmasculine voic.pdf},
  journal = {Language in Society},
  language = {en},
  number = {3}
}

@article{zimmanVariabilityTransgenderSpeakers2017,
  title = {Variability in /s/ among Transgender Speakers: {{Evidence}} for a Socially Grounded Account of Gender and Sibilants},
  shorttitle = {Variability in /s/ among Transgender Speakers},
  author = {Zimman, Lal},
  year = {2017},
  month = jan,
  volume = {55},
  issn = {0024-3949, 1613-396X},
  doi = {10.1515/ling-2017-0018},
  abstract = {Sibilant consonants are well-established as resources for the negotiation of gender and sexuality, but the origin of these links is less clearly agreed upon. Some researchers have pointed to sex differentiation in the vocal anatomy as a potential cause for gender differences in /s/, though a review of the literature indicates that learned articulatory patterns play a critical role. This article focuses on the spectral qualities of /s/ among 15 English-speaking transgender men and transmasculine individuals. Because their early socialization and physiological development is not normatively aligned with their self-defined gender identities, trans people are well-positioned to illuminate the relative contribution of physiology and identity to the gendered voice. Two analyses are presented, one of which focuses on inter-speaker variation among all 15 participants, and the other of which compares one bilingual speaker's productions of /s/ in English and Spanish. Together, these analyses demonstrate that sex category does not determine the gender-linked acoustic characteristics of /s/. Instead, a more complex, multidimensional framework for gender that distinguishes between gender assignment, role, identity, and presentation is necessary to account for the full range of gendered phonetic styles that speakers can employ and hence to understand the process through which gendered voices arise.},
  file = {/Users/megcychosz/Zotero/storage/KHLI2HNK/Zimman - 2017 - Variability in s among transgender speakers Evi.pdf},
  journal = {Linguistics},
  language = {en},
  number = {5}
}

@article{zinglerReductionFusionGrammaticalization2018,
  title = {Reduction without Fusion: {{Grammaticalization}} and Wordhood in {{Turkish}}},
  shorttitle = {Reduction without Fusion},
  author = {Zingler, Tim},
  year = {2018},
  month = oct,
  volume = {52},
  pages = {415--447},
  issn = {0165-4004, 1614-7308},
  doi = {10.1515/flin-2018-0011},
  abstract = {Despite ample evidence that grammaticalization is accompanied by phonological reduction and ultimately morphological fusion, the latter process is remarkably less common in Turkish \textendash{} hence its prototypically agglutinating morphology. Since vowel harmony is a means of articulatory reduction, Turkish, as a vowel-harmonic language, therefore shows reduction but (virtually) no fusion. One morphosyntactic consequence of agglutination is that Turkish ``suffixes'' in many ways continue to behave like free words. To compensate for the resulting lack of clear-cut suffixes, vowel harmony and stress are co-opted to perform affixal functions such as the demarcation of words and encoding of relationships among morphemes. Due to the grammatical function of suffix vowels, however, even grammaticalized items must then remain at least monosyllabic, which constrains the extent of fusion possible. This situation suggests that theories of grammaticalization that do not sufficiently distinguish between reduction and fusion need to be refined. In addition, it highlights the need for language-specific analyses on the diachronic dimension and restores the status of morphological typology as a predictor of certain linguistic variables.},
  file = {/Users/megcychosz/Zotero/storage/YSRBERRR/Zingler - 2018 - Reduction without fusion Grammaticalization and w.pdf},
  journal = {Folia Linguistica},
  language = {en},
  number = {2}
}

@article{zotero-4165,
  type = {Article}
}

@book{zotero-4219,
  type = {Book}
}

@article{zotero-5116,
  type = {Article}
}

@article{zotero-6062,
  type = {Article}
}

@incollection{zotero-6063,
  type = {Incollection}
}

@incollection{zotero-6168,
  type = {Incollection}
}

@article{zotero-6379,
  type = {Article}
}

@article{zotero-7132,
  type = {Article}
}

@article{zotero-7165,
  type = {Article}
}

@article{zotero-7264,
  type = {Article}
}


