---
title: "Rate normalization results"
author: "Meg Cychosz"
date: "5/15/2021"
output: 
  bookdown::pdf_document2:
    latex_engine: xelatex # to render IPA in the PDF
    keep_tex: true
indent: true
mainfont: Doulos SIL # to render IPA in the PDF
---

```{r, settings, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      include=FALSE)
```

```{r, libraries, include=FALSE}
library('tidyverse')
library('ggplot2')
library('kableExtra')
library('lme4')
library('lmerTest')
library('grid')
library('broom.mixed')
library('tikzDevice')
options(tikzLatexPackages = c(getOption("tikzLatexPackages"),
                                  "\\usepackage{tipa}",
                                  "\\usepackage{qtree}"))
```

# Experiment 1

```{r, load data}
shkas <- #read.csv('/Users/megcychosz/Library/CloudStorage/Box-Box/rate_normalization/Participant_Data/shkas/shkas.csv') %>%
  read.csv('shkas.csv') %>%
  filter(trial!='<end data>' & trial!='<start header>' & trial!='RT identification'
         & trial!='shkas.ssf' & trial!='1 30' & trial!='1 1' & trial!='none' & trial!='button' & trial!='1 2 3 4 5 6' & trial!='test'
         & trial!='<end header>' & trial!='<start data>' & stimulus!='NA' & rating!='NA' & participant!='practice') %>% # some cleaning
  filter(participant!='2a') %>% # remove the experimenter practice blocks (7 completed blocks)
  filter(participant!='8') %>% # remove the non-native speaker 
  group_by(participant) %>%
  mutate(block=rep(c(1,2,3,4),each=90)) # add block variable

# remove the n=7 participants with >80% of no ('0') response (288 trials)
final_shkas <- shkas %>%
  count(participant,rating) %>%
  mutate(prop_response=(n/360)*100) %>%
  filter(rating==0 & prop_response < 20) %>%
  select(-rating) %>%
  merge(., shkas, by=c('participant')) %>%
  select(-n, -prop_response) 

# sanity check there should be 21
final_shkas_count <- final_shkas %>%
  count(participant) %>%
  NROW()
```

```{r, get summary stats about participants who completed enough trials}
rmvd <- shkas %>%
  count(participant,rating) %>%
  mutate(prop_response=(n/360)*100) %>%
  filter(rating==0 & prop_response < 20) %>% # remove the participants without enough
  select(participant) %>%
  merge(., shkas, by=c("participant")) %>%
  count(participant,rating) %>%
  mutate(prop_response=(n/360)*100) %>%
  filter(rating!=0) %>%
  group_by(participant) %>%
  summarize(total_response = sum(prop_response)) %>%
  ungroup() %>%
  summarize(avg_response = mean(total_response),
            sd_response = sd(total_response))
```

```{r, create exp 1 rate variables}
# create rate variable
final_shkas2 <- final_shkas %>% 
  mutate(rate = ifelse((stimulus <= 10), "fast", ifelse(stimulus >= 11 & stimulus <= 20, "base", "slow"))) %>%
  arrange(participant,stimulus) %>%
  mutate(sh_ch_cont = rep(1:10,times=63,each=12)) %>% # create sh-CH continuum
  filter(rating!=0) # remove 'no' responses 
```

```{r, prepare exp 1 data for modeling}
model_data <- final_shkas2 %>%
  group_by(participant, stimulus) %>% # each participant heard each stimulus 12x
  summarize(avg_rating = mean(rating)) %>% # so get the mean rating of each stimulus
  merge(., final_shkas2, by=c('participant', 'stimulus')) %>%
  distinct_at(., vars(participant,stimulus), .keep_all = T)

# what % of each stimulus # received a '1-3' rating, indicating more SH-like response
pre_plot_data <- final_shkas2 %>%
  group_by(participant, stimulus) %>%
  count(rating) %>%
  mutate(prop_rating=n/sum(n)) %>%
  select(-n) %>%
  ungroup() %>%
  complete(participant, stimulus, rating, fill = list(prop_rating = 0)) %>%  # fill in '0' if the item didn't receive a particular rating level 
  filter(rating==1:3) %>% # only select % '1-3' responses
  group_by(participant, stimulus) %>%
  summarize(prop_sh=sum(prop_rating))
 
plot_data <- final_shkas2 %>%
  select(rate,sh_ch_cont,stimulus) %>% # grab the rate variables, etc. that were previously removed
  merge(., pre_plot_data, by=c("stimulus")) %>%
  distinct_at(., vars(participant,stimulus), .keep_all = T) %>%
  mutate(participant=as.factor(participant))
```

```{r, exp1-response-function, fig.cap="Spaghetti plot of proportion /ʃ/ response by series step and speaking rate: /k/ duration manipulation. Thick, darker lines represent group averages by speaking rate and lighter lines represent individual participant responses. Ribbons represent 95% confidence intervals.", echo=FALSE, include=TRUE}

sh <- textGrob("[ ʃkɑs ]", gp=gpar(fontsize=14, fontface="bold"))
ch <- textGrob("[ tʃkɑs ]", gp=gpar(fontsize=14, fontface="bold"))


#jpeg("/Users/megcychosz/Library/CloudStorage/Box-Box/rate_normalization/Results/figures/exp1-prop.jpeg", height = 400, width = 600) # print out to maintain IPA symbols in figure 

# spaghetti plot
plot_data %>% 
  mutate(rate=factor(rate,levels = c("fast","base","slow"))) %>%
  ggplot(., aes(x=sh_ch_cont, y=prop_sh)) + 
  geom_line(aes(group=factor(participant)), stat="smooth", method="loess", color='gray70',se=FALSE, alpha=.5, size=.5) +
  xlab("Continuum step") + 
  ylab("Proportion [ ʃ ] response") + 
  theme(axis.text=element_text(size=15),
        plot.margin = unit(c(1,1,2,1), "lines"),
        axis.title=element_text(size=20,face="bold"),
        #legend.title = element_text(size=15, face="bold"),
        #legend.background = element_rect(fill="white", 
        #size=0.5, linetype="solid"),
        legend.position = "none") +
        #legend.text = element_blank()) + 
 # guides(fill = guide_legend(override.aes = list(alpha = .55))) +
  scale_x_continuous(breaks=seq(1,10,by=1)) +
  annotation_custom(sh,xmin=1,xmax=1,ymin=-0.25,ymax=-0.25) + 
  annotation_custom(ch,xmin=10,xmax=10,ymin=-0.25,ymax=-0.25) + 

  geom_smooth(aes(fill=rate, color=rate, lty=rate)) + # now add the grouping by rate

  coord_cartesian(clip="off") + # turn off plot clipping  

  labs(color="Speaking Rate",fill="Speaking Rate",lty="Speaking Rate")

#dev.off()

```

```{r, exp1-eshness-rating, fig.cap="Spaghetti plot of /ʃ/-ness ratings (1=good /ʃ/, 6=good /tʃ/) by series step and speaking rate: /k/ duration manipulation. Thick, darker lines represent group averages by speaking rate and lighter lines represent individual participant responses. Ribbons represent 95% confidence intervals.", echo=FALSE, include=TRUE}
#jpeg("/Users/megcychosz/Library/CloudStorage/Box-Box/rate_normalization/Results/figures/exp1-eshness-rating.jpeg", height = 400, width = 600)

sh_y <- textGrob("/tʃ/", gp=gpar(fontsize=14, fontface="bold"))
ch_y <- textGrob("/ʃ/", gp=gpar(fontsize=14, fontface="bold"))

final_shkas2 %>% 
  mutate(rate=factor(rate,levels = c("fast","base","slow")),
         sh_ch_cont = as.numeric(sh_ch_cont)) %>%
  ggplot(., aes(x=sh_ch_cont, y=rating),color=rate) + 
  geom_line(aes(group=factor(participant)), stat="smooth", method="loess", color='gray70',se=FALSE, alpha=.5, size=.5) +
  xlab("Continuum step") + 
  ylab("[ ʃ ]-ness rating") + 
  theme(axis.text=element_text(size=17),
      axis.title=element_text(size=22,face="bold"),
      legend.title = element_text(size=17, face="bold"), 
      legend.text = element_text(size=17),
      legend.position = c(.85,.75),
      legend.background = element_rect(fill="white", 
                                  size=0.5, linetype="solid")) +
  guides(colour = guide_legend(override.aes = list(alpha = .55))) +
  scale_x_continuous(breaks=seq(1,10,by=1)) +
  scale_y_continuous(breaks=seq(1,6,by=1)) +
  
  scale_y_reverse() +

  annotation_custom(sh,xmin=1,xmax=1,ymin=-6.9,ymax=-6.9) + 
  annotation_custom(ch,xmin=10,xmax=10,ymin=-6.9,ymax=-6.9) +  
  annotation_custom(sh_y,xmin=0.2,xmax=0.2,ymin=-6.3,ymax=-6.3) + 
  annotation_custom(ch_y,xmin=0.2,xmax=0.2,ymin=-.85,ymax=-.85) + 


  geom_smooth(aes(fill=rate, color=rate, lty=rate)) + # now add the grouping by rate

  coord_cartesian(clip="off") + # turn off plot clipping  

  labs(color="Speaking Rate",fill="Speaking Rate",lty="Speaking Rate")

#dev.off()

```

```{r, prepare to fit models predicting proportion SH}
center_scale <- function(x) {
    scale(x, scale = FALSE)
}

prop_model_data <- final_shkas2 %>%
  mutate(sh_ch_cont_centered = center_scale(sh_ch_cont),  # center continuous variable for modeling
         outcome = as.integer(if_else(rating <=3, "1", "0"))) # create binary outcome
```

```{r, fit exp1 models to predict proportion SH, cache=TRUE}
# ideal baseline
base1 <- glmer(outcome ~ (1|participant) + (1+rate|participant) + (1+sh_ch_cont_centered|participant) + (1+rate|sh_ch_cont_centered),
               data=prop_model_data, 
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base2 <- glmer(outcome ~ (1|participant) + (1+rate|participant) + (1+sh_ch_cont_centered|participant) + (0+rate|sh_ch_cont_centered),
               data=prop_model_data, 
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base3 <- glmer(outcome ~ (1|participant) + (1+rate|participant) + (0+sh_ch_cont_centered|participant) + (0+rate|sh_ch_cont_centered),
               data=prop_model_data, 
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base4 <- glmer(outcome ~ (1|participant) + (0+rate|participant) + (0+sh_ch_cont_centered|participant) + (0+rate|sh_ch_cont_centered),
               data=prop_model_data, 
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base5 <- glmer(outcome ~ (1|participant) + (0+rate|participant) + (0+rate|sh_ch_cont_centered),
               data=prop_model_data, 
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base6 <- glmer(outcome ~ (1|participant) + (0+rate|sh_ch_cont_centered),
               data=prop_model_data, 
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base7 <- glmer(outcome ~ (1|participant),
               data=prop_model_data, 
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa")) 



# ---------------- add fixed effects 
prop_m1 <- glmer(outcome ~ rate + (1|participant), 
                 data=prop_model_data, 
                 family = binomial, 
                 control = glmerControl(optimizer = "bobyqa"))
anova(base5,prop_m1) # significant effect of rate on odds of 'sh' responses 

prop_m2 <- glmer(outcome ~ rate + sh_ch_cont_centered + (1|participant), 
                 data=prop_model_data,
                 family = binomial, 
                 control = glmerControl(optimizer = "bobyqa"))
anova(prop_m2,prop_m1) # sig effect of continuum step, which is not surprising since the acoustic cues varied by step

prop_m3 <- glmer(outcome ~ rate*sh_ch_cont_centered + (1|participant), 
                 data=prop_model_data,
                 family = binomial, 
                 control = glmerControl(optimizer = "bobyqa"))
anova(prop_m2,prop_m3) # no effect of interaction term
```

```{r, exp1-sh-prop-model-summary, echo=FALSE, include=TRUE}
# ---------------- FINAL MODEL

exp1_m_tbl_sum <- summary(prop_m2) # for writeup


# create model summary
exp1_m_tbl <- rbind(tidy(prop_m2,
                         effects = c("fixed"),
                         conf.int = TRUE)) %>%
  select(-effect) %>%
  mutate(term=recode(term,"(Intercept)"="Intercept",
                     "ratefast"="Rate:Fast",
                     "rateslow"="Rate:Slow",
                     "sh_ch_cont_centered"="Continuum Step")) %>%
  mutate_if(is.numeric, round, digits=2) %>%
  rename(Parameter=term,
         Estimate=estimate,
         S.E. = std.error,
         `z-statistic`=statistic,
         `p-value`=p.value) %>%
  mutate(`95% CI`=paste(conf.low,"–",conf.high)) %>%
  select(-conf.low,-conf.high)

knitr::kable(exp1_m_tbl,
             caption = 'Model predicting /ʃ/ responses: Experiment 1',
             booktabs=T) %>%
  kable_styling() %>%
  landscape()
```

To test for an effect of phoneme duration on rate normalization, we modeled two different outcome variables: proportion of /ʃ/ responses and /ʃ/-ness ratings. For the proportion of /ʃ/ responses, an average /ʃ/ response was calculated for each participant, for each stimulus item (Figure \@ref(fig:exp1-response-function)) while /ʃ/-ness ratings were simply computed for each individual stimulus item presented (item-level effect) (Figure \@ref(fig:exp1-eshness-rating)). We elected to model two outcomes because traditional work on rate normalization modeled proportion phoneme responses grouped over stimuli repetitions (e.g. Diehl & Walsh, 1989), while newer work has been able to model item-level effects (e.g. Maslowski et al., 2018) and we wished to make our work comparable to both of these domains. 

Figures \@ref(fig:exp1-response-function) and \@ref(fig:exp1-eshness-rating) suggest the presence of a rate normalization effect from phoneme duration manipulations. The confidence intervals surrounding the speaking rate conditions (Slow, Base, Fast) do not overlap in the middle, ambiguous section of the continuum. More specifically, we see the effect in the expected direction: slower speaking rates bias more /tʃ/ responses, and higher /tʃ/ ratings, while faster rates bias /ʃ/ responses and higher /ʃ/ ratings. 

To further examine a potential rate normalization effect, we fit models to our two outcome variables.  To predict the proportion of /ʃ/ responses, we fit a linear mixed effects model with the maximal random effect structure that permitted model convergence. This model included random slopes of Speaking Rate by Participant; slope terms for interactions of Speaking Rate and Continuum Step did not converge, nor did models with random intercepts of Participant together with slopes of Speaking Rate by Participant. The effect of Speaking Rate (modeled categorically as "Slow," "Base," and "Fast") improved upon the random effects only model as did Continuum Step (modeled as a continuous variable) (Table \@ref(tab:exp1-sh-prop-model-summary)). Unsurprisingly, the proportion of /ʃ/ responses decreased with increased steps along the continuum ($\beta$=`r round(exp1_m_tbl_sum$coefficients[4,1],2)`, z=`r round(exp1_m_tbl_sum$coefficients[4,4],2)`, p<.001). For Speaking Rate, there was a higher proportion of /ʃ/ responses in the Fast condition than the Base condition ($\beta$=`r round(exp1_m_tbl_sum$coefficients[2,1],2)`, z=`r round(exp1_m_tbl_sum$coefficients[2,3],2)`, p=`r round(exp1_m_tbl_sum$coefficients[2,4],3)`) and a lower proportion of /ʃ/ responses in the Slow condition than Base ($\beta$=`r round(exp1_m_tbl_sum$coefficients[3,1],2)`, z=`r round(exp1_m_tbl_sum$coefficients[3,3],2)`, p=`r round(exp1_m_tbl_sum$coefficients[3,4],3)`), suggesting a rate normalization effect. 

Overall, these results demonstrate that manipulating /k/ duration, while holding the syllable duration constant, significantly affected the proportion of /ʃ/ responses and /ʃ/-ness ratings, especially in the Slow speaking rate condition, suggesting that listeners can normalize for speaking rate over individual phonemes. 

# Experiment 2

```{r, load exp2 data}
SHwihb <- read.csv('shwib.csv') %>%
  filter(trial!='<end data>' & trial!='<start header>' & trial!='RT identification'
         & trial!='stwaes.ssf' & trial!='1 30' & trial!='1 1' & trial!='none' & trial!='button' & trial!='1 2 3 4 5 6' & trial!='test'
         & trial!='<end header>' & trial!='<start data>' & stimulus!='NA' & rating!='NA' & participant!='practice') %>% # some cleaning
  #filter(participant!='6') %>%
  group_by(participant) %>%
  mutate(block=rep(c(1,2,3,4),each=90)) %>%  # add block variable
  filter(participant !='12lf' & participant!='13LF' & participant!='3sj') # # remove 3 participants who did not complete at least 20% of trials


# sanity check there should be 19 participants
final_SHwihb_count <- SHwihb %>%
  count(participant) %>%
  NROW()
```

```{r, summary stats about participants who completed sufficient trials in exp 2}
rmvd_exp2 <- SHwihb %>%
  count(participant,rating) %>%
  mutate(prop_response=(n/360)*100) %>%
  filter(rating==0 & prop_response < 20) %>% # remove the participants without enough
  select(participant) %>%
  merge(., SHwihb, by=c("participant")) %>%
  count(participant,rating) %>%
  mutate(prop_response=(n/360)*100) %>%
  filter(rating!=0) %>%
  group_by(participant) %>%
  summarize(total_response = sum(prop_response)) %>%
  ungroup() %>%
  summarize(avg_response = mean(total_response),
            sd_response = sd(total_response))
 
```

```{r, create exp2 rate variables}
# create rate variable
final_SHwihb <- SHwihb %>% 
  mutate(rate = ifelse((stimulus <= 10), "fast", ifelse(stimulus >= 11 & stimulus <= 20, "base", "slow"))) %>%
  ungroup() %>%
  arrange(participant,stimulus) %>%
  mutate(sh_ch_cont = rep(1:10,times=57,each=12)) %>% # create sh-ch continuum
  filter(rating!=0)  # remove 'no' responses 
```

```{r, prepare exp2 for modeling}
# what % of each stimulus # received a '1-3' rating, indicating /s/ response
pre_SHwihb_plot_data <- final_SHwihb %>%
  group_by(participant, stimulus) %>%
  count(rating) %>%
  mutate(prop_rating=n/sum(n)) %>%
  select(-n) %>%
  ungroup() %>%
  complete(participant, stimulus, rating, fill = list(prop_rating = 0)) %>%  # fill in '0' if the item didn't receive a particular rating level 
  filter(rating==1:3) %>% # only select % '1-3' rating responses
  group_by(participant, stimulus) %>%
  summarize(prop_sh=sum(prop_rating))

plot_SHwihb_data <- final_SHwihb %>%
  select(rate,sh_ch_cont,stimulus) %>% # grab the rate variables, etc. that were previously removed
  merge(., pre_SHwihb_plot_data, by=c("stimulus")) %>%
  distinct_at(., vars(participant,stimulus), .keep_all = T) %>%
  mutate(participant=as.factor(participant))
```

```{r, exp2-response-function, fig.cap="Spaghetti plot of proportion /ʃ/ response by series step and speaking rate: /w/ duration manipulation. Thick, darker lines represent group averages by speaking rate and lighter lines represent individual participant responses. Ribbons represent 95% confidence intervals.", echo=FALSE, include=TRUE}
shw <- textGrob("[ ʃwɪb ]", gp=gpar(fontsize=14, fontface="bold"))
chw <- textGrob("[ tʃwɪb ]", gp=gpar(fontsize=14, fontface="bold"))

#jpeg("/Users/megcychosz/Library/CloudStorage/Box-Box/rate_normalization/Results/figures/exp2-prop.jpeg", height = 400, width = 600)

plot_SHwihb_data %>% 
  mutate(rate=factor(rate,levels = c("fast","base","slow"))) %>%
  ggplot(., aes(x=sh_ch_cont, y=prop_sh)) +
  geom_line(aes(group=factor(participant)), stat="smooth", method="loess", color="gray70",se=FALSE, alpha=.5, size=.5) + 
  xlab("Continuum step") + 
  ylab("Proportion [ ʃ ] response") + 
  theme(axis.text=element_text(size=15),
        plot.margin = unit(c(1,1,2,1), "lines"),
        axis.title=element_text(size=20,face="bold"),
        #legend.title = element_text(size=15, face="bold"),
        #legend.background = element_rect(fill="white", 
        #                                 size=0.5, linetype="solid"),
        legend.position = "none") +
        #legend.text = element_blank()) + 
  #guides(fill = guide_legend(override.aes = list(alpha = .55))) +
  scale_x_continuous(breaks=seq(1,10,by=1)) +
  annotation_custom(shw,xmin=1,xmax=1,ymin=-0.25,ymax=-0.25) + 
  annotation_custom(chw,xmin=10,xmax=10,ymin=-0.25,ymax=-0.25) + 

  geom_smooth(aes(fill=rate, color=rate, lty=rate)) +
  
  coord_cartesian(clip="off") + # turn off plot clipping  
  
  labs(color="Speaking Rate",fill="Speaking Rate",lty="Speaking Rate")

#dev.off()

```

```{r, exp2-eshness-rating, fig.cap="Spaghetti plot of /ʃ/-ness ratings (1=good /ʃ/, 6=good /tʃ/) by series step and speaking rate: /w/ duration manipulation. Thick, darker lines represent group averages by speaking rate and lighter lines represent individual participant responses. Ribbons represent 95% confidence intervals.", echo=FALSE, include=TRUE}

#jpeg("/Users/megcychosz/Library/CloudStorage/Box-Box/rate_normalization/Results/figures/exp2-eshness-rating.jpeg", height = 400, width = 600)


    
final_SHwihb %>% 
  mutate(rate=factor(rate,levels = c("fast","base","slow")),
                     sh_ch_cont = as.numeric(sh_ch_cont)) %>%
  ggplot(., aes(x=sh_ch_cont, y=rating),color=rate) + 
  geom_line(aes(group=factor(participant)), stat="smooth", method="loess", color='gray70',se=FALSE, alpha=.5, size=.5) +
  xlab("Continuum step") + 
  ylab("[ ʃ ]-ness rating") + 
    theme(axis.text=element_text(size=17),
        axis.title=element_text(size=22,face="bold"),
        legend.title = element_text(size=17, face="bold"), 
        legend.text = element_text(size=17),
        legend.position = c(.85,.75),
        legend.background = element_rect(fill="white", 
                                         size=0.5, linetype="solid")) +
  guides(colour = guide_legend(override.aes = list(alpha = .55))) +
  scale_x_continuous(breaks=seq(1,10,by=1)) +
  scale_y_continuous(breaks=seq(1,6,by=1)) +
  
   scale_y_reverse() +

  annotation_custom(shw,xmin=1,xmax=1,ymin=-6.6,ymax=-6.6) + 
  annotation_custom(chw,xmin=10,xmax=10,ymin=-6.6,ymax=-6.6) +  
  annotation_custom(sh_y,xmin=0.2,xmax=0.2,ymin=-6.3,ymax=-6.3) + 
  annotation_custom(ch_y,xmin=0.2,xmax=0.2,ymin=-.85,ymax=-.85) + 
  
  geom_smooth(aes(fill=rate, color=rate, lty=rate)) + # now add the grouping by rate
  
  coord_cartesian(clip="off") + # turn off plot clipping  
  
  labs(color="Speaking Rate",fill="Speaking Rate",lty="Speaking Rate")

#dev.off()

```

```{r, prepare to fit models predicting proportion SH response exp2}
prop_model_data2 <- final_SHwihb %>%
  mutate(sh_ch_cont_centered=center_scale(sh_ch_cont),
         outcome = as.integer(if_else(rating <=3, "1", "0")))
```

```{r, fit exp2 models to predict SH proportion, cache=TRUE}
# ideal baseline
base1 <- glmer(outcome ~ (1|participant) + (1+rate|participant) + (1+sh_ch_cont_centered|participant) + (1+rate|sh_ch_cont_centered), 
               data = prop_model_data2,
               family = binomial,
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base2 <- glmer(outcome ~ (1|participant) + (1+rate|participant) + (1+sh_ch_cont_centered|participant) + (0+rate|sh_ch_cont_centered), 
               data = prop_model_data2,
               family = binomial,
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base3 <- glmer(outcome ~ (1|participant) + (1+rate|participant) + (0+sh_ch_cont_centered|participant) + (0+rate|sh_ch_cont_centered), 
               data = prop_model_data2,
               family = binomial,
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base4 <- glmer(outcome ~ (1|participant) + (0+rate|participant) + (0+sh_ch_cont_centered|participant) + (0+rate|sh_ch_cont_centered), 
               data = prop_model_data2,
               family = binomial,
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base5 <- glmer(outcome ~ (1|participant) + (0+rate|participant) + (0+sh_ch_cont_centered|participant) + (0+rate|sh_ch_cont_centered), 
               data = prop_model_data2,
               family = binomial,
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base6 <- glmer(outcome ~ (1|participant) + (0+rate|participant) + (0+sh_ch_cont_centered|participant),
               data = prop_model_data2,
               family = binomial,
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base7 <- glmer(outcome ~ (1|participant) + (0+rate|participant),
               data = prop_model_data2,
               family = binomial,
               control = glmerControl(optimizer = "bobyqa")) # doesn't converge

base7 <- glmer(outcome ~ (1|participant),
               data = prop_model_data2,
               family = binomial,
               control = glmerControl(optimizer = "bobyqa")) 


# ---------------- add fixed effects 
prop_m4 <- glmer(outcome ~ rate + (1|participant), 
                 data=prop_model_data2,
                 family = binomial,
                 control = glmerControl(optimizer = "bobyqa"))
anova(base5,prop_m4) # rate improves

prop_m5 <- glmer(outcome ~ rate + sh_ch_cont_centered + (1|participant), 
                 data=prop_model_data2,
                 family = binomial,
                control = glmerControl(optimizer = "bobyqa"))
anova(prop_m4,prop_m5) # step improves

prop_m6 <- glmer(outcome ~ rate*sh_ch_cont + (1|participant), 
                 data=prop_model_data2,
                 family = binomial,
                control = glmerControl(optimizer = "bobyqa"))
anova(prop_m5, prop_m6) # interaction does not improve
```

```{r, exp2-sh-prop-model-summary, echo=FALSE, include=TRUE}
# --------------- FINAL MODEL

exp2_prop_sum <- summary(prop_m5)


# create model summary
exp2_m_tbl <- rbind(tidy(prop_m5, 
                         effects = c("fixed"), 
                         conf.int = TRUE)) %>%
  select(-effect) %>%
  mutate(term=recode(term,"(Intercept)"="Intercept",
                     "ratefast"="Rate:Fast",
                     "rateslow"="Rate:Slow",
                     "sh_ch_cont_centered"="Continuum Step")) %>%
  mutate_if(is.numeric, round, digits=2) %>%
  rename(Parameter=term,
         Estimate=estimate,
         S.E. = std.error,
         `z-statistic`=statistic,
         `p-value`=p.value) %>%
  mutate(`95% CI`=paste(conf.low,"-",conf.high)) %>%
  select(-conf.low,-conf.high)

knitr::kable(exp2_m_tbl, 
             caption = 'Model predicting /ʃ/ response: Experiment 2', 
             booktabs=T) %>%
  kable_styling() %>% 
  landscape()
```

As in Experiment 1, to evaluate a potential rate normalization effect we modeled two different outcome variables: proportion of /ʃ/ responses and /ʃ/-ness ratings. Again, an average /ʃ/ response was calculated for each participant (Figure \@ref(fig:exp2-response-function)) and /ʃ/-ness ratings were computed for each individual stimulus (Figure \@ref(fig:exp2-eshness-rating)). The visualizations suggest an effect of speaking rate (/w/ duration) upon /ʃ/ responses and /ʃ/ ratings in the same direction as Experiment 1: slower speaking rates bias more /tʃ/ responses. 

As before, we fit a series of models to the ambiguous items in the middle of the stimuli series, at the categorical perception boundary (steps 4 through 7). To predict the proportion of /ʃ/ responses, we fit a linear mixed effects model that included random slopes of Speaking Rate by Participant. Like Experiment 1, there were significant main effects of Speaking Rate and Continuum Step: there was a higher proportion of /ʃ/ responses as the continuum step increased (more /tʃ/-like stimuli) ($\beta$=`r round(exp2_prop_sum$coefficients[4,1],2)`, z=`r round(exp2_prop_sum$coefficients[4,3],2)`, p<.001). There was a significantly smaller proportion of /ʃ/ responses in the Slow speaking rate condition than Base condition ($\beta$=`r round(exp2_prop_sum$coefficients[3,1],2)`, z=`r round(exp2_prop_sum$coefficients[3,3],2)`, p=`r round(exp2_prop_sum$coefficients[3,4],2)`), but no difference in the proportion of /ʃ/ responses between the Fast speaking rate condition and the Base condition (Table \@ref(tab:exp2-sh-prop-model-summary)). 


